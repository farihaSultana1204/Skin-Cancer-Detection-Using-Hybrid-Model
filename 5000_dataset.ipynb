{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5UUigs334DGK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d8d26a9-a1fa-47fd-fa36-9e0ef8baaeee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "mX_icLuc4K9X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = '/content/drive/MyDrive/Skin-Cancer(2)'"
      ],
      "metadata": {
        "id": "0hsB3pha4M5J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "data_dir = \"/content/drive/MyDrive/Skin-Cancer(2)\"\n",
        "image_size = (100, 100)\n",
        "\n",
        "images = []\n",
        "labels = []\n",
        "\n",
        "label_mapping = {'benign': 0, 'malignant': 1}\n",
        "\n",
        "for class_name in os.listdir(data_dir):\n",
        "    class_dir = os.path.join(data_dir, class_name)\n",
        "    if os.path.isdir(class_dir):\n",
        "        for image_filename in os.listdir(class_dir):\n",
        "            image_path = os.path.join(class_dir, image_filename)\n",
        "            # Open and resize the image\n",
        "            image = Image.open(image_path)\n",
        "            image = image.resize(image_size)\n",
        "            image = np.array(image)\n",
        "            images.append(image)\n",
        "            labels.append(label_mapping[class_name])\n",
        "\n",
        "# Convert lists to numpy arrays\n",
        "images = np.array(images)\n",
        "labels = np.array(labels)\n"
      ],
      "metadata": {
        "id": "nrB2djVH4OwT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.125, random_state=42)"
      ],
      "metadata": {
        "id": "x_F_im3z4RPg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Shape of X_train: \", X_train.shape)\n",
        "print(\"Shape of y_train: \", y_train.shape)\n",
        "print(\"Shape of X_test: \", X_test.shape)\n",
        "print(\"Shape of y_test: \", y_test.shape)\n",
        "print(\"Shape of X_val: \", X_val.shape)\n",
        "print(\"Shape of y_val: \", y_val.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y8EH2zMk4Sv_",
        "outputId": "2dba7c1a-f95c-49f3-9504-168f0e5f9c38"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of X_train:  (3444, 100, 100, 3)\n",
            "Shape of y_train:  (3444,)\n",
            "Shape of X_test:  (984, 100, 100, 3)\n",
            "Shape of y_test:  (984,)\n",
            "Shape of X_val:  (492, 100, 100, 3)\n",
            "Shape of y_val:  (492,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(_, IMAGE_WIDTH, IMAGE_HEIGHT, IMAGE_CHANNELS) = X_train.shape\n",
        "\n",
        "print('IMAGE_WIDTH:', IMAGE_WIDTH);\n",
        "print('IMAGE_HEIGHT:', IMAGE_HEIGHT);\n",
        "print('IMAGE_CHANNELS:', IMAGE_CHANNELS);"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pJ4EwfuT4UVN",
        "outputId": "09e319eb-eb74-4efe-8616-a27e0a837c47"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IMAGE_WIDTH: 100\n",
            "IMAGE_HEIGHT: 100\n",
            "IMAGE_CHANNELS: 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#4. Reshape the data\n",
        "x_train_with_chanels = X_train.reshape(\n",
        "    X_train.shape[0],\n",
        "    IMAGE_WIDTH,\n",
        "    IMAGE_HEIGHT,\n",
        "    IMAGE_CHANNELS\n",
        ")\n",
        "\n",
        "x_test_with_chanels = X_test.reshape(\n",
        "    X_test.shape[0],\n",
        "    IMAGE_WIDTH,\n",
        "    IMAGE_HEIGHT,\n",
        "    IMAGE_CHANNELS\n",
        ")\n",
        "\n",
        "x_val_with_chanels = X_val.reshape(\n",
        "    X_val.shape[0],\n",
        "    IMAGE_WIDTH,\n",
        "    IMAGE_HEIGHT,\n",
        "    IMAGE_CHANNELS\n",
        ")"
      ],
      "metadata": {
        "id": "wUMgmOOY4WA_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('x_train_with_chanels:', x_train_with_chanels.shape)\n",
        "print('x_test_with_chanels:', x_test_with_chanels.shape)\n",
        "print('x_val_with_chanels:', x_val_with_chanels.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SdbF3WKN4Ws9",
        "outputId": "4f1b80db-e2bc-471e-bc00-f5628f2aae21"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_train_with_chanels: (3444, 100, 100, 3)\n",
            "x_test_with_chanels: (984, 100, 100, 3)\n",
            "x_val_with_chanels: (492, 100, 100, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#5. Normalize the data\n",
        "x_train_normalized = x_train_with_chanels / 255\n",
        "x_test_normalized = x_test_with_chanels / 255\n",
        "x_val_normalized = x_val_with_chanels / 255"
      ],
      "metadata": {
        "id": "5xgrn6bM4X10"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_normalized[0][18]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E2m15bpj4cSN",
        "outputId": "9f12c2f5-bd0c-49d6-8967-67b8248fd98d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        ],\n",
              "       [0.00392157, 0.00392157, 0.00392157],\n",
              "       [0.00784314, 0.00784314, 0.00784314],\n",
              "       [0.01176471, 0.01176471, 0.01176471],\n",
              "       [0.01568627, 0.01568627, 0.01568627],\n",
              "       [0.01960784, 0.01960784, 0.01960784],\n",
              "       [0.01960784, 0.01960784, 0.01960784],\n",
              "       [0.01960784, 0.01960784, 0.01960784],\n",
              "       [0.01960784, 0.01960784, 0.01960784],\n",
              "       [0.01960784, 0.01960784, 0.01960784],\n",
              "       [0.01960784, 0.01960784, 0.01960784],\n",
              "       [0.01568627, 0.01960784, 0.01568627],\n",
              "       [0.01176471, 0.01960784, 0.01568627],\n",
              "       [0.00784314, 0.01568627, 0.01568627],\n",
              "       [0.01176471, 0.01960784, 0.01568627],\n",
              "       [0.01176471, 0.01960784, 0.01568627],\n",
              "       [0.01960784, 0.01960784, 0.01960784],\n",
              "       [0.04313725, 0.02352941, 0.02745098],\n",
              "       [0.05098039, 0.03137255, 0.03921569],\n",
              "       [0.0627451 , 0.04705882, 0.05098039],\n",
              "       [0.0745098 , 0.05882353, 0.0627451 ],\n",
              "       [0.08627451, 0.07058824, 0.07058824],\n",
              "       [0.09803922, 0.08235294, 0.0627451 ],\n",
              "       [0.10196078, 0.08627451, 0.06666667],\n",
              "       [0.10196078, 0.08235294, 0.06666667],\n",
              "       [0.09411765, 0.0745098 , 0.05882353],\n",
              "       [0.07843137, 0.0627451 , 0.04313725],\n",
              "       [0.0627451 , 0.04705882, 0.03921569],\n",
              "       [0.05098039, 0.03529412, 0.03529412],\n",
              "       [0.04313725, 0.02745098, 0.02352941],\n",
              "       [0.03137255, 0.01568627, 0.01176471],\n",
              "       [0.02745098, 0.01176471, 0.00784314],\n",
              "       [0.02745098, 0.01176471, 0.01176471],\n",
              "       [0.03137255, 0.01176471, 0.01176471],\n",
              "       [0.02745098, 0.01568627, 0.01176471],\n",
              "       [0.02745098, 0.02352941, 0.01960784],\n",
              "       [0.02745098, 0.02745098, 0.02352941],\n",
              "       [0.02745098, 0.03137255, 0.02352941],\n",
              "       [0.03137255, 0.03137255, 0.03137255],\n",
              "       [0.03137255, 0.03137255, 0.03137255],\n",
              "       [0.03137255, 0.03137255, 0.03137255],\n",
              "       [0.02745098, 0.02745098, 0.02745098],\n",
              "       [0.02352941, 0.02352941, 0.02352941],\n",
              "       [0.01176471, 0.01176471, 0.01176471],\n",
              "       [0.00784314, 0.00784314, 0.00784314],\n",
              "       [0.00392157, 0.00392157, 0.00392157],\n",
              "       [0.00392157, 0.00392157, 0.00392157],\n",
              "       [0.00392157, 0.00392157, 0.00392157],\n",
              "       [0.00392157, 0.00392157, 0.00392157],\n",
              "       [0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        ]])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "y_train_encoded = to_categorical(y_train, num_classes=2)\n",
        "y_test_encoded = to_categorical(y_test, num_classes=2)\n",
        "y_val_encoded = to_categorical(y_val, num_classes=2)"
      ],
      "metadata": {
        "id": "Fi9w46LH4er5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 64\n",
        "\n",
        "# Data augmentation for the training set\n",
        "train_DataGen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "\n",
        "    rotation_range=40,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "# Data generator for the validation set (no augmentation)\n",
        "valid_datagen = tf.keras.preprocessing.image.ImageDataGenerator()\n",
        "\n",
        "# Data generator for the test set (no augmentation)\n",
        "test_datagen = tf.keras.preprocessing.image.ImageDataGenerator()\n",
        "\n",
        "# Create data generators\n",
        "train_set_conv = train_DataGen.flow(x_train_normalized, y_train_encoded, batch_size=batch_size)\n",
        "valid_set_conv = valid_datagen.flow(x_val_normalized, y_val_encoded, batch_size=batch_size)\n",
        "test_set_conv = test_datagen.flow(x_test_normalized, y_test_encoded, batch_size=batch_size)"
      ],
      "metadata": {
        "id": "RRXCEgUB4jAI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, ZeroPadding2D,\\\n",
        "     Flatten, BatchNormalization, AveragePooling2D, Dense, Activation, Add\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras import activations\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.regularizers import l2"
      ],
      "metadata": {
        "id": "lrOkMyFw4gEY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "# Define the CNN model\n",
        "model = models.Sequential()\n",
        "\n",
        "# Convolutional Layer 1\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(IMAGE_WIDTH, IMAGE_HEIGHT, IMAGE_CHANNELS)))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "# Convolutional Layer 2\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "# Convolutional Layer 3\n",
        "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "# Flatten the output for the fully connected layers\n",
        "model.add(layers.Flatten())\n",
        "\n",
        "# Fully Connected Layer 1\n",
        "model.add(layers.Dense(128, activation='relu'))\n",
        "\n",
        "# Output Layer\n",
        "model.add(layers.Dense(10, activation='softmax'))  # Assuming 10 classes\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Print the model summary\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "ahb8RfAA4xbD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "98e7ec1a-5229-4399-f94f-7a62b77e80fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 98, 98, 32)        896       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 49, 49, 32)        0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 47, 47, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 23, 23, 64)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 21, 21, 128)       73856     \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPoolin  (None, 10, 10, 128)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 12800)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               1638528   \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1733066 (6.61 MB)\n",
            "Trainable params: 1733066 (6.61 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the model to the data\n",
        "history = model.fit(train_set_conv,\n",
        "                    steps_per_epoch=len(x_train_normalized) // batch_size,\n",
        "                    epochs=10,  # You can adjust the number of epochs\n",
        "                    validation_data=valid_set_conv,\n",
        "                    validation_steps=len(x_val_normalized) // batch_size)\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "test_loss, test_accuracy = model.evaluate(test_set_conv)\n",
        "print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "zpJxG0Tu41v6",
        "outputId": "35ea1734-914a-45f3-951e-566449d74a24"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "InvalidArgumentError",
          "evalue": "Graph execution error:\n\nDetected at node categorical_crossentropy/softmax_cross_entropy_with_logits defined at (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n\n  File \"/usr/local/lib/python3.10/dist-packages/colab_kernel_launcher.py\", line 37, in <module>\n\n  File \"/usr/local/lib/python3.10/dist-packages/traitlets/config/application.py\", line 992, in launch_instance\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelapp.py\", line 619, in start\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/platform/asyncio.py\", line 195, in start\n\n  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n\n  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n\n  File \"/usr/lib/python3.10/asyncio/events.py\", line 80, in _run\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 685, in <lambda>\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 738, in _run_callback\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 825, in inner\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 786, in run\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 361, in process_one\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 261, in dispatch_shell\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 539, in execute_request\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py\", line 302, in do_execute\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/zmqshell.py\", line 539, in run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2975, in run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3257, in run_cell_async\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n\n  File \"<ipython-input-16-bc322981c8b6>\", line 2, in <cell line: 2>\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1807, in fit\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1401, in train_function\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1384, in step_function\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1373, in run_step\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1151, in train_step\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1209, in compute_loss\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/compile_utils.py\", line 277, in __call__\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/losses.py\", line 143, in __call__\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/losses.py\", line 270, in call\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/losses.py\", line 2221, in categorical_crossentropy\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/backend.py\", line 5579, in categorical_crossentropy\n\nlogits and labels must be broadcastable: logits_size=[64,10] labels_size=[64,2]\n\t [[{{node categorical_crossentropy/softmax_cross_entropy_with_logits}}]] [Op:__inference_train_function_1341]",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-bc322981c8b6>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Fit the model to the data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m history = model.fit(train_set_conv,\n\u001b[0m\u001b[1;32m      3\u001b[0m                     \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train_normalized\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# You can adjust the number of epochs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalid_set_conv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node categorical_crossentropy/softmax_cross_entropy_with_logits defined at (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n\n  File \"/usr/local/lib/python3.10/dist-packages/colab_kernel_launcher.py\", line 37, in <module>\n\n  File \"/usr/local/lib/python3.10/dist-packages/traitlets/config/application.py\", line 992, in launch_instance\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelapp.py\", line 619, in start\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/platform/asyncio.py\", line 195, in start\n\n  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n\n  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n\n  File \"/usr/lib/python3.10/asyncio/events.py\", line 80, in _run\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 685, in <lambda>\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 738, in _run_callback\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 825, in inner\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 786, in run\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 361, in process_one\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 261, in dispatch_shell\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 539, in execute_request\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py\", line 302, in do_execute\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/zmqshell.py\", line 539, in run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2975, in run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3257, in run_cell_async\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n\n  File \"<ipython-input-16-bc322981c8b6>\", line 2, in <cell line: 2>\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1807, in fit\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1401, in train_function\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1384, in step_function\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1373, in run_step\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1151, in train_step\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1209, in compute_loss\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/compile_utils.py\", line 277, in __call__\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/losses.py\", line 143, in __call__\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/losses.py\", line 270, in call\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/losses.py\", line 2221, in categorical_crossentropy\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/backend.py\", line 5579, in categorical_crossentropy\n\nlogits and labels must be broadcastable: logits_size=[64,10] labels_size=[64,2]\n\t [[{{node categorical_crossentropy/softmax_cross_entropy_with_logits}}]] [Op:__inference_train_function_1341]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.xlabel('Epoch Number')\n",
        "plt.ylabel('Loss')\n",
        "plt.plot(history.history['loss'], label='training set')\n",
        "plt.plot(history.history['val_loss'], label='test set')\n",
        "plt.legend()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 466
        },
        "id": "1WYyh2_P6cYG",
        "outputId": "fb2659c0-e0f1-46b3-cb6c-5633b56f1525"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7c81a68f4340>"
            ]
          },
          "metadata": {},
          "execution_count": 47
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.xlabel('Epoch Number')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.plot(history.history['accuracy'], label='training set')\n",
        "plt.plot(history.history['val_accuracy'], label='test set')\n",
        "plt.legend()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 466
        },
        "id": "ZiRpYbX46gCk",
        "outputId": "e7158dc4-d4dd-48b9-f1fe-72f8199eba6b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7c81a4f63e50>"
            ]
          },
          "metadata": {},
          "execution_count": 48
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_loss, train_accuracy = model.evaluate(train_set_conv)\n",
        "print(f\"Training Accuracy: {train_accuracy * 100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cKEmA3Ko6iRS",
        "outputId": "203b5411-4d61-4ac6-e9f8-68537bd088fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "37/37 [==============================] - 8s 226ms/step - loss: 0.3993 - accuracy: 0.7959\n",
            "Training Accuracy: 79.59%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_accuracy = model.evaluate(test_set_conv)\n",
        "print(f\"Validation Accuracy: {test_accuracy * 100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uQdxSXTc6k2H",
        "outputId": "745d1a27-04b0-4c12-ffa9-6ac50a923ae1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11/11 [==============================] - 0s 14ms/step - loss: 0.4000 - accuracy: 0.7994\n",
            "Validation Accuracy: 79.94%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "#ResNet-50 model\n",
        "def ResNet50(input_shape, num_classes):\n",
        "    input_tensor = tf.keras.layers.Input(shape=input_shape)\n",
        "\n",
        "    # Initial Convolution Layer\n",
        "    x = tf.keras.layers.ZeroPadding2D(padding=(3, 3))(input_tensor)\n",
        "    x = tf.keras.layers.Conv2D(64, (7, 7), strides=(2, 2), name='conv1')(x)\n",
        "    x = tf.keras.layers.BatchNormalization(axis=3, name='bn_conv1')(x)\n",
        "    x = tf.keras.layers.Activation('relu')(x)\n",
        "    x = tf.keras.layers.ZeroPadding2D(padding=(1, 1))(x)\n",
        "    x = tf.keras.layers.MaxPooling2D((3, 3), strides=(2, 2))(x)\n",
        "\n",
        "    # ResNet-50 architecture\n",
        "    x = tf.keras.layers.Conv2D(64, (1, 1), strides=(1, 1), name='conv2_1')(x)\n",
        "    x = tf.keras.layers.BatchNormalization(axis=3, name='bn2_1')(x)\n",
        "    x = tf.keras.layers.Activation('relu')(x)\n",
        "    x = tf.keras.layers.Conv2D(64, (3, 3), strides=(1, 1), padding='same', name='conv2_2')(x)\n",
        "    x = tf.keras.layers.BatchNormalization(axis=3, name='bn2_2')(x)\n",
        "    x = tf.keras.layers.Activation('relu')(x)\n",
        "    x = tf.keras.layers.Conv2D(256, (1, 1), strides=(1, 1), name='conv2_3')(x)\n",
        "    x = tf.keras.layers.BatchNormalization(axis=3, name='bn2_3')(x)\n",
        "\n",
        "    #shortcut\n",
        "    shortcut = tf.keras.layers.Conv2D(256, (1, 1), strides=(1, 1), name='conv2_4')(x)\n",
        "    shortcut = tf.keras.layers.BatchNormalization(axis=3, name='bn2_4')(shortcut)\n",
        "    x = tf.keras.layers.Add()([x, shortcut])\n",
        "    x = tf.keras.layers.Activation('relu')(x)\n",
        "\n",
        "    # Fully Connected Layer\n",
        "    x = tf.keras.layers.AveragePooling2D(pool_size=(7, 7), name='avg_pool')(x)\n",
        "    x = tf.keras.layers.Flatten()(x)\n",
        "    x = tf.keras.layers.Dense(num_classes, activation='softmax', name='fc1000')(x)\n",
        "\n",
        "    model = models.Model(inputs=input_tensor, outputs=x, name='resnet50')\n",
        "\n",
        "    return model\n",
        "\n",
        "#ResNet-50 model\n",
        "input_shape = (IMAGE_WIDTH, IMAGE_HEIGHT, IMAGE_CHANNELS)\n",
        "num_classes = 2\n",
        "resnet50_model = ResNet50(input_shape, num_classes)\n",
        "\n",
        "early_stopping = EarlyStopping(monitor='val_accuracy',  # You can choose 'val_loss' or other metrics\n",
        "                               patience=10,             # Number of epochs with no improvement before stopping\n",
        "                               restore_best_weights=True)\n",
        "optimizer = Adam(learning_rate=0.00001)\n",
        "resnet50_model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "resnet50_model.summary()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ptG9QNT0ZO_D",
        "outputId": "9e6a8c21-c8f2-4411-d9f2-e594f67b0e70"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"resnet50\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_3 (InputLayer)        [(None, 100, 100, 3)]        0         []                            \n",
            "                                                                                                  \n",
            " zero_padding2d_4 (ZeroPadd  (None, 106, 106, 3)          0         ['input_3[0][0]']             \n",
            " ing2D)                                                                                           \n",
            "                                                                                                  \n",
            " conv1 (Conv2D)              (None, 50, 50, 64)           9472      ['zero_padding2d_4[0][0]']    \n",
            "                                                                                                  \n",
            " bn_conv1 (BatchNormalizati  (None, 50, 50, 64)           256       ['conv1[0][0]']               \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " activation_8 (Activation)   (None, 50, 50, 64)           0         ['bn_conv1[0][0]']            \n",
            "                                                                                                  \n",
            " zero_padding2d_5 (ZeroPadd  (None, 52, 52, 64)           0         ['activation_8[0][0]']        \n",
            " ing2D)                                                                                           \n",
            "                                                                                                  \n",
            " max_pooling2d_5 (MaxPoolin  (None, 25, 25, 64)           0         ['zero_padding2d_5[0][0]']    \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv2_1 (Conv2D)            (None, 25, 25, 64)           4160      ['max_pooling2d_5[0][0]']     \n",
            "                                                                                                  \n",
            " bn2_1 (BatchNormalization)  (None, 25, 25, 64)           256       ['conv2_1[0][0]']             \n",
            "                                                                                                  \n",
            " activation_9 (Activation)   (None, 25, 25, 64)           0         ['bn2_1[0][0]']               \n",
            "                                                                                                  \n",
            " conv2_2 (Conv2D)            (None, 25, 25, 64)           36928     ['activation_9[0][0]']        \n",
            "                                                                                                  \n",
            " bn2_2 (BatchNormalization)  (None, 25, 25, 64)           256       ['conv2_2[0][0]']             \n",
            "                                                                                                  \n",
            " activation_10 (Activation)  (None, 25, 25, 64)           0         ['bn2_2[0][0]']               \n",
            "                                                                                                  \n",
            " conv2_3 (Conv2D)            (None, 25, 25, 256)          16640     ['activation_10[0][0]']       \n",
            "                                                                                                  \n",
            " bn2_3 (BatchNormalization)  (None, 25, 25, 256)          1024      ['conv2_3[0][0]']             \n",
            "                                                                                                  \n",
            " conv2_4 (Conv2D)            (None, 25, 25, 256)          65792     ['bn2_3[0][0]']               \n",
            "                                                                                                  \n",
            " bn2_4 (BatchNormalization)  (None, 25, 25, 256)          1024      ['conv2_4[0][0]']             \n",
            "                                                                                                  \n",
            " add_2 (Add)                 (None, 25, 25, 256)          0         ['bn2_3[0][0]',               \n",
            "                                                                     'bn2_4[0][0]']               \n",
            "                                                                                                  \n",
            " activation_11 (Activation)  (None, 25, 25, 256)          0         ['add_2[0][0]']               \n",
            "                                                                                                  \n",
            " avg_pool (AveragePooling2D  (None, 3, 3, 256)            0         ['activation_11[0][0]']       \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " flatten_3 (Flatten)         (None, 2304)                 0         ['avg_pool[0][0]']            \n",
            "                                                                                                  \n",
            " fc1000 (Dense)              (None, 2)                    4610      ['flatten_3[0][0]']           \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 140418 (548.51 KB)\n",
            "Trainable params: 139010 (543.01 KB)\n",
            "Non-trainable params: 1408 (5.50 KB)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "steps_per_epoch = len(x_train_normalized) // batch_size\n",
        "validation_steps = len(x_val_normalized) // batch_size\n",
        "\n",
        "# Train\n",
        "training_history = resnet50_model.fit(\n",
        "    train_set_conv,\n",
        "    steps_per_epoch=steps_per_epoch,\n",
        "    epochs=25,\n",
        "    validation_data=valid_set_conv,\n",
        "    validation_steps=validation_steps,\n",
        "    callbacks=[early_stopping]\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CqPeL3Qx6959",
        "outputId": "aba8260e-7023-4c9f-9057-dee9d8a45cb6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "53/53 [==============================] - 14s 199ms/step - loss: 0.5849 - accuracy: 0.7056 - val_loss: 0.6942 - val_accuracy: 0.5022\n",
            "Epoch 2/25\n",
            "53/53 [==============================] - 10s 189ms/step - loss: 0.3819 - accuracy: 0.8500 - val_loss: 0.6973 - val_accuracy: 0.5357\n",
            "Epoch 3/25\n",
            "53/53 [==============================] - 10s 183ms/step - loss: 0.3288 - accuracy: 0.8757 - val_loss: 0.6833 - val_accuracy: 0.5580\n",
            "Epoch 4/25\n",
            "53/53 [==============================] - 10s 193ms/step - loss: 0.3060 - accuracy: 0.8802 - val_loss: 0.6673 - val_accuracy: 0.5938\n",
            "Epoch 5/25\n",
            "53/53 [==============================] - 10s 194ms/step - loss: 0.2876 - accuracy: 0.8926 - val_loss: 0.6393 - val_accuracy: 0.6518\n",
            "Epoch 6/25\n",
            "53/53 [==============================] - 9s 167ms/step - loss: 0.2757 - accuracy: 0.8953 - val_loss: 0.5752 - val_accuracy: 0.7478\n",
            "Epoch 7/25\n",
            "53/53 [==============================] - 9s 174ms/step - loss: 0.2662 - accuracy: 0.8902 - val_loss: 0.4901 - val_accuracy: 0.8036\n",
            "Epoch 8/25\n",
            "53/53 [==============================] - 10s 191ms/step - loss: 0.2642 - accuracy: 0.8944 - val_loss: 0.4203 - val_accuracy: 0.8393\n",
            "Epoch 9/25\n",
            "53/53 [==============================] - 10s 194ms/step - loss: 0.2557 - accuracy: 0.8988 - val_loss: 0.3592 - val_accuracy: 0.8616\n",
            "Epoch 10/25\n",
            "53/53 [==============================] - 9s 165ms/step - loss: 0.2476 - accuracy: 0.9012 - val_loss: 0.3214 - val_accuracy: 0.8728\n",
            "Epoch 11/25\n",
            "53/53 [==============================] - 10s 193ms/step - loss: 0.2448 - accuracy: 0.9050 - val_loss: 0.2894 - val_accuracy: 0.8862\n",
            "Epoch 12/25\n",
            "53/53 [==============================] - 11s 200ms/step - loss: 0.2458 - accuracy: 0.9053 - val_loss: 0.2561 - val_accuracy: 0.8996\n",
            "Epoch 13/25\n",
            "53/53 [==============================] - 10s 184ms/step - loss: 0.2360 - accuracy: 0.9083 - val_loss: 0.2444 - val_accuracy: 0.9040\n",
            "Epoch 14/25\n",
            "53/53 [==============================] - 10s 182ms/step - loss: 0.2376 - accuracy: 0.9047 - val_loss: 0.2626 - val_accuracy: 0.8862\n",
            "Epoch 15/25\n",
            "53/53 [==============================] - 11s 199ms/step - loss: 0.2316 - accuracy: 0.9092 - val_loss: 0.2505 - val_accuracy: 0.8929\n",
            "Epoch 16/25\n",
            "53/53 [==============================] - 10s 195ms/step - loss: 0.2277 - accuracy: 0.9101 - val_loss: 0.2302 - val_accuracy: 0.9018\n",
            "Epoch 17/25\n",
            "53/53 [==============================] - 9s 175ms/step - loss: 0.2268 - accuracy: 0.9077 - val_loss: 0.2535 - val_accuracy: 0.8929\n",
            "Epoch 18/25\n",
            "53/53 [==============================] - 10s 194ms/step - loss: 0.2314 - accuracy: 0.9133 - val_loss: 0.2187 - val_accuracy: 0.8996\n",
            "Epoch 19/25\n",
            "53/53 [==============================] - 10s 196ms/step - loss: 0.2226 - accuracy: 0.9083 - val_loss: 0.2650 - val_accuracy: 0.8884\n",
            "Epoch 20/25\n",
            "53/53 [==============================] - 9s 170ms/step - loss: 0.2271 - accuracy: 0.9136 - val_loss: 0.2405 - val_accuracy: 0.8973\n",
            "Epoch 21/25\n",
            "53/53 [==============================] - 9s 170ms/step - loss: 0.2211 - accuracy: 0.9133 - val_loss: 0.2279 - val_accuracy: 0.9018\n",
            "Epoch 22/25\n",
            "53/53 [==============================] - 10s 196ms/step - loss: 0.2207 - accuracy: 0.9124 - val_loss: 0.2172 - val_accuracy: 0.9085\n",
            "Epoch 23/25\n",
            "53/53 [==============================] - 10s 196ms/step - loss: 0.2222 - accuracy: 0.9136 - val_loss: 0.2314 - val_accuracy: 0.9040\n",
            "Epoch 24/25\n",
            "53/53 [==============================] - 10s 181ms/step - loss: 0.2134 - accuracy: 0.9163 - val_loss: 0.2459 - val_accuracy: 0.8996\n",
            "Epoch 25/25\n",
            "53/53 [==============================] - 10s 184ms/step - loss: 0.2133 - accuracy: 0.9198 - val_loss: 0.2270 - val_accuracy: 0.8973\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.xlabel('Epoch Number')\n",
        "plt.ylabel('Loss')\n",
        "plt.plot(training_history.history['loss'], label='training set')\n",
        "plt.plot(training_history.history['val_loss'], label='test set')\n",
        "plt.legend()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        },
        "id": "Pvh1fbOj6_3F",
        "outputId": "7fef596a-45ec-4477-de0d-aa11bd43e007"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7852819abb80>"
            ]
          },
          "metadata": {},
          "execution_count": 51
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.xlabel('Epoch Number')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.plot(training_history.history['accuracy'], label='training set')\n",
        "plt.plot(training_history.history['val_accuracy'], label='test set')\n",
        "plt.legend()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        },
        "id": "L2Q4Qbvm7BKb",
        "outputId": "658e9c01-1f5e-4701-e158-0e8e2c006d62"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7852818321a0>"
            ]
          },
          "metadata": {},
          "execution_count": 52
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the ResNet-50 model on the training set\n",
        "train_loss, train_accuracy = resnet50_model.evaluate(train_set_conv, steps=len(x_train_normalized) // batch_size)\n",
        "print(f\"Training Accuracy: {train_accuracy * 100:.2f}%\")\n",
        "\n",
        "# Evaluate the ResNet-50 model on the test set\n",
        "test_loss, test_accuracy = resnet50_model.evaluate(test_set_conv)\n",
        "print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_O9nWaDy7DGd",
        "outputId": "e32a8f45-5fd3-4d42-ed77-afeea3f23401"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "53/53 [==============================] - 10s 181ms/step - loss: 0.2132 - accuracy: 0.9175\n",
            "Training Accuracy: 91.75%\n",
            "16/16 [==============================] - 0s 17ms/step - loss: 0.2246 - accuracy: 0.9106\n",
            "Test Accuracy: 91.06%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract features from ResNet-50\n",
        "x_train_features = resnet50_model.predict(x_train_normalized)\n",
        "x_val_features = resnet50_model.predict(x_val_normalized)\n",
        "x_test_features = resnet50_model.predict(x_test_normalized)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cOn0EnWsviSH",
        "outputId": "6b1f7bf6-a162-4d6f-b97c-9ed92cab627c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "108/108 [==============================] - 1s 6ms/step\n",
            "16/16 [==============================] - 0s 6ms/step\n",
            "31/31 [==============================] - 0s 6ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_features = x_train_features.reshape(x_train_features.shape[0], -1)\n",
        "x_val_features = x_val_features.reshape(x_val_features.shape[0], -1)\n",
        "x_test_features = x_test_features.reshape(x_test_features.shape[0], -1)"
      ],
      "metadata": {
        "id": "Sp3OAYa7vqFA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "param_grid = {\n",
        "    'C': [0.1, 1, 10],\n",
        "    'gamma': [0.01, 0.1, 1],\n",
        "    'kernel': ['rbf', 'linear', 'poly']\n",
        "}\n"
      ],
      "metadata": {
        "id": "MRnK2AU4yhpu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "\n",
        "\n",
        "# Define the SVM classifier\n",
        "svm_model = SVC()\n",
        "\n",
        "# Create GridSearchCV with the parameter grid and cross-validation\n",
        "grid_search = GridSearchCV(estimator=svm_model, param_grid=param_grid, cv=3, n_jobs=-1)\n",
        "\n",
        "# Perform the grid search on the training data\n",
        "grid_search.fit(x_train_features, y_train)\n",
        "\n",
        "# Print the best hyperparameters found by the grid search\n",
        "print(\"Best Hyperparameters:\", grid_search.best_params_)\n",
        "\n",
        "# Get the best SVM model from the grid search\n",
        "best_svm_model = grid_search.best_estimator_\n",
        "\n",
        "# Evaluate the best model on the test data\n",
        "y_pred_svm = best_svm_model.predict(x_test_features)\n",
        "\n",
        "svm_accuracy = accuracy_score(y_test, y_pred_svm)\n",
        "svm_precision = precision_score(y_test, y_pred_svm)\n",
        "svm_recall = recall_score(y_test, y_pred_svm)\n",
        "svm_f1 = f1_score(y_test, y_pred_svm)\n",
        "\n",
        "tn, fp, fn, tp = confusion_matrix(y_test, y_pred_svm).ravel()\n",
        "svm_specificity = tn / (tn + fp)\n",
        "\n",
        "print(\"SVM Accuracy:\", svm_accuracy)\n",
        "print(\"SVM Precision:\", svm_precision)\n",
        "print(\"SVM Sensitivity (Recall):\", svm_recall)\n",
        "print(\"SVM Specificity:\", svm_specificity)\n",
        "print(\"SVM F1 Score:\", svm_f1)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xRBdl8ywvyhc",
        "outputId": "65f6894e-f910-4ee6-b2e5-2c559b21a852"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Hyperparameters: {'C': 10, 'gamma': 0.1, 'kernel': 'poly'}\n",
            "SVM Accuracy: 0.9136178861788617\n",
            "SVM Precision: 0.9356136820925554\n",
            "SVM Sensitivity (Recall): 0.8976833976833977\n",
            "SVM Specificity: 0.9313304721030042\n",
            "SVM F1 Score: 0.916256157635468\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "import numpy as np\n",
        "\n",
        "# Define the parameter distributions for RandomizedSearchCV\n",
        "param_dist = {\n",
        "    'n_estimators': [100, 200, 300, 400],\n",
        "    'max_depth': [None, 10, 20, 30],\n",
        "    'min_samples_split': [2, 5, 10, 15],\n",
        "    'min_samples_leaf': [1, 2, 4, 8],\n",
        "    'max_features': ['auto', 'sqrt']\n",
        "}\n",
        "\n",
        "# Instantiate the Random Forest classifier\n",
        "rf_model = RandomForestClassifier(random_state=42)\n",
        "\n",
        "# Instantiate RandomizedSearchCV with the model, parameter distributions, and evaluation metric\n",
        "random_search = RandomizedSearchCV(estimator=rf_model, param_distributions=param_dist, n_iter=50, cv=3, n_jobs=-1, random_state=42, scoring='accuracy')\n",
        "\n",
        "# Early stopping parameters\n",
        "max_epochs = 25  # Maximum number of epochs to train\n",
        "patience = 5  # Number of epochs to wait for improvement\n",
        "counter = 0  # Counter to keep track of epochs with no improvement\n",
        "best_accuracy = 0  # Best validation accuracy\n",
        "\n",
        "# Training loop with early stopping\n",
        "for epoch in range(max_epochs):\n",
        "    # Perform the randomized search on your training data (x_train_features, y_train)\n",
        "    random_search.fit(x_train_features, y_train)\n",
        "\n",
        "    # Get the best hyperparameters and best model\n",
        "    best_params = random_search.best_params_\n",
        "    best_rf_model = random_search.best_estimator_\n",
        "\n",
        "    # Evaluate the model on the validation data\n",
        "    y_pred_val = best_rf_model.predict(x_val_features)\n",
        "    val_accuracy = accuracy_score(y_val, y_pred_val)\n",
        "\n",
        "    print(\"Epoch {}: Validation Accuracy: {:.4f}\".format(epoch, val_accuracy))\n",
        "\n",
        "    # Check for improvement in validation accuracy\n",
        "    if val_accuracy > best_accuracy:\n",
        "        best_accuracy = val_accuracy\n",
        "        counter = 0\n",
        "    else:\n",
        "        counter += 1\n",
        "\n",
        "    # Early stopping condition\n",
        "    if counter >= patience:\n",
        "        print(\"Early stopping after {} epochs of no improvement.\".format(epoch))\n",
        "        break\n",
        "\n",
        "# Evaluate the best model on the test data (x_test_features, y_test)\n",
        "y_pred_rf = best_rf_model.predict(x_test_features)\n",
        "rf_accuracy = accuracy_score(y_test, y_pred_rf)\n",
        "rf_precision = precision_score(y_test, y_pred_rf)\n",
        "rf_recall = recall_score(y_test, y_pred_rf)\n",
        "rf_f1 = f1_score(y_test, y_pred_rf)\n",
        "\n",
        "tn, fp, fn, tp = confusion_matrix(y_test, y_pred_rf).ravel()\n",
        "rf_specificity = tn / (tn + fp)\n",
        "\n",
        "print(\"Best Hyperparameters:\", best_params)\n",
        "print(\"Random Forest Accuracy:\", rf_accuracy)\n",
        "print(\"Random Forest Precision:\", rf_precision)\n",
        "print(\"Random Forest Sensitivity (Recall):\", rf_recall)\n",
        "print(\"Random Forest Specificity:\", rf_specificity)\n",
        "print(\"Random Forest F1 Score:\", rf_f1)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ak9VZwQEzTYX",
        "outputId": "3e77ef8b-3ae6-436d-f552-4a9291b46a2d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0: Validation Accuracy: 0.9045\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Validation Accuracy: 0.9045\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2: Validation Accuracy: 0.9045\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3: Validation Accuracy: 0.9045\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4: Validation Accuracy: 0.9045\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5: Validation Accuracy: 0.9045\n",
            "Early stopping after 5 epochs of no improvement.\n",
            "Best Hyperparameters: {'n_estimators': 100, 'min_samples_split': 2, 'min_samples_leaf': 8, 'max_features': 'auto', 'max_depth': 20}\n",
            "Random Forest Accuracy: 0.9024390243902439\n",
            "Random Forest Precision: 0.9271255060728745\n",
            "Random Forest Sensitivity (Recall): 0.8841698841698842\n",
            "Random Forest Specificity: 0.9227467811158798\n",
            "Random Forest F1 Score: 0.9051383399209486\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "\n",
        "# Instantiate the KNN classifier\n",
        "knn_model = KNeighborsClassifier(n_neighbors=5)\n",
        "\n",
        "# Early stopping parameters\n",
        "max_epochs = 10  # Maximum number of epochs (iterations) to train\n",
        "patience = 5  # Number of epochs to wait for improvement\n",
        "best_accuracy = 0  # Best validation accuracy\n",
        "counter = 0  # Counter to keep track of epochs with no improvement\n",
        "\n",
        "# Training loop with early stopping\n",
        "for epoch in range(max_epochs):\n",
        "    # Train the KNN model\n",
        "    knn_model.fit(x_train_features, y_train)\n",
        "\n",
        "    # Validate the model on the validation data\n",
        "    y_pred_val = knn_model.predict(x_val_features)\n",
        "    val_accuracy = accuracy_score(y_val, y_pred_val)\n",
        "\n",
        "    print(\"Epoch {}: Validation Accuracy: {:.4f}\".format(epoch, val_accuracy))\n",
        "\n",
        "    # Check for improvement in validation accuracy\n",
        "    if val_accuracy > best_accuracy:\n",
        "        best_accuracy = val_accuracy\n",
        "        counter = 0\n",
        "    else:\n",
        "        counter += 1\n",
        "\n",
        "    # Early stopping condition\n",
        "    if counter >= patience:\n",
        "        print(\"Early stopping after {} epochs of no improvement.\".format(epoch))\n",
        "        break\n",
        "\n",
        "# Evaluate the best model on the test data\n",
        "y_pred_test = knn_model.predict(x_test_features)\n",
        "knn_accuracy = accuracy_score(y_test, y_pred_test)\n",
        "knn_precision = precision_score(y_test, y_pred_test)\n",
        "knn_recall = recall_score(y_test, y_pred_test)\n",
        "knn_f1 = f1_score(y_test, y_pred_test)\n",
        "\n",
        "tn, fp, fn, tp = confusion_matrix(y_test, y_pred_test).ravel()\n",
        "knn_specificity = tn / (tn + fp)\n",
        "\n",
        "print(\"KNN Accuracy:\", knn_accuracy)\n",
        "print(\"KNN Precision:\", knn_precision)\n",
        "print(\"KNN Sensitivity (Recall):\", knn_recall)\n",
        "print(\"KNN Specificity:\", knn_specificity)\n",
        "print(\"KNN F1 Score:\", knn_f1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3j6NJyU_4tec",
        "outputId": "28f2bf98-7a0b-4243-db56-97b5a7439ddb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0: Validation Accuracy: 0.9024\n",
            "Epoch 1: Validation Accuracy: 0.9024\n",
            "Epoch 2: Validation Accuracy: 0.9024\n",
            "Epoch 3: Validation Accuracy: 0.9024\n",
            "Epoch 4: Validation Accuracy: 0.9024\n",
            "Epoch 5: Validation Accuracy: 0.9024\n",
            "Early stopping after 5 epochs of no improvement.\n",
            "KNN Accuracy: 0.8973577235772358\n",
            "KNN Precision: 0.9195171026156942\n",
            "KNN Sensitivity (Recall): 0.8822393822393823\n",
            "KNN Specificity: 0.9141630901287554\n",
            "KNN F1 Score: 0.9004926108374384\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import os\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "\n",
        "def VGG16(input_shape, num_classes):\n",
        "    inputs = Input(shape=input_shape)\n",
        "\n",
        "    # Block 1\n",
        "    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv1')(inputs)\n",
        "    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv2')(x)\n",
        "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block1_pool')(x)\n",
        "\n",
        "    # Block 2\n",
        "    x = Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv1')(x)\n",
        "    x = Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv2')(x)\n",
        "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block2_pool')(x)\n",
        "\n",
        "    # Block 3\n",
        "    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv1')(x)\n",
        "    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv2')(x)\n",
        "    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv3')(x)\n",
        "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block3_pool')(x)\n",
        "\n",
        "    # Block 4\n",
        "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv1')(x)\n",
        "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv2')(x)\n",
        "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv3')(x)\n",
        "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block4_pool')(x)\n",
        "\n",
        "    # Block 5\n",
        "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv1')(x)\n",
        "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv2')(x)\n",
        "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv3')(x)\n",
        "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block5_pool')(x)\n",
        "\n",
        "    # Flatten and Fully Connected Layers\n",
        "    x = Flatten(name='flatten')(x)\n",
        "    x = Dense(4096, activation='relu', name='fc1')(x)\n",
        "    x = Dropout(0.5)(x)\n",
        "    x = Dense(4096, activation='relu', name='fc2')(x)\n",
        "    x = Dropout(0.5)(x)\n",
        "    predictions = Dense(num_classes, activation='softmax', name='predictions')(x)\n",
        "\n",
        "    # Create the model\n",
        "    model = Model(inputs=inputs, outputs=predictions)\n",
        "    return model\n",
        "\n",
        "# Modify the input shape and number of classes based on your needs\n",
        "input_shape = (100, 100, 3)\n",
        "num_classes = 2\n",
        "\n",
        "model = VGG16(input_shape, num_classes)\n",
        "\n",
        "# Print model summary\n",
        "model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MtB5iJOhPGes",
        "outputId": "3cbfa458-ef69-4e76-c37c-d7864f43edf6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_5 (InputLayer)        [(None, 100, 100, 3)]     0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, 100, 100, 64)      1792      \n",
            "                                                                 \n",
            " block1_conv2 (Conv2D)       (None, 100, 100, 64)      36928     \n",
            "                                                                 \n",
            " block1_pool (MaxPooling2D)  (None, 50, 50, 64)        0         \n",
            "                                                                 \n",
            " block2_conv1 (Conv2D)       (None, 50, 50, 128)       73856     \n",
            "                                                                 \n",
            " block2_conv2 (Conv2D)       (None, 50, 50, 128)       147584    \n",
            "                                                                 \n",
            " block2_pool (MaxPooling2D)  (None, 25, 25, 128)       0         \n",
            "                                                                 \n",
            " block3_conv1 (Conv2D)       (None, 25, 25, 256)       295168    \n",
            "                                                                 \n",
            " block3_conv2 (Conv2D)       (None, 25, 25, 256)       590080    \n",
            "                                                                 \n",
            " block3_conv3 (Conv2D)       (None, 25, 25, 256)       590080    \n",
            "                                                                 \n",
            " block3_pool (MaxPooling2D)  (None, 12, 12, 256)       0         \n",
            "                                                                 \n",
            " block4_conv1 (Conv2D)       (None, 12, 12, 512)       1180160   \n",
            "                                                                 \n",
            " block4_conv2 (Conv2D)       (None, 12, 12, 512)       2359808   \n",
            "                                                                 \n",
            " block4_conv3 (Conv2D)       (None, 12, 12, 512)       2359808   \n",
            "                                                                 \n",
            " block4_pool (MaxPooling2D)  (None, 6, 6, 512)         0         \n",
            "                                                                 \n",
            " block5_conv1 (Conv2D)       (None, 6, 6, 512)         2359808   \n",
            "                                                                 \n",
            " block5_conv2 (Conv2D)       (None, 6, 6, 512)         2359808   \n",
            "                                                                 \n",
            " block5_conv3 (Conv2D)       (None, 6, 6, 512)         2359808   \n",
            "                                                                 \n",
            " block5_pool (MaxPooling2D)  (None, 3, 3, 512)         0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 4608)              0         \n",
            "                                                                 \n",
            " fc1 (Dense)                 (None, 4096)              18878464  \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 4096)              0         \n",
            "                                                                 \n",
            " fc2 (Dense)                 (None, 4096)              16781312  \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 4096)              0         \n",
            "                                                                 \n",
            " predictions (Dense)         (None, 2)                 8194      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 50382658 (192.19 MB)\n",
            "Trainable params: 50382658 (192.19 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Define learning rate\n",
        "learning_rate = 0.00001\n",
        "\n",
        "# Compile the model with the specified learning rate\n",
        "optimizer = Adam(learning_rate=learning_rate)\n",
        "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Define steps per epoch and validation steps\n",
        "steps_per_epoch = len(x_train_normalized) // batch_size\n",
        "validation_steps = len(x_val_normalized) // batch_size\n",
        "\n",
        "# Train the VGG16 model\n",
        "history = model.fit(\n",
        "    train_set_conv,\n",
        "    steps_per_epoch=steps_per_epoch,\n",
        "    epochs=25,  # You can adjust the number of epochs\n",
        "    validation_data=valid_set_conv,\n",
        "    validation_steps=validation_steps\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5qWDx_s3PwnT",
        "outputId": "57a5c07d-6c9f-495d-cc85-382a1c8537d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "53/53 [==============================] - 26s 304ms/step - loss: 0.6895 - accuracy: 0.5266 - val_loss: 0.6718 - val_accuracy: 0.5960\n",
            "Epoch 2/25\n",
            "53/53 [==============================] - 14s 259ms/step - loss: 0.5402 - accuracy: 0.7541 - val_loss: 0.4464 - val_accuracy: 0.7991\n",
            "Epoch 3/25\n",
            "53/53 [==============================] - 14s 271ms/step - loss: 0.3756 - accuracy: 0.8364 - val_loss: 0.3361 - val_accuracy: 0.8661\n",
            "Epoch 4/25\n",
            "53/53 [==============================] - 14s 256ms/step - loss: 0.3501 - accuracy: 0.8441 - val_loss: 0.3308 - val_accuracy: 0.8683\n",
            "Epoch 5/25\n",
            "53/53 [==============================] - 14s 260ms/step - loss: 0.3253 - accuracy: 0.8583 - val_loss: 0.3139 - val_accuracy: 0.8772\n",
            "Epoch 6/25\n",
            "53/53 [==============================] - 14s 259ms/step - loss: 0.3195 - accuracy: 0.8583 - val_loss: 0.3422 - val_accuracy: 0.8638\n",
            "Epoch 7/25\n",
            "53/53 [==============================] - 14s 261ms/step - loss: 0.3094 - accuracy: 0.8630 - val_loss: 0.3339 - val_accuracy: 0.8638\n",
            "Epoch 8/25\n",
            "53/53 [==============================] - 14s 258ms/step - loss: 0.3110 - accuracy: 0.8654 - val_loss: 0.2952 - val_accuracy: 0.8817\n",
            "Epoch 9/25\n",
            "53/53 [==============================] - 14s 256ms/step - loss: 0.2861 - accuracy: 0.8778 - val_loss: 0.2679 - val_accuracy: 0.8973\n",
            "Epoch 10/25\n",
            "53/53 [==============================] - 14s 270ms/step - loss: 0.2829 - accuracy: 0.8808 - val_loss: 0.2863 - val_accuracy: 0.8906\n",
            "Epoch 11/25\n",
            "53/53 [==============================] - 14s 261ms/step - loss: 0.2856 - accuracy: 0.8805 - val_loss: 0.2752 - val_accuracy: 0.8862\n",
            "Epoch 12/25\n",
            "53/53 [==============================] - 14s 257ms/step - loss: 0.2688 - accuracy: 0.8905 - val_loss: 0.2819 - val_accuracy: 0.8839\n",
            "Epoch 13/25\n",
            "53/53 [==============================] - 14s 259ms/step - loss: 0.2695 - accuracy: 0.8876 - val_loss: 0.2582 - val_accuracy: 0.8929\n",
            "Epoch 14/25\n",
            "53/53 [==============================] - 14s 260ms/step - loss: 0.2784 - accuracy: 0.8820 - val_loss: 0.3948 - val_accuracy: 0.8460\n",
            "Epoch 15/25\n",
            "53/53 [==============================] - 14s 259ms/step - loss: 0.2696 - accuracy: 0.8867 - val_loss: 0.2604 - val_accuracy: 0.8996\n",
            "Epoch 16/25\n",
            "53/53 [==============================] - 14s 258ms/step - loss: 0.2763 - accuracy: 0.8879 - val_loss: 0.2680 - val_accuracy: 0.8906\n",
            "Epoch 17/25\n",
            "53/53 [==============================] - 14s 257ms/step - loss: 0.2617 - accuracy: 0.8941 - val_loss: 0.2562 - val_accuracy: 0.8951\n",
            "Epoch 18/25\n",
            "53/53 [==============================] - 14s 260ms/step - loss: 0.2846 - accuracy: 0.8796 - val_loss: 0.2985 - val_accuracy: 0.8862\n",
            "Epoch 19/25\n",
            "53/53 [==============================] - 14s 260ms/step - loss: 0.2583 - accuracy: 0.8970 - val_loss: 0.2493 - val_accuracy: 0.9085\n",
            "Epoch 20/25\n",
            "53/53 [==============================] - 14s 260ms/step - loss: 0.2554 - accuracy: 0.8956 - val_loss: 0.2841 - val_accuracy: 0.8862\n",
            "Epoch 21/25\n",
            "53/53 [==============================] - 14s 263ms/step - loss: 0.2488 - accuracy: 0.8962 - val_loss: 0.2464 - val_accuracy: 0.9040\n",
            "Epoch 22/25\n",
            "53/53 [==============================] - 14s 256ms/step - loss: 0.2488 - accuracy: 0.8962 - val_loss: 0.4208 - val_accuracy: 0.8504\n",
            "Epoch 23/25\n",
            "53/53 [==============================] - 14s 260ms/step - loss: 0.2654 - accuracy: 0.8861 - val_loss: 0.2327 - val_accuracy: 0.9085\n",
            "Epoch 24/25\n",
            "53/53 [==============================] - 14s 258ms/step - loss: 0.2399 - accuracy: 0.9000 - val_loss: 0.2689 - val_accuracy: 0.8929\n",
            "Epoch 25/25\n",
            "53/53 [==============================] - 14s 258ms/step - loss: 0.2398 - accuracy: 0.8976 - val_loss: 0.2598 - val_accuracy: 0.9018\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on the training set\n",
        "train_loss, train_accuracy = model.evaluate(train_set_conv, steps=steps_per_epoch)\n",
        "print(f'Training Loss: {train_loss:.4f}')\n",
        "print(f'Training Accuracy: {train_accuracy * 100:.2f}%')\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "test_loss, test_accuracy = model.evaluate(test_set_conv)\n",
        "print(f'Test Loss: {test_loss:.4f}')\n",
        "print(f'Test Accuracy: {test_accuracy * 100:.2f}%')\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ykhi1MqhSG7x",
        "outputId": "755a7e07-0d3a-4c48-a0cb-9e72d8177d4d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "53/53 [==============================] - 11s 202ms/step - loss: 0.2291 - accuracy: 0.9068\n",
            "Training Loss: 0.2291\n",
            "Training Accuracy: 90.68%\n",
            "16/16 [==============================] - 2s 146ms/step - loss: 0.2361 - accuracy: 0.9096\n",
            "Test Loss: 0.2361\n",
            "Test Accuracy: 90.96%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_features = model.predict(x_train_normalized)\n",
        "x_val_features = model.predict(x_val_normalized)\n",
        "x_test_features = model.predict(x_test_normalized)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sSURlrrO7X7S",
        "outputId": "aa1380db-43ba-490f-a4b2-d9ae4e80ab2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "108/108 [==============================] - 6s 41ms/step\n",
            "16/16 [==============================] - 1s 94ms/step\n",
            "31/31 [==============================] - 1s 30ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_features = x_train_features.reshape(x_train_features.shape[0], -1)\n",
        "x_val_features = x_val_features.reshape(x_val_features.shape[0], -1)\n",
        "x_test_features = x_test_features.reshape(x_test_features.shape[0], -1)"
      ],
      "metadata": {
        "id": "pMvq9dBD7sPj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "\n",
        "# SVM Classifier\n",
        "svm_model = SVC(kernel='rbf', C=2, gamma='scale')\n",
        "\n",
        "# Early stopping parameters\n",
        "max_epochs = 25  # Maximum number of epochs (iterations) to train\n",
        "patience = 5  # Number of epochs to wait for improvement\n",
        "best_accuracy = 0  # Best validation accuracy\n",
        "counter = 0  # Counter to keep track of epochs with no improvement\n",
        "\n",
        "# Training loop with early stopping\n",
        "for epoch in range(max_epochs):\n",
        "    # Train the SVM model\n",
        "    svm_model.fit(x_train_features, y_train)\n",
        "\n",
        "    # Validate the model on the validation data\n",
        "    y_pred_val = svm_model.predict(x_val_features)\n",
        "    val_accuracy = accuracy_score(y_val, y_pred_val)\n",
        "\n",
        "    print(\"Epoch {}: Validation Accuracy: {:.4f}\".format(epoch, val_accuracy))\n",
        "\n",
        "    # Check for improvement in validation accuracy\n",
        "    if val_accuracy > best_accuracy:\n",
        "        best_accuracy = val_accuracy\n",
        "        counter = 0\n",
        "    else:\n",
        "        counter += 1\n",
        "\n",
        "    # Early stopping condition\n",
        "    if counter >= patience:\n",
        "        print(\"Early stopping after {} epochs of no improvement.\".format(epoch))\n",
        "        break\n",
        "\n",
        "# Evaluate the best model on the test data\n",
        "y_pred_test = svm_model.predict(x_test_features)\n",
        "svm_accuracy = accuracy_score(y_test, y_pred_test)\n",
        "svm_precision = precision_score(y_test, y_pred_test)\n",
        "svm_recall = recall_score(y_test, y_pred_test)\n",
        "svm_f1 = f1_score(y_test, y_pred_test)\n",
        "\n",
        "tn, fp, fn, tp = confusion_matrix(y_test, y_pred_test).ravel()\n",
        "svm_specificity = tn / (tn + fp)\n",
        "\n",
        "print(\"SVM Accuracy:\", svm_accuracy)\n",
        "print(\"SVM Precision:\", svm_precision)\n",
        "print(\"SVM Sensitivity (Recall):\", svm_recall)\n",
        "print(\"SVM Specificity:\", svm_specificity)\n",
        "print(\"SVM F1 Score:\", svm_f1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HpVu3WlK-ISk",
        "outputId": "eab7350d-24c9-4c30-d369-766d04336c7b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0: Validation Accuracy: 0.8984\n",
            "Epoch 1: Validation Accuracy: 0.8984\n",
            "Epoch 2: Validation Accuracy: 0.8984\n",
            "Epoch 3: Validation Accuracy: 0.8984\n",
            "Epoch 4: Validation Accuracy: 0.8984\n",
            "Epoch 5: Validation Accuracy: 0.8984\n",
            "Early stopping after 5 epochs of no improvement.\n",
            "SVM Accuracy: 0.9085365853658537\n",
            "SVM Precision: 0.9458333333333333\n",
            "SVM Sensitivity (Recall): 0.8764478764478765\n",
            "SVM Specificity: 0.944206008583691\n",
            "SVM F1 Score: 0.9098196392785571\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "import numpy as np\n",
        "\n",
        "# Define the parameter distributions for RandomizedSearchCV\n",
        "param_dist = {\n",
        "    'n_estimators': [100, 200, 300, 400],\n",
        "    'max_depth': [None, 10, 20, 30],\n",
        "    'min_samples_split': [2, 5, 10, 15],\n",
        "    'min_samples_leaf': [1, 2, 4, 8],\n",
        "    'max_features': ['auto', 'sqrt']\n",
        "}\n",
        "\n",
        "# Instantiate the Random Forest classifier\n",
        "rf_model = RandomForestClassifier(random_state=42)\n",
        "\n",
        "# Instantiate RandomizedSearchCV with the model, parameter distributions, and evaluation metric\n",
        "random_search = RandomizedSearchCV(estimator=rf_model, param_distributions=param_dist, n_iter=50, cv=3, n_jobs=-1, random_state=42, scoring='accuracy')\n",
        "\n",
        "# Perform the randomized search on your training data (x_train_features, y_train)\n",
        "random_search.fit(x_train_features, y_train)\n",
        "\n",
        "# Get the best hyperparameters and best model\n",
        "best_params = random_search.best_params_\n",
        "best_rf_model = random_search.best_estimator_\n",
        "\n",
        "# Evaluate the best model on the test data (x_test_features, y_test)\n",
        "y_pred_rf = best_rf_model.predict(x_test_features)\n",
        "rf_accuracy = accuracy_score(y_test, y_pred_rf)\n",
        "rf_precision = precision_score(y_test, y_pred_rf)\n",
        "rf_recall = recall_score(y_test, y_pred_rf)\n",
        "rf_f1 = f1_score(y_test, y_pred_rf)\n",
        "\n",
        "tn, fp, fn, tp = confusion_matrix(y_test, y_pred_rf).ravel()\n",
        "rf_specificity = tn / (tn + fp)\n",
        "\n",
        "print(\"Best Hyperparameters:\", best_params)\n",
        "print(\"Random Forest Accuracy:\", rf_accuracy)\n",
        "print(\"Random Forest Precision:\", rf_precision)\n",
        "print(\"Random Forest Sensitivity (Recall):\", rf_recall)\n",
        "print(\"Random Forest Specificity:\", rf_specificity)\n",
        "print(\"Random Forest F1 Score:\", rf_f1)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VpshrZHv-Xyg",
        "outputId": "5186739b-48f3-448c-adde-7a0b005aaf3c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Hyperparameters: {'n_estimators': 100, 'min_samples_split': 2, 'min_samples_leaf': 8, 'max_features': 'auto', 'max_depth': 20}\n",
            "Random Forest Accuracy: 0.899390243902439\n",
            "Random Forest Precision: 0.9466950959488273\n",
            "Random Forest Sensitivity (Recall): 0.8571428571428571\n",
            "Random Forest Specificity: 0.9463519313304721\n",
            "Random Forest F1 Score: 0.8996960486322189\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Define the parameter grid for GridSearchCV\n",
        "param_grid = {\n",
        "    'n_neighbors': [3, 5, 7, 9],  # Example values for the number of neighbors\n",
        "    'weights': ['uniform', 'distance'],  # Example values for the weight function\n",
        "    'p': [1, 2]  # Example values for the power parameter (1 for Manhattan distance, 2 for Euclidean distance)\n",
        "}\n",
        "\n",
        "# Instantiate the KNN classifier\n",
        "knn_model = KNeighborsClassifier()\n",
        "\n",
        "# Instantiate GridSearchCV with the model and parameter grid\n",
        "grid_search = GridSearchCV(estimator=knn_model, param_grid=param_grid, cv=3, n_jobs=-1, scoring='accuracy')\n",
        "\n",
        "# Perform grid search on your training data (x_train_features, y_train)\n",
        "grid_search.fit(x_train_features, y_train)\n",
        "\n",
        "# Get the best hyperparameters and best model\n",
        "best_params = grid_search.best_params_\n",
        "best_knn_model = grid_search.best_estimator_\n",
        "\n",
        "# Print the best hyperparameters\n",
        "print(\"Best Hyperparameters:\", best_params)\n",
        "\n",
        "# Evaluate the best model on the test data (x_test_features, y_test)\n",
        "y_pred_knn = best_knn_model.predict(x_test_features)\n",
        "knn_accuracy = accuracy_score(y_test, y_pred_knn)\n",
        "knn_precision = precision_score(y_test, y_pred_knn)\n",
        "knn_recall = recall_score(y_test, y_pred_knn)\n",
        "knn_f1 = f1_score(y_test, y_pred_knn)\n",
        "\n",
        "tn, fp, fn, tp = confusion_matrix(y_test, y_pred_knn).ravel()\n",
        "knn_specificity = tn / (tn + fp)\n",
        "\n",
        "print(\"KNN Accuracy:\", knn_accuracy)\n",
        "print(\"KNN Precision:\", knn_precision)\n",
        "print(\"KNN Sensitivity (Recall):\", knn_recall)\n",
        "print(\"KNN Specificity:\", knn_specificity)\n",
        "print(\"KNN F1 Score:\", knn_f1)\n",
        "\n",
        "# The best trained KNN model is stored in the variable 'best_knn_model'\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UbBXUe1f_mwM",
        "outputId": "22b19f5d-34cd-4f64-847d-d36f218e58e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Hyperparameters: {'n_neighbors': 9, 'p': 1, 'weights': 'uniform'}\n",
            "KNN Accuracy: 0.8963414634146342\n",
            "KNN Precision: 0.940677966101695\n",
            "KNN Sensitivity (Recall): 0.8571428571428571\n",
            "KNN Specificity: 0.9399141630901288\n",
            "KNN F1 Score: 0.896969696969697\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "def ShuffleNet(input_shape, num_classes):\n",
        "    def group(input, groups, in_channels, out_channels):\n",
        "        group_list = []\n",
        "        for i in range(groups):\n",
        "            x = layers.Conv2D(out_channels // groups, (1, 1), use_bias=False)(input)\n",
        "            x = layers.BatchNormalization()(x)\n",
        "            x = layers.Activation('relu')(x)\n",
        "            group_list.append(x)\n",
        "        if groups == 1:\n",
        "            return group_list[0]\n",
        "        else:\n",
        "            return layers.Concatenate()(group_list)\n",
        "\n",
        "    def channel_shuffle(x, groups):\n",
        "        _, width, height, channels = x.shape\n",
        "        group_channels = channels // groups\n",
        "        x = tf.reshape(x, [-1, width, height, group_channels, groups])\n",
        "        x = tf.transpose(x, [0, 1, 2, 4, 3])\n",
        "        x = tf.reshape(x, [-1, width, height, channels])\n",
        "        return x\n",
        "\n",
        "    input_tensor = tf.keras.layers.Input(shape=input_shape)\n",
        "    x = layers.Conv2D(24, (3, 3), strides=(2, 2), padding='same', use_bias=False)(input_tensor)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation('relu')(x)\n",
        "    x = layers.MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n",
        "\n",
        "    x = group(x, 4, 24, 384)\n",
        "    x = layers.Conv2D(196, (1, 1), use_bias=False)(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation('relu')(x)\n",
        "    x = channel_shuffle(x, 4)\n",
        "    x = layers.DepthwiseConv2D((3, 3), padding='same', use_bias=False)(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Conv2D(196, (1, 1), use_bias=False)(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation('relu')(x)\n",
        "\n",
        "    x = group(x, 4, 196, 384)\n",
        "    x = layers.Conv2D(392, (1, 1), use_bias=False)(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation('relu')(x)\n",
        "    x = channel_shuffle(x, 4)\n",
        "    x = layers.DepthwiseConv2D((3, 3), padding='same', use_bias=False)(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Conv2D(392, (1, 1), use_bias=False)(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation('relu')(x)\n",
        "\n",
        "    x = group(x, 4, 392, 784)\n",
        "    x = layers.Conv2D(196, (1, 1), use_bias=False)(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation('relu')(x)\n",
        "    x = channel_shuffle(x, 4)\n",
        "    x = layers.DepthwiseConv2D((3, 3), padding='same', use_bias=False)(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Conv2D(196, (1, 1), use_bias=False)(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation('relu')(x)\n",
        "\n",
        "    x = layers.GlobalAveragePooling2D()(x)\n",
        "    x = layers.Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "    model = models.Model(inputs=input_tensor, outputs=x, name='shufflenet')\n",
        "\n",
        "    return model\n",
        "\n",
        "input_shape = (100, 100, 3)\n",
        "num_classes = 2\n",
        "shufflenet_model = ShuffleNet(input_shape, num_classes)\n",
        "\n",
        "# Compile model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "optimizer = Adam(learning_rate=0.00001)\n",
        "shufflenet_model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "shufflenet_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2VOo_gpfCEiv",
        "outputId": "cadcf0b1-34b0-41eb-9f55-5f03c27df76b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"shufflenet\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_6 (InputLayer)        [(None, 100, 100, 3)]        0         []                            \n",
            "                                                                                                  \n",
            " conv2d_3 (Conv2D)           (None, 50, 50, 24)           648       ['input_6[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization (Batch  (None, 50, 50, 24)           96        ['conv2d_3[0][0]']            \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_12 (Activation)  (None, 50, 50, 24)           0         ['batch_normalization[0][0]'] \n",
            "                                                                                                  \n",
            " max_pooling2d_6 (MaxPoolin  (None, 25, 25, 24)           0         ['activation_12[0][0]']       \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv2d_4 (Conv2D)           (None, 25, 25, 96)           2304      ['max_pooling2d_6[0][0]']     \n",
            "                                                                                                  \n",
            " conv2d_5 (Conv2D)           (None, 25, 25, 96)           2304      ['max_pooling2d_6[0][0]']     \n",
            "                                                                                                  \n",
            " conv2d_6 (Conv2D)           (None, 25, 25, 96)           2304      ['max_pooling2d_6[0][0]']     \n",
            "                                                                                                  \n",
            " conv2d_7 (Conv2D)           (None, 25, 25, 96)           2304      ['max_pooling2d_6[0][0]']     \n",
            "                                                                                                  \n",
            " batch_normalization_1 (Bat  (None, 25, 25, 96)           384       ['conv2d_4[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_2 (Bat  (None, 25, 25, 96)           384       ['conv2d_5[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_3 (Bat  (None, 25, 25, 96)           384       ['conv2d_6[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_4 (Bat  (None, 25, 25, 96)           384       ['conv2d_7[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " activation_13 (Activation)  (None, 25, 25, 96)           0         ['batch_normalization_1[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " activation_14 (Activation)  (None, 25, 25, 96)           0         ['batch_normalization_2[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " activation_15 (Activation)  (None, 25, 25, 96)           0         ['batch_normalization_3[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " activation_16 (Activation)  (None, 25, 25, 96)           0         ['batch_normalization_4[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)   (None, 25, 25, 384)          0         ['activation_13[0][0]',       \n",
            "                                                                     'activation_14[0][0]',       \n",
            "                                                                     'activation_15[0][0]',       \n",
            "                                                                     'activation_16[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_8 (Conv2D)           (None, 25, 25, 196)          75264     ['concatenate[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_5 (Bat  (None, 25, 25, 196)          784       ['conv2d_8[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " activation_17 (Activation)  (None, 25, 25, 196)          0         ['batch_normalization_5[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " tf.reshape (TFOpLambda)     (None, 25, 25, 49, 4)        0         ['activation_17[0][0]']       \n",
            "                                                                                                  \n",
            " tf.compat.v1.transpose (TF  (None, 25, 25, 4, 49)        0         ['tf.reshape[0][0]']          \n",
            " OpLambda)                                                                                        \n",
            "                                                                                                  \n",
            " tf.reshape_1 (TFOpLambda)   (None, 25, 25, 196)          0         ['tf.compat.v1.transpose[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " depthwise_conv2d (Depthwis  (None, 25, 25, 196)          1764      ['tf.reshape_1[0][0]']        \n",
            " eConv2D)                                                                                         \n",
            "                                                                                                  \n",
            " batch_normalization_6 (Bat  (None, 25, 25, 196)          784       ['depthwise_conv2d[0][0]']    \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " conv2d_9 (Conv2D)           (None, 25, 25, 196)          38416     ['batch_normalization_6[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " batch_normalization_7 (Bat  (None, 25, 25, 196)          784       ['conv2d_9[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " activation_18 (Activation)  (None, 25, 25, 196)          0         ['batch_normalization_7[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " conv2d_10 (Conv2D)          (None, 25, 25, 96)           18816     ['activation_18[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_11 (Conv2D)          (None, 25, 25, 96)           18816     ['activation_18[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_12 (Conv2D)          (None, 25, 25, 96)           18816     ['activation_18[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_13 (Conv2D)          (None, 25, 25, 96)           18816     ['activation_18[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_8 (Bat  (None, 25, 25, 96)           384       ['conv2d_10[0][0]']           \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_9 (Bat  (None, 25, 25, 96)           384       ['conv2d_11[0][0]']           \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_10 (Ba  (None, 25, 25, 96)           384       ['conv2d_12[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_11 (Ba  (None, 25, 25, 96)           384       ['conv2d_13[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_19 (Activation)  (None, 25, 25, 96)           0         ['batch_normalization_8[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " activation_20 (Activation)  (None, 25, 25, 96)           0         ['batch_normalization_9[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " activation_21 (Activation)  (None, 25, 25, 96)           0         ['batch_normalization_10[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " activation_22 (Activation)  (None, 25, 25, 96)           0         ['batch_normalization_11[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " concatenate_1 (Concatenate  (None, 25, 25, 384)          0         ['activation_19[0][0]',       \n",
            " )                                                                   'activation_20[0][0]',       \n",
            "                                                                     'activation_21[0][0]',       \n",
            "                                                                     'activation_22[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_14 (Conv2D)          (None, 25, 25, 392)          150528    ['concatenate_1[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_12 (Ba  (None, 25, 25, 392)          1568      ['conv2d_14[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_23 (Activation)  (None, 25, 25, 392)          0         ['batch_normalization_12[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " tf.reshape_2 (TFOpLambda)   (None, 25, 25, 98, 4)        0         ['activation_23[0][0]']       \n",
            "                                                                                                  \n",
            " tf.compat.v1.transpose_1 (  (None, 25, 25, 4, 98)        0         ['tf.reshape_2[0][0]']        \n",
            " TFOpLambda)                                                                                      \n",
            "                                                                                                  \n",
            " tf.reshape_3 (TFOpLambda)   (None, 25, 25, 392)          0         ['tf.compat.v1.transpose_1[0][\n",
            "                                                                    0]']                          \n",
            "                                                                                                  \n",
            " depthwise_conv2d_1 (Depthw  (None, 25, 25, 392)          3528      ['tf.reshape_3[0][0]']        \n",
            " iseConv2D)                                                                                       \n",
            "                                                                                                  \n",
            " batch_normalization_13 (Ba  (None, 25, 25, 392)          1568      ['depthwise_conv2d_1[0][0]']  \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " conv2d_15 (Conv2D)          (None, 25, 25, 392)          153664    ['batch_normalization_13[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " batch_normalization_14 (Ba  (None, 25, 25, 392)          1568      ['conv2d_15[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_24 (Activation)  (None, 25, 25, 392)          0         ['batch_normalization_14[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_16 (Conv2D)          (None, 25, 25, 196)          76832     ['activation_24[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_17 (Conv2D)          (None, 25, 25, 196)          76832     ['activation_24[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_18 (Conv2D)          (None, 25, 25, 196)          76832     ['activation_24[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_19 (Conv2D)          (None, 25, 25, 196)          76832     ['activation_24[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_15 (Ba  (None, 25, 25, 196)          784       ['conv2d_16[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_16 (Ba  (None, 25, 25, 196)          784       ['conv2d_17[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_17 (Ba  (None, 25, 25, 196)          784       ['conv2d_18[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_18 (Ba  (None, 25, 25, 196)          784       ['conv2d_19[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_25 (Activation)  (None, 25, 25, 196)          0         ['batch_normalization_15[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " activation_26 (Activation)  (None, 25, 25, 196)          0         ['batch_normalization_16[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " activation_27 (Activation)  (None, 25, 25, 196)          0         ['batch_normalization_17[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " activation_28 (Activation)  (None, 25, 25, 196)          0         ['batch_normalization_18[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " concatenate_2 (Concatenate  (None, 25, 25, 784)          0         ['activation_25[0][0]',       \n",
            " )                                                                   'activation_26[0][0]',       \n",
            "                                                                     'activation_27[0][0]',       \n",
            "                                                                     'activation_28[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_20 (Conv2D)          (None, 25, 25, 196)          153664    ['concatenate_2[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_19 (Ba  (None, 25, 25, 196)          784       ['conv2d_20[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_29 (Activation)  (None, 25, 25, 196)          0         ['batch_normalization_19[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " tf.reshape_4 (TFOpLambda)   (None, 25, 25, 49, 4)        0         ['activation_29[0][0]']       \n",
            "                                                                                                  \n",
            " tf.compat.v1.transpose_2 (  (None, 25, 25, 4, 49)        0         ['tf.reshape_4[0][0]']        \n",
            " TFOpLambda)                                                                                      \n",
            "                                                                                                  \n",
            " tf.reshape_5 (TFOpLambda)   (None, 25, 25, 196)          0         ['tf.compat.v1.transpose_2[0][\n",
            "                                                                    0]']                          \n",
            "                                                                                                  \n",
            " depthwise_conv2d_2 (Depthw  (None, 25, 25, 196)          1764      ['tf.reshape_5[0][0]']        \n",
            " iseConv2D)                                                                                       \n",
            "                                                                                                  \n",
            " batch_normalization_20 (Ba  (None, 25, 25, 196)          784       ['depthwise_conv2d_2[0][0]']  \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " conv2d_21 (Conv2D)          (None, 25, 25, 196)          38416     ['batch_normalization_20[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " batch_normalization_21 (Ba  (None, 25, 25, 196)          784       ['conv2d_21[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_30 (Activation)  (None, 25, 25, 196)          0         ['batch_normalization_21[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " global_average_pooling2d (  (None, 196)                  0         ['activation_30[0][0]']       \n",
            " GlobalAveragePooling2D)                                                                          \n",
            "                                                                                                  \n",
            " dense_2 (Dense)             (None, 2)                    394       ['global_average_pooling2d[0][\n",
            "                                                                    0]']                          \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 1025570 (3.91 MB)\n",
            "Trainable params: 1017714 (3.88 MB)\n",
            "Non-trainable params: 7856 (30.69 KB)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "\n",
        "# Define steps per epoch and validation steps\n",
        "steps_per_epoch = len(x_train_normalized) // batch_size\n",
        "validation_steps = len(x_val_normalized) // batch_size\n",
        "\n",
        "# Train the model\n",
        "history = shufflenet_model.fit(\n",
        "    train_set_conv,\n",
        "    steps_per_epoch=steps_per_epoch,\n",
        "    epochs=25,  # You can adjust the number of epochs\n",
        "    validation_data=valid_set_conv,\n",
        "    validation_steps=validation_steps\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uy-XajMKply9",
        "outputId": "2466bfd6-aa34-4c18-a8de-8a6f52a8feae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "53/53 [==============================] - 28s 288ms/step - loss: 0.5917 - accuracy: 0.6423 - val_loss: 0.6932 - val_accuracy: 0.4888\n",
            "Epoch 2/25\n",
            "53/53 [==============================] - 13s 238ms/step - loss: 0.4121 - accuracy: 0.8180 - val_loss: 0.6938 - val_accuracy: 0.4888\n",
            "Epoch 3/25\n",
            "53/53 [==============================] - 13s 244ms/step - loss: 0.3542 - accuracy: 0.8574 - val_loss: 0.6959 - val_accuracy: 0.4844\n",
            "Epoch 4/25\n",
            "53/53 [==============================] - 13s 237ms/step - loss: 0.3245 - accuracy: 0.8695 - val_loss: 0.7004 - val_accuracy: 0.4821\n",
            "Epoch 5/25\n",
            "53/53 [==============================] - 13s 236ms/step - loss: 0.3073 - accuracy: 0.8722 - val_loss: 0.7065 - val_accuracy: 0.4888\n",
            "Epoch 6/25\n",
            "53/53 [==============================] - 13s 239ms/step - loss: 0.2985 - accuracy: 0.8787 - val_loss: 0.7226 - val_accuracy: 0.4799\n",
            "Epoch 7/25\n",
            "53/53 [==============================] - 13s 235ms/step - loss: 0.2839 - accuracy: 0.8840 - val_loss: 0.7386 - val_accuracy: 0.4777\n",
            "Epoch 8/25\n",
            "53/53 [==============================] - 13s 239ms/step - loss: 0.2769 - accuracy: 0.8896 - val_loss: 0.7341 - val_accuracy: 0.4888\n",
            "Epoch 9/25\n",
            "53/53 [==============================] - 13s 246ms/step - loss: 0.2626 - accuracy: 0.8944 - val_loss: 0.7013 - val_accuracy: 0.4866\n",
            "Epoch 10/25\n",
            "53/53 [==============================] - 13s 233ms/step - loss: 0.2583 - accuracy: 0.8982 - val_loss: 0.6029 - val_accuracy: 0.5893\n",
            "Epoch 11/25\n",
            "53/53 [==============================] - 13s 233ms/step - loss: 0.2533 - accuracy: 0.8976 - val_loss: 0.4749 - val_accuracy: 0.7344\n",
            "Epoch 12/25\n",
            "53/53 [==============================] - 13s 236ms/step - loss: 0.2471 - accuracy: 0.8992 - val_loss: 0.3991 - val_accuracy: 0.8192\n",
            "Epoch 13/25\n",
            "53/53 [==============================] - 13s 238ms/step - loss: 0.2390 - accuracy: 0.9074 - val_loss: 0.3169 - val_accuracy: 0.8616\n",
            "Epoch 14/25\n",
            "53/53 [==============================] - 12s 228ms/step - loss: 0.2335 - accuracy: 0.9047 - val_loss: 0.2874 - val_accuracy: 0.8839\n",
            "Epoch 15/25\n",
            "53/53 [==============================] - 13s 237ms/step - loss: 0.2302 - accuracy: 0.9089 - val_loss: 0.2555 - val_accuracy: 0.8951\n",
            "Epoch 16/25\n",
            "53/53 [==============================] - 13s 238ms/step - loss: 0.2247 - accuracy: 0.9080 - val_loss: 0.2751 - val_accuracy: 0.8929\n",
            "Epoch 17/25\n",
            "53/53 [==============================] - 13s 237ms/step - loss: 0.2185 - accuracy: 0.9083 - val_loss: 0.2573 - val_accuracy: 0.8996\n",
            "Epoch 18/25\n",
            "53/53 [==============================] - 13s 239ms/step - loss: 0.2125 - accuracy: 0.9142 - val_loss: 0.2414 - val_accuracy: 0.9062\n",
            "Epoch 19/25\n",
            "53/53 [==============================] - 12s 234ms/step - loss: 0.2137 - accuracy: 0.9136 - val_loss: 0.2329 - val_accuracy: 0.9107\n",
            "Epoch 20/25\n",
            "53/53 [==============================] - 12s 222ms/step - loss: 0.2043 - accuracy: 0.9189 - val_loss: 0.2447 - val_accuracy: 0.9062\n",
            "Epoch 21/25\n",
            "53/53 [==============================] - 12s 228ms/step - loss: 0.2014 - accuracy: 0.9178 - val_loss: 0.2440 - val_accuracy: 0.9040\n",
            "53/53 [==============================] - 13s 241ms/step - loss: 0.2114 - accuracy: 0.9107 - val_loss: 0.2279 - val_accuracy: 0.9107\n",
            "Epoch 23/25\n",
            "53/53 [==============================] - 12s 233ms/step - loss: 0.1979 - accuracy: 0.9183 - val_loss: 0.2509 - val_accuracy: 0.8973\n",
            "Epoch 24/25\n",
            "53/53 [==============================] - 13s 239ms/step - loss: 0.1999 - accuracy: 0.9195 - val_loss: 0.2364 - val_accuracy: 0.9085\n",
            "Epoch 25/25\n",
            "53/53 [==============================] - 13s 235ms/step - loss: 0.2001 - accuracy: 0.9160 - val_loss: 0.2489 - val_accuracy: 0.9062\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on the training data\n",
        "train_loss, train_accuracy = shufflenet_model.evaluate(train_set_conv, steps=steps_per_epoch)\n",
        "print(f\"Training Loss: {train_loss:.4f}\")\n",
        "print(f\"Training Accuracy: {train_accuracy * 100:.2f}%\")\n",
        "\n",
        "# Evaluate the model on the test data\n",
        "test_loss, test_accuracy = shufflenet_model.evaluate(test_set_conv, steps=validation_steps)\n",
        "print(f\"Test Loss: {test_loss:.4f}\")\n",
        "print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RSnmXTC0rgkf",
        "outputId": "c3803bf7-5df1-4ca1-aa39-098bee2a68c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "53/53 [==============================] - 11s 198ms/step - loss: 0.1797 - accuracy: 0.9316\n",
            "Training Loss: 0.1797\n",
            "Training Accuracy: 93.16%\n",
            "7/7 [==============================] - 0s 51ms/step - loss: 0.2356 - accuracy: 0.9152\n",
            "Test Loss: 0.2356\n",
            "Test Accuracy: 91.52%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_features = shufflenet_model.predict(x_train_normalized)\n",
        "x_val_features = shufflenet_model.predict(x_val_normalized)\n",
        "x_test_features = shufflenet_model.predict(x_test_normalized)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GGpcNLq2DZ58",
        "outputId": "1df65bf4-bb9b-40ee-f7dd-df91ed77797f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "108/108 [==============================] - 4s 25ms/step\n",
            "16/16 [==============================] - 1s 57ms/step\n",
            "31/31 [==============================] - 1s 41ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "d_Wvxch7M6UF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_features = x_train_features.reshape(x_train_features.shape[0], -1)\n",
        "x_val_features = x_val_features.reshape(x_val_features.shape[0], -1)\n",
        "x_test_features = x_test_features.reshape(x_test_features.shape[0], -1)"
      ],
      "metadata": {
        "id": "XbPLQEM5DZ7l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix"
      ],
      "metadata": {
        "id": "A-Ct9-3yDtlf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Define the parameter grid for GridSearchCV\n",
        "param_grid = {\n",
        "    'C': [0.1, 1, 10, 100],  # Example values for the regularization parameter\n",
        "    'gamma': ['scale', 'auto', 0.1, 1]  # Example values for the kernel coefficient (gamma) parameter\n",
        "}\n",
        "\n",
        "# Instantiate the SVM classifier\n",
        "svm_model = SVC(kernel='rbf')\n",
        "\n",
        "# Early stopping parameters\n",
        "max_epochs = 25  # Maximum number of epochs (iterations) to train\n",
        "patience = 5  # Number of epochs to wait for improvement\n",
        "best_accuracy = 0  # Best validation accuracy\n",
        "counter = 0  # Counter to keep track of epochs with no improvement\n",
        "\n",
        "# Training loop with early stopping and hyperparameter tuning using GridSearchCV\n",
        "for epoch in range(max_epochs):\n",
        "    # Perform grid search on your training data (x_train_features, y_train)\n",
        "    grid_search = GridSearchCV(estimator=svm_model, param_grid=param_grid, cv=3, n_jobs=-1, scoring='accuracy')\n",
        "    grid_search.fit(x_train_features, y_train)\n",
        "\n",
        "    # Get the best hyperparameters and best model\n",
        "    best_params = grid_search.best_params_\n",
        "    best_svm_model = grid_search.best_estimator_\n",
        "\n",
        "    # Validate the best model on the validation data\n",
        "    y_pred_val = best_svm_model.predict(x_val_features)\n",
        "    val_accuracy = accuracy_score(y_val, y_pred_val)\n",
        "\n",
        "    print(\"Epoch {}: Validation Accuracy: {:.4f}\".format(epoch, val_accuracy))\n",
        "\n",
        "    # Check for improvement in validation accuracy\n",
        "    if val_accuracy > best_accuracy:\n",
        "        best_accuracy = val_accuracy\n",
        "        counter = 0\n",
        "    else:\n",
        "        counter += 1\n",
        "\n",
        "    # Early stopping condition\n",
        "    if counter >= patience:\n",
        "        print(\"Early stopping after {} epochs of no improvement.\".format(epoch))\n",
        "        break\n",
        "\n",
        "# Evaluate the best model on the test data\n",
        "y_pred_svm = best_svm_model.predict(x_test_features)\n",
        "svm_accuracy = accuracy_score(y_test, y_pred_svm)\n",
        "svm_precision = precision_score(y_test, y_pred_svm)\n",
        "svm_recall = recall_score(y_test, y_pred_svm)\n",
        "svm_f1 = f1_score(y_test, y_pred_svm)\n",
        "\n",
        "tn, fp, fn, tp = confusion_matrix(y_test, y_pred_svm).ravel()\n",
        "svm_specificity = tn / (tn + fp)\n",
        "\n",
        "print(\"Best Hyperparameters:\", best_params)\n",
        "print(\"SVM Accuracy:\", svm_accuracy)\n",
        "print(\"SVM Precision:\", svm_precision)\n",
        "print(\"SVM Sensitivity (Recall):\", svm_recall)\n",
        "print(\"SVM Specificity:\", svm_specificity)\n",
        "print(\"SVM F1 Score:\", svm_f1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MlZ4CiFvEX7e",
        "outputId": "5e0ff86f-62a4-494c-cb5e-7b7fdd0b6ecf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0: Validation Accuracy: 0.9106\n",
            "Epoch 1: Validation Accuracy: 0.9106\n",
            "Epoch 2: Validation Accuracy: 0.9106\n",
            "Epoch 3: Validation Accuracy: 0.9106\n",
            "Epoch 4: Validation Accuracy: 0.9106\n",
            "Epoch 5: Validation Accuracy: 0.9106\n",
            "Early stopping after 5 epochs of no improvement.\n",
            "Best Hyperparameters: {'C': 0.1, 'gamma': 'auto'}\n",
            "SVM Accuracy: 0.9186991869918699\n",
            "SVM Precision: 0.9487704918032787\n",
            "SVM Sensitivity (Recall): 0.8938223938223938\n",
            "SVM Specificity: 0.9463519313304721\n",
            "SVM F1 Score: 0.9204771371769384\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
        "\n",
        "# Define a wider range of hyperparameters for the grid search\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'max_depth': [None, 10, 20],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4]\n",
        "}\n",
        "\n",
        "# Instantiate the Random Forest Classifier\n",
        "rf_model = RandomForestClassifier(random_state=42)\n",
        "\n",
        "# Perform Grid Search with cross-validation\n",
        "grid_search = GridSearchCV(estimator=rf_model, param_grid=param_grid, cv=3, n_jobs=-1, scoring='accuracy')\n",
        "\n",
        "# Fit the grid search to the data\n",
        "grid_search.fit(x_train_features, y_train)\n",
        "\n",
        "# Get the best hyperparameters and best model\n",
        "best_params = grid_search.best_params_\n",
        "best_rf_model = grid_search.best_estimator_\n",
        "\n",
        "# Evaluate the best model using cross-validation\n",
        "cv_scores = cross_val_score(best_rf_model, x_train_features, y_train, cv=5, scoring='accuracy')\n",
        "mean_cv_accuracy = cv_scores.mean()\n",
        "\n",
        "# Evaluate the best model on the test data\n",
        "y_pred_rf = best_rf_model.predict(x_test_features)\n",
        "rf_accuracy = accuracy_score(y_test, y_pred_rf)\n",
        "rf_precision = precision_score(y_test, y_pred_rf)\n",
        "rf_recall = recall_score(y_test, y_pred_rf)\n",
        "rf_f1 = f1_score(y_test, y_pred_rf)\n",
        "\n",
        "tn, fp, fn, tp = confusion_matrix(y_test, y_pred_rf).ravel()\n",
        "rf_specificity = tn / (tn + fp)\n",
        "\n",
        "print(\"Best Hyperparameters:\", best_params)\n",
        "print(\"Mean Cross-Validation Accuracy:\", mean_cv_accuracy)\n",
        "print(\"Random Forest Accuracy on Test Data:\", rf_accuracy)\n",
        "print(\"Random Forest Precision:\", rf_precision)\n",
        "print(\"Random Forest Sensitivity (Recall):\", rf_recall)\n",
        "print(\"Random Forest Specificity:\", rf_specificity)\n",
        "print(\"Random Forest F1 Score:\", rf_f1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nIiKeMbLGmaG",
        "outputId": "146f92c9-ee83-4af0-e841-b97b7ebce333"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Hyperparameters: {'max_depth': 10, 'min_samples_leaf': 4, 'min_samples_split': 10, 'n_estimators': 100}\n",
            "Mean Cross-Validation Accuracy: 0.9236330036790765\n",
            "Random Forest Accuracy on Test Data: 0.915650406504065\n",
            "Random Forest Precision: 0.9447852760736196\n",
            "Random Forest Sensitivity (Recall): 0.8918918918918919\n",
            "Random Forest Specificity: 0.9420600858369099\n",
            "Random Forest F1 Score: 0.9175769612711022\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "# Define a wider range of neighbors for RandomizedSearchCV\n",
        "param_dist = {\n",
        "    'n_neighbors': list(range(1, 101))  # Experiment with a wider range of neighbors (1 to 100)\n",
        "}\n",
        "\n",
        "# Instantiate the KNN Classifier\n",
        "knn_model = KNeighborsClassifier()\n",
        "\n",
        "# Perform RandomizedSearchCV\n",
        "random_search = RandomizedSearchCV(estimator=knn_model, param_distributions=param_dist, n_iter=30, cv=3, n_jobs=-1, scoring='accuracy')\n",
        "\n",
        "# Fit the randomized search to the data\n",
        "random_search.fit(x_train_features, y_train)\n",
        "\n",
        "# Get the best hyperparameters and best model\n",
        "best_params = random_search.best_params_\n",
        "best_knn_model = random_search.best_estimator_\n",
        "\n",
        "# Evaluate the best model using cross-validation\n",
        "cv_scores = cross_val_score(best_knn_model, x_train_features, y_train, cv=5, scoring='accuracy')\n",
        "mean_cv_accuracy = cv_scores.mean()\n",
        "\n",
        "# Evaluate the best model on the test data\n",
        "y_pred_knn = best_knn_model.predict(x_test_features)\n",
        "knn_accuracy = accuracy_score(y_test, y_pred_knn)\n",
        "knn_precision = precision_score(y_test, y_pred_knn)\n",
        "knn_recall = recall_score(y_test, y_pred_knn)\n",
        "knn_f1 = f1_score(y_test, y_pred_knn)\n",
        "\n",
        "tn, fp, fn, tp = confusion_matrix(y_test, y_pred_knn).ravel()\n",
        "knn_specificity = tn / (tn + fp)\n",
        "\n",
        "print(\"Best Hyperparameters:\", best_params)\n",
        "print(\"Mean Cross-Validation Accuracy:\", mean_cv_accuracy)\n",
        "print(\"KNN Accuracy on Test Data:\", knn_accuracy)\n",
        "print(\"KNN Precision:\", knn_precision)\n",
        "print(\"KNN Sensitivity (Recall):\", knn_recall)\n",
        "print(\"KNN Specificity:\", knn_specificity)\n",
        "print(\"KNN F1 Score:\", knn_f1)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PTNbp-xdH7wI",
        "outputId": "da59624e-b66d-427f-f06d-2626359d4406"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Hyperparameters: {'n_neighbors': 79}\n",
            "Mean Cross-Validation Accuracy: 0.932342542275627\n",
            "KNN Accuracy on Test Data: 0.9176829268292683\n",
            "KNN Precision: 0.945010183299389\n",
            "KNN Sensitivity (Recall): 0.8957528957528957\n",
            "KNN Specificity: 0.9420600858369099\n",
            "KNN F1 Score: 0.9197224975222993\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Conv2D, DepthwiseConv2D, BatchNormalization, ReLU, GlobalAveragePooling2D, Dense\n",
        "\n",
        "def MobileNetCustom(input_shape, num_classes):\n",
        "    input_tensor = Input(shape=input_shape)\n",
        "\n",
        "    # Initial Convolution Layer\n",
        "    x = Conv2D(32, (3, 3), strides=(2, 2), padding='same')(input_tensor)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = ReLU()(x)\n",
        "\n",
        "    # Depthwise Convolution Blocks\n",
        "    def depthwise_block(x, filters, strides):\n",
        "        x = DepthwiseConv2D((3, 3), strides=strides, padding='same')(x)\n",
        "        x = BatchNormalization()(x)\n",
        "        x = ReLU()(x)\n",
        "        x = Conv2D(filters, (1, 1), padding='same')(x)\n",
        "        x = BatchNormalization()(x)\n",
        "        x = ReLU()(x)\n",
        "        return x\n",
        "\n",
        "    x = depthwise_block(x, 64, (1, 1))\n",
        "    x = depthwise_block(x, 128, (2, 2))\n",
        "    x = depthwise_block(x, 128, (1, 1))\n",
        "    x = depthwise_block(x, 256, (2, 2))\n",
        "    x = depthwise_block(x, 256, (1, 1))\n",
        "    x = depthwise_block(x, 512, (2, 2))\n",
        "\n",
        "    # Global Average Pooling\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "\n",
        "    # Fully Connected Layer\n",
        "    x = Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "    model = tf.keras.Model(inputs=input_tensor, outputs=x)\n",
        "\n",
        "    return model\n",
        "\n",
        "input_shape = (100, 100, 3)\n",
        "num_classes = 2\n",
        "mobilenet_custom_model = MobileNetCustom(input_shape, num_classes)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.00001)\n",
        "mobilenet_custom_model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "early_stopping = EarlyStopping(monitor='val_accuracy',  # You can choose 'val_loss' or other metrics\n",
        "                               patience=10,             # Number of epochs with no improvement before stopping\n",
        "                               restore_best_weights=True)\n",
        "\n",
        "mobilenet_custom_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1GezI2g6tAaz",
        "outputId": "1ecb3210-67b8-4e48-cc20-de823dda3260"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_7 (InputLayer)        [(None, 100, 100, 3)]     0         \n",
            "                                                                 \n",
            " conv2d_22 (Conv2D)          (None, 50, 50, 32)        896       \n",
            "                                                                 \n",
            " batch_normalization_22 (Ba  (None, 50, 50, 32)        128       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " re_lu (ReLU)                (None, 50, 50, 32)        0         \n",
            "                                                                 \n",
            " depthwise_conv2d_3 (Depthw  (None, 50, 50, 32)        320       \n",
            " iseConv2D)                                                      \n",
            "                                                                 \n",
            " batch_normalization_23 (Ba  (None, 50, 50, 32)        128       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " re_lu_1 (ReLU)              (None, 50, 50, 32)        0         \n",
            "                                                                 \n",
            " conv2d_23 (Conv2D)          (None, 50, 50, 64)        2112      \n",
            "                                                                 \n",
            " batch_normalization_24 (Ba  (None, 50, 50, 64)        256       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " re_lu_2 (ReLU)              (None, 50, 50, 64)        0         \n",
            "                                                                 \n",
            " depthwise_conv2d_4 (Depthw  (None, 25, 25, 64)        640       \n",
            " iseConv2D)                                                      \n",
            "                                                                 \n",
            " batch_normalization_25 (Ba  (None, 25, 25, 64)        256       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " re_lu_3 (ReLU)              (None, 25, 25, 64)        0         \n",
            "                                                                 \n",
            " conv2d_24 (Conv2D)          (None, 25, 25, 128)       8320      \n",
            "                                                                 \n",
            " batch_normalization_26 (Ba  (None, 25, 25, 128)       512       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " re_lu_4 (ReLU)              (None, 25, 25, 128)       0         \n",
            "                                                                 \n",
            " depthwise_conv2d_5 (Depthw  (None, 25, 25, 128)       1280      \n",
            " iseConv2D)                                                      \n",
            "                                                                 \n",
            " batch_normalization_27 (Ba  (None, 25, 25, 128)       512       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " re_lu_5 (ReLU)              (None, 25, 25, 128)       0         \n",
            "                                                                 \n",
            " conv2d_25 (Conv2D)          (None, 25, 25, 128)       16512     \n",
            "                                                                 \n",
            " batch_normalization_28 (Ba  (None, 25, 25, 128)       512       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " re_lu_6 (ReLU)              (None, 25, 25, 128)       0         \n",
            "                                                                 \n",
            " depthwise_conv2d_6 (Depthw  (None, 13, 13, 128)       1280      \n",
            " iseConv2D)                                                      \n",
            "                                                                 \n",
            " batch_normalization_29 (Ba  (None, 13, 13, 128)       512       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " re_lu_7 (ReLU)              (None, 13, 13, 128)       0         \n",
            "                                                                 \n",
            " conv2d_26 (Conv2D)          (None, 13, 13, 256)       33024     \n",
            "                                                                 \n",
            " batch_normalization_30 (Ba  (None, 13, 13, 256)       1024      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " re_lu_8 (ReLU)              (None, 13, 13, 256)       0         \n",
            "                                                                 \n",
            " depthwise_conv2d_7 (Depthw  (None, 13, 13, 256)       2560      \n",
            " iseConv2D)                                                      \n",
            "                                                                 \n",
            " batch_normalization_31 (Ba  (None, 13, 13, 256)       1024      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " re_lu_9 (ReLU)              (None, 13, 13, 256)       0         \n",
            "                                                                 \n",
            " conv2d_27 (Conv2D)          (None, 13, 13, 256)       65792     \n",
            "                                                                 \n",
            " batch_normalization_32 (Ba  (None, 13, 13, 256)       1024      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " re_lu_10 (ReLU)             (None, 13, 13, 256)       0         \n",
            "                                                                 \n",
            " depthwise_conv2d_8 (Depthw  (None, 7, 7, 256)         2560      \n",
            " iseConv2D)                                                      \n",
            "                                                                 \n",
            " batch_normalization_33 (Ba  (None, 7, 7, 256)         1024      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " re_lu_11 (ReLU)             (None, 7, 7, 256)         0         \n",
            "                                                                 \n",
            " conv2d_28 (Conv2D)          (None, 7, 7, 512)         131584    \n",
            "                                                                 \n",
            " batch_normalization_34 (Ba  (None, 7, 7, 512)         2048      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " re_lu_12 (ReLU)             (None, 7, 7, 512)         0         \n",
            "                                                                 \n",
            " global_average_pooling2d_1  (None, 512)               0         \n",
            "  (GlobalAveragePooling2D)                                       \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 2)                 1026      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 276866 (1.06 MB)\n",
            "Trainable params: 272386 (1.04 MB)\n",
            "Non-trainable params: 4480 (17.50 KB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# Define early stopping callback\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "\n",
        "# Perform hyperparameter tuning with early stopping\n",
        "best_accuracy = 0\n",
        "best_hyperparameters = None\n",
        "\n",
        "for epoch in range(25):\n",
        "    # Train the model with the current hyperparameters\n",
        "    training_history = mobilenet_custom_model.fit(\n",
        "        train_set_conv,\n",
        "        steps_per_epoch=steps_per_epoch,\n",
        "        epochs=1,  # Train for one epoch at a time\n",
        "        validation_data=valid_set_conv,\n",
        "        validation_steps=validation_steps,\n",
        "        callbacks=[early_stopping]\n",
        "    )\n",
        "\n",
        "    # Get the validation accuracy from the training history\n",
        "    val_accuracy = training_history.history['val_accuracy'][0]\n",
        "\n",
        "    # Check for improvement in validation accuracy\n",
        "    if val_accuracy > best_accuracy:\n",
        "        best_accuracy = val_accuracy\n",
        "        best_hyperparameters = mobilenet_custom_model.get_config()  # Save the best hyperparameters\n",
        "\n",
        "    print(\"Epoch {}: Validation Accuracy: {:.4f}\".format(epoch, val_accuracy))\n",
        "\n",
        "    # Early stopping condition\n",
        "    if early_stopping.stopped_epoch > 0:\n",
        "        print(\"Early stopping after {} epochs of no improvement.\".format(early_stopping.stopped_epoch))\n",
        "        break\n",
        "\n",
        "# Evaluate the model with the best hyperparameters on the test data\n",
        "test_accuracy = mobilenet_custom_model.evaluate(test_set_conv)[1]\n",
        "print(\"Best Validation Accuracy:\", best_accuracy)\n",
        "print(\"Test Accuracy with Best Hyperparameters:\", test_accuracy)\n",
        "print(\"Best Hyperparameters:\", best_hyperparameters)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ey745hVWtjTE",
        "outputId": "ce426590-d4bc-4672-df69-2d94400e6f2f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "53/53 [==============================] - 20s 214ms/step - loss: 0.6716 - accuracy: 0.5186 - val_loss: 0.6933 - val_accuracy: 0.4844\n",
            "Epoch 0: Validation Accuracy: 0.4844\n",
            "53/53 [==============================] - 11s 208ms/step - loss: 0.5662 - accuracy: 0.7130 - val_loss: 0.6969 - val_accuracy: 0.4911\n",
            "Epoch 1: Validation Accuracy: 0.4911\n",
            "53/53 [==============================] - 11s 198ms/step - loss: 0.5049 - accuracy: 0.8000 - val_loss: 0.7113 - val_accuracy: 0.4866\n",
            "Epoch 2: Validation Accuracy: 0.4866\n",
            "53/53 [==============================] - 10s 198ms/step - loss: 0.4618 - accuracy: 0.8228 - val_loss: 0.7309 - val_accuracy: 0.4888\n",
            "Epoch 3: Validation Accuracy: 0.4888\n",
            "53/53 [==============================] - 10s 179ms/step - loss: 0.4199 - accuracy: 0.8379 - val_loss: 0.7684 - val_accuracy: 0.4732\n",
            "Epoch 4: Validation Accuracy: 0.4732\n",
            "53/53 [==============================] - 10s 190ms/step - loss: 0.3987 - accuracy: 0.8396 - val_loss: 0.7821 - val_accuracy: 0.4933\n",
            "Epoch 5: Validation Accuracy: 0.4933\n",
            "53/53 [==============================] - 10s 197ms/step - loss: 0.3745 - accuracy: 0.8497 - val_loss: 0.8250 - val_accuracy: 0.4844\n",
            "Epoch 6: Validation Accuracy: 0.4844\n",
            "53/53 [==============================] - 11s 204ms/step - loss: 0.3601 - accuracy: 0.8559 - val_loss: 0.8538 - val_accuracy: 0.4955\n",
            "Epoch 7: Validation Accuracy: 0.4955\n",
            "53/53 [==============================] - 10s 192ms/step - loss: 0.3460 - accuracy: 0.8615 - val_loss: 0.9286 - val_accuracy: 0.4888\n",
            "Epoch 8: Validation Accuracy: 0.4888\n",
            "53/53 [==============================] - 11s 198ms/step - loss: 0.3325 - accuracy: 0.8657 - val_loss: 0.9955 - val_accuracy: 0.4732\n",
            "Epoch 9: Validation Accuracy: 0.4732\n",
            "53/53 [==============================] - 11s 200ms/step - loss: 0.3258 - accuracy: 0.8636 - val_loss: 0.8889 - val_accuracy: 0.4911\n",
            "Epoch 10: Validation Accuracy: 0.4911\n",
            "53/53 [==============================] - 11s 205ms/step - loss: 0.3164 - accuracy: 0.8725 - val_loss: 0.6962 - val_accuracy: 0.5424\n",
            "Epoch 11: Validation Accuracy: 0.5424\n",
            "53/53 [==============================] - 10s 187ms/step - loss: 0.3124 - accuracy: 0.8707 - val_loss: 0.4933 - val_accuracy: 0.7388\n",
            "Epoch 12: Validation Accuracy: 0.7388\n",
            "53/53 [==============================] - 9s 172ms/step - loss: 0.3063 - accuracy: 0.8686 - val_loss: 0.3762 - val_accuracy: 0.8237\n",
            "Epoch 13: Validation Accuracy: 0.8237\n",
            "53/53 [==============================] - 11s 199ms/step - loss: 0.3024 - accuracy: 0.8787 - val_loss: 0.3319 - val_accuracy: 0.8594\n",
            "Epoch 14: Validation Accuracy: 0.8594\n",
            "53/53 [==============================] - 11s 202ms/step - loss: 0.2950 - accuracy: 0.8781 - val_loss: 0.2911 - val_accuracy: 0.8884\n",
            "Epoch 15: Validation Accuracy: 0.8884\n",
            "53/53 [==============================] - 9s 178ms/step - loss: 0.2919 - accuracy: 0.8787 - val_loss: 0.2730 - val_accuracy: 0.8862\n",
            "Epoch 16: Validation Accuracy: 0.8862\n",
            "53/53 [==============================] - 10s 179ms/step - loss: 0.2820 - accuracy: 0.8870 - val_loss: 0.2795 - val_accuracy: 0.8862\n",
            "Epoch 17: Validation Accuracy: 0.8862\n",
            "53/53 [==============================] - 10s 197ms/step - loss: 0.2751 - accuracy: 0.8932 - val_loss: 0.2836 - val_accuracy: 0.8839\n",
            "Epoch 18: Validation Accuracy: 0.8839\n",
            "53/53 [==============================] - 10s 198ms/step - loss: 0.2756 - accuracy: 0.8855 - val_loss: 0.2793 - val_accuracy: 0.8906\n",
            "Epoch 19: Validation Accuracy: 0.8906\n",
            "53/53 [==============================] - 11s 204ms/step - loss: 0.2762 - accuracy: 0.8822 - val_loss: 0.2677 - val_accuracy: 0.8929\n",
            "Epoch 20: Validation Accuracy: 0.8929\n",
            "53/53 [==============================] - 10s 187ms/step - loss: 0.2681 - accuracy: 0.8932 - val_loss: 0.2656 - val_accuracy: 0.8973\n",
            "Epoch 21: Validation Accuracy: 0.8973\n",
            "53/53 [==============================] - 11s 201ms/step - loss: 0.2657 - accuracy: 0.8938 - val_loss: 0.2547 - val_accuracy: 0.8973\n",
            "Epoch 22: Validation Accuracy: 0.8973\n",
            "53/53 [==============================] - 10s 195ms/step - loss: 0.2688 - accuracy: 0.8935 - val_loss: 0.2632 - val_accuracy: 0.8951\n",
            "Epoch 23: Validation Accuracy: 0.8951\n",
            "53/53 [==============================] - 10s 195ms/step - loss: 0.2632 - accuracy: 0.8967 - val_loss: 0.2596 - val_accuracy: 0.8951\n",
            "Epoch 24: Validation Accuracy: 0.8951\n",
            "16/16 [==============================] - 1s 43ms/step - loss: 0.2698 - accuracy: 0.8882\n",
            "Best Validation Accuracy: 0.8973214030265808\n",
            "Test Accuracy with Best Hyperparameters: 0.8882113695144653\n",
            "Best Hyperparameters: {'name': 'model_2', 'trainable': True, 'layers': [{'module': 'keras.layers', 'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 100, 100, 3), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'input_7'}, 'registered_name': None, 'name': 'input_7', 'inbound_nodes': []}, {'module': 'keras.layers', 'class_name': 'Conv2D', 'config': {'name': 'conv2d_22', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (3, 3), 'strides': (2, 2), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'module': 'keras.initializers', 'class_name': 'GlorotUniform', 'config': {'seed': None}, 'registered_name': None}, 'bias_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}, 'registered_name': None, 'build_config': {'input_shape': (None, 100, 100, 3)}, 'name': 'conv2d_22', 'inbound_nodes': [[['input_7', 0, 0, {}]]]}, {'module': 'keras.layers', 'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_22', 'trainable': True, 'dtype': 'float32', 'axis': [3], 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'gamma_initializer': {'module': 'keras.initializers', 'class_name': 'Ones', 'config': {}, 'registered_name': None}, 'moving_mean_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'moving_variance_initializer': {'module': 'keras.initializers', 'class_name': 'Ones', 'config': {}, 'registered_name': None}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}, 'registered_name': None, 'build_config': {'input_shape': (None, 50, 50, 32)}, 'name': 'batch_normalization_22', 'inbound_nodes': [[['conv2d_22', 0, 0, {}]]]}, {'module': 'keras.layers', 'class_name': 'ReLU', 'config': {'name': 're_lu', 'trainable': True, 'dtype': 'float32', 'max_value': None, 'negative_slope': 0.0, 'threshold': 0.0}, 'registered_name': None, 'build_config': {'input_shape': (None, 50, 50, 32)}, 'name': 're_lu', 'inbound_nodes': [[['batch_normalization_22', 0, 0, {}]]]}, {'module': 'keras.layers', 'class_name': 'DepthwiseConv2D', 'config': {'name': 'depthwise_conv2d_3', 'trainable': True, 'dtype': 'float32', 'kernel_size': (3, 3), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'linear', 'use_bias': True, 'bias_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'bias_regularizer': None, 'activity_regularizer': None, 'bias_constraint': None, 'depth_multiplier': 1, 'depthwise_initializer': {'module': 'keras.initializers', 'class_name': 'GlorotUniform', 'config': {'seed': None}, 'registered_name': None}, 'depthwise_regularizer': None, 'depthwise_constraint': None}, 'registered_name': None, 'build_config': {'input_shape': (None, 50, 50, 32)}, 'name': 'depthwise_conv2d_3', 'inbound_nodes': [[['re_lu', 0, 0, {}]]]}, {'module': 'keras.layers', 'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_23', 'trainable': True, 'dtype': 'float32', 'axis': [3], 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'gamma_initializer': {'module': 'keras.initializers', 'class_name': 'Ones', 'config': {}, 'registered_name': None}, 'moving_mean_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'moving_variance_initializer': {'module': 'keras.initializers', 'class_name': 'Ones', 'config': {}, 'registered_name': None}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}, 'registered_name': None, 'build_config': {'input_shape': (None, 50, 50, 32)}, 'name': 'batch_normalization_23', 'inbound_nodes': [[['depthwise_conv2d_3', 0, 0, {}]]]}, {'module': 'keras.layers', 'class_name': 'ReLU', 'config': {'name': 're_lu_1', 'trainable': True, 'dtype': 'float32', 'max_value': None, 'negative_slope': 0.0, 'threshold': 0.0}, 'registered_name': None, 'build_config': {'input_shape': (None, 50, 50, 32)}, 'name': 're_lu_1', 'inbound_nodes': [[['batch_normalization_23', 0, 0, {}]]]}, {'module': 'keras.layers', 'class_name': 'Conv2D', 'config': {'name': 'conv2d_23', 'trainable': True, 'dtype': 'float32', 'filters': 64, 'kernel_size': (1, 1), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'module': 'keras.initializers', 'class_name': 'GlorotUniform', 'config': {'seed': None}, 'registered_name': None}, 'bias_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}, 'registered_name': None, 'build_config': {'input_shape': (None, 50, 50, 32)}, 'name': 'conv2d_23', 'inbound_nodes': [[['re_lu_1', 0, 0, {}]]]}, {'module': 'keras.layers', 'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_24', 'trainable': True, 'dtype': 'float32', 'axis': [3], 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'gamma_initializer': {'module': 'keras.initializers', 'class_name': 'Ones', 'config': {}, 'registered_name': None}, 'moving_mean_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'moving_variance_initializer': {'module': 'keras.initializers', 'class_name': 'Ones', 'config': {}, 'registered_name': None}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}, 'registered_name': None, 'build_config': {'input_shape': (None, 50, 50, 64)}, 'name': 'batch_normalization_24', 'inbound_nodes': [[['conv2d_23', 0, 0, {}]]]}, {'module': 'keras.layers', 'class_name': 'ReLU', 'config': {'name': 're_lu_2', 'trainable': True, 'dtype': 'float32', 'max_value': None, 'negative_slope': 0.0, 'threshold': 0.0}, 'registered_name': None, 'build_config': {'input_shape': (None, 50, 50, 64)}, 'name': 're_lu_2', 'inbound_nodes': [[['batch_normalization_24', 0, 0, {}]]]}, {'module': 'keras.layers', 'class_name': 'DepthwiseConv2D', 'config': {'name': 'depthwise_conv2d_4', 'trainable': True, 'dtype': 'float32', 'kernel_size': (3, 3), 'strides': (2, 2), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'linear', 'use_bias': True, 'bias_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'bias_regularizer': None, 'activity_regularizer': None, 'bias_constraint': None, 'depth_multiplier': 1, 'depthwise_initializer': {'module': 'keras.initializers', 'class_name': 'GlorotUniform', 'config': {'seed': None}, 'registered_name': None}, 'depthwise_regularizer': None, 'depthwise_constraint': None}, 'registered_name': None, 'build_config': {'input_shape': (None, 50, 50, 64)}, 'name': 'depthwise_conv2d_4', 'inbound_nodes': [[['re_lu_2', 0, 0, {}]]]}, {'module': 'keras.layers', 'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_25', 'trainable': True, 'dtype': 'float32', 'axis': [3], 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'gamma_initializer': {'module': 'keras.initializers', 'class_name': 'Ones', 'config': {}, 'registered_name': None}, 'moving_mean_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'moving_variance_initializer': {'module': 'keras.initializers', 'class_name': 'Ones', 'config': {}, 'registered_name': None}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}, 'registered_name': None, 'build_config': {'input_shape': (None, 25, 25, 64)}, 'name': 'batch_normalization_25', 'inbound_nodes': [[['depthwise_conv2d_4', 0, 0, {}]]]}, {'module': 'keras.layers', 'class_name': 'ReLU', 'config': {'name': 're_lu_3', 'trainable': True, 'dtype': 'float32', 'max_value': None, 'negative_slope': 0.0, 'threshold': 0.0}, 'registered_name': None, 'build_config': {'input_shape': (None, 25, 25, 64)}, 'name': 're_lu_3', 'inbound_nodes': [[['batch_normalization_25', 0, 0, {}]]]}, {'module': 'keras.layers', 'class_name': 'Conv2D', 'config': {'name': 'conv2d_24', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (1, 1), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'module': 'keras.initializers', 'class_name': 'GlorotUniform', 'config': {'seed': None}, 'registered_name': None}, 'bias_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}, 'registered_name': None, 'build_config': {'input_shape': (None, 25, 25, 64)}, 'name': 'conv2d_24', 'inbound_nodes': [[['re_lu_3', 0, 0, {}]]]}, {'module': 'keras.layers', 'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_26', 'trainable': True, 'dtype': 'float32', 'axis': [3], 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'gamma_initializer': {'module': 'keras.initializers', 'class_name': 'Ones', 'config': {}, 'registered_name': None}, 'moving_mean_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'moving_variance_initializer': {'module': 'keras.initializers', 'class_name': 'Ones', 'config': {}, 'registered_name': None}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}, 'registered_name': None, 'build_config': {'input_shape': (None, 25, 25, 128)}, 'name': 'batch_normalization_26', 'inbound_nodes': [[['conv2d_24', 0, 0, {}]]]}, {'module': 'keras.layers', 'class_name': 'ReLU', 'config': {'name': 're_lu_4', 'trainable': True, 'dtype': 'float32', 'max_value': None, 'negative_slope': 0.0, 'threshold': 0.0}, 'registered_name': None, 'build_config': {'input_shape': (None, 25, 25, 128)}, 'name': 're_lu_4', 'inbound_nodes': [[['batch_normalization_26', 0, 0, {}]]]}, {'module': 'keras.layers', 'class_name': 'DepthwiseConv2D', 'config': {'name': 'depthwise_conv2d_5', 'trainable': True, 'dtype': 'float32', 'kernel_size': (3, 3), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'linear', 'use_bias': True, 'bias_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'bias_regularizer': None, 'activity_regularizer': None, 'bias_constraint': None, 'depth_multiplier': 1, 'depthwise_initializer': {'module': 'keras.initializers', 'class_name': 'GlorotUniform', 'config': {'seed': None}, 'registered_name': None}, 'depthwise_regularizer': None, 'depthwise_constraint': None}, 'registered_name': None, 'build_config': {'input_shape': (None, 25, 25, 128)}, 'name': 'depthwise_conv2d_5', 'inbound_nodes': [[['re_lu_4', 0, 0, {}]]]}, {'module': 'keras.layers', 'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_27', 'trainable': True, 'dtype': 'float32', 'axis': [3], 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'gamma_initializer': {'module': 'keras.initializers', 'class_name': 'Ones', 'config': {}, 'registered_name': None}, 'moving_mean_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'moving_variance_initializer': {'module': 'keras.initializers', 'class_name': 'Ones', 'config': {}, 'registered_name': None}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}, 'registered_name': None, 'build_config': {'input_shape': (None, 25, 25, 128)}, 'name': 'batch_normalization_27', 'inbound_nodes': [[['depthwise_conv2d_5', 0, 0, {}]]]}, {'module': 'keras.layers', 'class_name': 'ReLU', 'config': {'name': 're_lu_5', 'trainable': True, 'dtype': 'float32', 'max_value': None, 'negative_slope': 0.0, 'threshold': 0.0}, 'registered_name': None, 'build_config': {'input_shape': (None, 25, 25, 128)}, 'name': 're_lu_5', 'inbound_nodes': [[['batch_normalization_27', 0, 0, {}]]]}, {'module': 'keras.layers', 'class_name': 'Conv2D', 'config': {'name': 'conv2d_25', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (1, 1), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'module': 'keras.initializers', 'class_name': 'GlorotUniform', 'config': {'seed': None}, 'registered_name': None}, 'bias_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}, 'registered_name': None, 'build_config': {'input_shape': (None, 25, 25, 128)}, 'name': 'conv2d_25', 'inbound_nodes': [[['re_lu_5', 0, 0, {}]]]}, {'module': 'keras.layers', 'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_28', 'trainable': True, 'dtype': 'float32', 'axis': [3], 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'gamma_initializer': {'module': 'keras.initializers', 'class_name': 'Ones', 'config': {}, 'registered_name': None}, 'moving_mean_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'moving_variance_initializer': {'module': 'keras.initializers', 'class_name': 'Ones', 'config': {}, 'registered_name': None}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}, 'registered_name': None, 'build_config': {'input_shape': (None, 25, 25, 128)}, 'name': 'batch_normalization_28', 'inbound_nodes': [[['conv2d_25', 0, 0, {}]]]}, {'module': 'keras.layers', 'class_name': 'ReLU', 'config': {'name': 're_lu_6', 'trainable': True, 'dtype': 'float32', 'max_value': None, 'negative_slope': 0.0, 'threshold': 0.0}, 'registered_name': None, 'build_config': {'input_shape': (None, 25, 25, 128)}, 'name': 're_lu_6', 'inbound_nodes': [[['batch_normalization_28', 0, 0, {}]]]}, {'module': 'keras.layers', 'class_name': 'DepthwiseConv2D', 'config': {'name': 'depthwise_conv2d_6', 'trainable': True, 'dtype': 'float32', 'kernel_size': (3, 3), 'strides': (2, 2), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'linear', 'use_bias': True, 'bias_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'bias_regularizer': None, 'activity_regularizer': None, 'bias_constraint': None, 'depth_multiplier': 1, 'depthwise_initializer': {'module': 'keras.initializers', 'class_name': 'GlorotUniform', 'config': {'seed': None}, 'registered_name': None}, 'depthwise_regularizer': None, 'depthwise_constraint': None}, 'registered_name': None, 'build_config': {'input_shape': (None, 25, 25, 128)}, 'name': 'depthwise_conv2d_6', 'inbound_nodes': [[['re_lu_6', 0, 0, {}]]]}, {'module': 'keras.layers', 'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_29', 'trainable': True, 'dtype': 'float32', 'axis': [3], 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'gamma_initializer': {'module': 'keras.initializers', 'class_name': 'Ones', 'config': {}, 'registered_name': None}, 'moving_mean_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'moving_variance_initializer': {'module': 'keras.initializers', 'class_name': 'Ones', 'config': {}, 'registered_name': None}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}, 'registered_name': None, 'build_config': {'input_shape': (None, 13, 13, 128)}, 'name': 'batch_normalization_29', 'inbound_nodes': [[['depthwise_conv2d_6', 0, 0, {}]]]}, {'module': 'keras.layers', 'class_name': 'ReLU', 'config': {'name': 're_lu_7', 'trainable': True, 'dtype': 'float32', 'max_value': None, 'negative_slope': 0.0, 'threshold': 0.0}, 'registered_name': None, 'build_config': {'input_shape': (None, 13, 13, 128)}, 'name': 're_lu_7', 'inbound_nodes': [[['batch_normalization_29', 0, 0, {}]]]}, {'module': 'keras.layers', 'class_name': 'Conv2D', 'config': {'name': 'conv2d_26', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (1, 1), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'module': 'keras.initializers', 'class_name': 'GlorotUniform', 'config': {'seed': None}, 'registered_name': None}, 'bias_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}, 'registered_name': None, 'build_config': {'input_shape': (None, 13, 13, 128)}, 'name': 'conv2d_26', 'inbound_nodes': [[['re_lu_7', 0, 0, {}]]]}, {'module': 'keras.layers', 'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_30', 'trainable': True, 'dtype': 'float32', 'axis': [3], 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'gamma_initializer': {'module': 'keras.initializers', 'class_name': 'Ones', 'config': {}, 'registered_name': None}, 'moving_mean_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'moving_variance_initializer': {'module': 'keras.initializers', 'class_name': 'Ones', 'config': {}, 'registered_name': None}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}, 'registered_name': None, 'build_config': {'input_shape': (None, 13, 13, 256)}, 'name': 'batch_normalization_30', 'inbound_nodes': [[['conv2d_26', 0, 0, {}]]]}, {'module': 'keras.layers', 'class_name': 'ReLU', 'config': {'name': 're_lu_8', 'trainable': True, 'dtype': 'float32', 'max_value': None, 'negative_slope': 0.0, 'threshold': 0.0}, 'registered_name': None, 'build_config': {'input_shape': (None, 13, 13, 256)}, 'name': 're_lu_8', 'inbound_nodes': [[['batch_normalization_30', 0, 0, {}]]]}, {'module': 'keras.layers', 'class_name': 'DepthwiseConv2D', 'config': {'name': 'depthwise_conv2d_7', 'trainable': True, 'dtype': 'float32', 'kernel_size': (3, 3), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'linear', 'use_bias': True, 'bias_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'bias_regularizer': None, 'activity_regularizer': None, 'bias_constraint': None, 'depth_multiplier': 1, 'depthwise_initializer': {'module': 'keras.initializers', 'class_name': 'GlorotUniform', 'config': {'seed': None}, 'registered_name': None}, 'depthwise_regularizer': None, 'depthwise_constraint': None}, 'registered_name': None, 'build_config': {'input_shape': (None, 13, 13, 256)}, 'name': 'depthwise_conv2d_7', 'inbound_nodes': [[['re_lu_8', 0, 0, {}]]]}, {'module': 'keras.layers', 'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_31', 'trainable': True, 'dtype': 'float32', 'axis': [3], 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'gamma_initializer': {'module': 'keras.initializers', 'class_name': 'Ones', 'config': {}, 'registered_name': None}, 'moving_mean_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'moving_variance_initializer': {'module': 'keras.initializers', 'class_name': 'Ones', 'config': {}, 'registered_name': None}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}, 'registered_name': None, 'build_config': {'input_shape': (None, 13, 13, 256)}, 'name': 'batch_normalization_31', 'inbound_nodes': [[['depthwise_conv2d_7', 0, 0, {}]]]}, {'module': 'keras.layers', 'class_name': 'ReLU', 'config': {'name': 're_lu_9', 'trainable': True, 'dtype': 'float32', 'max_value': None, 'negative_slope': 0.0, 'threshold': 0.0}, 'registered_name': None, 'build_config': {'input_shape': (None, 13, 13, 256)}, 'name': 're_lu_9', 'inbound_nodes': [[['batch_normalization_31', 0, 0, {}]]]}, {'module': 'keras.layers', 'class_name': 'Conv2D', 'config': {'name': 'conv2d_27', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (1, 1), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'module': 'keras.initializers', 'class_name': 'GlorotUniform', 'config': {'seed': None}, 'registered_name': None}, 'bias_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}, 'registered_name': None, 'build_config': {'input_shape': (None, 13, 13, 256)}, 'name': 'conv2d_27', 'inbound_nodes': [[['re_lu_9', 0, 0, {}]]]}, {'module': 'keras.layers', 'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_32', 'trainable': True, 'dtype': 'float32', 'axis': [3], 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'gamma_initializer': {'module': 'keras.initializers', 'class_name': 'Ones', 'config': {}, 'registered_name': None}, 'moving_mean_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'moving_variance_initializer': {'module': 'keras.initializers', 'class_name': 'Ones', 'config': {}, 'registered_name': None}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}, 'registered_name': None, 'build_config': {'input_shape': (None, 13, 13, 256)}, 'name': 'batch_normalization_32', 'inbound_nodes': [[['conv2d_27', 0, 0, {}]]]}, {'module': 'keras.layers', 'class_name': 'ReLU', 'config': {'name': 're_lu_10', 'trainable': True, 'dtype': 'float32', 'max_value': None, 'negative_slope': 0.0, 'threshold': 0.0}, 'registered_name': None, 'build_config': {'input_shape': (None, 13, 13, 256)}, 'name': 're_lu_10', 'inbound_nodes': [[['batch_normalization_32', 0, 0, {}]]]}, {'module': 'keras.layers', 'class_name': 'DepthwiseConv2D', 'config': {'name': 'depthwise_conv2d_8', 'trainable': True, 'dtype': 'float32', 'kernel_size': (3, 3), 'strides': (2, 2), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'linear', 'use_bias': True, 'bias_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'bias_regularizer': None, 'activity_regularizer': None, 'bias_constraint': None, 'depth_multiplier': 1, 'depthwise_initializer': {'module': 'keras.initializers', 'class_name': 'GlorotUniform', 'config': {'seed': None}, 'registered_name': None}, 'depthwise_regularizer': None, 'depthwise_constraint': None}, 'registered_name': None, 'build_config': {'input_shape': (None, 13, 13, 256)}, 'name': 'depthwise_conv2d_8', 'inbound_nodes': [[['re_lu_10', 0, 0, {}]]]}, {'module': 'keras.layers', 'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_33', 'trainable': True, 'dtype': 'float32', 'axis': [3], 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'gamma_initializer': {'module': 'keras.initializers', 'class_name': 'Ones', 'config': {}, 'registered_name': None}, 'moving_mean_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'moving_variance_initializer': {'module': 'keras.initializers', 'class_name': 'Ones', 'config': {}, 'registered_name': None}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}, 'registered_name': None, 'build_config': {'input_shape': (None, 7, 7, 256)}, 'name': 'batch_normalization_33', 'inbound_nodes': [[['depthwise_conv2d_8', 0, 0, {}]]]}, {'module': 'keras.layers', 'class_name': 'ReLU', 'config': {'name': 're_lu_11', 'trainable': True, 'dtype': 'float32', 'max_value': None, 'negative_slope': 0.0, 'threshold': 0.0}, 'registered_name': None, 'build_config': {'input_shape': (None, 7, 7, 256)}, 'name': 're_lu_11', 'inbound_nodes': [[['batch_normalization_33', 0, 0, {}]]]}, {'module': 'keras.layers', 'class_name': 'Conv2D', 'config': {'name': 'conv2d_28', 'trainable': True, 'dtype': 'float32', 'filters': 512, 'kernel_size': (1, 1), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'module': 'keras.initializers', 'class_name': 'GlorotUniform', 'config': {'seed': None}, 'registered_name': None}, 'bias_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}, 'registered_name': None, 'build_config': {'input_shape': (None, 7, 7, 256)}, 'name': 'conv2d_28', 'inbound_nodes': [[['re_lu_11', 0, 0, {}]]]}, {'module': 'keras.layers', 'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_34', 'trainable': True, 'dtype': 'float32', 'axis': [3], 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'gamma_initializer': {'module': 'keras.initializers', 'class_name': 'Ones', 'config': {}, 'registered_name': None}, 'moving_mean_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'moving_variance_initializer': {'module': 'keras.initializers', 'class_name': 'Ones', 'config': {}, 'registered_name': None}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}, 'registered_name': None, 'build_config': {'input_shape': (None, 7, 7, 512)}, 'name': 'batch_normalization_34', 'inbound_nodes': [[['conv2d_28', 0, 0, {}]]]}, {'module': 'keras.layers', 'class_name': 'ReLU', 'config': {'name': 're_lu_12', 'trainable': True, 'dtype': 'float32', 'max_value': None, 'negative_slope': 0.0, 'threshold': 0.0}, 'registered_name': None, 'build_config': {'input_shape': (None, 7, 7, 512)}, 'name': 're_lu_12', 'inbound_nodes': [[['batch_normalization_34', 0, 0, {}]]]}, {'module': 'keras.layers', 'class_name': 'GlobalAveragePooling2D', 'config': {'name': 'global_average_pooling2d_1', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last', 'keepdims': False}, 'registered_name': None, 'build_config': {'input_shape': (None, 7, 7, 512)}, 'name': 'global_average_pooling2d_1', 'inbound_nodes': [[['re_lu_12', 0, 0, {}]]]}, {'module': 'keras.layers', 'class_name': 'Dense', 'config': {'name': 'dense_3', 'trainable': True, 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'module': 'keras.initializers', 'class_name': 'GlorotUniform', 'config': {'seed': None}, 'registered_name': None}, 'bias_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}, 'registered_name': None, 'build_config': {'input_shape': (None, 512)}, 'name': 'dense_3', 'inbound_nodes': [[['global_average_pooling2d_1', 0, 0, {}]]]}], 'input_layers': [['input_7', 0, 0]], 'output_layers': [['dense_3', 0, 0]]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on the training data\n",
        "train_loss, train_accuracy = mobilenet_custom_model.evaluate(train_set_conv, steps=steps_per_epoch)\n",
        "print(f\"Training Loss: {train_loss:.4f}\")\n",
        "print(f\"Training Accuracy: {train_accuracy * 100:.2f}%\")\n",
        "\n",
        "# Evaluate the model on the test data\n",
        "test_loss, test_accuracy = mobilenet_custom_model.evaluate(test_set_conv, steps=validation_steps)\n",
        "print(f\"Test Loss: {test_loss:.4f}\")\n",
        "print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Le26pi9MvEY7",
        "outputId": "e75eaf36-cd1e-4e01-e1ca-7ae37fee1034"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "53/53 [==============================] - 10s 181ms/step - loss: 0.2502 - accuracy: 0.9021\n",
            "Training Loss: 0.2502\n",
            "Training Accuracy: 90.21%\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 0.2451 - accuracy: 0.9018\n",
            "Test Loss: 0.2451\n",
            "Test Accuracy: 90.18%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_features = mobilenet_custom_model.predict(x_train_normalized)\n",
        "x_val_features = mobilenet_custom_model.predict(x_val_normalized)\n",
        "x_test_features = mobilenet_custom_model.predict(x_test_normalized)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hGHgE5ZGM_OD",
        "outputId": "050853e3-704f-4872-f971-47df1e37aa50"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "108/108 [==============================] - 2s 9ms/step\n",
            "16/16 [==============================] - 0s 20ms/step\n",
            "31/31 [==============================] - 0s 6ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_features = x_train_features.reshape(x_train_features.shape[0], -1)\n",
        "x_val_features = x_val_features.reshape(x_val_features.shape[0], -1)\n",
        "x_test_features = x_test_features.reshape(x_test_features.shape[0], -1)"
      ],
      "metadata": {
        "id": "GIWUvQF5OI7E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix"
      ],
      "metadata": {
        "id": "CAqytp7HOKgh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install scikit-optimize\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "of-QGjosQp2Q",
        "outputId": "032143a9-ae32-402e-b337-ae09d403651a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting scikit-optimize\n",
            "  Downloading scikit_optimize-0.9.0-py2.py3-none-any.whl (100 kB)\n",
            "\u001b[?25l     \u001b[90m\u001b[0m \u001b[32m0.0/100.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m\u001b[0m\u001b[91m\u001b[0m\u001b[90m\u001b[0m \u001b[32m92.2/100.3 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m\u001b[0m \u001b[32m100.3/100.3 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.10/dist-packages (from scikit-optimize) (1.3.2)\n",
            "Collecting pyaml>=16.9 (from scikit-optimize)\n",
            "  Downloading pyaml-23.12.0-py3-none-any.whl (23 kB)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.10/dist-packages (from scikit-optimize) (1.23.5)\n",
            "Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.10/dist-packages (from scikit-optimize) (1.11.4)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from scikit-optimize) (1.2.2)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from pyaml>=16.9->scikit-optimize) (6.0.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->scikit-optimize) (3.2.0)\n",
            "Installing collected packages: pyaml, scikit-optimize\n",
            "Successfully installed pyaml-23.12.0 scikit-optimize-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Support Vector Machine (SVM) with L2 Regularization-like behavior\n",
        "svm_model = SVC(kernel='rbf', C=1, gamma=0.006184517020465486)  # Set a smaller C for L2 regularization\n",
        "svm_model.fit(x_train_features, y_train)\n",
        "y_pred_svm = svm_model.predict(x_test_features)\n",
        "\n",
        "svm_accuracy = accuracy_score(y_test, y_pred_svm)\n",
        "svm_precision = precision_score(y_test, y_pred_svm)\n",
        "svm_recall = recall_score(y_test, y_pred_svm)\n",
        "svm_f1 = f1_score(y_test, y_pred_svm)\n",
        "\n",
        "tn, fp, fn, tp = confusion_matrix(y_test, y_pred_svm).ravel()\n",
        "svm_specificity = tn / (tn + fp)\n",
        "\n",
        "print(\"SVM Accuracy:\", svm_accuracy)\n",
        "print(\"SVM Precision:\", svm_precision)\n",
        "print(\"SVM Sensitivity (Recall):\", svm_recall)\n",
        "print(\"SVM Specificity:\", svm_specificity)\n",
        "print(\"SVM F1 Score:\", svm_f1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OKtS48F_TPgx",
        "outputId": "c3381162-6a07-4072-a3d6-43505781737f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVM Accuracy: 0.8882113821138211\n",
            "SVM Precision: 0.9015748031496063\n",
            "SVM Sensitivity (Recall): 0.8841698841698842\n",
            "SVM Specificity: 0.8927038626609443\n",
            "SVM F1 Score: 0.8927875243664717\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "\n",
        "# Define the parameter grid for GridSearchCV\n",
        "param_grid = {\n",
        "    'n_estimators': [50, 100, 200],  # Number of trees in the forest\n",
        "    'max_depth': [None, 10, 20, 30],  # Maximum depth of the tree\n",
        "    'min_samples_split': [2, 5, 10],  # Minimum number of samples required to split an internal node\n",
        "    'min_samples_leaf': [1, 2, 4]  # Minimum number of samples required to be at a leaf node\n",
        "}\n",
        "\n",
        "# Instantiate the Random Forest Classifier\n",
        "rf_model = RandomForestClassifier(random_state=42)\n",
        "\n",
        "# Perform Grid Search with cross-validation\n",
        "grid_search = GridSearchCV(estimator=rf_model, param_grid=param_grid, cv=3, n_jobs=-1, scoring='accuracy')\n",
        "\n",
        "# Fit the grid search to the data\n",
        "grid_search.fit(x_train_features, y_train)\n",
        "\n",
        "# Get the best hyperparameters and best model\n",
        "best_params = grid_search.best_params_\n",
        "best_rf_model = grid_search.best_estimator_\n",
        "\n",
        "# Evaluate the best model on the test data\n",
        "y_pred_rf = best_rf_model.predict(x_test_features)\n",
        "rf_accuracy = accuracy_score(y_test, y_pred_rf)\n",
        "rf_precision = precision_score(y_test, y_pred_rf)\n",
        "rf_recall = recall_score(y_test, y_pred_rf)\n",
        "rf_f1 = f1_score(y_test, y_pred_rf)\n",
        "\n",
        "tn, fp, fn, tp = confusion_matrix(y_test, y_pred_rf).ravel()\n",
        "rf_specificity = tn / (tn + fp)\n",
        "\n",
        "print(\"Best Hyperparameters:\", best_params)\n",
        "print(\"Random Forest Accuracy:\", rf_accuracy)\n",
        "print(\"Random Forest Precision:\", rf_precision)\n",
        "print(\"Random Forest Sensitivity (Recall):\", rf_recall)\n",
        "print(\"Random Forest Specificity:\", rf_specificity)\n",
        "print(\"Random Forest F1 Score:\", rf_f1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-fRzc0F7TPiT",
        "outputId": "4b1564c7-556b-4284-bb28-c02a611faf75"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Hyperparameters: {'max_depth': None, 'min_samples_leaf': 4, 'min_samples_split': 10, 'n_estimators': 100}\n",
            "Random Forest Accuracy: 0.8800813008130082\n",
            "Random Forest Precision: 0.8952569169960475\n",
            "Random Forest Sensitivity (Recall): 0.8745173745173745\n",
            "Random Forest Specificity: 0.8862660944206009\n",
            "Random Forest F1 Score: 0.8847656250000001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "\n",
        "# Define the parameter grid for GridSearchCV\n",
        "param_grid = {\n",
        "    'n_neighbors': [3, 5, 7, 9, 11]  # Example values for the number of neighbors (k)\n",
        "}\n",
        "\n",
        "# Instantiate the KNN Classifier\n",
        "knn_model = KNeighborsClassifier()\n",
        "\n",
        "# Early stopping parameters\n",
        "max_epochs = 25  # Maximum number of epochs (iterations) to train\n",
        "patience = 5  # Number of epochs to wait for improvement\n",
        "best_accuracy = 0  # Best validation accuracy\n",
        "counter = 0  # Counter to keep track of epochs with no improvement\n",
        "\n",
        "# Training loop with early stopping and hyperparameter tuning using GridSearchCV\n",
        "for epoch in range(max_epochs):\n",
        "    # Perform grid search on your training data (x_train_features, y_train)\n",
        "    grid_search = GridSearchCV(estimator=knn_model, param_grid=param_grid, cv=3, n_jobs=-1, scoring='accuracy')\n",
        "    grid_search.fit(x_train_features, y_train)\n",
        "\n",
        "    # Get the best hyperparameters and best model\n",
        "    best_params = grid_search.best_params_\n",
        "    best_knn_model = grid_search.best_estimator_\n",
        "\n",
        "    # Validate the best model on the validation data\n",
        "    y_pred_val = best_knn_model.predict(x_val_features)\n",
        "    val_accuracy = accuracy_score(y_val, y_pred_val)\n",
        "\n",
        "    print(\"Epoch {}: Validation Accuracy: {:.4f}\".format(epoch, val_accuracy))\n",
        "\n",
        "    # Check for improvement in validation accuracy\n",
        "    if val_accuracy > best_accuracy:\n",
        "        best_accuracy = val_accuracy\n",
        "        counter = 0\n",
        "    else:\n",
        "        counter += 1\n",
        "\n",
        "    # Early stopping condition\n",
        "    if counter >= patience:\n",
        "        print(\"Early stopping after {} epochs of no improvement.\".format(epoch))\n",
        "        break\n",
        "\n",
        "# Evaluate the best model on the test data\n",
        "y_pred_knn = best_knn_model.predict(x_test_features)\n",
        "knn_accuracy = accuracy_score(y_test, y_pred_knn)\n",
        "knn_precision = precision_score(y_test, y_pred_knn)\n",
        "knn_recall = recall_score(y_test, y_pred_knn)\n",
        "knn_f1 = f1_score(y_test, y_pred_knn)\n",
        "\n",
        "tn, fp, fn, tp = confusion_matrix(y_test, y_pred_knn).ravel()\n",
        "knn_specificity = tn / (tn + fp)\n",
        "\n",
        "print(\"Best Hyperparameters:\", best_params)\n",
        "print(\"KNN Accuracy on Test Data:\", knn_accuracy)\n",
        "print(\"KNN Precision:\", knn_precision)\n",
        "print(\"KNN Sensitivity (Recall):\", knn_recall)\n",
        "print(\"KNN Specificity:\", knn_specificity)\n",
        "print(\"KNN F1 Score:\", knn_f1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BhmBnlk9SLcu",
        "outputId": "c4ff9df4-ee18-47f8-f62f-c09f6d8878d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0: Validation Accuracy: 0.8943\n",
            "Epoch 1: Validation Accuracy: 0.8943\n",
            "Epoch 2: Validation Accuracy: 0.8943\n",
            "Epoch 3: Validation Accuracy: 0.8943\n",
            "Epoch 4: Validation Accuracy: 0.8943\n",
            "Epoch 5: Validation Accuracy: 0.8943\n",
            "Early stopping after 5 epochs of no improvement.\n",
            "Best Hyperparameters: {'n_neighbors': 7}\n",
            "KNN Accuracy on Test Data: 0.8821138211382114\n",
            "KNN Precision: 0.8988095238095238\n",
            "KNN Sensitivity (Recall): 0.8745173745173745\n",
            "KNN Specificity: 0.8905579399141631\n",
            "KNN F1 Score: 0.8864970645792565\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Conv2D, BatchNormalization, Activation, MaxPooling2D, GlobalAveragePooling2D, Dense, AveragePooling2D, Concatenate\n",
        "\n",
        "# Define your input shape and number of classes\n",
        "IMAGE_WIDTH, IMAGE_HEIGHT, IMAGE_CHANNELS = 100, 100, 3\n",
        "NUM_CLASSES = 2\n",
        "\n",
        "# Define the dense block\n",
        "def dense_block(x, growth_rate):\n",
        "    x1 = BatchNormalization()(x)\n",
        "    x1 = Activation('relu')(x1)\n",
        "    x1 = Conv2D(4 * growth_rate, (1, 1), padding='same')(x1)\n",
        "\n",
        "    x1 = BatchNormalization()(x1)\n",
        "    x1 = Activation('relu')(x1)\n",
        "    x1 = Conv2D(growth_rate, (3, 3), padding='same')(x1)\n",
        "\n",
        "    x = Concatenate()([x, x1])\n",
        "    return x\n",
        "\n",
        "# Define the transition layer\n",
        "def transition_block(x, reduction):\n",
        "    num_filters = int(x.shape[-1])\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Conv2D(int(num_filters * reduction), (1, 1), padding='same')(x)\n",
        "    x = AveragePooling2D((2, 2), strides=(2, 2))(x)\n",
        "    return x\n",
        "\n",
        "# Define the input shape\n",
        "input_shape = (IMAGE_WIDTH, IMAGE_HEIGHT, IMAGE_CHANNELS)\n",
        "input_tensor = Input(shape=input_shape)\n",
        "\n",
        "# Initial Convolution\n",
        "x = Conv2D(64, (7, 7), strides=(2, 2), padding='same')(input_tensor)\n",
        "x = BatchNormalization()(x)\n",
        "x = Activation('relu')(x)\n",
        "x = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n",
        "\n",
        "# Dense Blocks\n",
        "for _ in range(6):\n",
        "    x = dense_block(x, 32)\n",
        "\n",
        "x = transition_block(x, 0.5)\n",
        "\n",
        "for _ in range(12):\n",
        "    x = dense_block(x, 32)\n",
        "\n",
        "x = transition_block(x, 0.5)\n",
        "\n",
        "for _ in range(48):\n",
        "    x = dense_block(x, 32)\n",
        "\n",
        "# Global Average Pooling\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "\n",
        "# Fully Connected Layer\n",
        "output = Dense(NUM_CLASSES, activation='softmax')(x)\n",
        "\n",
        "# Create the model\n",
        "model = Model(inputs=input_tensor, outputs=output)\n",
        "\n",
        "# Compile the model with a learning rate of 0.00001\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.00001)\n",
        "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Print the model summary\n",
        "model.summary()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fqJ2WO3HvEaZ",
        "outputId": "e4e1a9fc-5293-4c0f-faf1-c6d0f50bddf3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)        [(None, 100, 100, 3)]        0         []                            \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)             (None, 50, 50, 64)           9472      ['input_1[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization (Batch  (None, 50, 50, 64)           256       ['conv2d[0][0]']              \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation (Activation)     (None, 50, 50, 64)           0         ['batch_normalization[0][0]'] \n",
            "                                                                                                  \n",
            " max_pooling2d (MaxPooling2  (None, 25, 25, 64)           0         ['activation[0][0]']          \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_1 (Bat  (None, 25, 25, 64)           256       ['max_pooling2d[0][0]']       \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " activation_1 (Activation)   (None, 25, 25, 64)           0         ['batch_normalization_1[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)           (None, 25, 25, 128)          8320      ['activation_1[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_2 (Bat  (None, 25, 25, 128)          512       ['conv2d_1[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " activation_2 (Activation)   (None, 25, 25, 128)          0         ['batch_normalization_2[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)           (None, 25, 25, 32)           36896     ['activation_2[0][0]']        \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)   (None, 25, 25, 96)           0         ['max_pooling2d[0][0]',       \n",
            "                                                                     'conv2d_2[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_3 (Bat  (None, 25, 25, 96)           384       ['concatenate[0][0]']         \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " activation_3 (Activation)   (None, 25, 25, 96)           0         ['batch_normalization_3[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " conv2d_3 (Conv2D)           (None, 25, 25, 128)          12416     ['activation_3[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_4 (Bat  (None, 25, 25, 128)          512       ['conv2d_3[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " activation_4 (Activation)   (None, 25, 25, 128)          0         ['batch_normalization_4[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " conv2d_4 (Conv2D)           (None, 25, 25, 32)           36896     ['activation_4[0][0]']        \n",
            "                                                                                                  \n",
            " concatenate_1 (Concatenate  (None, 25, 25, 128)          0         ['concatenate[0][0]',         \n",
            " )                                                                   'conv2d_4[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_5 (Bat  (None, 25, 25, 128)          512       ['concatenate_1[0][0]']       \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " activation_5 (Activation)   (None, 25, 25, 128)          0         ['batch_normalization_5[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " conv2d_5 (Conv2D)           (None, 25, 25, 128)          16512     ['activation_5[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_6 (Bat  (None, 25, 25, 128)          512       ['conv2d_5[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " activation_6 (Activation)   (None, 25, 25, 128)          0         ['batch_normalization_6[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " conv2d_6 (Conv2D)           (None, 25, 25, 32)           36896     ['activation_6[0][0]']        \n",
            "                                                                                                  \n",
            " concatenate_2 (Concatenate  (None, 25, 25, 160)          0         ['concatenate_1[0][0]',       \n",
            " )                                                                   'conv2d_6[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_7 (Bat  (None, 25, 25, 160)          640       ['concatenate_2[0][0]']       \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " activation_7 (Activation)   (None, 25, 25, 160)          0         ['batch_normalization_7[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " conv2d_7 (Conv2D)           (None, 25, 25, 128)          20608     ['activation_7[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_8 (Bat  (None, 25, 25, 128)          512       ['conv2d_7[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " activation_8 (Activation)   (None, 25, 25, 128)          0         ['batch_normalization_8[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " conv2d_8 (Conv2D)           (None, 25, 25, 32)           36896     ['activation_8[0][0]']        \n",
            "                                                                                                  \n",
            " concatenate_3 (Concatenate  (None, 25, 25, 192)          0         ['concatenate_2[0][0]',       \n",
            " )                                                                   'conv2d_8[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_9 (Bat  (None, 25, 25, 192)          768       ['concatenate_3[0][0]']       \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " activation_9 (Activation)   (None, 25, 25, 192)          0         ['batch_normalization_9[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " conv2d_9 (Conv2D)           (None, 25, 25, 128)          24704     ['activation_9[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_10 (Ba  (None, 25, 25, 128)          512       ['conv2d_9[0][0]']            \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_10 (Activation)  (None, 25, 25, 128)          0         ['batch_normalization_10[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_10 (Conv2D)          (None, 25, 25, 32)           36896     ['activation_10[0][0]']       \n",
            "                                                                                                  \n",
            " concatenate_4 (Concatenate  (None, 25, 25, 224)          0         ['concatenate_3[0][0]',       \n",
            " )                                                                   'conv2d_10[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_11 (Ba  (None, 25, 25, 224)          896       ['concatenate_4[0][0]']       \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_11 (Activation)  (None, 25, 25, 224)          0         ['batch_normalization_11[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_11 (Conv2D)          (None, 25, 25, 128)          28800     ['activation_11[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_12 (Ba  (None, 25, 25, 128)          512       ['conv2d_11[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_12 (Activation)  (None, 25, 25, 128)          0         ['batch_normalization_12[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_12 (Conv2D)          (None, 25, 25, 32)           36896     ['activation_12[0][0]']       \n",
            "                                                                                                  \n",
            " concatenate_5 (Concatenate  (None, 25, 25, 256)          0         ['concatenate_4[0][0]',       \n",
            " )                                                                   'conv2d_12[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_13 (Ba  (None, 25, 25, 256)          1024      ['concatenate_5[0][0]']       \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_13 (Activation)  (None, 25, 25, 256)          0         ['batch_normalization_13[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_13 (Conv2D)          (None, 25, 25, 128)          32896     ['activation_13[0][0]']       \n",
            "                                                                                                  \n",
            " average_pooling2d (Average  (None, 12, 12, 128)          0         ['conv2d_13[0][0]']           \n",
            " Pooling2D)                                                                                       \n",
            "                                                                                                  \n",
            " batch_normalization_14 (Ba  (None, 12, 12, 128)          512       ['average_pooling2d[0][0]']   \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_14 (Activation)  (None, 12, 12, 128)          0         ['batch_normalization_14[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_14 (Conv2D)          (None, 12, 12, 128)          16512     ['activation_14[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_15 (Ba  (None, 12, 12, 128)          512       ['conv2d_14[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_15 (Activation)  (None, 12, 12, 128)          0         ['batch_normalization_15[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_15 (Conv2D)          (None, 12, 12, 32)           36896     ['activation_15[0][0]']       \n",
            "                                                                                                  \n",
            " concatenate_6 (Concatenate  (None, 12, 12, 160)          0         ['average_pooling2d[0][0]',   \n",
            " )                                                                   'conv2d_15[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_16 (Ba  (None, 12, 12, 160)          640       ['concatenate_6[0][0]']       \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_16 (Activation)  (None, 12, 12, 160)          0         ['batch_normalization_16[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_16 (Conv2D)          (None, 12, 12, 128)          20608     ['activation_16[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_17 (Ba  (None, 12, 12, 128)          512       ['conv2d_16[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_17 (Activation)  (None, 12, 12, 128)          0         ['batch_normalization_17[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_17 (Conv2D)          (None, 12, 12, 32)           36896     ['activation_17[0][0]']       \n",
            "                                                                                                  \n",
            " concatenate_7 (Concatenate  (None, 12, 12, 192)          0         ['concatenate_6[0][0]',       \n",
            " )                                                                   'conv2d_17[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_18 (Ba  (None, 12, 12, 192)          768       ['concatenate_7[0][0]']       \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_18 (Activation)  (None, 12, 12, 192)          0         ['batch_normalization_18[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_18 (Conv2D)          (None, 12, 12, 128)          24704     ['activation_18[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_19 (Ba  (None, 12, 12, 128)          512       ['conv2d_18[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_19 (Activation)  (None, 12, 12, 128)          0         ['batch_normalization_19[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_19 (Conv2D)          (None, 12, 12, 32)           36896     ['activation_19[0][0]']       \n",
            "                                                                                                  \n",
            " concatenate_8 (Concatenate  (None, 12, 12, 224)          0         ['concatenate_7[0][0]',       \n",
            " )                                                                   'conv2d_19[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_20 (Ba  (None, 12, 12, 224)          896       ['concatenate_8[0][0]']       \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_20 (Activation)  (None, 12, 12, 224)          0         ['batch_normalization_20[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_20 (Conv2D)          (None, 12, 12, 128)          28800     ['activation_20[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_21 (Ba  (None, 12, 12, 128)          512       ['conv2d_20[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_21 (Activation)  (None, 12, 12, 128)          0         ['batch_normalization_21[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_21 (Conv2D)          (None, 12, 12, 32)           36896     ['activation_21[0][0]']       \n",
            "                                                                                                  \n",
            " concatenate_9 (Concatenate  (None, 12, 12, 256)          0         ['concatenate_8[0][0]',       \n",
            " )                                                                   'conv2d_21[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_22 (Ba  (None, 12, 12, 256)          1024      ['concatenate_9[0][0]']       \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_22 (Activation)  (None, 12, 12, 256)          0         ['batch_normalization_22[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_22 (Conv2D)          (None, 12, 12, 128)          32896     ['activation_22[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_23 (Ba  (None, 12, 12, 128)          512       ['conv2d_22[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_23 (Activation)  (None, 12, 12, 128)          0         ['batch_normalization_23[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_23 (Conv2D)          (None, 12, 12, 32)           36896     ['activation_23[0][0]']       \n",
            "                                                                                                  \n",
            " concatenate_10 (Concatenat  (None, 12, 12, 288)          0         ['concatenate_9[0][0]',       \n",
            " e)                                                                  'conv2d_23[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_24 (Ba  (None, 12, 12, 288)          1152      ['concatenate_10[0][0]']      \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_24 (Activation)  (None, 12, 12, 288)          0         ['batch_normalization_24[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_24 (Conv2D)          (None, 12, 12, 128)          36992     ['activation_24[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_25 (Ba  (None, 12, 12, 128)          512       ['conv2d_24[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_25 (Activation)  (None, 12, 12, 128)          0         ['batch_normalization_25[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_25 (Conv2D)          (None, 12, 12, 32)           36896     ['activation_25[0][0]']       \n",
            "                                                                                                  \n",
            " concatenate_11 (Concatenat  (None, 12, 12, 320)          0         ['concatenate_10[0][0]',      \n",
            " e)                                                                  'conv2d_25[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_26 (Ba  (None, 12, 12, 320)          1280      ['concatenate_11[0][0]']      \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_26 (Activation)  (None, 12, 12, 320)          0         ['batch_normalization_26[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_26 (Conv2D)          (None, 12, 12, 128)          41088     ['activation_26[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_27 (Ba  (None, 12, 12, 128)          512       ['conv2d_26[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_27 (Activation)  (None, 12, 12, 128)          0         ['batch_normalization_27[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_27 (Conv2D)          (None, 12, 12, 32)           36896     ['activation_27[0][0]']       \n",
            "                                                                                                  \n",
            " concatenate_12 (Concatenat  (None, 12, 12, 352)          0         ['concatenate_11[0][0]',      \n",
            " e)                                                                  'conv2d_27[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_28 (Ba  (None, 12, 12, 352)          1408      ['concatenate_12[0][0]']      \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_28 (Activation)  (None, 12, 12, 352)          0         ['batch_normalization_28[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_28 (Conv2D)          (None, 12, 12, 128)          45184     ['activation_28[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_29 (Ba  (None, 12, 12, 128)          512       ['conv2d_28[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_29 (Activation)  (None, 12, 12, 128)          0         ['batch_normalization_29[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_29 (Conv2D)          (None, 12, 12, 32)           36896     ['activation_29[0][0]']       \n",
            "                                                                                                  \n",
            " concatenate_13 (Concatenat  (None, 12, 12, 384)          0         ['concatenate_12[0][0]',      \n",
            " e)                                                                  'conv2d_29[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_30 (Ba  (None, 12, 12, 384)          1536      ['concatenate_13[0][0]']      \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_30 (Activation)  (None, 12, 12, 384)          0         ['batch_normalization_30[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_30 (Conv2D)          (None, 12, 12, 128)          49280     ['activation_30[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_31 (Ba  (None, 12, 12, 128)          512       ['conv2d_30[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_31 (Activation)  (None, 12, 12, 128)          0         ['batch_normalization_31[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_31 (Conv2D)          (None, 12, 12, 32)           36896     ['activation_31[0][0]']       \n",
            "                                                                                                  \n",
            " concatenate_14 (Concatenat  (None, 12, 12, 416)          0         ['concatenate_13[0][0]',      \n",
            " e)                                                                  'conv2d_31[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_32 (Ba  (None, 12, 12, 416)          1664      ['concatenate_14[0][0]']      \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_32 (Activation)  (None, 12, 12, 416)          0         ['batch_normalization_32[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_32 (Conv2D)          (None, 12, 12, 128)          53376     ['activation_32[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_33 (Ba  (None, 12, 12, 128)          512       ['conv2d_32[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_33 (Activation)  (None, 12, 12, 128)          0         ['batch_normalization_33[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_33 (Conv2D)          (None, 12, 12, 32)           36896     ['activation_33[0][0]']       \n",
            "                                                                                                  \n",
            " concatenate_15 (Concatenat  (None, 12, 12, 448)          0         ['concatenate_14[0][0]',      \n",
            " e)                                                                  'conv2d_33[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_34 (Ba  (None, 12, 12, 448)          1792      ['concatenate_15[0][0]']      \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_34 (Activation)  (None, 12, 12, 448)          0         ['batch_normalization_34[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_34 (Conv2D)          (None, 12, 12, 128)          57472     ['activation_34[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_35 (Ba  (None, 12, 12, 128)          512       ['conv2d_34[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_35 (Activation)  (None, 12, 12, 128)          0         ['batch_normalization_35[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_35 (Conv2D)          (None, 12, 12, 32)           36896     ['activation_35[0][0]']       \n",
            "                                                                                                  \n",
            " concatenate_16 (Concatenat  (None, 12, 12, 480)          0         ['concatenate_15[0][0]',      \n",
            " e)                                                                  'conv2d_35[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_36 (Ba  (None, 12, 12, 480)          1920      ['concatenate_16[0][0]']      \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_36 (Activation)  (None, 12, 12, 480)          0         ['batch_normalization_36[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_36 (Conv2D)          (None, 12, 12, 128)          61568     ['activation_36[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_37 (Ba  (None, 12, 12, 128)          512       ['conv2d_36[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_37 (Activation)  (None, 12, 12, 128)          0         ['batch_normalization_37[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_37 (Conv2D)          (None, 12, 12, 32)           36896     ['activation_37[0][0]']       \n",
            "                                                                                                  \n",
            " concatenate_17 (Concatenat  (None, 12, 12, 512)          0         ['concatenate_16[0][0]',      \n",
            " e)                                                                  'conv2d_37[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_38 (Ba  (None, 12, 12, 512)          2048      ['concatenate_17[0][0]']      \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_38 (Activation)  (None, 12, 12, 512)          0         ['batch_normalization_38[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_38 (Conv2D)          (None, 12, 12, 256)          131328    ['activation_38[0][0]']       \n",
            "                                                                                                  \n",
            " average_pooling2d_1 (Avera  (None, 6, 6, 256)            0         ['conv2d_38[0][0]']           \n",
            " gePooling2D)                                                                                     \n",
            "                                                                                                  \n",
            " batch_normalization_39 (Ba  (None, 6, 6, 256)            1024      ['average_pooling2d_1[0][0]'] \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_39 (Activation)  (None, 6, 6, 256)            0         ['batch_normalization_39[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_39 (Conv2D)          (None, 6, 6, 128)            32896     ['activation_39[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_40 (Ba  (None, 6, 6, 128)            512       ['conv2d_39[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_40 (Activation)  (None, 6, 6, 128)            0         ['batch_normalization_40[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_40 (Conv2D)          (None, 6, 6, 32)             36896     ['activation_40[0][0]']       \n",
            "                                                                                                  \n",
            " concatenate_18 (Concatenat  (None, 6, 6, 288)            0         ['average_pooling2d_1[0][0]', \n",
            " e)                                                                  'conv2d_40[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_41 (Ba  (None, 6, 6, 288)            1152      ['concatenate_18[0][0]']      \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_41 (Activation)  (None, 6, 6, 288)            0         ['batch_normalization_41[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_41 (Conv2D)          (None, 6, 6, 128)            36992     ['activation_41[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_42 (Ba  (None, 6, 6, 128)            512       ['conv2d_41[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_42 (Activation)  (None, 6, 6, 128)            0         ['batch_normalization_42[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_42 (Conv2D)          (None, 6, 6, 32)             36896     ['activation_42[0][0]']       \n",
            "                                                                                                  \n",
            " concatenate_19 (Concatenat  (None, 6, 6, 320)            0         ['concatenate_18[0][0]',      \n",
            " e)                                                                  'conv2d_42[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_43 (Ba  (None, 6, 6, 320)            1280      ['concatenate_19[0][0]']      \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_43 (Activation)  (None, 6, 6, 320)            0         ['batch_normalization_43[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_43 (Conv2D)          (None, 6, 6, 128)            41088     ['activation_43[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_44 (Ba  (None, 6, 6, 128)            512       ['conv2d_43[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_44 (Activation)  (None, 6, 6, 128)            0         ['batch_normalization_44[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_44 (Conv2D)          (None, 6, 6, 32)             36896     ['activation_44[0][0]']       \n",
            "                                                                                                  \n",
            " concatenate_20 (Concatenat  (None, 6, 6, 352)            0         ['concatenate_19[0][0]',      \n",
            " e)                                                                  'conv2d_44[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_45 (Ba  (None, 6, 6, 352)            1408      ['concatenate_20[0][0]']      \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_45 (Activation)  (None, 6, 6, 352)            0         ['batch_normalization_45[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_45 (Conv2D)          (None, 6, 6, 128)            45184     ['activation_45[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_46 (Ba  (None, 6, 6, 128)            512       ['conv2d_45[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_46 (Activation)  (None, 6, 6, 128)            0         ['batch_normalization_46[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_46 (Conv2D)          (None, 6, 6, 32)             36896     ['activation_46[0][0]']       \n",
            "                                                                                                  \n",
            " concatenate_21 (Concatenat  (None, 6, 6, 384)            0         ['concatenate_20[0][0]',      \n",
            " e)                                                                  'conv2d_46[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_47 (Ba  (None, 6, 6, 384)            1536      ['concatenate_21[0][0]']      \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_47 (Activation)  (None, 6, 6, 384)            0         ['batch_normalization_47[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_47 (Conv2D)          (None, 6, 6, 128)            49280     ['activation_47[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_48 (Ba  (None, 6, 6, 128)            512       ['conv2d_47[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_48 (Activation)  (None, 6, 6, 128)            0         ['batch_normalization_48[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_48 (Conv2D)          (None, 6, 6, 32)             36896     ['activation_48[0][0]']       \n",
            "                                                                                                  \n",
            " concatenate_22 (Concatenat  (None, 6, 6, 416)            0         ['concatenate_21[0][0]',      \n",
            " e)                                                                  'conv2d_48[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_49 (Ba  (None, 6, 6, 416)            1664      ['concatenate_22[0][0]']      \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_49 (Activation)  (None, 6, 6, 416)            0         ['batch_normalization_49[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_49 (Conv2D)          (None, 6, 6, 128)            53376     ['activation_49[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_50 (Ba  (None, 6, 6, 128)            512       ['conv2d_49[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_50 (Activation)  (None, 6, 6, 128)            0         ['batch_normalization_50[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_50 (Conv2D)          (None, 6, 6, 32)             36896     ['activation_50[0][0]']       \n",
            "                                                                                                  \n",
            " concatenate_23 (Concatenat  (None, 6, 6, 448)            0         ['concatenate_22[0][0]',      \n",
            " e)                                                                  'conv2d_50[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_51 (Ba  (None, 6, 6, 448)            1792      ['concatenate_23[0][0]']      \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_51 (Activation)  (None, 6, 6, 448)            0         ['batch_normalization_51[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_51 (Conv2D)          (None, 6, 6, 128)            57472     ['activation_51[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_52 (Ba  (None, 6, 6, 128)            512       ['conv2d_51[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_52 (Activation)  (None, 6, 6, 128)            0         ['batch_normalization_52[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_52 (Conv2D)          (None, 6, 6, 32)             36896     ['activation_52[0][0]']       \n",
            "                                                                                                  \n",
            " concatenate_24 (Concatenat  (None, 6, 6, 480)            0         ['concatenate_23[0][0]',      \n",
            " e)                                                                  'conv2d_52[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_53 (Ba  (None, 6, 6, 480)            1920      ['concatenate_24[0][0]']      \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_53 (Activation)  (None, 6, 6, 480)            0         ['batch_normalization_53[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_53 (Conv2D)          (None, 6, 6, 128)            61568     ['activation_53[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_54 (Ba  (None, 6, 6, 128)            512       ['conv2d_53[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_54 (Activation)  (None, 6, 6, 128)            0         ['batch_normalization_54[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_54 (Conv2D)          (None, 6, 6, 32)             36896     ['activation_54[0][0]']       \n",
            "                                                                                                  \n",
            " concatenate_25 (Concatenat  (None, 6, 6, 512)            0         ['concatenate_24[0][0]',      \n",
            " e)                                                                  'conv2d_54[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_55 (Ba  (None, 6, 6, 512)            2048      ['concatenate_25[0][0]']      \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_55 (Activation)  (None, 6, 6, 512)            0         ['batch_normalization_55[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_55 (Conv2D)          (None, 6, 6, 128)            65664     ['activation_55[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_56 (Ba  (None, 6, 6, 128)            512       ['conv2d_55[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_56 (Activation)  (None, 6, 6, 128)            0         ['batch_normalization_56[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_56 (Conv2D)          (None, 6, 6, 32)             36896     ['activation_56[0][0]']       \n",
            "                                                                                                  \n",
            " concatenate_26 (Concatenat  (None, 6, 6, 544)            0         ['concatenate_25[0][0]',      \n",
            " e)                                                                  'conv2d_56[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_57 (Ba  (None, 6, 6, 544)            2176      ['concatenate_26[0][0]']      \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_57 (Activation)  (None, 6, 6, 544)            0         ['batch_normalization_57[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_57 (Conv2D)          (None, 6, 6, 128)            69760     ['activation_57[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_58 (Ba  (None, 6, 6, 128)            512       ['conv2d_57[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_58 (Activation)  (None, 6, 6, 128)            0         ['batch_normalization_58[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_58 (Conv2D)          (None, 6, 6, 32)             36896     ['activation_58[0][0]']       \n",
            "                                                                                                  \n",
            " concatenate_27 (Concatenat  (None, 6, 6, 576)            0         ['concatenate_26[0][0]',      \n",
            " e)                                                                  'conv2d_58[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_59 (Ba  (None, 6, 6, 576)            2304      ['concatenate_27[0][0]']      \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_59 (Activation)  (None, 6, 6, 576)            0         ['batch_normalization_59[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_59 (Conv2D)          (None, 6, 6, 128)            73856     ['activation_59[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_60 (Ba  (None, 6, 6, 128)            512       ['conv2d_59[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_60 (Activation)  (None, 6, 6, 128)            0         ['batch_normalization_60[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_60 (Conv2D)          (None, 6, 6, 32)             36896     ['activation_60[0][0]']       \n",
            "                                                                                                  \n",
            " concatenate_28 (Concatenat  (None, 6, 6, 608)            0         ['concatenate_27[0][0]',      \n",
            " e)                                                                  'conv2d_60[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_61 (Ba  (None, 6, 6, 608)            2432      ['concatenate_28[0][0]']      \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_61 (Activation)  (None, 6, 6, 608)            0         ['batch_normalization_61[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_61 (Conv2D)          (None, 6, 6, 128)            77952     ['activation_61[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_62 (Ba  (None, 6, 6, 128)            512       ['conv2d_61[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_62 (Activation)  (None, 6, 6, 128)            0         ['batch_normalization_62[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_62 (Conv2D)          (None, 6, 6, 32)             36896     ['activation_62[0][0]']       \n",
            "                                                                                                  \n",
            " concatenate_29 (Concatenat  (None, 6, 6, 640)            0         ['concatenate_28[0][0]',      \n",
            " e)                                                                  'conv2d_62[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_63 (Ba  (None, 6, 6, 640)            2560      ['concatenate_29[0][0]']      \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_63 (Activation)  (None, 6, 6, 640)            0         ['batch_normalization_63[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_63 (Conv2D)          (None, 6, 6, 128)            82048     ['activation_63[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_64 (Ba  (None, 6, 6, 128)            512       ['conv2d_63[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_64 (Activation)  (None, 6, 6, 128)            0         ['batch_normalization_64[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_64 (Conv2D)          (None, 6, 6, 32)             36896     ['activation_64[0][0]']       \n",
            "                                                                                                  \n",
            " concatenate_30 (Concatenat  (None, 6, 6, 672)            0         ['concatenate_29[0][0]',      \n",
            " e)                                                                  'conv2d_64[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_65 (Ba  (None, 6, 6, 672)            2688      ['concatenate_30[0][0]']      \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_65 (Activation)  (None, 6, 6, 672)            0         ['batch_normalization_65[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_65 (Conv2D)          (None, 6, 6, 128)            86144     ['activation_65[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_66 (Ba  (None, 6, 6, 128)            512       ['conv2d_65[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_66 (Activation)  (None, 6, 6, 128)            0         ['batch_normalization_66[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_66 (Conv2D)          (None, 6, 6, 32)             36896     ['activation_66[0][0]']       \n",
            "                                                                                                  \n",
            " concatenate_31 (Concatenat  (None, 6, 6, 704)            0         ['concatenate_30[0][0]',      \n",
            " e)                                                                  'conv2d_66[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_67 (Ba  (None, 6, 6, 704)            2816      ['concatenate_31[0][0]']      \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_67 (Activation)  (None, 6, 6, 704)            0         ['batch_normalization_67[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_67 (Conv2D)          (None, 6, 6, 128)            90240     ['activation_67[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_68 (Ba  (None, 6, 6, 128)            512       ['conv2d_67[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_68 (Activation)  (None, 6, 6, 128)            0         ['batch_normalization_68[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_68 (Conv2D)          (None, 6, 6, 32)             36896     ['activation_68[0][0]']       \n",
            "                                                                                                  \n",
            " concatenate_32 (Concatenat  (None, 6, 6, 736)            0         ['concatenate_31[0][0]',      \n",
            " e)                                                                  'conv2d_68[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_69 (Ba  (None, 6, 6, 736)            2944      ['concatenate_32[0][0]']      \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_69 (Activation)  (None, 6, 6, 736)            0         ['batch_normalization_69[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_69 (Conv2D)          (None, 6, 6, 128)            94336     ['activation_69[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_70 (Ba  (None, 6, 6, 128)            512       ['conv2d_69[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_70 (Activation)  (None, 6, 6, 128)            0         ['batch_normalization_70[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_70 (Conv2D)          (None, 6, 6, 32)             36896     ['activation_70[0][0]']       \n",
            "                                                                                                  \n",
            " concatenate_33 (Concatenat  (None, 6, 6, 768)            0         ['concatenate_32[0][0]',      \n",
            " e)                                                                  'conv2d_70[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_71 (Ba  (None, 6, 6, 768)            3072      ['concatenate_33[0][0]']      \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_71 (Activation)  (None, 6, 6, 768)            0         ['batch_normalization_71[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_71 (Conv2D)          (None, 6, 6, 128)            98432     ['activation_71[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_72 (Ba  (None, 6, 6, 128)            512       ['conv2d_71[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_72 (Activation)  (None, 6, 6, 128)            0         ['batch_normalization_72[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_72 (Conv2D)          (None, 6, 6, 32)             36896     ['activation_72[0][0]']       \n",
            "                                                                                                  \n",
            " concatenate_34 (Concatenat  (None, 6, 6, 800)            0         ['concatenate_33[0][0]',      \n",
            " e)                                                                  'conv2d_72[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_73 (Ba  (None, 6, 6, 800)            3200      ['concatenate_34[0][0]']      \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_73 (Activation)  (None, 6, 6, 800)            0         ['batch_normalization_73[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_73 (Conv2D)          (None, 6, 6, 128)            102528    ['activation_73[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_74 (Ba  (None, 6, 6, 128)            512       ['conv2d_73[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_74 (Activation)  (None, 6, 6, 128)            0         ['batch_normalization_74[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_74 (Conv2D)          (None, 6, 6, 32)             36896     ['activation_74[0][0]']       \n",
            "                                                                                                  \n",
            " concatenate_35 (Concatenat  (None, 6, 6, 832)            0         ['concatenate_34[0][0]',      \n",
            " e)                                                                  'conv2d_74[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_75 (Ba  (None, 6, 6, 832)            3328      ['concatenate_35[0][0]']      \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_75 (Activation)  (None, 6, 6, 832)            0         ['batch_normalization_75[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_75 (Conv2D)          (None, 6, 6, 128)            106624    ['activation_75[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_76 (Ba  (None, 6, 6, 128)            512       ['conv2d_75[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_76 (Activation)  (None, 6, 6, 128)            0         ['batch_normalization_76[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_76 (Conv2D)          (None, 6, 6, 32)             36896     ['activation_76[0][0]']       \n",
            "                                                                                                  \n",
            " concatenate_36 (Concatenat  (None, 6, 6, 864)            0         ['concatenate_35[0][0]',      \n",
            " e)                                                                  'conv2d_76[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_77 (Ba  (None, 6, 6, 864)            3456      ['concatenate_36[0][0]']      \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_77 (Activation)  (None, 6, 6, 864)            0         ['batch_normalization_77[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_77 (Conv2D)          (None, 6, 6, 128)            110720    ['activation_77[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_78 (Ba  (None, 6, 6, 128)            512       ['conv2d_77[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_78 (Activation)  (None, 6, 6, 128)            0         ['batch_normalization_78[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_78 (Conv2D)          (None, 6, 6, 32)             36896     ['activation_78[0][0]']       \n",
            "                                                                                                  \n",
            " concatenate_37 (Concatenat  (None, 6, 6, 896)            0         ['concatenate_36[0][0]',      \n",
            " e)                                                                  'conv2d_78[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_79 (Ba  (None, 6, 6, 896)            3584      ['concatenate_37[0][0]']      \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_79 (Activation)  (None, 6, 6, 896)            0         ['batch_normalization_79[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_79 (Conv2D)          (None, 6, 6, 128)            114816    ['activation_79[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_80 (Ba  (None, 6, 6, 128)            512       ['conv2d_79[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_80 (Activation)  (None, 6, 6, 128)            0         ['batch_normalization_80[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_80 (Conv2D)          (None, 6, 6, 32)             36896     ['activation_80[0][0]']       \n",
            "                                                                                                  \n",
            " concatenate_38 (Concatenat  (None, 6, 6, 928)            0         ['concatenate_37[0][0]',      \n",
            " e)                                                                  'conv2d_80[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_81 (Ba  (None, 6, 6, 928)            3712      ['concatenate_38[0][0]']      \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_81 (Activation)  (None, 6, 6, 928)            0         ['batch_normalization_81[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_81 (Conv2D)          (None, 6, 6, 128)            118912    ['activation_81[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_82 (Ba  (None, 6, 6, 128)            512       ['conv2d_81[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_82 (Activation)  (None, 6, 6, 128)            0         ['batch_normalization_82[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_82 (Conv2D)          (None, 6, 6, 32)             36896     ['activation_82[0][0]']       \n",
            "                                                                                                  \n",
            " concatenate_39 (Concatenat  (None, 6, 6, 960)            0         ['concatenate_38[0][0]',      \n",
            " e)                                                                  'conv2d_82[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_83 (Ba  (None, 6, 6, 960)            3840      ['concatenate_39[0][0]']      \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_83 (Activation)  (None, 6, 6, 960)            0         ['batch_normalization_83[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_83 (Conv2D)          (None, 6, 6, 128)            123008    ['activation_83[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_84 (Ba  (None, 6, 6, 128)            512       ['conv2d_83[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_84 (Activation)  (None, 6, 6, 128)            0         ['batch_normalization_84[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_84 (Conv2D)          (None, 6, 6, 32)             36896     ['activation_84[0][0]']       \n",
            "                                                                                                  \n",
            " concatenate_40 (Concatenat  (None, 6, 6, 992)            0         ['concatenate_39[0][0]',      \n",
            " e)                                                                  'conv2d_84[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_85 (Ba  (None, 6, 6, 992)            3968      ['concatenate_40[0][0]']      \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_85 (Activation)  (None, 6, 6, 992)            0         ['batch_normalization_85[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_85 (Conv2D)          (None, 6, 6, 128)            127104    ['activation_85[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_86 (Ba  (None, 6, 6, 128)            512       ['conv2d_85[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_86 (Activation)  (None, 6, 6, 128)            0         ['batch_normalization_86[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_86 (Conv2D)          (None, 6, 6, 32)             36896     ['activation_86[0][0]']       \n",
            "                                                                                                  \n",
            " concatenate_41 (Concatenat  (None, 6, 6, 1024)           0         ['concatenate_40[0][0]',      \n",
            " e)                                                                  'conv2d_86[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_87 (Ba  (None, 6, 6, 1024)           4096      ['concatenate_41[0][0]']      \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_87 (Activation)  (None, 6, 6, 1024)           0         ['batch_normalization_87[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_87 (Conv2D)          (None, 6, 6, 128)            131200    ['activation_87[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_88 (Ba  (None, 6, 6, 128)            512       ['conv2d_87[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_88 (Activation)  (None, 6, 6, 128)            0         ['batch_normalization_88[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_88 (Conv2D)          (None, 6, 6, 32)             36896     ['activation_88[0][0]']       \n",
            "                                                                                                  \n",
            " concatenate_42 (Concatenat  (None, 6, 6, 1056)           0         ['concatenate_41[0][0]',      \n",
            " e)                                                                  'conv2d_88[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_89 (Ba  (None, 6, 6, 1056)           4224      ['concatenate_42[0][0]']      \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_89 (Activation)  (None, 6, 6, 1056)           0         ['batch_normalization_89[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_89 (Conv2D)          (None, 6, 6, 128)            135296    ['activation_89[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_90 (Ba  (None, 6, 6, 128)            512       ['conv2d_89[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_90 (Activation)  (None, 6, 6, 128)            0         ['batch_normalization_90[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_90 (Conv2D)          (None, 6, 6, 32)             36896     ['activation_90[0][0]']       \n",
            "                                                                                                  \n",
            " concatenate_43 (Concatenat  (None, 6, 6, 1088)           0         ['concatenate_42[0][0]',      \n",
            " e)                                                                  'conv2d_90[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_91 (Ba  (None, 6, 6, 1088)           4352      ['concatenate_43[0][0]']      \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_91 (Activation)  (None, 6, 6, 1088)           0         ['batch_normalization_91[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_91 (Conv2D)          (None, 6, 6, 128)            139392    ['activation_91[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_92 (Ba  (None, 6, 6, 128)            512       ['conv2d_91[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_92 (Activation)  (None, 6, 6, 128)            0         ['batch_normalization_92[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_92 (Conv2D)          (None, 6, 6, 32)             36896     ['activation_92[0][0]']       \n",
            "                                                                                                  \n",
            " concatenate_44 (Concatenat  (None, 6, 6, 1120)           0         ['concatenate_43[0][0]',      \n",
            " e)                                                                  'conv2d_92[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_93 (Ba  (None, 6, 6, 1120)           4480      ['concatenate_44[0][0]']      \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_93 (Activation)  (None, 6, 6, 1120)           0         ['batch_normalization_93[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_93 (Conv2D)          (None, 6, 6, 128)            143488    ['activation_93[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_94 (Ba  (None, 6, 6, 128)            512       ['conv2d_93[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_94 (Activation)  (None, 6, 6, 128)            0         ['batch_normalization_94[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_94 (Conv2D)          (None, 6, 6, 32)             36896     ['activation_94[0][0]']       \n",
            "                                                                                                  \n",
            " concatenate_45 (Concatenat  (None, 6, 6, 1152)           0         ['concatenate_44[0][0]',      \n",
            " e)                                                                  'conv2d_94[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_95 (Ba  (None, 6, 6, 1152)           4608      ['concatenate_45[0][0]']      \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_95 (Activation)  (None, 6, 6, 1152)           0         ['batch_normalization_95[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_95 (Conv2D)          (None, 6, 6, 128)            147584    ['activation_95[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_96 (Ba  (None, 6, 6, 128)            512       ['conv2d_95[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_96 (Activation)  (None, 6, 6, 128)            0         ['batch_normalization_96[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_96 (Conv2D)          (None, 6, 6, 32)             36896     ['activation_96[0][0]']       \n",
            "                                                                                                  \n",
            " concatenate_46 (Concatenat  (None, 6, 6, 1184)           0         ['concatenate_45[0][0]',      \n",
            " e)                                                                  'conv2d_96[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_97 (Ba  (None, 6, 6, 1184)           4736      ['concatenate_46[0][0]']      \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_97 (Activation)  (None, 6, 6, 1184)           0         ['batch_normalization_97[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_97 (Conv2D)          (None, 6, 6, 128)            151680    ['activation_97[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_98 (Ba  (None, 6, 6, 128)            512       ['conv2d_97[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_98 (Activation)  (None, 6, 6, 128)            0         ['batch_normalization_98[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_98 (Conv2D)          (None, 6, 6, 32)             36896     ['activation_98[0][0]']       \n",
            "                                                                                                  \n",
            " concatenate_47 (Concatenat  (None, 6, 6, 1216)           0         ['concatenate_46[0][0]',      \n",
            " e)                                                                  'conv2d_98[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_99 (Ba  (None, 6, 6, 1216)           4864      ['concatenate_47[0][0]']      \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_99 (Activation)  (None, 6, 6, 1216)           0         ['batch_normalization_99[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_99 (Conv2D)          (None, 6, 6, 128)            155776    ['activation_99[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_100 (B  (None, 6, 6, 128)            512       ['conv2d_99[0][0]']           \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_100 (Activation  (None, 6, 6, 128)            0         ['batch_normalization_100[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_100 (Conv2D)         (None, 6, 6, 32)             36896     ['activation_100[0][0]']      \n",
            "                                                                                                  \n",
            " concatenate_48 (Concatenat  (None, 6, 6, 1248)           0         ['concatenate_47[0][0]',      \n",
            " e)                                                                  'conv2d_100[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_101 (B  (None, 6, 6, 1248)           4992      ['concatenate_48[0][0]']      \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_101 (Activation  (None, 6, 6, 1248)           0         ['batch_normalization_101[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_101 (Conv2D)         (None, 6, 6, 128)            159872    ['activation_101[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_102 (B  (None, 6, 6, 128)            512       ['conv2d_101[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_102 (Activation  (None, 6, 6, 128)            0         ['batch_normalization_102[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_102 (Conv2D)         (None, 6, 6, 32)             36896     ['activation_102[0][0]']      \n",
            "                                                                                                  \n",
            " concatenate_49 (Concatenat  (None, 6, 6, 1280)           0         ['concatenate_48[0][0]',      \n",
            " e)                                                                  'conv2d_102[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_103 (B  (None, 6, 6, 1280)           5120      ['concatenate_49[0][0]']      \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_103 (Activation  (None, 6, 6, 1280)           0         ['batch_normalization_103[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_103 (Conv2D)         (None, 6, 6, 128)            163968    ['activation_103[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_104 (B  (None, 6, 6, 128)            512       ['conv2d_103[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_104 (Activation  (None, 6, 6, 128)            0         ['batch_normalization_104[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_104 (Conv2D)         (None, 6, 6, 32)             36896     ['activation_104[0][0]']      \n",
            "                                                                                                  \n",
            " concatenate_50 (Concatenat  (None, 6, 6, 1312)           0         ['concatenate_49[0][0]',      \n",
            " e)                                                                  'conv2d_104[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_105 (B  (None, 6, 6, 1312)           5248      ['concatenate_50[0][0]']      \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_105 (Activation  (None, 6, 6, 1312)           0         ['batch_normalization_105[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_105 (Conv2D)         (None, 6, 6, 128)            168064    ['activation_105[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_106 (B  (None, 6, 6, 128)            512       ['conv2d_105[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_106 (Activation  (None, 6, 6, 128)            0         ['batch_normalization_106[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_106 (Conv2D)         (None, 6, 6, 32)             36896     ['activation_106[0][0]']      \n",
            "                                                                                                  \n",
            " concatenate_51 (Concatenat  (None, 6, 6, 1344)           0         ['concatenate_50[0][0]',      \n",
            " e)                                                                  'conv2d_106[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_107 (B  (None, 6, 6, 1344)           5376      ['concatenate_51[0][0]']      \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_107 (Activation  (None, 6, 6, 1344)           0         ['batch_normalization_107[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_107 (Conv2D)         (None, 6, 6, 128)            172160    ['activation_107[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_108 (B  (None, 6, 6, 128)            512       ['conv2d_107[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_108 (Activation  (None, 6, 6, 128)            0         ['batch_normalization_108[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_108 (Conv2D)         (None, 6, 6, 32)             36896     ['activation_108[0][0]']      \n",
            "                                                                                                  \n",
            " concatenate_52 (Concatenat  (None, 6, 6, 1376)           0         ['concatenate_51[0][0]',      \n",
            " e)                                                                  'conv2d_108[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_109 (B  (None, 6, 6, 1376)           5504      ['concatenate_52[0][0]']      \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_109 (Activation  (None, 6, 6, 1376)           0         ['batch_normalization_109[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_109 (Conv2D)         (None, 6, 6, 128)            176256    ['activation_109[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_110 (B  (None, 6, 6, 128)            512       ['conv2d_109[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_110 (Activation  (None, 6, 6, 128)            0         ['batch_normalization_110[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_110 (Conv2D)         (None, 6, 6, 32)             36896     ['activation_110[0][0]']      \n",
            "                                                                                                  \n",
            " concatenate_53 (Concatenat  (None, 6, 6, 1408)           0         ['concatenate_52[0][0]',      \n",
            " e)                                                                  'conv2d_110[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_111 (B  (None, 6, 6, 1408)           5632      ['concatenate_53[0][0]']      \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_111 (Activation  (None, 6, 6, 1408)           0         ['batch_normalization_111[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_111 (Conv2D)         (None, 6, 6, 128)            180352    ['activation_111[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_112 (B  (None, 6, 6, 128)            512       ['conv2d_111[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_112 (Activation  (None, 6, 6, 128)            0         ['batch_normalization_112[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_112 (Conv2D)         (None, 6, 6, 32)             36896     ['activation_112[0][0]']      \n",
            "                                                                                                  \n",
            " concatenate_54 (Concatenat  (None, 6, 6, 1440)           0         ['concatenate_53[0][0]',      \n",
            " e)                                                                  'conv2d_112[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_113 (B  (None, 6, 6, 1440)           5760      ['concatenate_54[0][0]']      \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_113 (Activation  (None, 6, 6, 1440)           0         ['batch_normalization_113[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_113 (Conv2D)         (None, 6, 6, 128)            184448    ['activation_113[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_114 (B  (None, 6, 6, 128)            512       ['conv2d_113[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_114 (Activation  (None, 6, 6, 128)            0         ['batch_normalization_114[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_114 (Conv2D)         (None, 6, 6, 32)             36896     ['activation_114[0][0]']      \n",
            "                                                                                                  \n",
            " concatenate_55 (Concatenat  (None, 6, 6, 1472)           0         ['concatenate_54[0][0]',      \n",
            " e)                                                                  'conv2d_114[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_115 (B  (None, 6, 6, 1472)           5888      ['concatenate_55[0][0]']      \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_115 (Activation  (None, 6, 6, 1472)           0         ['batch_normalization_115[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_115 (Conv2D)         (None, 6, 6, 128)            188544    ['activation_115[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_116 (B  (None, 6, 6, 128)            512       ['conv2d_115[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_116 (Activation  (None, 6, 6, 128)            0         ['batch_normalization_116[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_116 (Conv2D)         (None, 6, 6, 32)             36896     ['activation_116[0][0]']      \n",
            "                                                                                                  \n",
            " concatenate_56 (Concatenat  (None, 6, 6, 1504)           0         ['concatenate_55[0][0]',      \n",
            " e)                                                                  'conv2d_116[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_117 (B  (None, 6, 6, 1504)           6016      ['concatenate_56[0][0]']      \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_117 (Activation  (None, 6, 6, 1504)           0         ['batch_normalization_117[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_117 (Conv2D)         (None, 6, 6, 128)            192640    ['activation_117[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_118 (B  (None, 6, 6, 128)            512       ['conv2d_117[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_118 (Activation  (None, 6, 6, 128)            0         ['batch_normalization_118[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_118 (Conv2D)         (None, 6, 6, 32)             36896     ['activation_118[0][0]']      \n",
            "                                                                                                  \n",
            " concatenate_57 (Concatenat  (None, 6, 6, 1536)           0         ['concatenate_56[0][0]',      \n",
            " e)                                                                  'conv2d_118[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_119 (B  (None, 6, 6, 1536)           6144      ['concatenate_57[0][0]']      \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_119 (Activation  (None, 6, 6, 1536)           0         ['batch_normalization_119[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_119 (Conv2D)         (None, 6, 6, 128)            196736    ['activation_119[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_120 (B  (None, 6, 6, 128)            512       ['conv2d_119[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_120 (Activation  (None, 6, 6, 128)            0         ['batch_normalization_120[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_120 (Conv2D)         (None, 6, 6, 32)             36896     ['activation_120[0][0]']      \n",
            "                                                                                                  \n",
            " concatenate_58 (Concatenat  (None, 6, 6, 1568)           0         ['concatenate_57[0][0]',      \n",
            " e)                                                                  'conv2d_120[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_121 (B  (None, 6, 6, 1568)           6272      ['concatenate_58[0][0]']      \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_121 (Activation  (None, 6, 6, 1568)           0         ['batch_normalization_121[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_121 (Conv2D)         (None, 6, 6, 128)            200832    ['activation_121[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_122 (B  (None, 6, 6, 128)            512       ['conv2d_121[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_122 (Activation  (None, 6, 6, 128)            0         ['batch_normalization_122[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_122 (Conv2D)         (None, 6, 6, 32)             36896     ['activation_122[0][0]']      \n",
            "                                                                                                  \n",
            " concatenate_59 (Concatenat  (None, 6, 6, 1600)           0         ['concatenate_58[0][0]',      \n",
            " e)                                                                  'conv2d_122[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_123 (B  (None, 6, 6, 1600)           6400      ['concatenate_59[0][0]']      \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_123 (Activation  (None, 6, 6, 1600)           0         ['batch_normalization_123[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_123 (Conv2D)         (None, 6, 6, 128)            204928    ['activation_123[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_124 (B  (None, 6, 6, 128)            512       ['conv2d_123[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_124 (Activation  (None, 6, 6, 128)            0         ['batch_normalization_124[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_124 (Conv2D)         (None, 6, 6, 32)             36896     ['activation_124[0][0]']      \n",
            "                                                                                                  \n",
            " concatenate_60 (Concatenat  (None, 6, 6, 1632)           0         ['concatenate_59[0][0]',      \n",
            " e)                                                                  'conv2d_124[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_125 (B  (None, 6, 6, 1632)           6528      ['concatenate_60[0][0]']      \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_125 (Activation  (None, 6, 6, 1632)           0         ['batch_normalization_125[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_125 (Conv2D)         (None, 6, 6, 128)            209024    ['activation_125[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_126 (B  (None, 6, 6, 128)            512       ['conv2d_125[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_126 (Activation  (None, 6, 6, 128)            0         ['batch_normalization_126[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_126 (Conv2D)         (None, 6, 6, 32)             36896     ['activation_126[0][0]']      \n",
            "                                                                                                  \n",
            " concatenate_61 (Concatenat  (None, 6, 6, 1664)           0         ['concatenate_60[0][0]',      \n",
            " e)                                                                  'conv2d_126[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_127 (B  (None, 6, 6, 1664)           6656      ['concatenate_61[0][0]']      \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_127 (Activation  (None, 6, 6, 1664)           0         ['batch_normalization_127[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_127 (Conv2D)         (None, 6, 6, 128)            213120    ['activation_127[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_128 (B  (None, 6, 6, 128)            512       ['conv2d_127[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_128 (Activation  (None, 6, 6, 128)            0         ['batch_normalization_128[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_128 (Conv2D)         (None, 6, 6, 32)             36896     ['activation_128[0][0]']      \n",
            "                                                                                                  \n",
            " concatenate_62 (Concatenat  (None, 6, 6, 1696)           0         ['concatenate_61[0][0]',      \n",
            " e)                                                                  'conv2d_128[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_129 (B  (None, 6, 6, 1696)           6784      ['concatenate_62[0][0]']      \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_129 (Activation  (None, 6, 6, 1696)           0         ['batch_normalization_129[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_129 (Conv2D)         (None, 6, 6, 128)            217216    ['activation_129[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_130 (B  (None, 6, 6, 128)            512       ['conv2d_129[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_130 (Activation  (None, 6, 6, 128)            0         ['batch_normalization_130[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_130 (Conv2D)         (None, 6, 6, 32)             36896     ['activation_130[0][0]']      \n",
            "                                                                                                  \n",
            " concatenate_63 (Concatenat  (None, 6, 6, 1728)           0         ['concatenate_62[0][0]',      \n",
            " e)                                                                  'conv2d_130[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_131 (B  (None, 6, 6, 1728)           6912      ['concatenate_63[0][0]']      \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_131 (Activation  (None, 6, 6, 1728)           0         ['batch_normalization_131[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_131 (Conv2D)         (None, 6, 6, 128)            221312    ['activation_131[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_132 (B  (None, 6, 6, 128)            512       ['conv2d_131[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_132 (Activation  (None, 6, 6, 128)            0         ['batch_normalization_132[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_132 (Conv2D)         (None, 6, 6, 32)             36896     ['activation_132[0][0]']      \n",
            "                                                                                                  \n",
            " concatenate_64 (Concatenat  (None, 6, 6, 1760)           0         ['concatenate_63[0][0]',      \n",
            " e)                                                                  'conv2d_132[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_133 (B  (None, 6, 6, 1760)           7040      ['concatenate_64[0][0]']      \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_133 (Activation  (None, 6, 6, 1760)           0         ['batch_normalization_133[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_133 (Conv2D)         (None, 6, 6, 128)            225408    ['activation_133[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_134 (B  (None, 6, 6, 128)            512       ['conv2d_133[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_134 (Activation  (None, 6, 6, 128)            0         ['batch_normalization_134[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_134 (Conv2D)         (None, 6, 6, 32)             36896     ['activation_134[0][0]']      \n",
            "                                                                                                  \n",
            " concatenate_65 (Concatenat  (None, 6, 6, 1792)           0         ['concatenate_64[0][0]',      \n",
            " e)                                                                  'conv2d_134[0][0]']          \n",
            "                                                                                                  \n",
            " global_average_pooling2d (  (None, 1792)                 0         ['concatenate_65[0][0]']      \n",
            " GlobalAveragePooling2D)                                                                          \n",
            "                                                                                                  \n",
            " dense (Dense)               (None, 2)                    3586      ['global_average_pooling2d[0][\n",
            "                                                                    0]']                          \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 9640258 (36.77 MB)\n",
            "Trainable params: 9515906 (36.30 MB)\n",
            "Non-trainable params: 124352 (485.75 KB)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "learning_rate = 0.00001\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "\n",
        "\n",
        "# Define steps per epoch and validation steps\n",
        "steps_per_epoch = len(x_train_normalized) // batch_size\n",
        "validation_steps = len(x_val_normalized) // batch_size\n",
        "\n",
        "# Train the model with early stopping\n",
        "history = model.fit(\n",
        "    train_set_conv,\n",
        "    steps_per_epoch=steps_per_epoch,\n",
        "    epochs=25,  # You can adjust the number of epochs\n",
        "    validation_data=valid_set_conv,\n",
        "    validation_steps=validation_steps,\n",
        "\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IrFrlLXj00sa",
        "outputId": "5842d0d5-636a-4a1d-c827-d3cda98c60a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "53/53 [==============================] - 129s 465ms/step - loss: 0.3973 - accuracy: 0.8299 - val_loss: 0.6963 - val_accuracy: 0.5179\n",
            "Epoch 2/25\n",
            "53/53 [==============================] - 17s 305ms/step - loss: 0.3011 - accuracy: 0.8751 - val_loss: 0.7615 - val_accuracy: 0.5201\n",
            "Epoch 3/25\n",
            "53/53 [==============================] - 15s 289ms/step - loss: 0.2625 - accuracy: 0.8979 - val_loss: 0.7534 - val_accuracy: 0.5067\n",
            "Epoch 4/25\n",
            "53/53 [==============================] - 16s 290ms/step - loss: 0.2516 - accuracy: 0.8971 - val_loss: 0.7407 - val_accuracy: 0.4353\n",
            "Epoch 5/25\n",
            "53/53 [==============================] - 15s 288ms/step - loss: 0.2344 - accuracy: 0.9068 - val_loss: 0.8959 - val_accuracy: 0.5112\n",
            "Epoch 6/25\n",
            "53/53 [==============================] - 16s 291ms/step - loss: 0.2275 - accuracy: 0.9104 - val_loss: 0.8650 - val_accuracy: 0.5469\n",
            "Epoch 7/25\n",
            "53/53 [==============================] - 16s 301ms/step - loss: 0.2172 - accuracy: 0.9160 - val_loss: 1.1394 - val_accuracy: 0.5625\n",
            "Epoch 8/25\n",
            "53/53 [==============================] - 16s 290ms/step - loss: 0.2074 - accuracy: 0.9169 - val_loss: 0.6188 - val_accuracy: 0.6920\n",
            "Epoch 9/25\n",
            "53/53 [==============================] - 15s 287ms/step - loss: 0.2011 - accuracy: 0.9210 - val_loss: 0.5885 - val_accuracy: 0.7366\n",
            "Epoch 10/25\n",
            "53/53 [==============================] - 16s 290ms/step - loss: 0.1943 - accuracy: 0.9243 - val_loss: 0.4270 - val_accuracy: 0.8125\n",
            "Epoch 11/25\n",
            "53/53 [==============================] - 15s 289ms/step - loss: 0.1941 - accuracy: 0.9195 - val_loss: 0.3329 - val_accuracy: 0.8661\n",
            "Epoch 12/25\n",
            "53/53 [==============================] - 16s 301ms/step - loss: 0.1770 - accuracy: 0.9320 - val_loss: 0.3448 - val_accuracy: 0.8817\n",
            "Epoch 13/25\n",
            "53/53 [==============================] - 16s 294ms/step - loss: 0.1768 - accuracy: 0.9298 - val_loss: 0.3218 - val_accuracy: 0.8906\n",
            "Epoch 14/25\n",
            "53/53 [==============================] - 15s 287ms/step - loss: 0.1755 - accuracy: 0.9322 - val_loss: 0.2316 - val_accuracy: 0.9062\n",
            "Epoch 15/25\n",
            "53/53 [==============================] - 16s 291ms/step - loss: 0.1767 - accuracy: 0.9299 - val_loss: 0.2596 - val_accuracy: 0.9107\n",
            "Epoch 16/25\n",
            "53/53 [==============================] - 16s 291ms/step - loss: 0.1675 - accuracy: 0.9367 - val_loss: 0.2544 - val_accuracy: 0.9062\n",
            "Epoch 17/25\n",
            "53/53 [==============================] - 16s 306ms/step - loss: 0.1697 - accuracy: 0.9340 - val_loss: 0.2932 - val_accuracy: 0.9085\n",
            "Epoch 18/25\n",
            "53/53 [==============================] - 15s 289ms/step - loss: 0.1644 - accuracy: 0.9343 - val_loss: 0.3163 - val_accuracy: 0.8996\n",
            "Epoch 19/25\n",
            "53/53 [==============================] - 16s 291ms/step - loss: 0.1590 - accuracy: 0.9388 - val_loss: 0.2690 - val_accuracy: 0.9174\n",
            "Epoch 20/25\n",
            "53/53 [==============================] - 16s 291ms/step - loss: 0.1572 - accuracy: 0.9340 - val_loss: 0.2471 - val_accuracy: 0.9085\n",
            "Epoch 21/25\n",
            "53/53 [==============================] - 15s 288ms/step - loss: 0.1565 - accuracy: 0.9385 - val_loss: 0.2560 - val_accuracy: 0.9129\n",
            "Epoch 22/25\n",
            "53/53 [==============================] - 16s 293ms/step - loss: 0.1504 - accuracy: 0.9411 - val_loss: 0.3158 - val_accuracy: 0.9040\n",
            "Epoch 23/25\n",
            "53/53 [==============================] - 17s 316ms/step - loss: 0.1470 - accuracy: 0.9438 - val_loss: 0.2226 - val_accuracy: 0.9018\n",
            "Epoch 24/25\n",
            "53/53 [==============================] - 16s 297ms/step - loss: 0.1430 - accuracy: 0.9456 - val_loss: 0.2861 - val_accuracy: 0.8973\n",
            "Epoch 25/25\n",
            "53/53 [==============================] - 15s 290ms/step - loss: 0.1395 - accuracy: 0.9476 - val_loss: 0.2938 - val_accuracy: 0.9107\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on the training data\n",
        "train_loss, train_accuracy = model.evaluate(train_set_conv, steps=steps_per_epoch)\n",
        "print(f\"Training Loss: {train_loss:.4f}\")\n",
        "print(f\"Training Accuracy: {train_accuracy * 100:.2f}%\")\n",
        "\n",
        "# Evaluate the model on the test data\n",
        "test_loss, test_accuracy = model.evaluate(test_set_conv, steps=validation_steps)\n",
        "print(f\"Test Loss: {test_loss:.4f}\")\n",
        "print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SWuZRBUS2PjM",
        "outputId": "2b0d6f82-f586-4de3-ad85-d6ba01a18d03"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "53/53 [==============================] - 12s 223ms/step - loss: 0.1280 - accuracy: 0.9522\n",
            "Training Loss: 0.1280\n",
            "Training Accuracy: 95.22%\n",
            "7/7 [==============================] - 1s 70ms/step - loss: 0.2881 - accuracy: 0.9018\n",
            "Test Loss: 0.2881\n",
            "Test Accuracy: 90.18%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_features = model.predict(x_train_normalized)\n",
        "x_val_features = model.predict(x_val_normalized)\n",
        "x_test_features = model.predict(x_test_normalized)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QM-Z5XlreDzt",
        "outputId": "3384590d-e9e0-4d39-b544-8fe7da92e655"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "108/108 [==============================] - 17s 77ms/step\n",
            "16/16 [==============================] - 3s 180ms/step\n",
            "31/31 [==============================] - 3s 113ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_features = x_train_features.reshape(x_train_features.shape[0], -1)\n",
        "x_val_features = x_val_features.reshape(x_val_features.shape[0], -1)\n",
        "x_test_features = x_test_features.reshape(x_test_features.shape[0], -1)"
      ],
      "metadata": {
        "id": "27F309BPhjSY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix"
      ],
      "metadata": {
        "id": "FN70K9hzhtGD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Support Vector Machine (SVM)\n",
        "svm_model = SVC(kernel='rbf', C=4, gamma='scale')\n",
        "svm_model.fit(x_train_features, y_train)\n",
        "y_pred_svm = svm_model.predict(x_test_features)\n",
        "\n",
        "svm_accuracy = accuracy_score(y_test, y_pred_svm)\n",
        "svm_precision = precision_score(y_test, y_pred_svm)\n",
        "svm_recall = recall_score(y_test, y_pred_svm)\n",
        "svm_f1 = f1_score(y_test, y_pred_svm)\n",
        "\n",
        "tn, fp, fn, tp = confusion_matrix(y_test, y_pred_svm).ravel()\n",
        "svm_specificity = tn / (tn + fp)\n",
        "\n",
        "print(\"SVM Accuracy:\", svm_accuracy)\n",
        "print(\"SVM Precision:\", svm_precision)\n",
        "print(\"SVM Sensitivity (Recall):\", svm_recall)\n",
        "print(\"SVM Specificity:\", svm_specificity)\n",
        "print(\"SVM F1 Score:\", svm_f1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XtM1oVJdh5kE",
        "outputId": "02d01668-8db4-41a8-c625-09f07ee3a5d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVM Accuracy: 0.9197154471544715\n",
            "SVM Precision: 0.9452332657200812\n",
            "SVM Sensitivity (Recall): 0.8996138996138996\n",
            "SVM Specificity: 0.9420600858369099\n",
            "SVM F1 Score: 0.9218595450049455\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Random Forest Classifier\n",
        "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf_model.fit(x_train_features, y_train)\n",
        "y_pred_rf = rf_model.predict(x_test_features)\n",
        "\n",
        "rf_accuracy = accuracy_score(y_test, y_pred_rf)\n",
        "rf_precision = precision_score(y_test, y_pred_rf)\n",
        "rf_recall = recall_score(y_test, y_pred_rf)\n",
        "rf_f1 = f1_score(y_test, y_pred_rf)\n",
        "\n",
        "tn, fp, fn, tp = confusion_matrix(y_test, y_pred_rf).ravel()\n",
        "rf_specificity = tn / (tn + fp)\n",
        "\n",
        "print(\"Random Forest Accuracy:\", rf_accuracy)\n",
        "print(\"Random Forest Precision:\", rf_precision)\n",
        "print(\"Random Forest Sensitivity (Recall):\", rf_recall)\n",
        "print(\"Random Forest Specificity:\", rf_specificity)\n",
        "print(\"Random Forest F1 Score:\", rf_f1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x9i0kygfivs3",
        "outputId": "7c40c71a-1b16-4c77-a1b0-653cd164e078"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest Accuracy: 0.9034552845528455\n",
            "Random Forest Precision: 0.9255533199195171\n",
            "Random Forest Sensitivity (Recall): 0.888030888030888\n",
            "Random Forest Specificity: 0.9206008583690987\n",
            "Random Forest F1 Score: 0.9064039408866996\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# K-Nearest Neighbors Classifier\n",
        "knn_model = KNeighborsClassifier(n_neighbors=5)\n",
        "knn_model.fit(x_train_features, y_train)\n",
        "y_pred_knn = knn_model.predict(x_test_features)\n",
        "\n",
        "knn_accuracy = accuracy_score(y_test, y_pred_knn)\n",
        "knn_precision = precision_score(y_test, y_pred_knn)\n",
        "knn_recall = recall_score(y_test, y_pred_knn)\n",
        "knn_f1 = f1_score(y_test, y_pred_knn)\n",
        "\n",
        "tn, fp, fn, tp = confusion_matrix(y_test, y_pred_knn).ravel()\n",
        "knn_specificity = tn / (tn + fp)\n",
        "\n",
        "print(\"KNN Accuracy:\", knn_accuracy)\n",
        "print(\"KNN Precision:\", knn_precision)\n",
        "print(\"KNN Sensitivity (Recall):\", knn_recall)\n",
        "print(\"KNN Specificity:\", knn_specificity)\n",
        "print(\"KNN F1 Score:\", knn_f1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uczXAF8ri2g6",
        "outputId": "663b9e1b-0605-4984-9549-273d715e2718"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KNN Accuracy: 0.915650406504065\n",
            "KNN Precision: 0.937625754527163\n",
            "KNN Sensitivity (Recall): 0.8996138996138996\n",
            "KNN Specificity: 0.9334763948497854\n",
            "KNN F1 Score: 0.9182266009852217\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hybrid (RESNET-50"
      ],
      "metadata": {
        "id": "_zoagaCD4hp2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Conv2D, BatchNormalization, ReLU, DepthwiseConv2D, GlobalAveragePooling2D, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.layers import Dropout\n",
        "\n",
        "# Define input shape\n",
        "input_shape = (100, 100, 3)  # Assuming input images have shape (224, 224, 3)\n",
        "num_classes = 2  # Number of output classes\n",
        "\n",
        "# Build ResNet50-like architecture\n",
        "def build_resnet50(input_shape):\n",
        "    input_tensor = Input(shape=input_shape)\n",
        "\n",
        "    # Initial convolutional layer\n",
        "    x = Conv2D(64, (7, 7), strides=(2, 2), padding='same')(input_tensor)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = ReLU()(x)\n",
        "\n",
        "    # Residual blocks\n",
        "    x = resnet_block(x, filters=[64, 64, 256], strides=1, block_name='block1')\n",
        "    x = resnet_block(x, filters=[128, 128, 512], strides=2, block_name='block2')\n",
        "    x = resnet_block(x, filters=[256, 256, 1024], strides=2, block_name='block3')\n",
        "    x = resnet_block(x, filters=[512, 512, 2048], strides=2, block_name='block4')\n",
        "\n",
        "    # Global Average Pooling\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "\n",
        "    return Model(inputs=input_tensor, outputs=x)\n",
        "\n",
        "# Define MobileNet-like architecture\n",
        "def build_mobilenet(input_shape):\n",
        "    input_tensor = Input(shape=input_shape)\n",
        "\n",
        "    # Initial depthwise separable convolution\n",
        "    x = DepthwiseConv2D((3, 3), strides=(2, 2), padding='same')(input_tensor)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = ReLU()(x)\n",
        "\n",
        "    # Depthwise separable convolutions\n",
        "    x = mobilenet_block(x, filters=128, strides=1, block_name='block1')\n",
        "    x = mobilenet_block(x, filters=256, strides=2, block_name='block2')\n",
        "    x = mobilenet_block(x, filters=512, strides=2, block_name='block3')\n",
        "    x = mobilenet_block(x, filters=1024, strides=2, block_name='block4')\n",
        "\n",
        "    # Global Average Pooling\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "\n",
        "    return Model(inputs=input_tensor, outputs=x)\n",
        "\n",
        "# ResNet block\n",
        "def resnet_block(input_tensor, filters, strides, block_name):\n",
        "    x = Conv2D(filters[0], (1, 1), strides=strides, padding='same', name=block_name+'_conv1')(input_tensor)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = ReLU()(x)\n",
        "\n",
        "    x = Conv2D(filters[1], (3, 3), padding='same', name=block_name+'_conv2')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = ReLU()(x)\n",
        "\n",
        "    x = Conv2D(filters[2], (1, 1), padding='same', name=block_name+'_conv3')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "\n",
        "    # Shortcut connection\n",
        "    shortcut = Conv2D(filters[2], (1, 1), strides=strides, padding='same', name=block_name+'_shortcut')(input_tensor)\n",
        "    shortcut = BatchNormalization()(shortcut)\n",
        "\n",
        "    # Add shortcut to the output\n",
        "    x = tf.keras.layers.add([x, shortcut])\n",
        "    x = ReLU()(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "# MobileNet block\n",
        "def mobilenet_block(input_tensor, filters, strides, block_name):\n",
        "    x = DepthwiseConv2D((3, 3), strides=strides, padding='same', name=block_name+'_depthwise')(input_tensor)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = ReLU()(x)\n",
        "\n",
        "    x = Conv2D(filters, (1, 1), padding='same', name=block_name+'_pointwise')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = ReLU()(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "# Build ResNet50 model\n",
        "resnet_model = build_resnet50(input_shape)\n",
        "\n",
        "# Build MobileNet model\n",
        "mobilenet_model = build_mobilenet(input_shape)\n",
        "\n",
        "# Concatenate the output tensors from ResNet50 and MobileNet\n",
        "concatenated_output = tf.keras.layers.Concatenate()([resnet_model.output, mobilenet_model.output])\n",
        "\n",
        "# Add custom dense layers for classification with regularization\n",
        "dense_layer = Dense(128, activation='relu', kernel_regularizer=l2(0.001))(concatenated_output)\n",
        "dense_layer = Dropout(0.5)(dense_layer)  # Adding dropout with a rate of 0.5\n",
        "\n",
        "output_layer = Dense(num_classes, activation='softmax', kernel_regularizer=l2(0.001))(dense_layer)\n",
        "\n",
        "# Create the hybrid model with regularization\n",
        "hybrid_model_regularized = Model(inputs=[resnet_model.input, mobilenet_model.input], outputs=output_layer)\n",
        "\n",
        "# Compile the model\n",
        "hybrid_model_regularized.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Print summary of the model architecture\n",
        "hybrid_model_regularized.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tcFcTMo-j2-J",
        "outputId": "99ef69aa-9d19-4939-9597-96eed0b62dce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_3\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_2 (InputLayer)        [(None, 100, 100, 3)]        0         []                            \n",
            "                                                                                                  \n",
            " conv2d_135 (Conv2D)         (None, 50, 50, 64)           9472      ['input_2[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_135 (B  (None, 50, 50, 64)           256       ['conv2d_135[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " re_lu (ReLU)                (None, 50, 50, 64)           0         ['batch_normalization_135[0][0\n",
            "                                                                    ]']                           \n",
            "                                                                                                  \n",
            " block1_conv1 (Conv2D)       (None, 50, 50, 64)           4160      ['re_lu[0][0]']               \n",
            "                                                                                                  \n",
            " batch_normalization_136 (B  (None, 50, 50, 64)           256       ['block1_conv1[0][0]']        \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " re_lu_1 (ReLU)              (None, 50, 50, 64)           0         ['batch_normalization_136[0][0\n",
            "                                                                    ]']                           \n",
            "                                                                                                  \n",
            " block1_conv2 (Conv2D)       (None, 50, 50, 64)           36928     ['re_lu_1[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_137 (B  (None, 50, 50, 64)           256       ['block1_conv2[0][0]']        \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " re_lu_2 (ReLU)              (None, 50, 50, 64)           0         ['batch_normalization_137[0][0\n",
            "                                                                    ]']                           \n",
            "                                                                                                  \n",
            " block1_conv3 (Conv2D)       (None, 50, 50, 256)          16640     ['re_lu_2[0][0]']             \n",
            "                                                                                                  \n",
            " block1_shortcut (Conv2D)    (None, 50, 50, 256)          16640     ['re_lu[0][0]']               \n",
            "                                                                                                  \n",
            " batch_normalization_138 (B  (None, 50, 50, 256)          1024      ['block1_conv3[0][0]']        \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_139 (B  (None, 50, 50, 256)          1024      ['block1_shortcut[0][0]']     \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " add (Add)                   (None, 50, 50, 256)          0         ['batch_normalization_138[0][0\n",
            "                                                                    ]',                           \n",
            "                                                                     'batch_normalization_139[0][0\n",
            "                                                                    ]']                           \n",
            "                                                                                                  \n",
            " re_lu_3 (ReLU)              (None, 50, 50, 256)          0         ['add[0][0]']                 \n",
            "                                                                                                  \n",
            " block2_conv1 (Conv2D)       (None, 25, 25, 128)          32896     ['re_lu_3[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_140 (B  (None, 25, 25, 128)          512       ['block2_conv1[0][0]']        \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " re_lu_4 (ReLU)              (None, 25, 25, 128)          0         ['batch_normalization_140[0][0\n",
            "                                                                    ]']                           \n",
            "                                                                                                  \n",
            " input_3 (InputLayer)        [(None, 100, 100, 3)]        0         []                            \n",
            "                                                                                                  \n",
            " block2_conv2 (Conv2D)       (None, 25, 25, 128)          147584    ['re_lu_4[0][0]']             \n",
            "                                                                                                  \n",
            " depthwise_conv2d (Depthwis  (None, 50, 50, 3)            30        ['input_3[0][0]']             \n",
            " eConv2D)                                                                                         \n",
            "                                                                                                  \n",
            " batch_normalization_141 (B  (None, 25, 25, 128)          512       ['block2_conv2[0][0]']        \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_152 (B  (None, 50, 50, 3)            12        ['depthwise_conv2d[0][0]']    \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " re_lu_5 (ReLU)              (None, 25, 25, 128)          0         ['batch_normalization_141[0][0\n",
            "                                                                    ]']                           \n",
            "                                                                                                  \n",
            " re_lu_13 (ReLU)             (None, 50, 50, 3)            0         ['batch_normalization_152[0][0\n",
            "                                                                    ]']                           \n",
            "                                                                                                  \n",
            " block2_conv3 (Conv2D)       (None, 25, 25, 512)          66048     ['re_lu_5[0][0]']             \n",
            "                                                                                                  \n",
            " block2_shortcut (Conv2D)    (None, 25, 25, 512)          131584    ['re_lu_3[0][0]']             \n",
            "                                                                                                  \n",
            " block1_depthwise (Depthwis  (None, 50, 50, 3)            30        ['re_lu_13[0][0]']            \n",
            " eConv2D)                                                                                         \n",
            "                                                                                                  \n",
            " batch_normalization_142 (B  (None, 25, 25, 512)          2048      ['block2_conv3[0][0]']        \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_143 (B  (None, 25, 25, 512)          2048      ['block2_shortcut[0][0]']     \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_153 (B  (None, 50, 50, 3)            12        ['block1_depthwise[0][0]']    \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " add_1 (Add)                 (None, 25, 25, 512)          0         ['batch_normalization_142[0][0\n",
            "                                                                    ]',                           \n",
            "                                                                     'batch_normalization_143[0][0\n",
            "                                                                    ]']                           \n",
            "                                                                                                  \n",
            " re_lu_14 (ReLU)             (None, 50, 50, 3)            0         ['batch_normalization_153[0][0\n",
            "                                                                    ]']                           \n",
            "                                                                                                  \n",
            " re_lu_6 (ReLU)              (None, 25, 25, 512)          0         ['add_1[0][0]']               \n",
            "                                                                                                  \n",
            " block1_pointwise (Conv2D)   (None, 50, 50, 128)          512       ['re_lu_14[0][0]']            \n",
            "                                                                                                  \n",
            " block3_conv1 (Conv2D)       (None, 13, 13, 256)          131328    ['re_lu_6[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_154 (B  (None, 50, 50, 128)          512       ['block1_pointwise[0][0]']    \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_144 (B  (None, 13, 13, 256)          1024      ['block3_conv1[0][0]']        \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " re_lu_15 (ReLU)             (None, 50, 50, 128)          0         ['batch_normalization_154[0][0\n",
            "                                                                    ]']                           \n",
            "                                                                                                  \n",
            " re_lu_7 (ReLU)              (None, 13, 13, 256)          0         ['batch_normalization_144[0][0\n",
            "                                                                    ]']                           \n",
            "                                                                                                  \n",
            " block2_depthwise (Depthwis  (None, 25, 25, 128)          1280      ['re_lu_15[0][0]']            \n",
            " eConv2D)                                                                                         \n",
            "                                                                                                  \n",
            " block3_conv2 (Conv2D)       (None, 13, 13, 256)          590080    ['re_lu_7[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_155 (B  (None, 25, 25, 128)          512       ['block2_depthwise[0][0]']    \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_145 (B  (None, 13, 13, 256)          1024      ['block3_conv2[0][0]']        \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " re_lu_16 (ReLU)             (None, 25, 25, 128)          0         ['batch_normalization_155[0][0\n",
            "                                                                    ]']                           \n",
            "                                                                                                  \n",
            " re_lu_8 (ReLU)              (None, 13, 13, 256)          0         ['batch_normalization_145[0][0\n",
            "                                                                    ]']                           \n",
            "                                                                                                  \n",
            " block2_pointwise (Conv2D)   (None, 25, 25, 256)          33024     ['re_lu_16[0][0]']            \n",
            "                                                                                                  \n",
            " block3_conv3 (Conv2D)       (None, 13, 13, 1024)         263168    ['re_lu_8[0][0]']             \n",
            "                                                                                                  \n",
            " block3_shortcut (Conv2D)    (None, 13, 13, 1024)         525312    ['re_lu_6[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_156 (B  (None, 25, 25, 256)          1024      ['block2_pointwise[0][0]']    \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_146 (B  (None, 13, 13, 1024)         4096      ['block3_conv3[0][0]']        \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_147 (B  (None, 13, 13, 1024)         4096      ['block3_shortcut[0][0]']     \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " re_lu_17 (ReLU)             (None, 25, 25, 256)          0         ['batch_normalization_156[0][0\n",
            "                                                                    ]']                           \n",
            "                                                                                                  \n",
            " add_2 (Add)                 (None, 13, 13, 1024)         0         ['batch_normalization_146[0][0\n",
            "                                                                    ]',                           \n",
            "                                                                     'batch_normalization_147[0][0\n",
            "                                                                    ]']                           \n",
            "                                                                                                  \n",
            " block3_depthwise (Depthwis  (None, 13, 13, 256)          2560      ['re_lu_17[0][0]']            \n",
            " eConv2D)                                                                                         \n",
            "                                                                                                  \n",
            " re_lu_9 (ReLU)              (None, 13, 13, 1024)         0         ['add_2[0][0]']               \n",
            "                                                                                                  \n",
            " batch_normalization_157 (B  (None, 13, 13, 256)          1024      ['block3_depthwise[0][0]']    \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " block4_conv1 (Conv2D)       (None, 7, 7, 512)            524800    ['re_lu_9[0][0]']             \n",
            "                                                                                                  \n",
            " re_lu_18 (ReLU)             (None, 13, 13, 256)          0         ['batch_normalization_157[0][0\n",
            "                                                                    ]']                           \n",
            "                                                                                                  \n",
            " batch_normalization_148 (B  (None, 7, 7, 512)            2048      ['block4_conv1[0][0]']        \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " block3_pointwise (Conv2D)   (None, 13, 13, 512)          131584    ['re_lu_18[0][0]']            \n",
            "                                                                                                  \n",
            " re_lu_10 (ReLU)             (None, 7, 7, 512)            0         ['batch_normalization_148[0][0\n",
            "                                                                    ]']                           \n",
            "                                                                                                  \n",
            " batch_normalization_158 (B  (None, 13, 13, 512)          2048      ['block3_pointwise[0][0]']    \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " block4_conv2 (Conv2D)       (None, 7, 7, 512)            2359808   ['re_lu_10[0][0]']            \n",
            "                                                                                                  \n",
            " re_lu_19 (ReLU)             (None, 13, 13, 512)          0         ['batch_normalization_158[0][0\n",
            "                                                                    ]']                           \n",
            "                                                                                                  \n",
            " batch_normalization_149 (B  (None, 7, 7, 512)            2048      ['block4_conv2[0][0]']        \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " block4_depthwise (Depthwis  (None, 7, 7, 512)            5120      ['re_lu_19[0][0]']            \n",
            " eConv2D)                                                                                         \n",
            "                                                                                                  \n",
            " re_lu_11 (ReLU)             (None, 7, 7, 512)            0         ['batch_normalization_149[0][0\n",
            "                                                                    ]']                           \n",
            "                                                                                                  \n",
            " batch_normalization_159 (B  (None, 7, 7, 512)            2048      ['block4_depthwise[0][0]']    \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " block4_conv3 (Conv2D)       (None, 7, 7, 2048)           1050624   ['re_lu_11[0][0]']            \n",
            "                                                                                                  \n",
            " block4_shortcut (Conv2D)    (None, 7, 7, 2048)           2099200   ['re_lu_9[0][0]']             \n",
            "                                                                                                  \n",
            " re_lu_20 (ReLU)             (None, 7, 7, 512)            0         ['batch_normalization_159[0][0\n",
            "                                                                    ]']                           \n",
            "                                                                                                  \n",
            " batch_normalization_150 (B  (None, 7, 7, 2048)           8192      ['block4_conv3[0][0]']        \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_151 (B  (None, 7, 7, 2048)           8192      ['block4_shortcut[0][0]']     \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " block4_pointwise (Conv2D)   (None, 7, 7, 1024)           525312    ['re_lu_20[0][0]']            \n",
            "                                                                                                  \n",
            " add_3 (Add)                 (None, 7, 7, 2048)           0         ['batch_normalization_150[0][0\n",
            "                                                                    ]',                           \n",
            "                                                                     'batch_normalization_151[0][0\n",
            "                                                                    ]']                           \n",
            "                                                                                                  \n",
            " batch_normalization_160 (B  (None, 7, 7, 1024)           4096      ['block4_pointwise[0][0]']    \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " re_lu_12 (ReLU)             (None, 7, 7, 2048)           0         ['add_3[0][0]']               \n",
            "                                                                                                  \n",
            " re_lu_21 (ReLU)             (None, 7, 7, 1024)           0         ['batch_normalization_160[0][0\n",
            "                                                                    ]']                           \n",
            "                                                                                                  \n",
            " global_average_pooling2d_1  (None, 2048)                 0         ['re_lu_12[0][0]']            \n",
            "  (GlobalAveragePooling2D)                                                                        \n",
            "                                                                                                  \n",
            " global_average_pooling2d_2  (None, 1024)                 0         ['re_lu_21[0][0]']            \n",
            "  (GlobalAveragePooling2D)                                                                        \n",
            "                                                                                                  \n",
            " concatenate_66 (Concatenat  (None, 3072)                 0         ['global_average_pooling2d_1[0\n",
            " e)                                                                 ][0]',                        \n",
            "                                                                     'global_average_pooling2d_2[0\n",
            "                                                                    ][0]']                        \n",
            "                                                                                                  \n",
            " dense_1 (Dense)             (None, 128)                  393344    ['concatenate_66[0][0]']      \n",
            "                                                                                                  \n",
            " dropout (Dropout)           (None, 128)                  0         ['dense_1[0][0]']             \n",
            "                                                                                                  \n",
            " dense_2 (Dense)             (None, 2)                    258       ['dropout[0][0]']             \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 9149270 (34.90 MB)\n",
            "Trainable params: 9124298 (34.81 MB)\n",
            "Non-trainable params: 24972 (97.55 KB)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.layers import Dropout\n",
        "\n",
        "# Assuming you have your optimizer, data, and other parameters defined\n",
        "\n",
        "learning_rate = 0.00001\n",
        "optimizer = Adam(learning_rate=learning_rate)\n",
        "\n",
        "# ... (Define x_train_normalized, x_val_normalized, y_train, y_val, batch_size, etc.)\n",
        "\n",
        "# Build the hybrid model with regularization (using previously modified code)\n",
        "# ... (Code for building the model as previously shown)\n",
        "\n",
        "# Compile the model\n",
        "hybrid_model_regularized.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "epochs = 25\n",
        "\n",
        "# Train the regularized model\n",
        "history_regularized = hybrid_model_regularized.fit(\n",
        "    [x_train_normalized, x_train_normalized],\n",
        "    y_train,\n",
        "    epochs=epochs,\n",
        "    batch_size=batch_size,\n",
        "    validation_data=([x_val_normalized, x_val_normalized], y_val)\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_cUxpb9Tj5mH",
        "outputId": "1b3d35f7-4ba1-449e-a87e-24ef098cacc8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "54/54 [==============================] - 50s 469ms/step - loss: 0.7030 - accuracy: 0.7866 - val_loss: 0.9428 - val_accuracy: 0.4878\n",
            "Epoch 2/25\n",
            "54/54 [==============================] - 13s 243ms/step - loss: 0.5431 - accuracy: 0.8792 - val_loss: 0.9727 - val_accuracy: 0.4878\n",
            "Epoch 3/25\n",
            "54/54 [==============================] - 13s 244ms/step - loss: 0.5040 - accuracy: 0.8961 - val_loss: 1.0306 - val_accuracy: 0.4878\n",
            "Epoch 4/25\n",
            "54/54 [==============================] - 13s 243ms/step - loss: 0.4776 - accuracy: 0.9059 - val_loss: 1.0844 - val_accuracy: 0.4878\n",
            "Epoch 5/25\n",
            "54/54 [==============================] - 13s 243ms/step - loss: 0.4637 - accuracy: 0.9123 - val_loss: 1.2099 - val_accuracy: 0.4878\n",
            "Epoch 6/25\n",
            "54/54 [==============================] - 13s 243ms/step - loss: 0.4528 - accuracy: 0.9216 - val_loss: 1.1208 - val_accuracy: 0.5061\n",
            "Epoch 7/25\n",
            "54/54 [==============================] - 13s 243ms/step - loss: 0.4347 - accuracy: 0.9254 - val_loss: 1.0667 - val_accuracy: 0.5366\n",
            "Epoch 8/25\n",
            "54/54 [==============================] - 13s 242ms/step - loss: 0.4173 - accuracy: 0.9347 - val_loss: 0.9597 - val_accuracy: 0.5894\n",
            "Epoch 9/25\n",
            "54/54 [==============================] - 13s 245ms/step - loss: 0.4098 - accuracy: 0.9352 - val_loss: 0.8324 - val_accuracy: 0.6728\n",
            "Epoch 10/25\n",
            "54/54 [==============================] - 13s 242ms/step - loss: 0.4014 - accuracy: 0.9355 - val_loss: 0.6750 - val_accuracy: 0.7866\n",
            "Epoch 11/25\n",
            "54/54 [==============================] - 13s 243ms/step - loss: 0.3915 - accuracy: 0.9428 - val_loss: 0.5268 - val_accuracy: 0.8780\n",
            "Epoch 12/25\n",
            "54/54 [==============================] - 13s 245ms/step - loss: 0.3862 - accuracy: 0.9440 - val_loss: 0.4846 - val_accuracy: 0.8943\n",
            "Epoch 13/25\n",
            "54/54 [==============================] - 13s 245ms/step - loss: 0.3632 - accuracy: 0.9547 - val_loss: 0.4575 - val_accuracy: 0.9085\n",
            "Epoch 14/25\n",
            "54/54 [==============================] - 13s 245ms/step - loss: 0.3645 - accuracy: 0.9498 - val_loss: 0.4527 - val_accuracy: 0.9126\n",
            "Epoch 15/25\n",
            "54/54 [==============================] - 13s 245ms/step - loss: 0.3533 - accuracy: 0.9541 - val_loss: 0.4262 - val_accuracy: 0.9126\n",
            "Epoch 16/25\n",
            "54/54 [==============================] - 13s 243ms/step - loss: 0.3515 - accuracy: 0.9530 - val_loss: 0.4590 - val_accuracy: 0.9187\n",
            "Epoch 17/25\n",
            "54/54 [==============================] - 13s 243ms/step - loss: 0.3322 - accuracy: 0.9599 - val_loss: 0.4207 - val_accuracy: 0.9167\n",
            "Epoch 18/25\n",
            "54/54 [==============================] - 13s 245ms/step - loss: 0.3261 - accuracy: 0.9637 - val_loss: 0.4038 - val_accuracy: 0.9289\n",
            "Epoch 19/25\n",
            "54/54 [==============================] - 13s 244ms/step - loss: 0.3147 - accuracy: 0.9686 - val_loss: 0.4001 - val_accuracy: 0.9329\n",
            "Epoch 20/25\n",
            "54/54 [==============================] - 13s 245ms/step - loss: 0.3028 - accuracy: 0.9739 - val_loss: 0.4027 - val_accuracy: 0.9228\n",
            "Epoch 21/25\n",
            "54/54 [==============================] - 13s 243ms/step - loss: 0.2946 - accuracy: 0.9727 - val_loss: 0.4269 - val_accuracy: 0.9167\n",
            "Epoch 22/25\n",
            "54/54 [==============================] - 13s 245ms/step - loss: 0.2928 - accuracy: 0.9768 - val_loss: 0.4378 - val_accuracy: 0.9207\n",
            "Epoch 23/25\n",
            "54/54 [==============================] - 13s 243ms/step - loss: 0.2875 - accuracy: 0.9768 - val_loss: 0.4183 - val_accuracy: 0.9167\n",
            "Epoch 24/25\n",
            "54/54 [==============================] - 13s 245ms/step - loss: 0.2775 - accuracy: 0.9820 - val_loss: 0.4452 - val_accuracy: 0.9329\n",
            "Epoch 25/25\n",
            "54/54 [==============================] - 13s 245ms/step - loss: 0.2634 - accuracy: 0.9849 - val_loss: 0.4133 - val_accuracy: 0.9248\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate on the training set\n",
        "train_evaluation = hybrid_model_regularized.evaluate([x_train_normalized, x_train_normalized], y_train)\n",
        "train_loss = train_evaluation[0]\n",
        "train_accuracy = train_evaluation[1]\n",
        "\n",
        "print(f\"Training Loss: {train_loss:.4f}\")\n",
        "print(f\"Training Accuracy: {train_accuracy:.4f}\")\n",
        "\n",
        "# Evaluate on the test set\n",
        "test_evaluation = hybrid_model_regularized.evaluate([x_test_normalized, x_test_normalized], y_test)\n",
        "test_loss = test_evaluation[0]\n",
        "test_accuracy = test_evaluation[1]\n",
        "\n",
        "print(f\"Test Loss: {test_loss:.4f}\")\n",
        "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9orXmIz9ma_W",
        "outputId": "958558e6-910d-481a-b6f1-0dc2863cf42d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "108/108 [==============================] - 7s 48ms/step - loss: 0.2492 - accuracy: 0.9901\n",
            "Training Loss: 0.2492\n",
            "Training Accuracy: 0.9901\n",
            "31/31 [==============================] - 3s 82ms/step - loss: 0.4309 - accuracy: 0.9197\n",
            "Test Loss: 0.4309\n",
            "Test Accuracy: 0.9197\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Create an instance of ImageDataGenerator for augmentation\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=20,  # Random rotation within the range of (-20, 20) degrees\n",
        "    width_shift_range=0.1,  # Randomly shift images horizontally (10% of total width)\n",
        "    height_shift_range=0.1,  # Randomly shift images vertically (10% of total height)\n",
        "    shear_range=0.2,  # Shear intensity (20%)\n",
        "    zoom_range=0.2,  # Zoom randomly within 20% range\n",
        "    horizontal_flip=True,  # Randomly flip images horizontally\n",
        "    fill_mode='nearest'  # Strategy for filling in newly created pixels\n",
        ")\n",
        "\n",
        "# Fit the ImageDataGenerator on your original training data\n",
        "datagen.fit(x_train_normalized)\n",
        "\n",
        "# Define the number of augmented images you want to generate\n",
        "num_augmented_images = 1000  # Modify this based on your requirement\n",
        "\n",
        "# Generate augmented images using the ImageDataGenerator\n",
        "augmented_data = datagen.flow(x_train_normalized, y_train, batch_size=num_augmented_images)\n",
        "\n",
        "# Retrieve augmented images and labels\n",
        "x_augmented, y_augmented = augmented_data.next()\n",
        "\n",
        "# Concatenate augmented data with original data\n",
        "x_combined = np.concatenate((x_train_normalized, x_augmented))\n",
        "y_combined = np.concatenate((y_train, y_augmented))\n",
        "\n",
        "# Train the model using the augmented dataset\n",
        "# ... (continue with model creation, compilation, and training using x_combined, y_combined)\n"
      ],
      "metadata": {
        "id": "CGQSuMJBnp2W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Assuming you have your hybrid model already trained and stored in hybrid_model_regularized\n",
        "\n",
        "# Extract features from the hybrid model for training, validation, and test sets\n",
        "x_train_features = hybrid_model_regularized.predict([x_train_normalized, x_train_normalized])\n",
        "x_val_features = hybrid_model_regularized.predict([x_val_normalized, x_val_normalized])\n",
        "x_test_features = hybrid_model_regularized.predict([x_test_normalized, x_test_normalized])\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NBMxycobzUKN",
        "outputId": "3b7cccc7-70e1-4652-da7f-6d2431079905"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "108/108 [==============================] - 4s 33ms/step\n",
            "16/16 [==============================] - 2s 101ms/step\n",
            "31/31 [==============================] - 1s 32ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_features = x_train_features.reshape(x_train_features.shape[0], -1)\n",
        "x_val_features = x_val_features.reshape(x_val_features.shape[0], -1)\n",
        "x_test_features = x_test_features.reshape(x_test_features.shape[0], -1)"
      ],
      "metadata": {
        "id": "bsPOAXS_0Xic"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "\n",
        "\n",
        "\n",
        "# Define the best hyperparameters obtained from GridSearchCV\n",
        "best_params = {'C': 6, 'gamma': 'scale'}  # Replace these values with the best parameters found\n",
        "\n",
        "# Train SVM model with the best hyperparameters\n",
        "svm_model = SVC(kernel='rbf', C=best_params['C'], gamma=best_params['gamma'])\n",
        "svm_model.fit(x_train_features, y_train)\n",
        "\n",
        "# Predict on the test set using the trained SVM model\n",
        "y_pred_svm = svm_model.predict(x_test_features)\n",
        "\n",
        "# Calculate evaluation metrics\n",
        "svm_accuracy = accuracy_score(y_test, y_pred_svm)\n",
        "svm_precision = precision_score(y_test, y_pred_svm)\n",
        "svm_recall = recall_score(y_test, y_pred_svm)\n",
        "svm_f1 = f1_score(y_test, y_pred_svm)\n",
        "\n",
        "# Calculate specificity\n",
        "tn, fp, fn, tp = confusion_matrix(y_test, y_pred_svm).ravel()\n",
        "svm_specificity = tn / (tn + fp)\n",
        "\n",
        "# Print evaluation metrics\n",
        "print(\"SVM Accuracy:\", svm_accuracy)\n",
        "print(\"SVM Precision:\", svm_precision)\n",
        "print(\"SVM Sensitivity (Recall):\", svm_recall)\n",
        "print(\"SVM Specificity:\", svm_specificity)\n",
        "print(\"SVM F1 Score:\", svm_f1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6E_riZegoOR3",
        "outputId": "538b06d4-7179-4431-b9c0-3893c0a08bad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVM Accuracy: 0.9278455284552846\n",
            "SVM Precision: 0.9496981891348089\n",
            "SVM Sensitivity (Recall): 0.9111969111969112\n",
            "SVM Specificity: 0.9463519313304721\n",
            "SVM F1 Score: 0.9300492610837438\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Create an instance of ImageDataGenerator for augmentation\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=20,  # Random rotation within the range of (-20, 20) degrees\n",
        "    width_shift_range=0.1,  # Randomly shift images horizontally (10% of total width)\n",
        "    height_shift_range=0.1,  # Randomly shift images vertically (10% of total height)\n",
        "    shear_range=0.2,  # Shear intensity (20%)\n",
        "    zoom_range=0.2,  # Zoom randomly within 20% range\n",
        "    horizontal_flip=True,  # Randomly flip images horizontally\n",
        "    fill_mode='nearest'  # Strategy for filling in newly created pixels\n",
        ")\n",
        "\n",
        "# Fit the ImageDataGenerator on your original training data\n",
        "datagen.fit(x_train_normalized)\n",
        "\n",
        "# Define the number of augmented images you want to generate\n",
        "num_augmented_images = 2000  # Modify this based on your requirement\n",
        "\n",
        "# Generate augmented images using the ImageDataGenerator\n",
        "augmented_data = datagen.flow(x_train_normalized, y_train, batch_size=num_augmented_images)\n",
        "\n",
        "# Retrieve augmented images and labels\n",
        "x_augmented, y_augmented = augmented_data.next()\n",
        "\n",
        "# Concatenate augmented data with original data\n",
        "x_combined = np.concatenate((x_train_normalized, x_augmented))\n",
        "y_combined = np.concatenate((y_train, y_augmented))\n",
        "\n",
        "# Train the model using the augmented dataset\n",
        "# ... (continue with model creation, compilation, and training using x_combined, y_combined)"
      ],
      "metadata": {
        "id": "u18qRHOLpa25"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Conv2D, BatchNormalization, ReLU, GlobalAveragePooling2D, Dense, Concatenate\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "# Define MobileNet-inspired architecture\n",
        "def MobileNetCustom(input_shape):\n",
        "    input_tensor = Input(shape=input_shape)\n",
        "\n",
        "    # Initial Convolution Layer\n",
        "    x = Conv2D(32, (3, 3), strides=(2, 2), padding='same')(input_tensor)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = ReLU()(x)\n",
        "    # Add more layers as per your MobileNet design\n",
        "\n",
        "    # Global Average Pooling\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "\n",
        "    return Model(inputs=input_tensor, outputs=x)\n",
        "\n",
        "# Define DenseNet-inspired architecture\n",
        "def DenseNetCustom(input_shape):\n",
        "    input_tensor = Input(shape=input_shape)\n",
        "\n",
        "    # Define your DenseNet-like architecture\n",
        "    # ... Add layers as per your DenseNet design\n",
        "\n",
        "    # Global Average Pooling\n",
        "    x = GlobalAveragePooling2D()(input_tensor)\n",
        "\n",
        "    return Model(inputs=input_tensor, outputs=x)\n",
        "\n",
        "# Input shape and number of classes\n",
        "input_shape = (100, 100, 3)\n",
        "num_classes = 2\n",
        "\n",
        "# Build MobileNet and DenseNet branches\n",
        "mobilenet_model = MobileNetCustom(input_shape)\n",
        "densenet_model = DenseNetCustom(input_shape)\n",
        "\n",
        "# Get the outputs of the two models\n",
        "mobilenet_output = mobilenet_model.output\n",
        "densenet_output = densenet_model.output\n",
        "\n",
        "# Concatenate the outputs\n",
        "merged_output = Concatenate()([mobilenet_output, densenet_output])\n",
        "\n",
        "# Add more layers for classification\n",
        "x = Dense(256, activation='relu')(merged_output)\n",
        "x = Dense(128, activation='relu')(x)\n",
        "predictions = Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "# Create the hybrid model\n",
        "hybrid_model = Model(inputs=[mobilenet_model.input, densenet_model.input], outputs=predictions)\n",
        "\n",
        "# Compile the model\n",
        "hybrid_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Display the summary of the hybrid model\n",
        "hybrid_model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TNChm1qAiEmw",
        "outputId": "1ed7b3f8-485e-462c-ff08-1d4295dd7c6f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)        [(None, 100, 100, 3)]        0         []                            \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)             (None, 50, 50, 32)           896       ['input_1[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization (Batch  (None, 50, 50, 32)           128       ['conv2d[0][0]']              \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " re_lu (ReLU)                (None, 50, 50, 32)           0         ['batch_normalization[0][0]'] \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)        [(None, 100, 100, 3)]        0         []                            \n",
            "                                                                                                  \n",
            " global_average_pooling2d (  (None, 32)                   0         ['re_lu[0][0]']               \n",
            " GlobalAveragePooling2D)                                                                          \n",
            "                                                                                                  \n",
            " global_average_pooling2d_1  (None, 3)                    0         ['input_2[0][0]']             \n",
            "  (GlobalAveragePooling2D)                                                                        \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)   (None, 35)                   0         ['global_average_pooling2d[0][\n",
            "                                                                    0]',                          \n",
            "                                                                     'global_average_pooling2d_1[0\n",
            "                                                                    ][0]']                        \n",
            "                                                                                                  \n",
            " dense (Dense)               (None, 256)                  9216      ['concatenate[0][0]']         \n",
            "                                                                                                  \n",
            " dense_1 (Dense)             (None, 128)                  32896     ['dense[0][0]']               \n",
            "                                                                                                  \n",
            " dense_2 (Dense)             (None, 2)                    258       ['dense_1[0][0]']             \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 43394 (169.51 KB)\n",
            "Trainable params: 43330 (169.26 KB)\n",
            "Non-trainable params: 64 (256.00 Byte)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Set the learning rate\n",
        "learning_rate = 0.00001\n",
        "\n",
        "# Compile the model with the specified learning rate\n",
        "hybrid_model.compile(optimizer=Adam(learning_rate=learning_rate),\n",
        "                     loss='categorical_crossentropy',\n",
        "                     metrics=['accuracy'])\n",
        "\n",
        "# Train the hybrid model for 25 epochs with the specified learning rate\n",
        "history = hybrid_model.fit(\n",
        "    [x_train_normalized, x_train_normalized],  # Replace with your training data\n",
        "    y_train_encoded,  # Replace with your training labels\n",
        "    epochs=65,\n",
        "    batch_size=batch_size,\n",
        "    validation_data=([x_val_normalized, x_val_normalized], y_val_encoded),  # Replace with your validation data\n",
        "    shuffle=True,\n",
        "    verbose=1\n",
        ")\n"
      ],
      "metadata": {
        "id": "5pP9jGtGiN_e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "38db4c4e-6861-4a9d-aaf8-d6bc4817b5a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/65\n",
            "54/54 [==============================] - 7s 66ms/step - loss: 0.3007 - accuracy: 0.8667 - val_loss: 0.2906 - val_accuracy: 0.8841\n",
            "Epoch 2/65\n",
            "54/54 [==============================] - 2s 38ms/step - loss: 0.3028 - accuracy: 0.8635 - val_loss: 0.2898 - val_accuracy: 0.8841\n",
            "Epoch 3/65\n",
            "54/54 [==============================] - 1s 24ms/step - loss: 0.3015 - accuracy: 0.8659 - val_loss: 0.2902 - val_accuracy: 0.8841\n",
            "Epoch 4/65\n",
            "54/54 [==============================] - 1s 23ms/step - loss: 0.2981 - accuracy: 0.8682 - val_loss: 0.2907 - val_accuracy: 0.8841\n",
            "Epoch 5/65\n",
            "54/54 [==============================] - 2s 29ms/step - loss: 0.3003 - accuracy: 0.8638 - val_loss: 0.2909 - val_accuracy: 0.8841\n",
            "Epoch 6/65\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.3018 - accuracy: 0.8676 - val_loss: 0.2899 - val_accuracy: 0.8862\n",
            "Epoch 7/65\n",
            "54/54 [==============================] - 1s 15ms/step - loss: 0.3005 - accuracy: 0.8673 - val_loss: 0.2905 - val_accuracy: 0.8841\n",
            "Epoch 8/65\n",
            "54/54 [==============================] - 1s 15ms/step - loss: 0.2999 - accuracy: 0.8708 - val_loss: 0.2904 - val_accuracy: 0.8841\n",
            "Epoch 9/65\n",
            "54/54 [==============================] - 1s 15ms/step - loss: 0.2990 - accuracy: 0.8693 - val_loss: 0.2902 - val_accuracy: 0.8841\n",
            "Epoch 10/65\n",
            "54/54 [==============================] - 1s 15ms/step - loss: 0.3018 - accuracy: 0.8638 - val_loss: 0.2904 - val_accuracy: 0.8841\n",
            "Epoch 11/65\n",
            "54/54 [==============================] - 1s 14ms/step - loss: 0.2993 - accuracy: 0.8676 - val_loss: 0.2898 - val_accuracy: 0.8841\n",
            "Epoch 12/65\n",
            "54/54 [==============================] - 1s 16ms/step - loss: 0.3009 - accuracy: 0.8711 - val_loss: 0.2896 - val_accuracy: 0.8841\n",
            "Epoch 13/65\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.2968 - accuracy: 0.8685 - val_loss: 0.2897 - val_accuracy: 0.8862\n",
            "Epoch 14/65\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.2957 - accuracy: 0.8685 - val_loss: 0.2900 - val_accuracy: 0.8841\n",
            "Epoch 15/65\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.2984 - accuracy: 0.8685 - val_loss: 0.2902 - val_accuracy: 0.8841\n",
            "Epoch 16/65\n",
            "54/54 [==============================] - 1s 14ms/step - loss: 0.2976 - accuracy: 0.8644 - val_loss: 0.2901 - val_accuracy: 0.8841\n",
            "Epoch 17/65\n",
            "54/54 [==============================] - 1s 16ms/step - loss: 0.2983 - accuracy: 0.8676 - val_loss: 0.2898 - val_accuracy: 0.8841\n",
            "Epoch 18/65\n",
            "54/54 [==============================] - 1s 15ms/step - loss: 0.2990 - accuracy: 0.8696 - val_loss: 0.2897 - val_accuracy: 0.8841\n",
            "Epoch 19/65\n",
            "54/54 [==============================] - 1s 14ms/step - loss: 0.2972 - accuracy: 0.8714 - val_loss: 0.2905 - val_accuracy: 0.8841\n",
            "Epoch 20/65\n",
            "54/54 [==============================] - 1s 15ms/step - loss: 0.2981 - accuracy: 0.8682 - val_loss: 0.2892 - val_accuracy: 0.8841\n",
            "Epoch 21/65\n",
            "54/54 [==============================] - 1s 16ms/step - loss: 0.2957 - accuracy: 0.8708 - val_loss: 0.2897 - val_accuracy: 0.8862\n",
            "Epoch 22/65\n",
            "54/54 [==============================] - 1s 16ms/step - loss: 0.2960 - accuracy: 0.8708 - val_loss: 0.2891 - val_accuracy: 0.8841\n",
            "Epoch 23/65\n",
            "54/54 [==============================] - 1s 16ms/step - loss: 0.2972 - accuracy: 0.8690 - val_loss: 0.2892 - val_accuracy: 0.8862\n",
            "Epoch 24/65\n",
            "54/54 [==============================] - 1s 14ms/step - loss: 0.2975 - accuracy: 0.8670 - val_loss: 0.2884 - val_accuracy: 0.8862\n",
            "Epoch 25/65\n",
            "54/54 [==============================] - 1s 15ms/step - loss: 0.2993 - accuracy: 0.8661 - val_loss: 0.2893 - val_accuracy: 0.8841\n",
            "Epoch 26/65\n",
            "54/54 [==============================] - 1s 15ms/step - loss: 0.2987 - accuracy: 0.8673 - val_loss: 0.2881 - val_accuracy: 0.8862\n",
            "Epoch 27/65\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 0.2952 - accuracy: 0.8679 - val_loss: 0.2888 - val_accuracy: 0.8841\n",
            "Epoch 28/65\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.2961 - accuracy: 0.8702 - val_loss: 0.2889 - val_accuracy: 0.8841\n",
            "Epoch 29/65\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.2958 - accuracy: 0.8720 - val_loss: 0.2888 - val_accuracy: 0.8841\n",
            "Epoch 30/65\n",
            "54/54 [==============================] - 1s 16ms/step - loss: 0.2950 - accuracy: 0.8659 - val_loss: 0.2888 - val_accuracy: 0.8862\n",
            "Epoch 31/65\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 0.2987 - accuracy: 0.8693 - val_loss: 0.2880 - val_accuracy: 0.8862\n",
            "Epoch 32/65\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 0.2974 - accuracy: 0.8659 - val_loss: 0.2889 - val_accuracy: 0.8862\n",
            "Epoch 33/65\n",
            "54/54 [==============================] - 1s 16ms/step - loss: 0.2979 - accuracy: 0.8650 - val_loss: 0.2884 - val_accuracy: 0.8841\n",
            "Epoch 34/65\n",
            "54/54 [==============================] - 1s 16ms/step - loss: 0.3018 - accuracy: 0.8653 - val_loss: 0.2872 - val_accuracy: 0.8882\n",
            "Epoch 35/65\n",
            "54/54 [==============================] - 1s 15ms/step - loss: 0.2975 - accuracy: 0.8688 - val_loss: 0.2872 - val_accuracy: 0.8882\n",
            "Epoch 36/65\n",
            "54/54 [==============================] - 1s 15ms/step - loss: 0.2997 - accuracy: 0.8630 - val_loss: 0.2879 - val_accuracy: 0.8882\n",
            "Epoch 37/65\n",
            "54/54 [==============================] - 1s 16ms/step - loss: 0.2980 - accuracy: 0.8685 - val_loss: 0.2885 - val_accuracy: 0.8862\n",
            "Epoch 38/65\n",
            "54/54 [==============================] - 1s 15ms/step - loss: 0.2979 - accuracy: 0.8670 - val_loss: 0.2877 - val_accuracy: 0.8882\n",
            "Epoch 39/65\n",
            "54/54 [==============================] - 1s 15ms/step - loss: 0.2931 - accuracy: 0.8720 - val_loss: 0.2882 - val_accuracy: 0.8862\n",
            "Epoch 40/65\n",
            "54/54 [==============================] - 1s 16ms/step - loss: 0.2961 - accuracy: 0.8688 - val_loss: 0.2883 - val_accuracy: 0.8841\n",
            "Epoch 41/65\n",
            "54/54 [==============================] - 1s 16ms/step - loss: 0.2979 - accuracy: 0.8670 - val_loss: 0.2881 - val_accuracy: 0.8862\n",
            "Epoch 42/65\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.2935 - accuracy: 0.8664 - val_loss: 0.2885 - val_accuracy: 0.8862\n",
            "Epoch 43/65\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.2945 - accuracy: 0.8693 - val_loss: 0.2878 - val_accuracy: 0.8841\n",
            "Epoch 44/65\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.2952 - accuracy: 0.8632 - val_loss: 0.2876 - val_accuracy: 0.8862\n",
            "Epoch 45/65\n",
            "54/54 [==============================] - 1s 16ms/step - loss: 0.2966 - accuracy: 0.8615 - val_loss: 0.2883 - val_accuracy: 0.8862\n",
            "Epoch 46/65\n",
            "54/54 [==============================] - 1s 15ms/step - loss: 0.2967 - accuracy: 0.8690 - val_loss: 0.2883 - val_accuracy: 0.8862\n",
            "Epoch 47/65\n",
            "54/54 [==============================] - 1s 14ms/step - loss: 0.2959 - accuracy: 0.8667 - val_loss: 0.2875 - val_accuracy: 0.8862\n",
            "Epoch 48/65\n",
            "54/54 [==============================] - 1s 14ms/step - loss: 0.2931 - accuracy: 0.8749 - val_loss: 0.2883 - val_accuracy: 0.8841\n",
            "Epoch 49/65\n",
            "54/54 [==============================] - 1s 14ms/step - loss: 0.2944 - accuracy: 0.8699 - val_loss: 0.2876 - val_accuracy: 0.8862\n",
            "Epoch 50/65\n",
            "54/54 [==============================] - 1s 16ms/step - loss: 0.2932 - accuracy: 0.8702 - val_loss: 0.2881 - val_accuracy: 0.8862\n",
            "Epoch 51/65\n",
            "54/54 [==============================] - 1s 16ms/step - loss: 0.2956 - accuracy: 0.8656 - val_loss: 0.2881 - val_accuracy: 0.8841\n",
            "Epoch 52/65\n",
            "54/54 [==============================] - 1s 15ms/step - loss: 0.2951 - accuracy: 0.8682 - val_loss: 0.2883 - val_accuracy: 0.8841\n",
            "Epoch 53/65\n",
            "54/54 [==============================] - 1s 15ms/step - loss: 0.2914 - accuracy: 0.8702 - val_loss: 0.2879 - val_accuracy: 0.8862\n",
            "Epoch 54/65\n",
            "54/54 [==============================] - 1s 15ms/step - loss: 0.2925 - accuracy: 0.8705 - val_loss: 0.2873 - val_accuracy: 0.8862\n",
            "Epoch 55/65\n",
            "54/54 [==============================] - 1s 15ms/step - loss: 0.2918 - accuracy: 0.8711 - val_loss: 0.2876 - val_accuracy: 0.8862\n",
            "Epoch 56/65\n",
            "54/54 [==============================] - 1s 16ms/step - loss: 0.2970 - accuracy: 0.8667 - val_loss: 0.2867 - val_accuracy: 0.8882\n",
            "Epoch 57/65\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.2955 - accuracy: 0.8708 - val_loss: 0.2858 - val_accuracy: 0.8882\n",
            "Epoch 58/65\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.2947 - accuracy: 0.8722 - val_loss: 0.2868 - val_accuracy: 0.8862\n",
            "Epoch 59/65\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.2970 - accuracy: 0.8682 - val_loss: 0.2855 - val_accuracy: 0.8902\n",
            "Epoch 60/65\n",
            "54/54 [==============================] - 1s 16ms/step - loss: 0.2936 - accuracy: 0.8670 - val_loss: 0.2868 - val_accuracy: 0.8862\n",
            "Epoch 61/65\n",
            "54/54 [==============================] - 1s 16ms/step - loss: 0.2925 - accuracy: 0.8731 - val_loss: 0.2870 - val_accuracy: 0.8862\n",
            "Epoch 62/65\n",
            "54/54 [==============================] - 1s 15ms/step - loss: 0.2921 - accuracy: 0.8696 - val_loss: 0.2880 - val_accuracy: 0.8821\n",
            "Epoch 63/65\n",
            "54/54 [==============================] - 1s 15ms/step - loss: 0.2927 - accuracy: 0.8743 - val_loss: 0.2870 - val_accuracy: 0.8862\n",
            "Epoch 64/65\n",
            "54/54 [==============================] - 1s 14ms/step - loss: 0.2910 - accuracy: 0.8690 - val_loss: 0.2872 - val_accuracy: 0.8841\n",
            "Epoch 65/65\n",
            "54/54 [==============================] - 1s 16ms/step - loss: 0.2909 - accuracy: 0.8699 - val_loss: 0.2867 - val_accuracy: 0.8841\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on the test data\n",
        "test_loss, test_accuracy = hybrid_model.evaluate([x_test_normalized, x_test_normalized], y_test_encoded)\n",
        "\n",
        "print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")\n",
        "print(f\"Test Loss: {test_loss}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y-q420Zut6pi",
        "outputId": "28a715f0-9337-468a-ceb5-4bf6f72cd1a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "31/31 [==============================] - 0s 8ms/step - loss: 0.3073 - accuracy: 0.8659\n",
            "Test Accuracy: 86.59%\n",
            "Test Loss: 0.3073199391365051\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Assuming you have your hybrid model already trained and stored in hybrid_model_regularized\n",
        "\n",
        "# Extract features from the hybrid model for training, validation, and test sets\n",
        "x_train_features = hybrid_model.predict([x_train_normalized, x_train_normalized])\n",
        "x_val_features = hybrid_model.predict([x_val_normalized, x_val_normalized])\n",
        "x_test_features = hybrid_model.predict([x_test_normalized, x_test_normalized])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fpehwDOMJ7uC",
        "outputId": "d455daf5-a875-4d69-ffbb-a01f4cde73fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "108/108 [==============================] - 1s 5ms/step\n",
            "16/16 [==============================] - 0s 10ms/step\n",
            "31/31 [==============================] - 0s 4ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_features = x_train_features.reshape(x_train_features.shape[0], -1)\n",
        "x_val_features = x_val_features.reshape(x_val_features.shape[0], -1)\n",
        "x_test_features = x_test_features.reshape(x_test_features.shape[0], -1)"
      ],
      "metadata": {
        "id": "Gpp9Rm__KVDD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "\n",
        "\n",
        "\n",
        "# Define the best hyperparameters obtained from GridSearchCV\n",
        "best_params = {'C': 2, 'gamma': 'scale'}  # Replace these values with the best parameters found\n",
        "\n",
        "# Train SVM model with the best hyperparameters\n",
        "svm_model = SVC(kernel='linear', C=best_params['C'], gamma=best_params['gamma'])\n",
        "svm_model.fit(x_train_features, y_train)\n",
        "\n",
        "# Predict on the test set using the trained SVM model\n",
        "y_pred_svm = svm_model.predict(x_test_features)\n",
        "\n",
        "# Calculate evaluation metrics\n",
        "svm_accuracy = accuracy_score(y_test, y_pred_svm)\n",
        "svm_precision = precision_score(y_test, y_pred_svm)\n",
        "svm_recall = recall_score(y_test, y_pred_svm)\n",
        "svm_f1 = f1_score(y_test, y_pred_svm)\n",
        "\n",
        "# Calculate specificity\n",
        "tn, fp, fn, tp = confusion_matrix(y_test, y_pred_svm).ravel()\n",
        "svm_specificity = tn / (tn + fp)\n",
        "\n",
        "# Print evaluation metrics\n",
        "print(\"SVM Accuracy:\", svm_accuracy)\n",
        "print(\"SVM Precision:\", svm_precision)\n",
        "print(\"SVM Sensitivity (Recall):\", svm_recall)\n",
        "print(\"SVM Specificity:\", svm_specificity)\n",
        "print(\"SVM F1 Score:\", svm_f1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8DLwKW3zKdmQ",
        "outputId": "e2c6a0eb-7ac8-46fa-de4b-49d135fe3cfd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVM Accuracy: 0.866869918699187\n",
            "SVM Precision: 0.8989690721649485\n",
            "SVM Sensitivity (Recall): 0.8416988416988417\n",
            "SVM Specificity: 0.8948497854077253\n",
            "SVM F1 Score: 0.8693918245264207\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Conv2D, BatchNormalization, ReLU, Add, Concatenate, GlobalAveragePooling2D, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "# ResNet50-inspired architecture (more detailed)\n",
        "def ResNet50Custom(input_shape):\n",
        "    input_tensor = Input(shape=input_shape)\n",
        "\n",
        "    # Stage 1\n",
        "    x = Conv2D(64, (7, 7), strides=(2, 2), padding='same')(input_tensor)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = ReLU()(x)\n",
        "\n",
        "    # Stage 2\n",
        "    x = Conv2D(64, (3, 3), padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = ReLU()(x)\n",
        "    x = Conv2D(64, (3, 3), padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    shortcut = Conv2D(64, (1, 1), strides=(2, 2), padding='same')(input_tensor)\n",
        "    shortcut = BatchNormalization()(shortcut)\n",
        "    x = Add()([x, shortcut])\n",
        "    x = ReLU()(x)\n",
        "\n",
        "    # Stage 3 (you can extend these stages similar to a real ResNet50)\n",
        "\n",
        "    # Global Average Pooling\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "\n",
        "    return Model(inputs=input_tensor, outputs=x)\n",
        "\n",
        "# DenseNet201-inspired architecture (more detailed)\n",
        "def DenseNet201Custom(input_shape):\n",
        "    input_tensor = Input(shape=input_shape)\n",
        "\n",
        "    # Dense Block 1\n",
        "    x = Conv2D(64, (3, 3), padding='same')(input_tensor)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = ReLU()(x)\n",
        "    concat_layers = [x]\n",
        "\n",
        "    # Transition Layer\n",
        "    x = Conv2D(128, (1, 1), padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = ReLU()(x)\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "\n",
        "    return Model(inputs=input_tensor, outputs=x)\n",
        "\n",
        "# Input shape and number of classes\n",
        "input_shape = (100, 100, 3)\n",
        "num_classes = 2\n",
        "\n",
        "# Build ResNet50 and DenseNet201 branches\n",
        "resnet_model = ResNet50Custom(input_shape)\n",
        "densenet_model = DenseNet201Custom(input_shape)\n",
        "\n",
        "# Get the outputs of the two models\n",
        "resnet_output = resnet_model.output\n",
        "densenet_output = densenet_model.output\n",
        "\n",
        "# Concatenate the outputs\n",
        "merged_output = Concatenate()([resnet_output, densenet_output])\n",
        "\n",
        "# Add more layers for classification\n",
        "x = Dense(256, activation='relu')(merged_output)\n",
        "x = Dense(128, activation='relu')(x)\n",
        "predictions = Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "# Create the hybrid model\n",
        "hybrid_model = Model(inputs=[resnet_model.input, densenet_model.input], outputs=predictions)\n",
        "\n",
        "# Compile the model\n",
        "hybrid_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Display the summary of the hybrid model\n",
        "hybrid_model.summary()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9G2pZppSOmNh",
        "outputId": "5a8d85af-73b4-4a82-a2fc-558af5088373"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)        [(None, 100, 100, 3)]        0         []                            \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)             (None, 50, 50, 64)           9472      ['input_1[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization (Batch  (None, 50, 50, 64)           256       ['conv2d[0][0]']              \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " re_lu (ReLU)                (None, 50, 50, 64)           0         ['batch_normalization[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)           (None, 50, 50, 64)           36928     ['re_lu[0][0]']               \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)        [(None, 100, 100, 3)]        0         []                            \n",
            "                                                                                                  \n",
            " batch_normalization_1 (Bat  (None, 50, 50, 64)           256       ['conv2d_1[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " conv2d_4 (Conv2D)           (None, 100, 100, 64)         1792      ['input_2[0][0]']             \n",
            "                                                                                                  \n",
            " re_lu_1 (ReLU)              (None, 50, 50, 64)           0         ['batch_normalization_1[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " batch_normalization_4 (Bat  (None, 100, 100, 64)         256       ['conv2d_4[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)           (None, 50, 50, 64)           36928     ['re_lu_1[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_3 (Conv2D)           (None, 50, 50, 64)           256       ['input_1[0][0]']             \n",
            "                                                                                                  \n",
            " re_lu_3 (ReLU)              (None, 100, 100, 64)         0         ['batch_normalization_4[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " batch_normalization_2 (Bat  (None, 50, 50, 64)           256       ['conv2d_2[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_3 (Bat  (None, 50, 50, 64)           256       ['conv2d_3[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " conv2d_5 (Conv2D)           (None, 100, 100, 128)        8320      ['re_lu_3[0][0]']             \n",
            "                                                                                                  \n",
            " add (Add)                   (None, 50, 50, 64)           0         ['batch_normalization_2[0][0]'\n",
            "                                                                    , 'batch_normalization_3[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " batch_normalization_5 (Bat  (None, 100, 100, 128)        512       ['conv2d_5[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " re_lu_2 (ReLU)              (None, 50, 50, 64)           0         ['add[0][0]']                 \n",
            "                                                                                                  \n",
            " re_lu_4 (ReLU)              (None, 100, 100, 128)        0         ['batch_normalization_5[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " global_average_pooling2d (  (None, 64)                   0         ['re_lu_2[0][0]']             \n",
            " GlobalAveragePooling2D)                                                                          \n",
            "                                                                                                  \n",
            " global_average_pooling2d_1  (None, 128)                  0         ['re_lu_4[0][0]']             \n",
            "  (GlobalAveragePooling2D)                                                                        \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)   (None, 192)                  0         ['global_average_pooling2d[0][\n",
            "                                                                    0]',                          \n",
            "                                                                     'global_average_pooling2d_1[0\n",
            "                                                                    ][0]']                        \n",
            "                                                                                                  \n",
            " dense (Dense)               (None, 256)                  49408     ['concatenate[0][0]']         \n",
            "                                                                                                  \n",
            " dense_1 (Dense)             (None, 128)                  32896     ['dense[0][0]']               \n",
            "                                                                                                  \n",
            " dense_2 (Dense)             (None, 2)                    258       ['dense_1[0][0]']             \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 178050 (695.51 KB)\n",
            "Trainable params: 177154 (692.01 KB)\n",
            "Non-trainable params: 896 (3.50 KB)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# Set the learning rate\n",
        "learning_rate = 0.00001\n",
        "\n",
        "# Compile the model with the specified learning rate\n",
        "hybrid_model.compile(optimizer=Adam(learning_rate=learning_rate),\n",
        "                     loss='categorical_crossentropy',\n",
        "                     metrics=['accuracy'])\n",
        "\n",
        "# Define early stopping criteria\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "\n",
        "# Train the hybrid model with early stopping\n",
        "history = hybrid_model.fit(\n",
        "    [x_train_normalized, x_train_normalized],  # Replace with your training data\n",
        "    y_train_encoded,  # Replace with your training labels\n",
        "    epochs=60,\n",
        "    batch_size=batch_size,\n",
        "    validation_data=([x_val_normalized, x_val_normalized], y_val_encoded),  # Replace with your validation data\n",
        "    shuffle=True,\n",
        "    verbose=1,\n",
        "    callbacks=[early_stopping]  # Include the early stopping callback\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DVdcNByQP2CK",
        "outputId": "99b60e0d-39d5-4aba-f7e4-83bf7416b562"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/60\n",
            "54/54 [==============================] - 17s 164ms/step - loss: 0.5581 - accuracy: 0.6879 - val_loss: 0.6814 - val_accuracy: 0.4878\n",
            "Epoch 2/60\n",
            "54/54 [==============================] - 6s 113ms/step - loss: 0.4455 - accuracy: 0.8267 - val_loss: 0.6752 - val_accuracy: 0.4980\n",
            "Epoch 3/60\n",
            "54/54 [==============================] - 6s 114ms/step - loss: 0.3980 - accuracy: 0.8487 - val_loss: 0.6494 - val_accuracy: 0.6037\n",
            "Epoch 4/60\n",
            "54/54 [==============================] - 6s 113ms/step - loss: 0.3713 - accuracy: 0.8476 - val_loss: 0.6136 - val_accuracy: 0.7317\n",
            "Epoch 5/60\n",
            "54/54 [==============================] - 6s 115ms/step - loss: 0.3562 - accuracy: 0.8525 - val_loss: 0.5695 - val_accuracy: 0.7988\n",
            "Epoch 6/60\n",
            "54/54 [==============================] - 6s 113ms/step - loss: 0.3488 - accuracy: 0.8551 - val_loss: 0.5171 - val_accuracy: 0.8191\n",
            "Epoch 7/60\n",
            "54/54 [==============================] - 6s 114ms/step - loss: 0.3419 - accuracy: 0.8548 - val_loss: 0.4582 - val_accuracy: 0.8293\n",
            "Epoch 8/60\n",
            "54/54 [==============================] - 6s 114ms/step - loss: 0.3328 - accuracy: 0.8548 - val_loss: 0.4088 - val_accuracy: 0.8598\n",
            "Epoch 9/60\n",
            "54/54 [==============================] - 6s 115ms/step - loss: 0.3250 - accuracy: 0.8632 - val_loss: 0.3735 - val_accuracy: 0.8598\n",
            "Epoch 10/60\n",
            "54/54 [==============================] - 6s 114ms/step - loss: 0.3191 - accuracy: 0.8647 - val_loss: 0.3457 - val_accuracy: 0.8740\n",
            "Epoch 11/60\n",
            "54/54 [==============================] - 6s 117ms/step - loss: 0.3128 - accuracy: 0.8661 - val_loss: 0.3358 - val_accuracy: 0.8659\n",
            "Epoch 12/60\n",
            "54/54 [==============================] - 6s 115ms/step - loss: 0.3085 - accuracy: 0.8676 - val_loss: 0.3177 - val_accuracy: 0.8740\n",
            "Epoch 13/60\n",
            "54/54 [==============================] - 6s 114ms/step - loss: 0.3080 - accuracy: 0.8670 - val_loss: 0.3092 - val_accuracy: 0.8801\n",
            "Epoch 14/60\n",
            "54/54 [==============================] - 6s 113ms/step - loss: 0.3048 - accuracy: 0.8688 - val_loss: 0.2997 - val_accuracy: 0.8902\n",
            "Epoch 15/60\n",
            "54/54 [==============================] - 6s 116ms/step - loss: 0.3010 - accuracy: 0.8757 - val_loss: 0.2948 - val_accuracy: 0.8902\n",
            "Epoch 16/60\n",
            "54/54 [==============================] - 6s 114ms/step - loss: 0.2964 - accuracy: 0.8690 - val_loss: 0.2908 - val_accuracy: 0.8923\n",
            "Epoch 17/60\n",
            "54/54 [==============================] - 6s 115ms/step - loss: 0.2943 - accuracy: 0.8728 - val_loss: 0.2859 - val_accuracy: 0.8963\n",
            "Epoch 18/60\n",
            "54/54 [==============================] - 6s 113ms/step - loss: 0.2929 - accuracy: 0.8705 - val_loss: 0.2824 - val_accuracy: 0.8943\n",
            "Epoch 19/60\n",
            "54/54 [==============================] - 6s 116ms/step - loss: 0.2877 - accuracy: 0.8783 - val_loss: 0.2805 - val_accuracy: 0.8984\n",
            "Epoch 20/60\n",
            "54/54 [==============================] - 6s 113ms/step - loss: 0.2866 - accuracy: 0.8760 - val_loss: 0.2775 - val_accuracy: 0.8984\n",
            "Epoch 21/60\n",
            "54/54 [==============================] - 6s 115ms/step - loss: 0.2811 - accuracy: 0.8821 - val_loss: 0.2776 - val_accuracy: 0.8902\n",
            "Epoch 22/60\n",
            "54/54 [==============================] - 6s 114ms/step - loss: 0.2800 - accuracy: 0.8821 - val_loss: 0.2746 - val_accuracy: 0.8963\n",
            "Epoch 23/60\n",
            "54/54 [==============================] - 6s 114ms/step - loss: 0.2777 - accuracy: 0.8844 - val_loss: 0.2753 - val_accuracy: 0.8902\n",
            "Epoch 24/60\n",
            "54/54 [==============================] - 6s 114ms/step - loss: 0.2741 - accuracy: 0.8882 - val_loss: 0.2700 - val_accuracy: 0.8963\n",
            "Epoch 25/60\n",
            "54/54 [==============================] - 6s 114ms/step - loss: 0.2729 - accuracy: 0.8815 - val_loss: 0.2694 - val_accuracy: 0.8984\n",
            "Epoch 26/60\n",
            "54/54 [==============================] - 6s 114ms/step - loss: 0.2709 - accuracy: 0.8891 - val_loss: 0.2731 - val_accuracy: 0.8902\n",
            "Epoch 27/60\n",
            "54/54 [==============================] - 6s 115ms/step - loss: 0.2659 - accuracy: 0.8891 - val_loss: 0.2640 - val_accuracy: 0.8963\n",
            "Epoch 28/60\n",
            "54/54 [==============================] - 6s 114ms/step - loss: 0.2656 - accuracy: 0.8844 - val_loss: 0.2674 - val_accuracy: 0.8943\n",
            "Epoch 29/60\n",
            "54/54 [==============================] - 6s 115ms/step - loss: 0.2630 - accuracy: 0.8911 - val_loss: 0.2612 - val_accuracy: 0.8943\n",
            "Epoch 30/60\n",
            "54/54 [==============================] - 6s 116ms/step - loss: 0.2607 - accuracy: 0.8905 - val_loss: 0.2633 - val_accuracy: 0.8984\n",
            "Epoch 31/60\n",
            "54/54 [==============================] - 6s 114ms/step - loss: 0.2614 - accuracy: 0.8920 - val_loss: 0.2626 - val_accuracy: 0.8984\n",
            "Epoch 32/60\n",
            "54/54 [==============================] - 6s 115ms/step - loss: 0.2556 - accuracy: 0.8917 - val_loss: 0.2566 - val_accuracy: 0.8984\n",
            "Epoch 33/60\n",
            "54/54 [==============================] - 7s 123ms/step - loss: 0.2562 - accuracy: 0.8929 - val_loss: 0.2629 - val_accuracy: 0.8923\n",
            "Epoch 34/60\n",
            "54/54 [==============================] - 7s 128ms/step - loss: 0.2501 - accuracy: 0.8975 - val_loss: 0.2575 - val_accuracy: 0.8963\n",
            "Epoch 35/60\n",
            "54/54 [==============================] - 6s 115ms/step - loss: 0.2517 - accuracy: 0.8972 - val_loss: 0.2602 - val_accuracy: 0.8943\n",
            "Epoch 36/60\n",
            "54/54 [==============================] - 6s 115ms/step - loss: 0.2508 - accuracy: 0.8926 - val_loss: 0.2561 - val_accuracy: 0.9004\n",
            "Epoch 37/60\n",
            "54/54 [==============================] - 6s 113ms/step - loss: 0.2467 - accuracy: 0.8984 - val_loss: 0.2662 - val_accuracy: 0.8963\n",
            "Epoch 38/60\n",
            "54/54 [==============================] - 6s 116ms/step - loss: 0.2447 - accuracy: 0.8990 - val_loss: 0.2519 - val_accuracy: 0.8984\n",
            "Epoch 39/60\n",
            "54/54 [==============================] - 6s 113ms/step - loss: 0.2453 - accuracy: 0.8961 - val_loss: 0.2656 - val_accuracy: 0.8963\n",
            "Epoch 40/60\n",
            "54/54 [==============================] - 6s 116ms/step - loss: 0.2407 - accuracy: 0.9039 - val_loss: 0.2751 - val_accuracy: 0.8963\n",
            "Epoch 41/60\n",
            "54/54 [==============================] - 6s 113ms/step - loss: 0.2383 - accuracy: 0.8990 - val_loss: 0.2447 - val_accuracy: 0.9004\n",
            "Epoch 42/60\n",
            "54/54 [==============================] - 6s 116ms/step - loss: 0.2387 - accuracy: 0.9021 - val_loss: 0.2458 - val_accuracy: 0.9045\n",
            "Epoch 43/60\n",
            "54/54 [==============================] - 6s 115ms/step - loss: 0.2370 - accuracy: 0.9048 - val_loss: 0.2827 - val_accuracy: 0.8882\n",
            "Epoch 44/60\n",
            "54/54 [==============================] - 6s 117ms/step - loss: 0.2393 - accuracy: 0.8984 - val_loss: 0.2550 - val_accuracy: 0.9004\n",
            "Epoch 45/60\n",
            "54/54 [==============================] - 6s 115ms/step - loss: 0.2359 - accuracy: 0.9045 - val_loss: 0.2513 - val_accuracy: 0.9004\n",
            "Epoch 46/60\n",
            "54/54 [==============================] - 6s 116ms/step - loss: 0.2308 - accuracy: 0.9036 - val_loss: 0.2449 - val_accuracy: 0.9004\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on the test data\n",
        "test_loss, test_accuracy = hybrid_model.evaluate([x_test_normalized, x_test_normalized], y_test_encoded)\n",
        "\n",
        "print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")\n",
        "print(f\"Test Loss: {test_loss}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VOXGbt-z3npV",
        "outputId": "8af9db5a-fb47-4bfa-a337-e410a6bcc5e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "31/31 [==============================] - 1s 30ms/step - loss: 0.2647 - accuracy: 0.8892\n",
            "Test Accuracy: 88.92%\n",
            "Test Loss: 0.2647169530391693\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Assuming you have your hybrid model already trained and stored in hybrid_model_regularized\n",
        "\n",
        "# Extract features from the hybrid model for training, validation, and test sets\n",
        "x_train_features = hybrid_model.predict([x_train_normalized, x_train_normalized])\n",
        "x_val_features = hybrid_model.predict([x_val_normalized, x_val_normalized])\n",
        "x_test_features = hybrid_model.predict([x_test_normalized, x_test_normalized])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LTrhr2lYTeLk",
        "outputId": "d5dbc833-abc2-4f1c-ca92-901957048598"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "108/108 [==============================] - 3s 23ms/step\n",
            "16/16 [==============================] - 1s 35ms/step\n",
            "31/31 [==============================] - 0s 16ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_features = x_train_features.reshape(x_train_features.shape[0], -1)\n",
        "x_val_features = x_val_features.reshape(x_val_features.shape[0], -1)\n",
        "x_test_features = x_test_features.reshape(x_test_features.shape[0], -1)"
      ],
      "metadata": {
        "id": "7b8zviITTokP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "\n",
        "\n",
        "\n",
        "# Define the best hyperparameters obtained from GridSearchCV\n",
        "best_params = {'C': 1, 'gamma': 'scale'}  # Replace these values with the best parameters found\n",
        "\n",
        "# Train SVM model with the best hyperparameters\n",
        "svm_model = SVC(kernel='rbf', C=best_params['C'], gamma=best_params['gamma'])\n",
        "svm_model.fit(x_train_features, y_train)\n",
        "\n",
        "# Predict on the test set using the trained SVM model\n",
        "y_pred_svm = svm_model.predict(x_test_features)\n",
        "\n",
        "# Calculate evaluation metrics\n",
        "svm_accuracy = accuracy_score(y_test, y_pred_svm)\n",
        "svm_precision = precision_score(y_test, y_pred_svm)\n",
        "svm_recall = recall_score(y_test, y_pred_svm)\n",
        "svm_f1 = f1_score(y_test, y_pred_svm)\n",
        "\n",
        "# Calculate specificity\n",
        "tn, fp, fn, tp = confusion_matrix(y_test, y_pred_svm).ravel()\n",
        "svm_specificity = tn / (tn + fp)\n",
        "\n",
        "# Print evaluation metrics\n",
        "print(\"SVM Accuracy:\", svm_accuracy)\n",
        "print(\"SVM Precision:\", svm_precision)\n",
        "print(\"SVM Sensitivity (Recall):\", svm_recall)\n",
        "print(\"SVM Specificity:\", svm_specificity)\n",
        "print(\"SVM F1 Score:\", svm_f1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MYfWgTTFTuD0",
        "outputId": "e5f79776-f70b-42e1-dfd9-df2ea7b16e61"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVM Accuracy: 0.8973577235772358\n",
            "SVM Precision: 0.924643584521385\n",
            "SVM Sensitivity (Recall): 0.8764478764478765\n",
            "SVM Specificity: 0.9206008583690987\n",
            "SVM F1 Score: 0.8999008919722499\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Input, Conv2D, BatchNormalization, ReLU, GlobalAveragePooling2D, Dense, Concatenate\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "# Depthwise Separable Convolution Block\n",
        "def depthwise_separable_block(input_tensor, filters, kernel_size, strides):\n",
        "    x = Conv2D(filters, kernel_size, strides=strides, padding='same')(input_tensor)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = ReLU()(x)\n",
        "    return x\n",
        "\n",
        "# ShuffleNet-like architecture\n",
        "def ShuffleNetCustom(input_shape):\n",
        "    input_tensor = Input(shape=input_shape)\n",
        "\n",
        "    x = Conv2D(64, (3, 3), strides=(2, 2), padding='same')(input_tensor)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = ReLU()(x)\n",
        "\n",
        "    # Depthwise separable blocks (simplified for demonstration)\n",
        "    x = depthwise_separable_block(x, 128, (3, 3), strides=(1, 1))\n",
        "    x = depthwise_separable_block(x, 128, (3, 3), strides=(1, 1))\n",
        "    x = depthwise_separable_block(x, 128, (3, 3), strides=(1, 1))\n",
        "\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    return Model(inputs=input_tensor, outputs=x)\n",
        "\n",
        "# MobileNet-like architecture\n",
        "def MobileNetCustom(input_shape):\n",
        "    input_tensor = Input(shape=input_shape)\n",
        "\n",
        "    x = Conv2D(32, (3, 3), strides=(2, 2), padding='same')(input_tensor)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = ReLU()(x)\n",
        "\n",
        "    # Depthwise separable blocks (simplified for demonstration)\n",
        "    x = depthwise_separable_block(x, 64, (3, 3), strides=(1, 1))\n",
        "    x = depthwise_separable_block(x, 64, (3, 3), strides=(1, 1))\n",
        "    x = depthwise_separable_block(x, 64, (3, 3), strides=(1, 1))\n",
        "\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    return Model(inputs=input_tensor, outputs=x)\n",
        "\n",
        "# Input shape and number of classes\n",
        "input_shape = (100, 100, 3)\n",
        "num_classes = 2\n",
        "\n",
        "# Build ShuffleNet-like and MobileNet-like models\n",
        "shufflenet_model = ShuffleNetCustom(input_shape)\n",
        "mobilenet_model = MobileNetCustom(input_shape)\n",
        "\n",
        "# Get the output tensors from both models\n",
        "shufflenet_output = shufflenet_model.output\n",
        "mobilenet_output = mobilenet_model.output\n",
        "\n",
        "# Concatenate the outputs\n",
        "merged_output = Concatenate()([shufflenet_output, mobilenet_output])\n",
        "\n",
        "# Add more layers for classification\n",
        "x = Dense(256, activation='relu')(merged_output)\n",
        "x = Dense(128, activation='relu')(x)\n",
        "predictions = Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "# Create the hybrid model\n",
        "hybrid_model = Model(inputs=[shufflenet_model.input, mobilenet_model.input], outputs=predictions)\n",
        "\n",
        "# Compile the hybrid model\n",
        "hybrid_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Display the summary of the hybrid model\n",
        "hybrid_model.summary()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WVQj9VkWT8po",
        "outputId": "89da796c-21e7-4fd0-fddc-82d472a7a413"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_5\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_3 (InputLayer)        [(None, 100, 100, 3)]        0         []                            \n",
            "                                                                                                  \n",
            " input_4 (InputLayer)        [(None, 100, 100, 3)]        0         []                            \n",
            "                                                                                                  \n",
            " conv2d_6 (Conv2D)           (None, 50, 50, 64)           1792      ['input_3[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_10 (Conv2D)          (None, 50, 50, 32)           896       ['input_4[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_6 (Bat  (None, 50, 50, 64)           256       ['conv2d_6[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_10 (Ba  (None, 50, 50, 32)           128       ['conv2d_10[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " re_lu_5 (ReLU)              (None, 50, 50, 64)           0         ['batch_normalization_6[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " re_lu_9 (ReLU)              (None, 50, 50, 32)           0         ['batch_normalization_10[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_7 (Conv2D)           (None, 50, 50, 128)          73856     ['re_lu_5[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_11 (Conv2D)          (None, 50, 50, 64)           18496     ['re_lu_9[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_7 (Bat  (None, 50, 50, 128)          512       ['conv2d_7[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_11 (Ba  (None, 50, 50, 64)           256       ['conv2d_11[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " re_lu_6 (ReLU)              (None, 50, 50, 128)          0         ['batch_normalization_7[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " re_lu_10 (ReLU)             (None, 50, 50, 64)           0         ['batch_normalization_11[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_8 (Conv2D)           (None, 50, 50, 128)          147584    ['re_lu_6[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_12 (Conv2D)          (None, 50, 50, 64)           36928     ['re_lu_10[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_8 (Bat  (None, 50, 50, 128)          512       ['conv2d_8[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_12 (Ba  (None, 50, 50, 64)           256       ['conv2d_12[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " re_lu_7 (ReLU)              (None, 50, 50, 128)          0         ['batch_normalization_8[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " re_lu_11 (ReLU)             (None, 50, 50, 64)           0         ['batch_normalization_12[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_9 (Conv2D)           (None, 50, 50, 128)          147584    ['re_lu_7[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_13 (Conv2D)          (None, 50, 50, 64)           36928     ['re_lu_11[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_9 (Bat  (None, 50, 50, 128)          512       ['conv2d_9[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_13 (Ba  (None, 50, 50, 64)           256       ['conv2d_13[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " re_lu_8 (ReLU)              (None, 50, 50, 128)          0         ['batch_normalization_9[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " re_lu_12 (ReLU)             (None, 50, 50, 64)           0         ['batch_normalization_13[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " global_average_pooling2d_2  (None, 128)                  0         ['re_lu_8[0][0]']             \n",
            "  (GlobalAveragePooling2D)                                                                        \n",
            "                                                                                                  \n",
            " global_average_pooling2d_3  (None, 64)                   0         ['re_lu_12[0][0]']            \n",
            "  (GlobalAveragePooling2D)                                                                        \n",
            "                                                                                                  \n",
            " concatenate_1 (Concatenate  (None, 192)                  0         ['global_average_pooling2d_2[0\n",
            " )                                                                  ][0]',                        \n",
            "                                                                     'global_average_pooling2d_3[0\n",
            "                                                                    ][0]']                        \n",
            "                                                                                                  \n",
            " dense_3 (Dense)             (None, 256)                  49408     ['concatenate_1[0][0]']       \n",
            "                                                                                                  \n",
            " dense_4 (Dense)             (None, 128)                  32896     ['dense_3[0][0]']             \n",
            "                                                                                                  \n",
            " dense_5 (Dense)             (None, 2)                    258       ['dense_4[0][0]']             \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 549314 (2.10 MB)\n",
            "Trainable params: 547970 (2.09 MB)\n",
            "Non-trainable params: 1344 (5.25 KB)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# Set the learning rate\n",
        "learning_rate = 0.00001\n",
        "\n",
        "# Compile the model with the specified learning rate\n",
        "hybrid_model.compile(optimizer=Adam(learning_rate=learning_rate),\n",
        "                     loss='categorical_crossentropy',\n",
        "                     metrics=['accuracy'])\n",
        "\n",
        "# Define early stopping criteria\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "\n",
        "# Train the hybrid model with early stopping\n",
        "history = hybrid_model.fit(\n",
        "    [x_train_normalized, x_train_normalized],  # Replace with your training data\n",
        "    y_train_encoded,  # Replace with your training labels\n",
        "    epochs=60,\n",
        "    batch_size=batch_size,\n",
        "    validation_data=([x_val_normalized, x_val_normalized], y_val_encoded),  # Replace with your validation data\n",
        "    shuffle=True,\n",
        "    verbose=1,\n",
        "    callbacks=[early_stopping]  # Include the early stopping callback\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GRHY1ONZU8n1",
        "outputId": "4d23c42e-9ea0-45aa-b889-3f663efe40b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/60\n",
            "54/54 [==============================] - 20s 208ms/step - loss: 0.5538 - accuracy: 0.7308 - val_loss: 0.6830 - val_accuracy: 0.6138\n",
            "Epoch 2/60\n",
            "54/54 [==============================] - 8s 140ms/step - loss: 0.4136 - accuracy: 0.8435 - val_loss: 0.6802 - val_accuracy: 0.5122\n",
            "Epoch 3/60\n",
            "54/54 [==============================] - 7s 136ms/step - loss: 0.3730 - accuracy: 0.8502 - val_loss: 0.6708 - val_accuracy: 0.5122\n",
            "Epoch 4/60\n",
            "54/54 [==============================] - 7s 135ms/step - loss: 0.3522 - accuracy: 0.8513 - val_loss: 0.6494 - val_accuracy: 0.7093\n",
            "Epoch 5/60\n",
            "54/54 [==============================] - 7s 135ms/step - loss: 0.3413 - accuracy: 0.8548 - val_loss: 0.6044 - val_accuracy: 0.7947\n",
            "Epoch 6/60\n",
            "54/54 [==============================] - 8s 141ms/step - loss: 0.3302 - accuracy: 0.8612 - val_loss: 0.5328 - val_accuracy: 0.8272\n",
            "Epoch 7/60\n",
            "54/54 [==============================] - 7s 133ms/step - loss: 0.3191 - accuracy: 0.8682 - val_loss: 0.4642 - val_accuracy: 0.8496\n",
            "Epoch 8/60\n",
            "54/54 [==============================] - 8s 142ms/step - loss: 0.3140 - accuracy: 0.8647 - val_loss: 0.3967 - val_accuracy: 0.8618\n",
            "Epoch 9/60\n",
            "54/54 [==============================] - 7s 132ms/step - loss: 0.3056 - accuracy: 0.8699 - val_loss: 0.3557 - val_accuracy: 0.8679\n",
            "Epoch 10/60\n",
            "54/54 [==============================] - 7s 134ms/step - loss: 0.2947 - accuracy: 0.8812 - val_loss: 0.3230 - val_accuracy: 0.8760\n",
            "Epoch 11/60\n",
            "54/54 [==============================] - 7s 138ms/step - loss: 0.2898 - accuracy: 0.8812 - val_loss: 0.3023 - val_accuracy: 0.8821\n",
            "Epoch 12/60\n",
            "54/54 [==============================] - 7s 134ms/step - loss: 0.2861 - accuracy: 0.8810 - val_loss: 0.2881 - val_accuracy: 0.8841\n",
            "Epoch 13/60\n",
            "54/54 [==============================] - 7s 135ms/step - loss: 0.2805 - accuracy: 0.8873 - val_loss: 0.2785 - val_accuracy: 0.8902\n",
            "Epoch 14/60\n",
            "54/54 [==============================] - 7s 133ms/step - loss: 0.2759 - accuracy: 0.8900 - val_loss: 0.2738 - val_accuracy: 0.8862\n",
            "Epoch 15/60\n",
            "54/54 [==============================] - 8s 142ms/step - loss: 0.2695 - accuracy: 0.8885 - val_loss: 0.2638 - val_accuracy: 0.8882\n",
            "Epoch 16/60\n",
            "54/54 [==============================] - 8s 140ms/step - loss: 0.2654 - accuracy: 0.8946 - val_loss: 0.2618 - val_accuracy: 0.8943\n",
            "Epoch 17/60\n",
            "54/54 [==============================] - 7s 135ms/step - loss: 0.2557 - accuracy: 0.8995 - val_loss: 0.2578 - val_accuracy: 0.8923\n",
            "Epoch 18/60\n",
            "54/54 [==============================] - 7s 135ms/step - loss: 0.2557 - accuracy: 0.8943 - val_loss: 0.2504 - val_accuracy: 0.9004\n",
            "Epoch 19/60\n",
            "54/54 [==============================] - 8s 140ms/step - loss: 0.2489 - accuracy: 0.9019 - val_loss: 0.2495 - val_accuracy: 0.8943\n",
            "Epoch 20/60\n",
            "54/54 [==============================] - 7s 135ms/step - loss: 0.2446 - accuracy: 0.9036 - val_loss: 0.2521 - val_accuracy: 0.8984\n",
            "Epoch 21/60\n",
            "54/54 [==============================] - 7s 133ms/step - loss: 0.2446 - accuracy: 0.8966 - val_loss: 0.2480 - val_accuracy: 0.8984\n",
            "Epoch 22/60\n",
            "54/54 [==============================] - 7s 134ms/step - loss: 0.2366 - accuracy: 0.9019 - val_loss: 0.2431 - val_accuracy: 0.9004\n",
            "Epoch 23/60\n",
            "54/54 [==============================] - 7s 133ms/step - loss: 0.2346 - accuracy: 0.9036 - val_loss: 0.2406 - val_accuracy: 0.9065\n",
            "Epoch 24/60\n",
            "54/54 [==============================] - 8s 145ms/step - loss: 0.2303 - accuracy: 0.9097 - val_loss: 0.2408 - val_accuracy: 0.9045\n",
            "Epoch 25/60\n",
            "54/54 [==============================] - 7s 135ms/step - loss: 0.2264 - accuracy: 0.9100 - val_loss: 0.2396 - val_accuracy: 0.9045\n",
            "Epoch 26/60\n",
            "54/54 [==============================] - 7s 134ms/step - loss: 0.2219 - accuracy: 0.9114 - val_loss: 0.2345 - val_accuracy: 0.9085\n",
            "Epoch 27/60\n",
            "54/54 [==============================] - 7s 138ms/step - loss: 0.2188 - accuracy: 0.9094 - val_loss: 0.2342 - val_accuracy: 0.9126\n",
            "Epoch 28/60\n",
            "54/54 [==============================] - 7s 135ms/step - loss: 0.2168 - accuracy: 0.9146 - val_loss: 0.2293 - val_accuracy: 0.9167\n",
            "Epoch 29/60\n",
            "54/54 [==============================] - 8s 142ms/step - loss: 0.2145 - accuracy: 0.9161 - val_loss: 0.2323 - val_accuracy: 0.9085\n",
            "Epoch 30/60\n",
            "54/54 [==============================] - 7s 133ms/step - loss: 0.2159 - accuracy: 0.9138 - val_loss: 0.2316 - val_accuracy: 0.9106\n",
            "Epoch 31/60\n",
            "54/54 [==============================] - 7s 135ms/step - loss: 0.2082 - accuracy: 0.9204 - val_loss: 0.2294 - val_accuracy: 0.9126\n",
            "Epoch 32/60\n",
            "54/54 [==============================] - 8s 140ms/step - loss: 0.2089 - accuracy: 0.9178 - val_loss: 0.2240 - val_accuracy: 0.9146\n",
            "Epoch 33/60\n",
            "54/54 [==============================] - 7s 133ms/step - loss: 0.2029 - accuracy: 0.9207 - val_loss: 0.2326 - val_accuracy: 0.9024\n",
            "Epoch 34/60\n",
            "54/54 [==============================] - 7s 135ms/step - loss: 0.2057 - accuracy: 0.9184 - val_loss: 0.2257 - val_accuracy: 0.9106\n",
            "Epoch 35/60\n",
            "54/54 [==============================] - 7s 132ms/step - loss: 0.1994 - accuracy: 0.9199 - val_loss: 0.2263 - val_accuracy: 0.9126\n",
            "Epoch 36/60\n",
            "54/54 [==============================] - 8s 140ms/step - loss: 0.1966 - accuracy: 0.9213 - val_loss: 0.2342 - val_accuracy: 0.8984\n",
            "Epoch 37/60\n",
            "54/54 [==============================] - 7s 133ms/step - loss: 0.1950 - accuracy: 0.9219 - val_loss: 0.2230 - val_accuracy: 0.9187\n",
            "Epoch 38/60\n",
            "54/54 [==============================] - 7s 135ms/step - loss: 0.1937 - accuracy: 0.9228 - val_loss: 0.2204 - val_accuracy: 0.9146\n",
            "Epoch 39/60\n",
            "54/54 [==============================] - 7s 134ms/step - loss: 0.1936 - accuracy: 0.9210 - val_loss: 0.2238 - val_accuracy: 0.9065\n",
            "Epoch 40/60\n",
            "54/54 [==============================] - 7s 133ms/step - loss: 0.1915 - accuracy: 0.9236 - val_loss: 0.2298 - val_accuracy: 0.9085\n",
            "Epoch 41/60\n",
            "54/54 [==============================] - 7s 135ms/step - loss: 0.1875 - accuracy: 0.9289 - val_loss: 0.2324 - val_accuracy: 0.9024\n",
            "Epoch 42/60\n",
            "54/54 [==============================] - 7s 133ms/step - loss: 0.1917 - accuracy: 0.9248 - val_loss: 0.2179 - val_accuracy: 0.9228\n",
            "Epoch 43/60\n",
            "54/54 [==============================] - 7s 135ms/step - loss: 0.1857 - accuracy: 0.9265 - val_loss: 0.2188 - val_accuracy: 0.9207\n",
            "Epoch 44/60\n",
            "54/54 [==============================] - 7s 132ms/step - loss: 0.1856 - accuracy: 0.9233 - val_loss: 0.2226 - val_accuracy: 0.9126\n",
            "Epoch 45/60\n",
            "54/54 [==============================] - 7s 135ms/step - loss: 0.1825 - accuracy: 0.9286 - val_loss: 0.2184 - val_accuracy: 0.9146\n",
            "Epoch 46/60\n",
            "54/54 [==============================] - 7s 133ms/step - loss: 0.1840 - accuracy: 0.9292 - val_loss: 0.2195 - val_accuracy: 0.9167\n",
            "Epoch 47/60\n",
            "54/54 [==============================] - 7s 134ms/step - loss: 0.1845 - accuracy: 0.9271 - val_loss: 0.2185 - val_accuracy: 0.9146\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on the test data\n",
        "test_loss, test_accuracy = hybrid_model.evaluate([x_test_normalized, x_test_normalized], y_test_encoded)\n",
        "\n",
        "print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")\n",
        "print(f\"Test Loss: {test_loss}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rM3iQi_UUYPH",
        "outputId": "e27d2a03-23b8-4941-e0aa-73cf2f18c392"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "31/31 [==============================] - 2s 38ms/step - loss: 0.2174 - accuracy: 0.9065\n",
            "Test Accuracy: 90.65%\n",
            "Test Loss: 0.2174423485994339\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Assuming you have your hybrid model already trained and stored in hybrid_model_regularized\n",
        "\n",
        "# Extract features from the hybrid model for training, validation, and test sets\n",
        "x_train_features = hybrid_model.predict([x_train_normalized, x_train_normalized])\n",
        "x_val_features = hybrid_model.predict([x_val_normalized, x_val_normalized])\n",
        "x_test_features = hybrid_model.predict([x_test_normalized, x_test_normalized])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7VX2J4xlWzF1",
        "outputId": "d187fd24-532b-4602-f386-05e0715f88dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "108/108 [==============================] - 3s 25ms/step\n",
            "16/16 [==============================] - 1s 41ms/step\n",
            "31/31 [==============================] - 1s 20ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_features = x_train_features.reshape(x_train_features.shape[0], -1)\n",
        "x_val_features = x_val_features.reshape(x_val_features.shape[0], -1)\n",
        "x_test_features = x_test_features.reshape(x_test_features.shape[0], -1)"
      ],
      "metadata": {
        "id": "V9UUDTRFXDdC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "\n",
        "\n",
        "\n",
        "# Define the best hyperparameters obtained from GridSearchCV\n",
        "best_params = {'C': 0.1, 'gamma': 'scale'}  # Replace these values with the best parameters found\n",
        "\n",
        "# Train SVM model with the best hyperparameters\n",
        "svm_model = SVC(kernel='rbf', C=best_params['C'], gamma=best_params['gamma'])\n",
        "svm_model.fit(x_train_features, y_train)\n",
        "\n",
        "# Predict on the test set using the trained SVM model\n",
        "y_pred_svm = svm_model.predict(x_test_features)\n",
        "\n",
        "# Calculate evaluation metrics\n",
        "svm_accuracy = accuracy_score(y_test, y_pred_svm)\n",
        "svm_precision = precision_score(y_test, y_pred_svm)\n",
        "svm_recall = recall_score(y_test, y_pred_svm)\n",
        "svm_f1 = f1_score(y_test, y_pred_svm)\n",
        "\n",
        "# Calculate specificity\n",
        "tn, fp, fn, tp = confusion_matrix(y_test, y_pred_svm).ravel()\n",
        "svm_specificity = tn / (tn + fp)\n",
        "\n",
        "# Print evaluation metrics\n",
        "print(\"SVM Accuracy:\", svm_accuracy)\n",
        "print(\"SVM Precision:\", svm_precision)\n",
        "print(\"SVM Sensitivity (Recall):\", svm_recall)\n",
        "print(\"SVM Specificity:\", svm_specificity)\n",
        "print(\"SVM F1 Score:\", svm_f1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fHbZrxmqXJwF",
        "outputId": "eaa1c6bc-e4c3-4b81-d5b7-9f696406e670"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVM Accuracy: 0.9186991869918699\n",
            "SVM Precision: 0.9506172839506173\n",
            "SVM Sensitivity (Recall): 0.8918918918918919\n",
            "SVM Specificity: 0.9484978540772532\n",
            "SVM F1 Score: 0.9203187250996016\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Input, Conv2D, BatchNormalization, ReLU, GlobalAveragePooling2D, Dense, Concatenate, Add, MaxPooling2D\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "# Basic Convolution Block with BatchNormalization and ReLU\n",
        "def conv_block(input_tensor, filters, kernel_size, strides=(1, 1)):\n",
        "    x = Conv2D(filters, kernel_size, strides=strides, padding='same')(input_tensor)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = ReLU()(x)\n",
        "    return x\n",
        "\n",
        "# Residual Block\n",
        "def residual_block(input_tensor, filters, kernel_size=(3, 3), strides=(1, 1)):\n",
        "    shortcut = input_tensor\n",
        "    x = conv_block(input_tensor, filters, kernel_size, strides)\n",
        "    x = conv_block(x, filters, kernel_size)\n",
        "    shortcut = Conv2D(filters, (1, 1), strides=strides, padding='same')(shortcut)\n",
        "    x = Add()([x, shortcut])\n",
        "    x = ReLU()(x)\n",
        "    return x\n",
        "\n",
        "# ShuffleNet-like architecture (simplified)\n",
        "def ShuffleNetCustom(input_shape):\n",
        "    input_tensor = Input(shape=input_shape)\n",
        "\n",
        "    # Convolution Block\n",
        "    x = conv_block(input_tensor, 64, (3, 3), strides=(2, 2))\n",
        "\n",
        "    # Stage 1 - ShuffleNet-like\n",
        "    x = residual_block(x, 128)\n",
        "    x = residual_block(x, 128)\n",
        "    x = residual_block(x, 128)\n",
        "\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    return Model(inputs=input_tensor, outputs=x)\n",
        "\n",
        "# ResNet50-like architecture (simplified)\n",
        "def ResNet50Custom(input_shape):\n",
        "    input_tensor = Input(shape=input_shape)\n",
        "\n",
        "    # Convolution Block\n",
        "    x = conv_block(input_tensor, 64, (7, 7), strides=(2, 2))\n",
        "\n",
        "    # Stage 1 - ResNet50-like\n",
        "    x = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n",
        "\n",
        "    x = residual_block(x, 256)\n",
        "    x = residual_block(x, 256)\n",
        "    x = residual_block(x, 256)\n",
        "\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    return Model(inputs=input_tensor, outputs=x)\n",
        "\n",
        "# Input shape and number of classes\n",
        "input_shape = (100, 100, 3)\n",
        "num_classes = 2\n",
        "\n",
        "# Build ShuffleNet-like and ResNet50-like models\n",
        "shufflenet_model = ShuffleNetCustom(input_shape)\n",
        "resnet50_model = ResNet50Custom(input_shape)\n",
        "\n",
        "# Get the output tensors from both models\n",
        "shufflenet_output = shufflenet_model.output\n",
        "resnet50_output = resnet50_model.output\n",
        "\n",
        "# Concatenate the outputs\n",
        "merged_output = Concatenate()([shufflenet_output, resnet50_output])\n",
        "\n",
        "# Add more layers for classification\n",
        "x = Dense(256, activation='relu')(merged_output)\n",
        "x = Dense(128, activation='relu')(x)\n",
        "predictions = Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "# Create the hybrid model\n",
        "hybrid_model = Model(inputs=[shufflenet_model.input, resnet50_model.input], outputs=predictions)\n",
        "\n",
        "# Compile the hybrid model\n",
        "hybrid_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Display the summary of the hybrid model\n",
        "hybrid_model.summary()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rv9uhjSoYABm",
        "outputId": "6a68be89-3b6d-4146-be89-5d8a154d8eb8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_8\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_6 (InputLayer)        [(None, 100, 100, 3)]        0         []                            \n",
            "                                                                                                  \n",
            " input_5 (InputLayer)        [(None, 100, 100, 3)]        0         []                            \n",
            "                                                                                                  \n",
            " conv2d_24 (Conv2D)          (None, 50, 50, 64)           9472      ['input_6[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_14 (Conv2D)          (None, 50, 50, 64)           1792      ['input_5[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_21 (Ba  (None, 50, 50, 64)           256       ['conv2d_24[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_14 (Ba  (None, 50, 50, 64)           256       ['conv2d_14[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " re_lu_23 (ReLU)             (None, 50, 50, 64)           0         ['batch_normalization_21[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " re_lu_13 (ReLU)             (None, 50, 50, 64)           0         ['batch_normalization_14[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " max_pooling2d (MaxPooling2  (None, 25, 25, 64)           0         ['re_lu_23[0][0]']            \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv2d_15 (Conv2D)          (None, 50, 50, 128)          73856     ['re_lu_13[0][0]']            \n",
            "                                                                                                  \n",
            " conv2d_25 (Conv2D)          (None, 25, 25, 256)          147712    ['max_pooling2d[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_15 (Ba  (None, 50, 50, 128)          512       ['conv2d_15[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_22 (Ba  (None, 25, 25, 256)          1024      ['conv2d_25[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " re_lu_14 (ReLU)             (None, 50, 50, 128)          0         ['batch_normalization_15[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " re_lu_24 (ReLU)             (None, 25, 25, 256)          0         ['batch_normalization_22[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_16 (Conv2D)          (None, 50, 50, 128)          147584    ['re_lu_14[0][0]']            \n",
            "                                                                                                  \n",
            " conv2d_26 (Conv2D)          (None, 25, 25, 256)          590080    ['re_lu_24[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_16 (Ba  (None, 50, 50, 128)          512       ['conv2d_16[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_23 (Ba  (None, 25, 25, 256)          1024      ['conv2d_26[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " re_lu_15 (ReLU)             (None, 50, 50, 128)          0         ['batch_normalization_16[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_17 (Conv2D)          (None, 50, 50, 128)          8320      ['re_lu_13[0][0]']            \n",
            "                                                                                                  \n",
            " re_lu_25 (ReLU)             (None, 25, 25, 256)          0         ['batch_normalization_23[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_27 (Conv2D)          (None, 25, 25, 256)          16640     ['max_pooling2d[0][0]']       \n",
            "                                                                                                  \n",
            " add_1 (Add)                 (None, 50, 50, 128)          0         ['re_lu_15[0][0]',            \n",
            "                                                                     'conv2d_17[0][0]']           \n",
            "                                                                                                  \n",
            " add_4 (Add)                 (None, 25, 25, 256)          0         ['re_lu_25[0][0]',            \n",
            "                                                                     'conv2d_27[0][0]']           \n",
            "                                                                                                  \n",
            " re_lu_16 (ReLU)             (None, 50, 50, 128)          0         ['add_1[0][0]']               \n",
            "                                                                                                  \n",
            " re_lu_26 (ReLU)             (None, 25, 25, 256)          0         ['add_4[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_18 (Conv2D)          (None, 50, 50, 128)          147584    ['re_lu_16[0][0]']            \n",
            "                                                                                                  \n",
            " conv2d_28 (Conv2D)          (None, 25, 25, 256)          590080    ['re_lu_26[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_17 (Ba  (None, 50, 50, 128)          512       ['conv2d_18[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_24 (Ba  (None, 25, 25, 256)          1024      ['conv2d_28[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " re_lu_17 (ReLU)             (None, 50, 50, 128)          0         ['batch_normalization_17[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " re_lu_27 (ReLU)             (None, 25, 25, 256)          0         ['batch_normalization_24[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_19 (Conv2D)          (None, 50, 50, 128)          147584    ['re_lu_17[0][0]']            \n",
            "                                                                                                  \n",
            " conv2d_29 (Conv2D)          (None, 25, 25, 256)          590080    ['re_lu_27[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_18 (Ba  (None, 50, 50, 128)          512       ['conv2d_19[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_25 (Ba  (None, 25, 25, 256)          1024      ['conv2d_29[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " re_lu_18 (ReLU)             (None, 50, 50, 128)          0         ['batch_normalization_18[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_20 (Conv2D)          (None, 50, 50, 128)          16512     ['re_lu_16[0][0]']            \n",
            "                                                                                                  \n",
            " re_lu_28 (ReLU)             (None, 25, 25, 256)          0         ['batch_normalization_25[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_30 (Conv2D)          (None, 25, 25, 256)          65792     ['re_lu_26[0][0]']            \n",
            "                                                                                                  \n",
            " add_2 (Add)                 (None, 50, 50, 128)          0         ['re_lu_18[0][0]',            \n",
            "                                                                     'conv2d_20[0][0]']           \n",
            "                                                                                                  \n",
            " add_5 (Add)                 (None, 25, 25, 256)          0         ['re_lu_28[0][0]',            \n",
            "                                                                     'conv2d_30[0][0]']           \n",
            "                                                                                                  \n",
            " re_lu_19 (ReLU)             (None, 50, 50, 128)          0         ['add_2[0][0]']               \n",
            "                                                                                                  \n",
            " re_lu_29 (ReLU)             (None, 25, 25, 256)          0         ['add_5[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_21 (Conv2D)          (None, 50, 50, 128)          147584    ['re_lu_19[0][0]']            \n",
            "                                                                                                  \n",
            " conv2d_31 (Conv2D)          (None, 25, 25, 256)          590080    ['re_lu_29[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_19 (Ba  (None, 50, 50, 128)          512       ['conv2d_21[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_26 (Ba  (None, 25, 25, 256)          1024      ['conv2d_31[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " re_lu_20 (ReLU)             (None, 50, 50, 128)          0         ['batch_normalization_19[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " re_lu_30 (ReLU)             (None, 25, 25, 256)          0         ['batch_normalization_26[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_22 (Conv2D)          (None, 50, 50, 128)          147584    ['re_lu_20[0][0]']            \n",
            "                                                                                                  \n",
            " conv2d_32 (Conv2D)          (None, 25, 25, 256)          590080    ['re_lu_30[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_20 (Ba  (None, 50, 50, 128)          512       ['conv2d_22[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_27 (Ba  (None, 25, 25, 256)          1024      ['conv2d_32[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " re_lu_21 (ReLU)             (None, 50, 50, 128)          0         ['batch_normalization_20[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_23 (Conv2D)          (None, 50, 50, 128)          16512     ['re_lu_19[0][0]']            \n",
            "                                                                                                  \n",
            " re_lu_31 (ReLU)             (None, 25, 25, 256)          0         ['batch_normalization_27[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_33 (Conv2D)          (None, 25, 25, 256)          65792     ['re_lu_29[0][0]']            \n",
            "                                                                                                  \n",
            " add_3 (Add)                 (None, 50, 50, 128)          0         ['re_lu_21[0][0]',            \n",
            "                                                                     'conv2d_23[0][0]']           \n",
            "                                                                                                  \n",
            " add_6 (Add)                 (None, 25, 25, 256)          0         ['re_lu_31[0][0]',            \n",
            "                                                                     'conv2d_33[0][0]']           \n",
            "                                                                                                  \n",
            " re_lu_22 (ReLU)             (None, 50, 50, 128)          0         ['add_3[0][0]']               \n",
            "                                                                                                  \n",
            " re_lu_32 (ReLU)             (None, 25, 25, 256)          0         ['add_6[0][0]']               \n",
            "                                                                                                  \n",
            " global_average_pooling2d_4  (None, 128)                  0         ['re_lu_22[0][0]']            \n",
            "  (GlobalAveragePooling2D)                                                                        \n",
            "                                                                                                  \n",
            " global_average_pooling2d_5  (None, 256)                  0         ['re_lu_32[0][0]']            \n",
            "  (GlobalAveragePooling2D)                                                                        \n",
            "                                                                                                  \n",
            " concatenate_2 (Concatenate  (None, 384)                  0         ['global_average_pooling2d_4[0\n",
            " )                                                                  ][0]',                        \n",
            "                                                                     'global_average_pooling2d_5[0\n",
            "                                                                    ][0]']                        \n",
            "                                                                                                  \n",
            " dense_6 (Dense)             (None, 256)                  98560     ['concatenate_2[0][0]']       \n",
            "                                                                                                  \n",
            " dense_7 (Dense)             (None, 128)                  32896     ['dense_6[0][0]']             \n",
            "                                                                                                  \n",
            " dense_8 (Dense)             (None, 2)                    258       ['dense_7[0][0]']             \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 4252162 (16.22 MB)\n",
            "Trainable params: 4247298 (16.20 MB)\n",
            "Non-trainable params: 4864 (19.00 KB)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "\\\n",
        "\n",
        "# Set the learning rate\n",
        "learning_rate = 0.0001\n",
        "\n",
        "# Compile the model with the specified learning rate\n",
        "hybrid_model.compile(optimizer=Adam(learning_rate=learning_rate),\n",
        "                     loss='categorical_crossentropy',\n",
        "                     metrics=['accuracy'])\n",
        "\n",
        "# Train the hybrid model\n",
        "history = hybrid_model.fit(\n",
        "    [x_train_normalized, x_train_normalized],  # Replace with your training data\n",
        "    y_train_encoded,  # Replace with your training labels\n",
        "    epochs=55,\n",
        "    batch_size=batch_size,\n",
        "    validation_data=([x_val_normalized, x_val_normalized], y_val_encoded),  # Replace with your validation data\n",
        "    shuffle=True,\n",
        "    verbose=1,\n",
        "\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wdYync6zZObS",
        "outputId": "861be9ec-c30b-47e1-b8bc-41e6c4119d60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/55\n",
            "54/54 [==============================] - 35s 419ms/step - loss: 0.2907 - accuracy: 0.8783 - val_loss: 0.6792 - val_accuracy: 0.4878\n",
            "Epoch 2/55\n",
            "54/54 [==============================] - 19s 359ms/step - loss: 0.2202 - accuracy: 0.9088 - val_loss: 0.8036 - val_accuracy: 0.4878\n",
            "Epoch 3/55\n",
            "54/54 [==============================] - 19s 347ms/step - loss: 0.1923 - accuracy: 0.9219 - val_loss: 0.9623 - val_accuracy: 0.4878\n",
            "Epoch 4/55\n",
            "54/54 [==============================] - 19s 344ms/step - loss: 0.1844 - accuracy: 0.9239 - val_loss: 1.4671 - val_accuracy: 0.4878\n",
            "Epoch 5/55\n",
            "54/54 [==============================] - 19s 353ms/step - loss: 0.1822 - accuracy: 0.9257 - val_loss: 1.9495 - val_accuracy: 0.4878\n",
            "Epoch 6/55\n",
            "54/54 [==============================] - 19s 354ms/step - loss: 0.1746 - accuracy: 0.9312 - val_loss: 1.1286 - val_accuracy: 0.5732\n",
            "Epoch 7/55\n",
            "54/54 [==============================] - 19s 357ms/step - loss: 0.1650 - accuracy: 0.9370 - val_loss: 1.3094 - val_accuracy: 0.5325\n",
            "Epoch 8/55\n",
            "54/54 [==============================] - 19s 346ms/step - loss: 0.1566 - accuracy: 0.9399 - val_loss: 1.5004 - val_accuracy: 0.5935\n",
            "Epoch 9/55\n",
            "54/54 [==============================] - 19s 354ms/step - loss: 0.1459 - accuracy: 0.9448 - val_loss: 0.6963 - val_accuracy: 0.7398\n",
            "Epoch 10/55\n",
            "54/54 [==============================] - 19s 354ms/step - loss: 0.1407 - accuracy: 0.9422 - val_loss: 0.5343 - val_accuracy: 0.8049\n",
            "Epoch 11/55\n",
            "54/54 [==============================] - 19s 354ms/step - loss: 0.1490 - accuracy: 0.9396 - val_loss: 0.7308 - val_accuracy: 0.7439\n",
            "Epoch 12/55\n",
            "54/54 [==============================] - 19s 345ms/step - loss: 0.1389 - accuracy: 0.9457 - val_loss: 0.4270 - val_accuracy: 0.8537\n",
            "Epoch 13/55\n",
            "54/54 [==============================] - 19s 354ms/step - loss: 0.1399 - accuracy: 0.9425 - val_loss: 0.3779 - val_accuracy: 0.8659\n",
            "Epoch 14/55\n",
            "54/54 [==============================] - 19s 354ms/step - loss: 0.1306 - accuracy: 0.9469 - val_loss: 0.2766 - val_accuracy: 0.9004\n",
            "Epoch 15/55\n",
            "54/54 [==============================] - 19s 355ms/step - loss: 0.1284 - accuracy: 0.9492 - val_loss: 0.3039 - val_accuracy: 0.8841\n",
            "Epoch 16/55\n",
            "54/54 [==============================] - 19s 354ms/step - loss: 0.1125 - accuracy: 0.9556 - val_loss: 1.2755 - val_accuracy: 0.6545\n",
            "Epoch 17/55\n",
            "54/54 [==============================] - 19s 355ms/step - loss: 0.1209 - accuracy: 0.9535 - val_loss: 0.2772 - val_accuracy: 0.9126\n",
            "Epoch 18/55\n",
            "54/54 [==============================] - 19s 345ms/step - loss: 0.1159 - accuracy: 0.9527 - val_loss: 0.2034 - val_accuracy: 0.9228\n",
            "Epoch 19/55\n",
            "54/54 [==============================] - 19s 354ms/step - loss: 0.1072 - accuracy: 0.9625 - val_loss: 0.3152 - val_accuracy: 0.8821\n",
            "Epoch 20/55\n",
            "54/54 [==============================] - 19s 353ms/step - loss: 0.1048 - accuracy: 0.9617 - val_loss: 0.3010 - val_accuracy: 0.8923\n",
            "Epoch 21/55\n",
            "54/54 [==============================] - 19s 346ms/step - loss: 0.1207 - accuracy: 0.9544 - val_loss: 0.2959 - val_accuracy: 0.9126\n",
            "Epoch 22/55\n",
            "54/54 [==============================] - 19s 345ms/step - loss: 0.1025 - accuracy: 0.9617 - val_loss: 0.2974 - val_accuracy: 0.9004\n",
            "Epoch 23/55\n",
            "54/54 [==============================] - 19s 347ms/step - loss: 0.0941 - accuracy: 0.9631 - val_loss: 0.3068 - val_accuracy: 0.8882\n",
            "Epoch 24/55\n",
            "54/54 [==============================] - 19s 346ms/step - loss: 0.0926 - accuracy: 0.9637 - val_loss: 0.2118 - val_accuracy: 0.9146\n",
            "Epoch 25/55\n",
            "54/54 [==============================] - 19s 347ms/step - loss: 0.0893 - accuracy: 0.9669 - val_loss: 0.3125 - val_accuracy: 0.8821\n",
            "Epoch 26/55\n",
            "54/54 [==============================] - 19s 354ms/step - loss: 0.0840 - accuracy: 0.9686 - val_loss: 0.5239 - val_accuracy: 0.8313\n",
            "Epoch 27/55\n",
            "54/54 [==============================] - 19s 346ms/step - loss: 0.0810 - accuracy: 0.9707 - val_loss: 0.2304 - val_accuracy: 0.9126\n",
            "Epoch 28/55\n",
            "54/54 [==============================] - 19s 354ms/step - loss: 0.0795 - accuracy: 0.9692 - val_loss: 0.4059 - val_accuracy: 0.8679\n",
            "Epoch 29/55\n",
            "54/54 [==============================] - 19s 347ms/step - loss: 0.0753 - accuracy: 0.9715 - val_loss: 0.3905 - val_accuracy: 0.8699\n",
            "Epoch 30/55\n",
            "54/54 [==============================] - 19s 355ms/step - loss: 0.0811 - accuracy: 0.9701 - val_loss: 0.3155 - val_accuracy: 0.9045\n",
            "Epoch 31/55\n",
            "54/54 [==============================] - 19s 358ms/step - loss: 0.0655 - accuracy: 0.9762 - val_loss: 0.2714 - val_accuracy: 0.8963\n",
            "Epoch 32/55\n",
            "54/54 [==============================] - 19s 358ms/step - loss: 0.0708 - accuracy: 0.9776 - val_loss: 0.2773 - val_accuracy: 0.9146\n",
            "Epoch 33/55\n",
            "54/54 [==============================] - 19s 345ms/step - loss: 0.0629 - accuracy: 0.9768 - val_loss: 0.6442 - val_accuracy: 0.8089\n",
            "Epoch 34/55\n",
            "54/54 [==============================] - 19s 346ms/step - loss: 0.0727 - accuracy: 0.9742 - val_loss: 0.2903 - val_accuracy: 0.8963\n",
            "Epoch 35/55\n",
            "54/54 [==============================] - 19s 354ms/step - loss: 0.0573 - accuracy: 0.9805 - val_loss: 0.2694 - val_accuracy: 0.9085\n",
            "Epoch 36/55\n",
            "54/54 [==============================] - 19s 355ms/step - loss: 0.0535 - accuracy: 0.9820 - val_loss: 0.4102 - val_accuracy: 0.8720\n",
            "Epoch 37/55\n",
            "54/54 [==============================] - 19s 346ms/step - loss: 0.0534 - accuracy: 0.9797 - val_loss: 0.2731 - val_accuracy: 0.9045\n",
            "Epoch 38/55\n",
            "54/54 [==============================] - 19s 346ms/step - loss: 0.0563 - accuracy: 0.9774 - val_loss: 0.4655 - val_accuracy: 0.8638\n",
            "Epoch 39/55\n",
            "54/54 [==============================] - 19s 354ms/step - loss: 0.0674 - accuracy: 0.9742 - val_loss: 0.4848 - val_accuracy: 0.8801\n",
            "Epoch 40/55\n",
            "54/54 [==============================] - 19s 346ms/step - loss: 0.0653 - accuracy: 0.9742 - val_loss: 0.3548 - val_accuracy: 0.8638\n",
            "Epoch 41/55\n",
            "54/54 [==============================] - 19s 346ms/step - loss: 0.0559 - accuracy: 0.9788 - val_loss: 0.5200 - val_accuracy: 0.8780\n",
            "Epoch 42/55\n",
            "54/54 [==============================] - 19s 347ms/step - loss: 0.0516 - accuracy: 0.9808 - val_loss: 0.3263 - val_accuracy: 0.9126\n",
            "Epoch 43/55\n",
            "54/54 [==============================] - 19s 346ms/step - loss: 0.0410 - accuracy: 0.9869 - val_loss: 0.5871 - val_accuracy: 0.8435\n",
            "Epoch 44/55\n",
            "54/54 [==============================] - 19s 347ms/step - loss: 0.0447 - accuracy: 0.9817 - val_loss: 0.4091 - val_accuracy: 0.8984\n",
            "Epoch 45/55\n",
            "54/54 [==============================] - 19s 346ms/step - loss: 0.0567 - accuracy: 0.9779 - val_loss: 0.5085 - val_accuracy: 0.8902\n",
            "Epoch 46/55\n",
            "54/54 [==============================] - 19s 354ms/step - loss: 0.0476 - accuracy: 0.9829 - val_loss: 0.2431 - val_accuracy: 0.9146\n",
            "Epoch 47/55\n",
            "54/54 [==============================] - 19s 346ms/step - loss: 0.0440 - accuracy: 0.9829 - val_loss: 0.3029 - val_accuracy: 0.9126\n",
            "Epoch 48/55\n",
            "54/54 [==============================] - 19s 347ms/step - loss: 0.0340 - accuracy: 0.9881 - val_loss: 0.5356 - val_accuracy: 0.8313\n",
            "Epoch 49/55\n",
            "54/54 [==============================] - 19s 354ms/step - loss: 0.0385 - accuracy: 0.9849 - val_loss: 0.3007 - val_accuracy: 0.9126\n",
            "Epoch 50/55\n",
            "54/54 [==============================] - 19s 355ms/step - loss: 0.0352 - accuracy: 0.9869 - val_loss: 0.4986 - val_accuracy: 0.8862\n",
            "Epoch 51/55\n",
            "54/54 [==============================] - 19s 346ms/step - loss: 0.0365 - accuracy: 0.9872 - val_loss: 0.3951 - val_accuracy: 0.8963\n",
            "Epoch 52/55\n",
            "54/54 [==============================] - 19s 347ms/step - loss: 0.0302 - accuracy: 0.9884 - val_loss: 0.5965 - val_accuracy: 0.8638\n",
            "Epoch 53/55\n",
            "54/54 [==============================] - 19s 345ms/step - loss: 0.0327 - accuracy: 0.9893 - val_loss: 0.3439 - val_accuracy: 0.9106\n",
            "Epoch 54/55\n",
            "54/54 [==============================] - 19s 354ms/step - loss: 0.0381 - accuracy: 0.9858 - val_loss: 1.5050 - val_accuracy: 0.6809\n",
            "Epoch 55/55\n",
            "54/54 [==============================] - 19s 346ms/step - loss: 0.0386 - accuracy: 0.9861 - val_loss: 0.4135 - val_accuracy: 0.9065\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on the test data\n",
        "test_loss, test_accuracy = hybrid_model.evaluate([x_test_normalized, x_test_normalized], y_test_encoded)\n",
        "\n",
        "print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")\n",
        "print(f\"Test Loss: {test_loss}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y6VZe44jZ86G",
        "outputId": "7da650ec-6e5d-41d5-e698-c767b45761a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "31/31 [==============================] - 3s 77ms/step - loss: 0.3838 - accuracy: 0.9055\n",
            "Test Accuracy: 90.55%\n",
            "Test Loss: 0.383775919675827\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Assuming you have your hybrid model already trained and stored in hybrid_model_regularized\n",
        "\n",
        "# Extract features from the hybrid model for training, validation, and test sets\n",
        "x_train_features = hybrid_model.predict([x_train_normalized, x_train_normalized])\n",
        "x_val_features = hybrid_model.predict([x_val_normalized, x_val_normalized])\n",
        "x_test_features = hybrid_model.predict([x_test_normalized, x_test_normalized])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wi5T6VgmhJcf",
        "outputId": "db8eca1e-89f0-4c0d-e77a-67d62f769a22"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "108/108 [==============================] - 7s 61ms/step\n",
            "16/16 [==============================] - 1s 81ms/step\n",
            "31/31 [==============================] - 2s 54ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_features = x_train_features.reshape(x_train_features.shape[0], -1)\n",
        "x_val_features = x_val_features.reshape(x_val_features.shape[0], -1)\n",
        "x_test_features = x_test_features.reshape(x_test_features.shape[0], -1)"
      ],
      "metadata": {
        "id": "9bP1tTnvhQFY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "\n",
        "\n",
        "\n",
        "# Define the best hyperparameters obtained from GridSearchCV\n",
        "best_params = {'C': 3, 'gamma': 'scale'}  # Replace these values with the best parameters found\n",
        "\n",
        "# Train SVM model with the best hyperparameters\n",
        "svm_model = SVC(kernel='rbf', C=best_params['C'], gamma=best_params['gamma'])\n",
        "svm_model.fit(x_train_features, y_train)\n",
        "\n",
        "# Predict on the test set using the trained SVM model\n",
        "y_pred_svm = svm_model.predict(x_test_features)\n",
        "\n",
        "# Calculate evaluation metrics\n",
        "svm_accuracy = accuracy_score(y_test, y_pred_svm)\n",
        "svm_precision = precision_score(y_test, y_pred_svm)\n",
        "svm_recall = recall_score(y_test, y_pred_svm)\n",
        "svm_f1 = f1_score(y_test, y_pred_svm)\n",
        "\n",
        "# Calculate specificity\n",
        "tn, fp, fn, tp = confusion_matrix(y_test, y_pred_svm).ravel()\n",
        "svm_specificity = tn / (tn + fp)\n",
        "\n",
        "# Print evaluation metrics\n",
        "print(\"SVM Accuracy:\", svm_accuracy)\n",
        "print(\"SVM Precision:\", svm_precision)\n",
        "print(\"SVM Sensitivity (Recall):\", svm_recall)\n",
        "print(\"SVM Specificity:\", svm_specificity)\n",
        "print(\"SVM F1 Score:\", svm_f1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IowHNKiQhY6O",
        "outputId": "337fd9bb-07b9-4a33-f507-78742f64e38e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVM Accuracy: 0.9146341463414634\n",
            "SVM Precision: 0.9520833333333333\n",
            "SVM Sensitivity (Recall): 0.8822393822393823\n",
            "SVM Specificity: 0.9506437768240343\n",
            "SVM F1 Score: 0.9158316633266533\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Input, Conv2D, BatchNormalization, ReLU, GlobalAveragePooling2D, Dense, Concatenate, MaxPooling2D\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "# Basic Convolution Block with BatchNormalization and ReLU\n",
        "def conv_block(input_tensor, filters, kernel_size, strides=(1, 1)):\n",
        "    x = Conv2D(filters, kernel_size, strides=strides, padding='same')(input_tensor)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = ReLU()(x)\n",
        "    return x\n",
        "\n",
        "# VGG16-like architecture (simplified)\n",
        "def VGG16Custom(input_shape):\n",
        "    input_tensor = Input(shape=input_shape)\n",
        "\n",
        "    # Convolution Block\n",
        "    x = conv_block(input_tensor, 64, (3, 3))\n",
        "    x = conv_block(x, 64, (3, 3))\n",
        "    x = MaxPooling2D((2, 2))(x)\n",
        "\n",
        "    x = conv_block(x, 128, (3, 3))\n",
        "    x = conv_block(x, 128, (3, 3))\n",
        "    x = MaxPooling2D((2, 2))(x)\n",
        "\n",
        "    x = conv_block(x, 256, (3, 3))\n",
        "    x = conv_block(x, 256, (3, 3))\n",
        "    x = conv_block(x, 256, (3, 3))\n",
        "    x = MaxPooling2D((2, 2))(x)\n",
        "\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    return Model(inputs=input_tensor, outputs=x)\n",
        "\n",
        "# ResNet50-like architecture (simplified)\n",
        "def ResNet50Custom(input_shape):\n",
        "    input_tensor = Input(shape=input_shape)\n",
        "\n",
        "    # Convolution Block\n",
        "    x = conv_block(input_tensor, 64, (7, 7), strides=(2, 2))\n",
        "    x = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n",
        "\n",
        "    x = residual_block(x, 256)\n",
        "    x = residual_block(x, 256)\n",
        "    x = residual_block(x, 256)\n",
        "\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    return Model(inputs=input_tensor, outputs=x)\n",
        "\n",
        "# Define the residual block used in ResNet50\n",
        "def residual_block(input_tensor, filters, kernel_size=(3, 3), strides=(1, 1)):\n",
        "    shortcut = input_tensor\n",
        "    x = conv_block(input_tensor, filters, kernel_size, strides)\n",
        "    x = conv_block(x, filters, kernel_size)\n",
        "    shortcut = Conv2D(filters, (1, 1), strides=strides, padding='same')(shortcut)\n",
        "    x = Add()([x, shortcut])\n",
        "    x = ReLU()(x)\n",
        "    return x\n",
        "\n",
        "# Input shape and number of classes\n",
        "input_shape = (100, 100, 3)\n",
        "num_classes = 2\n",
        "\n",
        "# Build VGG16-like and ResNet50-like models\n",
        "vgg16_model = VGG16Custom(input_shape)\n",
        "resnet50_model = ResNet50Custom(input_shape)\n",
        "\n",
        "# Get the output tensors from both models\n",
        "vgg16_output = vgg16_model.output\n",
        "resnet50_output = resnet50_model.output\n",
        "\n",
        "# Concatenate the outputs\n",
        "merged_output = Concatenate()([vgg16_output, resnet50_output])\n",
        "\n",
        "# Add more layers for classification\n",
        "x = Dense(256, activation='relu')(merged_output)\n",
        "x = Dense(128, activation='relu')(x)\n",
        "predictions = Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "# Create the hybrid model\n",
        "hybrid_model = Model(inputs=[vgg16_model.input, resnet50_model.input], outputs=predictions)\n",
        "\n",
        "# Compile the hybrid model\n",
        "hybrid_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Display the summary of the hybrid model\n",
        "hybrid_model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2BbXpU3nmYcu",
        "outputId": "74125b54-fabd-44d6-9bf6-641d38ec9e9d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_2 (InputLayer)        [(None, 100, 100, 3)]        0         []                            \n",
            "                                                                                                  \n",
            " conv2d_7 (Conv2D)           (None, 50, 50, 64)           9472      ['input_2[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_7 (Bat  (None, 50, 50, 64)           256       ['conv2d_7[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " re_lu_7 (ReLU)              (None, 50, 50, 64)           0         ['batch_normalization_7[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " input_1 (InputLayer)        [(None, 100, 100, 3)]        0         []                            \n",
            "                                                                                                  \n",
            " max_pooling2d_3 (MaxPoolin  (None, 25, 25, 64)           0         ['re_lu_7[0][0]']             \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)             (None, 100, 100, 64)         1792      ['input_1[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_8 (Conv2D)           (None, 25, 25, 256)          147712    ['max_pooling2d_3[0][0]']     \n",
            "                                                                                                  \n",
            " batch_normalization (Batch  (None, 100, 100, 64)         256       ['conv2d[0][0]']              \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " batch_normalization_8 (Bat  (None, 25, 25, 256)          1024      ['conv2d_8[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " re_lu (ReLU)                (None, 100, 100, 64)         0         ['batch_normalization[0][0]'] \n",
            "                                                                                                  \n",
            " re_lu_8 (ReLU)              (None, 25, 25, 256)          0         ['batch_normalization_8[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)           (None, 100, 100, 64)         36928     ['re_lu[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_9 (Conv2D)           (None, 25, 25, 256)          590080    ['re_lu_8[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_1 (Bat  (None, 100, 100, 64)         256       ['conv2d_1[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_9 (Bat  (None, 25, 25, 256)          1024      ['conv2d_9[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " re_lu_1 (ReLU)              (None, 100, 100, 64)         0         ['batch_normalization_1[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " re_lu_9 (ReLU)              (None, 25, 25, 256)          0         ['batch_normalization_9[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " conv2d_10 (Conv2D)          (None, 25, 25, 256)          16640     ['max_pooling2d_3[0][0]']     \n",
            "                                                                                                  \n",
            " max_pooling2d (MaxPooling2  (None, 50, 50, 64)           0         ['re_lu_1[0][0]']             \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " add (Add)                   (None, 25, 25, 256)          0         ['re_lu_9[0][0]',             \n",
            "                                                                     'conv2d_10[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)           (None, 50, 50, 128)          73856     ['max_pooling2d[0][0]']       \n",
            "                                                                                                  \n",
            " re_lu_10 (ReLU)             (None, 25, 25, 256)          0         ['add[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_2 (Bat  (None, 50, 50, 128)          512       ['conv2d_2[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " conv2d_11 (Conv2D)          (None, 25, 25, 256)          590080    ['re_lu_10[0][0]']            \n",
            "                                                                                                  \n",
            " re_lu_2 (ReLU)              (None, 50, 50, 128)          0         ['batch_normalization_2[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " batch_normalization_10 (Ba  (None, 25, 25, 256)          1024      ['conv2d_11[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " conv2d_3 (Conv2D)           (None, 50, 50, 128)          147584    ['re_lu_2[0][0]']             \n",
            "                                                                                                  \n",
            " re_lu_11 (ReLU)             (None, 25, 25, 256)          0         ['batch_normalization_10[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " batch_normalization_3 (Bat  (None, 50, 50, 128)          512       ['conv2d_3[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " conv2d_12 (Conv2D)          (None, 25, 25, 256)          590080    ['re_lu_11[0][0]']            \n",
            "                                                                                                  \n",
            " re_lu_3 (ReLU)              (None, 50, 50, 128)          0         ['batch_normalization_3[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " batch_normalization_11 (Ba  (None, 25, 25, 256)          1024      ['conv2d_12[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " max_pooling2d_1 (MaxPoolin  (None, 25, 25, 128)          0         ['re_lu_3[0][0]']             \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " re_lu_12 (ReLU)             (None, 25, 25, 256)          0         ['batch_normalization_11[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_13 (Conv2D)          (None, 25, 25, 256)          65792     ['re_lu_10[0][0]']            \n",
            "                                                                                                  \n",
            " conv2d_4 (Conv2D)           (None, 25, 25, 256)          295168    ['max_pooling2d_1[0][0]']     \n",
            "                                                                                                  \n",
            " add_1 (Add)                 (None, 25, 25, 256)          0         ['re_lu_12[0][0]',            \n",
            "                                                                     'conv2d_13[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_4 (Bat  (None, 25, 25, 256)          1024      ['conv2d_4[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " re_lu_13 (ReLU)             (None, 25, 25, 256)          0         ['add_1[0][0]']               \n",
            "                                                                                                  \n",
            " re_lu_4 (ReLU)              (None, 25, 25, 256)          0         ['batch_normalization_4[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " conv2d_14 (Conv2D)          (None, 25, 25, 256)          590080    ['re_lu_13[0][0]']            \n",
            "                                                                                                  \n",
            " conv2d_5 (Conv2D)           (None, 25, 25, 256)          590080    ['re_lu_4[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_12 (Ba  (None, 25, 25, 256)          1024      ['conv2d_14[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_5 (Bat  (None, 25, 25, 256)          1024      ['conv2d_5[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " re_lu_14 (ReLU)             (None, 25, 25, 256)          0         ['batch_normalization_12[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " re_lu_5 (ReLU)              (None, 25, 25, 256)          0         ['batch_normalization_5[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " conv2d_15 (Conv2D)          (None, 25, 25, 256)          590080    ['re_lu_14[0][0]']            \n",
            "                                                                                                  \n",
            " conv2d_6 (Conv2D)           (None, 25, 25, 256)          590080    ['re_lu_5[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_13 (Ba  (None, 25, 25, 256)          1024      ['conv2d_15[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_6 (Bat  (None, 25, 25, 256)          1024      ['conv2d_6[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " re_lu_15 (ReLU)             (None, 25, 25, 256)          0         ['batch_normalization_13[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_16 (Conv2D)          (None, 25, 25, 256)          65792     ['re_lu_13[0][0]']            \n",
            "                                                                                                  \n",
            " re_lu_6 (ReLU)              (None, 25, 25, 256)          0         ['batch_normalization_6[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " add_2 (Add)                 (None, 25, 25, 256)          0         ['re_lu_15[0][0]',            \n",
            "                                                                     'conv2d_16[0][0]']           \n",
            "                                                                                                  \n",
            " max_pooling2d_2 (MaxPoolin  (None, 12, 12, 256)          0         ['re_lu_6[0][0]']             \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " re_lu_16 (ReLU)             (None, 25, 25, 256)          0         ['add_2[0][0]']               \n",
            "                                                                                                  \n",
            " global_average_pooling2d (  (None, 256)                  0         ['max_pooling2d_2[0][0]']     \n",
            " GlobalAveragePooling2D)                                                                          \n",
            "                                                                                                  \n",
            " global_average_pooling2d_1  (None, 256)                  0         ['re_lu_16[0][0]']            \n",
            "  (GlobalAveragePooling2D)                                                                        \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)   (None, 512)                  0         ['global_average_pooling2d[0][\n",
            "                                                                    0]',                          \n",
            "                                                                     'global_average_pooling2d_1[0\n",
            "                                                                    ][0]']                        \n",
            "                                                                                                  \n",
            " dense (Dense)               (None, 256)                  131328    ['concatenate[0][0]']         \n",
            "                                                                                                  \n",
            " dense_1 (Dense)             (None, 128)                  32896     ['dense[0][0]']               \n",
            "                                                                                                  \n",
            " dense_2 (Dense)             (None, 2)                    258       ['dense_1[0][0]']             \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 5166786 (19.71 MB)\n",
            "Trainable params: 5161282 (19.69 MB)\n",
            "Non-trainable params: 5504 (21.50 KB)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "\n",
        "# Set the learning rate\n",
        "learning_rate = 0.00001\n",
        "\n",
        "# Compile the model with the specified learning rate\n",
        "hybrid_model.compile(optimizer=Adam(learning_rate=learning_rate),\n",
        "                     loss='categorical_crossentropy',\n",
        "                     metrics=['accuracy'])\n",
        "\n",
        "# Train the hybrid model\n",
        "history = hybrid_model.fit(\n",
        "    [x_train_normalized, x_train_normalized],  # Replace with your training data\n",
        "    y_train_encoded,  # Replace with your training labels\n",
        "    epochs=55,\n",
        "    batch_size=batch_size,\n",
        "    validation_data=([x_val_normalized, x_val_normalized], y_val_encoded),  # Replace with your validation data\n",
        "    shuffle=True,\n",
        "    verbose=1,\n",
        "\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K9Lo3wUroRd7",
        "outputId": "5730b2a0-614b-4c5a-eaa7-19c62bd58aee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/55\n",
            "54/54 [==============================] - 53s 469ms/step - loss: 0.3924 - accuracy: 0.8226 - val_loss: 0.6910 - val_accuracy: 0.4878\n",
            "Epoch 2/55\n",
            "54/54 [==============================] - 17s 310ms/step - loss: 0.2764 - accuracy: 0.8914 - val_loss: 0.7274 - val_accuracy: 0.4878\n",
            "Epoch 3/55\n",
            "54/54 [==============================] - 17s 322ms/step - loss: 0.2350 - accuracy: 0.9091 - val_loss: 0.8940 - val_accuracy: 0.4878\n",
            "Epoch 4/55\n",
            "54/54 [==============================] - 17s 316ms/step - loss: 0.2189 - accuracy: 0.9143 - val_loss: 0.9955 - val_accuracy: 0.4878\n",
            "Epoch 5/55\n",
            "54/54 [==============================] - 18s 329ms/step - loss: 0.2033 - accuracy: 0.9161 - val_loss: 1.1999 - val_accuracy: 0.4898\n",
            "Epoch 6/55\n",
            "54/54 [==============================] - 18s 329ms/step - loss: 0.1899 - accuracy: 0.9283 - val_loss: 1.0818 - val_accuracy: 0.5366\n",
            "Epoch 7/55\n",
            "54/54 [==============================] - 17s 322ms/step - loss: 0.1832 - accuracy: 0.9262 - val_loss: 0.8260 - val_accuracy: 0.6118\n",
            "Epoch 8/55\n",
            "54/54 [==============================] - 18s 333ms/step - loss: 0.1825 - accuracy: 0.9268 - val_loss: 0.5416 - val_accuracy: 0.7297\n",
            "Epoch 9/55\n",
            "54/54 [==============================] - 18s 326ms/step - loss: 0.1682 - accuracy: 0.9312 - val_loss: 0.3534 - val_accuracy: 0.8455\n",
            "Epoch 10/55\n",
            "54/54 [==============================] - 18s 336ms/step - loss: 0.1576 - accuracy: 0.9376 - val_loss: 0.2895 - val_accuracy: 0.8780\n",
            "Epoch 11/55\n",
            "54/54 [==============================] - 18s 328ms/step - loss: 0.1590 - accuracy: 0.9367 - val_loss: 0.2742 - val_accuracy: 0.8923\n",
            "Epoch 12/55\n",
            "54/54 [==============================] - 18s 339ms/step - loss: 0.1568 - accuracy: 0.9393 - val_loss: 0.2099 - val_accuracy: 0.9045\n",
            "Epoch 13/55\n",
            "54/54 [==============================] - 18s 339ms/step - loss: 0.1485 - accuracy: 0.9460 - val_loss: 0.2444 - val_accuracy: 0.9085\n",
            "Epoch 14/55\n",
            "54/54 [==============================] - 18s 331ms/step - loss: 0.1514 - accuracy: 0.9437 - val_loss: 0.2178 - val_accuracy: 0.9146\n",
            "Epoch 15/55\n",
            "54/54 [==============================] - 18s 331ms/step - loss: 0.1416 - accuracy: 0.9460 - val_loss: 0.1981 - val_accuracy: 0.9106\n",
            "Epoch 16/55\n",
            "54/54 [==============================] - 18s 341ms/step - loss: 0.1430 - accuracy: 0.9440 - val_loss: 0.2137 - val_accuracy: 0.9106\n",
            "Epoch 17/55\n",
            "54/54 [==============================] - 18s 334ms/step - loss: 0.1436 - accuracy: 0.9411 - val_loss: 0.2633 - val_accuracy: 0.9085\n",
            "Epoch 18/55\n",
            "54/54 [==============================] - 18s 342ms/step - loss: 0.1351 - accuracy: 0.9474 - val_loss: 0.1957 - val_accuracy: 0.9167\n",
            "Epoch 19/55\n",
            "54/54 [==============================] - 18s 335ms/step - loss: 0.1290 - accuracy: 0.9483 - val_loss: 0.2418 - val_accuracy: 0.9228\n",
            "Epoch 20/55\n",
            "54/54 [==============================] - 19s 345ms/step - loss: 0.1347 - accuracy: 0.9512 - val_loss: 0.2051 - val_accuracy: 0.9187\n",
            "Epoch 21/55\n",
            "54/54 [==============================] - 19s 346ms/step - loss: 0.1255 - accuracy: 0.9521 - val_loss: 0.2088 - val_accuracy: 0.9106\n",
            "Epoch 22/55\n",
            "54/54 [==============================] - 18s 336ms/step - loss: 0.1228 - accuracy: 0.9515 - val_loss: 0.1913 - val_accuracy: 0.9126\n",
            "Epoch 23/55\n",
            "54/54 [==============================] - 19s 346ms/step - loss: 0.1201 - accuracy: 0.9544 - val_loss: 0.1940 - val_accuracy: 0.9228\n",
            "Epoch 24/55\n",
            "54/54 [==============================] - 18s 337ms/step - loss: 0.1195 - accuracy: 0.9567 - val_loss: 0.2265 - val_accuracy: 0.9207\n",
            "Epoch 25/55\n",
            "54/54 [==============================] - 19s 346ms/step - loss: 0.1185 - accuracy: 0.9567 - val_loss: 0.2049 - val_accuracy: 0.9207\n",
            "Epoch 26/55\n",
            "54/54 [==============================] - 19s 346ms/step - loss: 0.1097 - accuracy: 0.9588 - val_loss: 0.1991 - val_accuracy: 0.9207\n",
            "Epoch 27/55\n",
            "54/54 [==============================] - 18s 337ms/step - loss: 0.1122 - accuracy: 0.9614 - val_loss: 0.2152 - val_accuracy: 0.9085\n",
            "Epoch 28/55\n",
            "54/54 [==============================] - 18s 338ms/step - loss: 0.1050 - accuracy: 0.9596 - val_loss: 0.1969 - val_accuracy: 0.9228\n",
            "Epoch 29/55\n",
            "54/54 [==============================] - 19s 348ms/step - loss: 0.1074 - accuracy: 0.9634 - val_loss: 0.2126 - val_accuracy: 0.9228\n",
            "Epoch 30/55\n",
            "54/54 [==============================] - 19s 348ms/step - loss: 0.1040 - accuracy: 0.9605 - val_loss: 0.2108 - val_accuracy: 0.9187\n",
            "Epoch 31/55\n",
            "54/54 [==============================] - 19s 348ms/step - loss: 0.1001 - accuracy: 0.9617 - val_loss: 0.2497 - val_accuracy: 0.9187\n",
            "Epoch 32/55\n",
            "54/54 [==============================] - 18s 339ms/step - loss: 0.1043 - accuracy: 0.9585 - val_loss: 0.2239 - val_accuracy: 0.9248\n",
            "Epoch 33/55\n",
            "54/54 [==============================] - 19s 349ms/step - loss: 0.0931 - accuracy: 0.9672 - val_loss: 0.2482 - val_accuracy: 0.9146\n",
            "Epoch 34/55\n",
            "54/54 [==============================] - 19s 349ms/step - loss: 0.0923 - accuracy: 0.9628 - val_loss: 0.1989 - val_accuracy: 0.9248\n",
            "Epoch 35/55\n",
            "54/54 [==============================] - 19s 349ms/step - loss: 0.0884 - accuracy: 0.9672 - val_loss: 0.2105 - val_accuracy: 0.9289\n",
            "Epoch 36/55\n",
            "54/54 [==============================] - 19s 348ms/step - loss: 0.0920 - accuracy: 0.9634 - val_loss: 0.2158 - val_accuracy: 0.9228\n",
            "Epoch 37/55\n",
            "54/54 [==============================] - 19s 349ms/step - loss: 0.0894 - accuracy: 0.9692 - val_loss: 0.3175 - val_accuracy: 0.8882\n",
            "Epoch 38/55\n",
            "54/54 [==============================] - 19s 348ms/step - loss: 0.0898 - accuracy: 0.9669 - val_loss: 0.2099 - val_accuracy: 0.9126\n",
            "Epoch 39/55\n",
            "54/54 [==============================] - 18s 341ms/step - loss: 0.0826 - accuracy: 0.9718 - val_loss: 0.1985 - val_accuracy: 0.9248\n",
            "Epoch 40/55\n",
            "54/54 [==============================] - 19s 348ms/step - loss: 0.0838 - accuracy: 0.9689 - val_loss: 0.2170 - val_accuracy: 0.9248\n",
            "Epoch 41/55\n",
            "54/54 [==============================] - 19s 349ms/step - loss: 0.0752 - accuracy: 0.9750 - val_loss: 0.2450 - val_accuracy: 0.9146\n",
            "Epoch 42/55\n",
            "54/54 [==============================] - 18s 339ms/step - loss: 0.0776 - accuracy: 0.9733 - val_loss: 0.2159 - val_accuracy: 0.9228\n",
            "Epoch 43/55\n",
            "54/54 [==============================] - 19s 348ms/step - loss: 0.0764 - accuracy: 0.9739 - val_loss: 0.2211 - val_accuracy: 0.9045\n",
            "Epoch 44/55\n",
            "54/54 [==============================] - 18s 339ms/step - loss: 0.0748 - accuracy: 0.9715 - val_loss: 0.2656 - val_accuracy: 0.9187\n",
            "Epoch 45/55\n",
            "54/54 [==============================] - 19s 348ms/step - loss: 0.0754 - accuracy: 0.9736 - val_loss: 0.2851 - val_accuracy: 0.9106\n",
            "Epoch 46/55\n",
            "54/54 [==============================] - 18s 339ms/step - loss: 0.0707 - accuracy: 0.9747 - val_loss: 0.2327 - val_accuracy: 0.9167\n",
            "Epoch 47/55\n",
            "54/54 [==============================] - 18s 339ms/step - loss: 0.0639 - accuracy: 0.9765 - val_loss: 0.2240 - val_accuracy: 0.9268\n",
            "Epoch 48/55\n",
            "54/54 [==============================] - 19s 349ms/step - loss: 0.0673 - accuracy: 0.9765 - val_loss: 0.2015 - val_accuracy: 0.9228\n",
            "Epoch 49/55\n",
            "54/54 [==============================] - 19s 348ms/step - loss: 0.0666 - accuracy: 0.9768 - val_loss: 0.2220 - val_accuracy: 0.9248\n",
            "Epoch 50/55\n",
            "54/54 [==============================] - 18s 341ms/step - loss: 0.0603 - accuracy: 0.9785 - val_loss: 0.3409 - val_accuracy: 0.8963\n",
            "Epoch 51/55\n",
            "54/54 [==============================] - 19s 349ms/step - loss: 0.0658 - accuracy: 0.9765 - val_loss: 0.2257 - val_accuracy: 0.9228\n",
            "Epoch 52/55\n",
            "54/54 [==============================] - 19s 350ms/step - loss: 0.0562 - accuracy: 0.9820 - val_loss: 0.2385 - val_accuracy: 0.9167\n",
            "Epoch 53/55\n",
            "54/54 [==============================] - 18s 340ms/step - loss: 0.0564 - accuracy: 0.9800 - val_loss: 0.2433 - val_accuracy: 0.9268\n",
            "Epoch 54/55\n",
            "54/54 [==============================] - 18s 340ms/step - loss: 0.0535 - accuracy: 0.9840 - val_loss: 0.3070 - val_accuracy: 0.9126\n",
            "Epoch 55/55\n",
            "54/54 [==============================] - 18s 340ms/step - loss: 0.0528 - accuracy: 0.9823 - val_loss: 0.2336 - val_accuracy: 0.9248\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on the test data\n",
        "test_loss, test_accuracy = hybrid_model.evaluate([x_test_normalized, x_test_normalized], y_test_encoded)\n",
        "\n",
        "print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")\n",
        "print(f\"Test Loss: {test_loss}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dqWdJmDoq424",
        "outputId": "5432a027-69a1-4fcc-c625-b7a98f2fbef4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "31/31 [==============================] - 5s 114ms/step - loss: 0.2093 - accuracy: 0.9299\n",
            "Test Accuracy: 92.99%\n",
            "Test Loss: 0.2093406468629837\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Assuming you have your hybrid model already trained and stored in hybrid_model_regularized\n",
        "\n",
        "# Extract features from the hybrid model for training, validation, and test sets\n",
        "x_train_features = hybrid_model.predict([x_train_normalized, x_train_normalized])\n",
        "x_val_features = hybrid_model.predict([x_val_normalized, x_val_normalized])\n",
        "x_test_features = hybrid_model.predict([x_test_normalized, x_test_normalized])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_jzT1lNtrEPW",
        "outputId": "ddfc554f-b8bc-448e-c935-453c9b0e1c27"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "108/108 [==============================] - 7s 62ms/step\n",
            "16/16 [==============================] - 2s 110ms/step\n",
            "31/31 [==============================] - 2s 54ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_features = x_train_features.reshape(x_train_features.shape[0], -1)\n",
        "x_val_features = x_val_features.reshape(x_val_features.shape[0], -1)\n",
        "x_test_features = x_test_features.reshape(x_test_features.shape[0], -1)"
      ],
      "metadata": {
        "id": "VeMNUQTfrKUN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "\n",
        "# Assuming you have x_train_features, x_test_features, y_train, and y_test\n",
        "\n",
        "# Define the regularization parameter\n",
        "regularization_param = 0.1  # Adjust this value as needed\n",
        "\n",
        "# Train SVM model with regularization\n",
        "svm_model_reg = SVC(kernel='rbf', C=regularization_param, gamma='scale')\n",
        "svm_model_reg.fit(x_train_features, y_train)\n",
        "\n",
        "# Predict on the test set using the trained SVM model with regularization\n",
        "y_pred_svm_reg = svm_model_reg.predict(x_test_features)\n",
        "\n",
        "# Calculate evaluation metrics for the regularized SVM model\n",
        "svm_accuracy_reg = accuracy_score(y_test, y_pred_svm_reg)\n",
        "svm_precision_reg = precision_score(y_test, y_pred_svm_reg)\n",
        "svm_recall_reg = recall_score(y_test, y_pred_svm_reg)\n",
        "svm_f1_reg = f1_score(y_test, y_pred_svm_reg)\n",
        "\n",
        "# Calculate specificity for the regularized SVM model\n",
        "tn_reg, fp_reg, fn_reg, tp_reg = confusion_matrix(y_test, y_pred_svm_reg).ravel()\n",
        "svm_specificity_reg = tn_reg / (tn_reg + fp_reg)\n",
        "\n",
        "# Print evaluation metrics for the regularized SVM model\n",
        "print(\"Regularized SVM Accuracy:\", svm_accuracy_reg)\n",
        "print(\"Regularized SVM Precision:\", svm_precision_reg)\n",
        "print(\"Regularized SVM Sensitivity (Recall):\", svm_recall_reg)\n",
        "print(\"Regularized SVM Specificity:\", svm_specificity_reg)\n",
        "print(\"Regularized SVM F1 Score:\", svm_f1_reg)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dnXImNjZASRn",
        "outputId": "62710aac-953d-4c45-d193-5a21a8c4ea4c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Regularized SVM Accuracy: 0.9329268292682927\n",
            "Regularized SVM Precision: 0.9556451612903226\n",
            "Regularized SVM Sensitivity (Recall): 0.915057915057915\n",
            "Regularized SVM Specificity: 0.9527896995708155\n",
            "Regularized SVM F1 Score: 0.9349112426035502\n"
          ]
        }
      ]
    }
  ]
}