{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5UUigs334DGK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39c66792-dfa4-4f64-9e97-36a4be9e39d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "mX_icLuc4K9X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = '/content/drive/MyDrive/Thesis (Skin-Cancer)'"
      ],
      "metadata": {
        "id": "0hsB3pha4M5J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "data_dir = \"/content/drive/MyDrive/Thesis (Skin-Cancer)\"\n",
        "image_size = (100, 100)\n",
        "\n",
        "images = []\n",
        "labels = []\n",
        "\n",
        "label_mapping = {'benign': 0, 'malignant': 1}\n",
        "\n",
        "for class_name in os.listdir(data_dir):\n",
        "    class_dir = os.path.join(data_dir, class_name)\n",
        "    if os.path.isdir(class_dir):\n",
        "        for image_filename in os.listdir(class_dir):\n",
        "            image_path = os.path.join(class_dir, image_filename)\n",
        "            # Open and resize the image\n",
        "            image = Image.open(image_path)\n",
        "            image = image.resize(image_size)\n",
        "            image = np.array(image)\n",
        "            images.append(image)\n",
        "            labels.append(label_mapping[class_name])\n",
        "\n",
        "# Convert lists to numpy arrays\n",
        "images = np.array(images)\n",
        "labels = np.array(labels)\n"
      ],
      "metadata": {
        "id": "nrB2djVH4OwT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.125, random_state=42)"
      ],
      "metadata": {
        "id": "x_F_im3z4RPg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Shape of X_train: \", X_train.shape)\n",
        "print(\"Shape of y_train: \", y_train.shape)\n",
        "print(\"Shape of X_test: \", X_test.shape)\n",
        "print(\"Shape of y_test: \", y_test.shape)\n",
        "print(\"Shape of X_val: \", X_val.shape)\n",
        "print(\"Shape of y_val: \", y_val.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y8EH2zMk4Sv_",
        "outputId": "8e27abf7-5f49-44af-c131-3509aeab989e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of X_train:  (2317, 100, 100, 3)\n",
            "Shape of y_train:  (2317,)\n",
            "Shape of X_test:  (663, 100, 100, 3)\n",
            "Shape of y_test:  (663,)\n",
            "Shape of X_val:  (331, 100, 100, 3)\n",
            "Shape of y_val:  (331,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(_, IMAGE_WIDTH, IMAGE_HEIGHT, IMAGE_CHANNELS) = X_train.shape\n",
        "\n",
        "print('IMAGE_WIDTH:', IMAGE_WIDTH);\n",
        "print('IMAGE_HEIGHT:', IMAGE_HEIGHT);\n",
        "print('IMAGE_CHANNELS:', IMAGE_CHANNELS);"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pJ4EwfuT4UVN",
        "outputId": "4cb8696a-23d2-4dbd-86e4-9578d09be90a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IMAGE_WIDTH: 100\n",
            "IMAGE_HEIGHT: 100\n",
            "IMAGE_CHANNELS: 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#4. Reshape the data\n",
        "x_train_with_chanels = X_train.reshape(\n",
        "    X_train.shape[0],\n",
        "    IMAGE_WIDTH,\n",
        "    IMAGE_HEIGHT,\n",
        "    IMAGE_CHANNELS\n",
        ")\n",
        "\n",
        "x_test_with_chanels = X_test.reshape(\n",
        "    X_test.shape[0],\n",
        "    IMAGE_WIDTH,\n",
        "    IMAGE_HEIGHT,\n",
        "    IMAGE_CHANNELS\n",
        ")\n",
        "\n",
        "x_val_with_chanels = X_val.reshape(\n",
        "    X_val.shape[0],\n",
        "    IMAGE_WIDTH,\n",
        "    IMAGE_HEIGHT,\n",
        "    IMAGE_CHANNELS\n",
        ")"
      ],
      "metadata": {
        "id": "wUMgmOOY4WA_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('x_train_with_chanels:', x_train_with_chanels.shape)\n",
        "print('x_test_with_chanels:', x_test_with_chanels.shape)\n",
        "print('x_val_with_chanels:', x_val_with_chanels.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SdbF3WKN4Ws9",
        "outputId": "54ea0d8a-21b4-44a0-f173-2b617eed80c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_train_with_chanels: (2317, 100, 100, 3)\n",
            "x_test_with_chanels: (663, 100, 100, 3)\n",
            "x_val_with_chanels: (331, 100, 100, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#5. Normalize the data\n",
        "x_train_normalized = x_train_with_chanels / 255\n",
        "x_test_normalized = x_test_with_chanels / 255\n",
        "x_val_normalized = x_val_with_chanels / 255"
      ],
      "metadata": {
        "id": "5xgrn6bM4X10"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_normalized[0][18]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E2m15bpj4cSN",
        "outputId": "3807d1b2-0406-484f-f5d0-a2d624d2b0f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.82745098, 0.54509804, 0.62352941],\n",
              "       [0.83921569, 0.55686275, 0.63529412],\n",
              "       [0.83137255, 0.54901961, 0.62745098],\n",
              "       [0.83921569, 0.55686275, 0.63529412],\n",
              "       [0.84313725, 0.56078431, 0.63921569],\n",
              "       [0.82352941, 0.54117647, 0.61960784],\n",
              "       [0.81960784, 0.5372549 , 0.61568627],\n",
              "       [0.83529412, 0.54901961, 0.64313725],\n",
              "       [0.82745098, 0.5372549 , 0.63921569],\n",
              "       [0.81568627, 0.5254902 , 0.62352941],\n",
              "       [0.81176471, 0.52156863, 0.61960784],\n",
              "       [0.81960784, 0.52941176, 0.62745098],\n",
              "       [0.82745098, 0.5372549 , 0.63529412],\n",
              "       [0.83921569, 0.54901961, 0.65098039],\n",
              "       [0.84705882, 0.56078431, 0.65098039],\n",
              "       [0.83921569, 0.55686275, 0.64313725],\n",
              "       [0.83921569, 0.55686275, 0.64313725],\n",
              "       [0.84313725, 0.56078431, 0.64705882],\n",
              "       [0.84705882, 0.56470588, 0.65098039],\n",
              "       [0.84313725, 0.56078431, 0.64705882],\n",
              "       [0.83137255, 0.55294118, 0.63529412],\n",
              "       [0.84313725, 0.55686275, 0.64705882],\n",
              "       [0.85098039, 0.56078431, 0.65882353],\n",
              "       [0.83137255, 0.54117647, 0.63921569],\n",
              "       [0.82352941, 0.54117647, 0.63529412],\n",
              "       [0.83529412, 0.56078431, 0.65490196],\n",
              "       [0.84705882, 0.57254902, 0.66666667],\n",
              "       [0.83529412, 0.56862745, 0.65882353],\n",
              "       [0.82745098, 0.56862745, 0.65490196],\n",
              "       [0.83137255, 0.58039216, 0.66666667],\n",
              "       [0.84705882, 0.58431373, 0.6745098 ],\n",
              "       [0.83529412, 0.56862745, 0.65490196],\n",
              "       [0.83137255, 0.56078431, 0.63921569],\n",
              "       [0.82745098, 0.54901961, 0.62745098],\n",
              "       [0.81176471, 0.52941176, 0.60784314],\n",
              "       [0.81176471, 0.52941176, 0.59607843],\n",
              "       [0.80784314, 0.51764706, 0.58039216],\n",
              "       [0.79607843, 0.50588235, 0.57647059],\n",
              "       [0.80392157, 0.50588235, 0.57254902],\n",
              "       [0.8       , 0.48627451, 0.55294118],\n",
              "       [0.78039216, 0.44313725, 0.50196078],\n",
              "       [0.76862745, 0.40784314, 0.45098039],\n",
              "       [0.75686275, 0.38823529, 0.41176471],\n",
              "       [0.75294118, 0.39215686, 0.40392157],\n",
              "       [0.7372549 , 0.37647059, 0.38431373],\n",
              "       [0.73333333, 0.36862745, 0.37254902],\n",
              "       [0.7372549 , 0.36470588, 0.36862745],\n",
              "       [0.7372549 , 0.36862745, 0.36470588],\n",
              "       [0.7372549 , 0.36862745, 0.36078431],\n",
              "       [0.73333333, 0.36470588, 0.35686275],\n",
              "       [0.72941176, 0.35686275, 0.35686275],\n",
              "       [0.74117647, 0.36862745, 0.36078431],\n",
              "       [0.72941176, 0.36470588, 0.34509804],\n",
              "       [0.72941176, 0.37254902, 0.34509804],\n",
              "       [0.74117647, 0.38431373, 0.37254902],\n",
              "       [0.76078431, 0.40392157, 0.40784314],\n",
              "       [0.78039216, 0.42745098, 0.44705882],\n",
              "       [0.77647059, 0.44705882, 0.46666667],\n",
              "       [0.79215686, 0.47058824, 0.49803922],\n",
              "       [0.81960784, 0.50196078, 0.53333333],\n",
              "       [0.82745098, 0.52156863, 0.56078431],\n",
              "       [0.81960784, 0.53333333, 0.58039216],\n",
              "       [0.83529412, 0.55294118, 0.60784314],\n",
              "       [0.85098039, 0.57254902, 0.63529412],\n",
              "       [0.8627451 , 0.58431373, 0.64705882],\n",
              "       [0.86666667, 0.58823529, 0.65098039],\n",
              "       [0.8627451 , 0.58431373, 0.65098039],\n",
              "       [0.85098039, 0.58039216, 0.65098039],\n",
              "       [0.84313725, 0.58039216, 0.65098039],\n",
              "       [0.85098039, 0.59215686, 0.6627451 ],\n",
              "       [0.87058824, 0.61960784, 0.69411765],\n",
              "       [0.88235294, 0.62352941, 0.70196078],\n",
              "       [0.8745098 , 0.60784314, 0.69019608],\n",
              "       [0.87058824, 0.60392157, 0.68627451],\n",
              "       [0.87843137, 0.61176471, 0.69411765],\n",
              "       [0.87843137, 0.61176471, 0.69411765],\n",
              "       [0.8627451 , 0.59607843, 0.67843137],\n",
              "       [0.8745098 , 0.60784314, 0.69019608],\n",
              "       [0.88235294, 0.61568627, 0.69411765],\n",
              "       [0.85490196, 0.58431373, 0.65882353],\n",
              "       [0.85882353, 0.58823529, 0.6627451 ],\n",
              "       [0.87843137, 0.60784314, 0.68235294],\n",
              "       [0.88235294, 0.61176471, 0.68627451],\n",
              "       [0.89019608, 0.61960784, 0.69411765],\n",
              "       [0.89803922, 0.62745098, 0.70196078],\n",
              "       [0.89803922, 0.62745098, 0.70196078],\n",
              "       [0.89411765, 0.63137255, 0.69803922],\n",
              "       [0.90196078, 0.63921569, 0.70588235],\n",
              "       [0.89019608, 0.62745098, 0.69411765],\n",
              "       [0.87058824, 0.60784314, 0.6745098 ],\n",
              "       [0.85882353, 0.59607843, 0.6627451 ],\n",
              "       [0.88627451, 0.62352941, 0.69019608],\n",
              "       [0.87843137, 0.61568627, 0.68235294],\n",
              "       [0.88235294, 0.61960784, 0.69019608],\n",
              "       [0.87843137, 0.61568627, 0.68627451],\n",
              "       [0.87058824, 0.60784314, 0.67843137],\n",
              "       [0.87843137, 0.61568627, 0.68627451],\n",
              "       [0.87058824, 0.60784314, 0.67843137],\n",
              "       [0.85098039, 0.58823529, 0.65882353],\n",
              "       [0.83529412, 0.57254902, 0.64313725]])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "y_train_encoded = to_categorical(y_train, num_classes=2)\n",
        "y_test_encoded = to_categorical(y_test, num_classes=2)\n",
        "y_val_encoded = to_categorical(y_val, num_classes=2)"
      ],
      "metadata": {
        "id": "Fi9w46LH4er5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 64\n",
        "\n",
        "# Data augmentation for the training set\n",
        "train_DataGen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "\n",
        "    rotation_range=40,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "# Data generator for the validation set (no augmentation)\n",
        "valid_datagen = tf.keras.preprocessing.image.ImageDataGenerator()\n",
        "\n",
        "# Data generator for the test set (no augmentation)\n",
        "test_datagen = tf.keras.preprocessing.image.ImageDataGenerator()\n",
        "\n",
        "# Create data generators\n",
        "train_set_conv = train_DataGen.flow(x_train_normalized, y_train_encoded, batch_size=batch_size)\n",
        "valid_set_conv = valid_datagen.flow(x_val_normalized, y_val_encoded, batch_size=batch_size)\n",
        "test_set_conv = test_datagen.flow(x_test_normalized, y_test_encoded, batch_size=batch_size)"
      ],
      "metadata": {
        "id": "RRXCEgUB4jAI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, ZeroPadding2D,\\\n",
        "     Flatten, BatchNormalization, AveragePooling2D, Dense, Activation, Add\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras import activations\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.regularizers import l2"
      ],
      "metadata": {
        "id": "lrOkMyFw4gEY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "# Define the CNN model\n",
        "model = models.Sequential()\n",
        "\n",
        "# Convolutional Layer 1\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(IMAGE_WIDTH, IMAGE_HEIGHT, IMAGE_CHANNELS)))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "# Convolutional Layer 2\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "# Convolutional Layer 3\n",
        "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "# Flatten the output for the fully connected layers\n",
        "model.add(layers.Flatten())\n",
        "\n",
        "# Fully Connected Layer 1\n",
        "model.add(layers.Dense(128, activation='relu'))\n",
        "\n",
        "# Output Layer\n",
        "model.add(layers.Dense(10, activation='softmax'))  # Assuming 10 classes\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Print the model summary\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "ahb8RfAA4xbD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "568f31c6-3779-4679-8dc0-d12642450a16"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_3 (Conv2D)           (None, 98, 98, 32)        896       \n",
            "                                                                 \n",
            " max_pooling2d_4 (MaxPoolin  (None, 49, 49, 32)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 47, 47, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_5 (MaxPoolin  (None, 23, 23, 64)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 21, 21, 128)       73856     \n",
            "                                                                 \n",
            " max_pooling2d_6 (MaxPoolin  (None, 10, 10, 128)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_2 (Flatten)         (None, 12800)             0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 128)               1638528   \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1733066 (6.61 MB)\n",
            "Trainable params: 1733066 (6.61 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the model to the data\n",
        "history = model.fit(train_set_conv,\n",
        "                    steps_per_epoch=len(x_train_normalized) // batch_size,\n",
        "                    epochs=10,  # You can adjust the number of epochs\n",
        "                    validation_data=valid_set_conv,\n",
        "                    validation_steps=len(x_val_normalized) // batch_size)\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "test_loss, test_accuracy = model.evaluate(test_set_conv)\n",
        "print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zpJxG0Tu41v6",
        "outputId": "9666d11e-adcf-4a72-ff69-ae7f009b2870"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "36/36 [==============================] - 8s 169ms/step - loss: 0.7968 - accuracy: 0.5180 - val_loss: 0.8303 - val_accuracy: 0.5125\n",
            "Epoch 2/10\n",
            "36/36 [==============================] - 8s 205ms/step - loss: 0.6549 - accuracy: 0.6525 - val_loss: 0.5345 - val_accuracy: 0.7844\n",
            "Epoch 3/10\n",
            "36/36 [==============================] - 6s 156ms/step - loss: 0.5072 - accuracy: 0.7395 - val_loss: 0.4557 - val_accuracy: 0.7406\n",
            "Epoch 4/10\n",
            "36/36 [==============================] - 7s 208ms/step - loss: 0.4730 - accuracy: 0.7581 - val_loss: 0.5105 - val_accuracy: 0.7688\n",
            "Epoch 5/10\n",
            "36/36 [==============================] - 6s 154ms/step - loss: 0.4506 - accuracy: 0.7776 - val_loss: 0.3771 - val_accuracy: 0.7875\n",
            "Epoch 6/10\n",
            "36/36 [==============================] - 8s 214ms/step - loss: 0.4664 - accuracy: 0.7612 - val_loss: 0.3761 - val_accuracy: 0.8094\n",
            "Epoch 7/10\n",
            "36/36 [==============================] - 6s 154ms/step - loss: 0.4392 - accuracy: 0.7772 - val_loss: 0.3797 - val_accuracy: 0.8281\n",
            "Epoch 8/10\n",
            "36/36 [==============================] - 7s 205ms/step - loss: 0.4201 - accuracy: 0.7870 - val_loss: 0.4134 - val_accuracy: 0.7906\n",
            "Epoch 9/10\n",
            "36/36 [==============================] - 7s 188ms/step - loss: 0.4153 - accuracy: 0.7825 - val_loss: 0.3600 - val_accuracy: 0.8219\n",
            "Epoch 10/10\n",
            "36/36 [==============================] - 6s 156ms/step - loss: 0.4480 - accuracy: 0.7759 - val_loss: 0.3614 - val_accuracy: 0.8156\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.4000 - accuracy: 0.7994\n",
            "Test Accuracy: 79.94%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.xlabel('Epoch Number')\n",
        "plt.ylabel('Loss')\n",
        "plt.plot(history.history['loss'], label='training set')\n",
        "plt.plot(history.history['val_loss'], label='test set')\n",
        "plt.legend()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 466
        },
        "id": "1WYyh2_P6cYG",
        "outputId": "fb2659c0-e0f1-46b3-cb6c-5633b56f1525"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7c81a68f4340>"
            ]
          },
          "metadata": {},
          "execution_count": 47
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.xlabel('Epoch Number')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.plot(history.history['accuracy'], label='training set')\n",
        "plt.plot(history.history['val_accuracy'], label='test set')\n",
        "plt.legend()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 466
        },
        "id": "ZiRpYbX46gCk",
        "outputId": "e7158dc4-d4dd-48b9-f1fe-72f8199eba6b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7c81a4f63e50>"
            ]
          },
          "metadata": {},
          "execution_count": 48
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_loss, train_accuracy = model.evaluate(train_set_conv)\n",
        "print(f\"Training Accuracy: {train_accuracy * 100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cKEmA3Ko6iRS",
        "outputId": "203b5411-4d61-4ac6-e9f8-68537bd088fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "37/37 [==============================] - 8s 226ms/step - loss: 0.3993 - accuracy: 0.7959\n",
            "Training Accuracy: 79.59%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_accuracy = model.evaluate(test_set_conv)\n",
        "print(f\"Validation Accuracy: {test_accuracy * 100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uQdxSXTc6k2H",
        "outputId": "745d1a27-04b0-4c12-ffa9-6ac50a923ae1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11/11 [==============================] - 0s 14ms/step - loss: 0.4000 - accuracy: 0.7994\n",
            "Validation Accuracy: 79.94%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "#ResNet-50 model\n",
        "def ResNet50(input_shape, num_classes):\n",
        "    input_tensor = tf.keras.layers.Input(shape=input_shape)\n",
        "\n",
        "    # Initial Convolution Layer\n",
        "    x = tf.keras.layers.ZeroPadding2D(padding=(3, 3))(input_tensor)\n",
        "    x = tf.keras.layers.Conv2D(64, (7, 7), strides=(2, 2), name='conv1')(x)\n",
        "    x = tf.keras.layers.BatchNormalization(axis=3, name='bn_conv1')(x)\n",
        "    x = tf.keras.layers.Activation('relu')(x)\n",
        "    x = tf.keras.layers.ZeroPadding2D(padding=(1, 1))(x)\n",
        "    x = tf.keras.layers.MaxPooling2D((3, 3), strides=(2, 2))(x)\n",
        "\n",
        "    # ResNet-50 architecture\n",
        "    x = tf.keras.layers.Conv2D(64, (1, 1), strides=(1, 1), name='conv2_1')(x)\n",
        "    x = tf.keras.layers.BatchNormalization(axis=3, name='bn2_1')(x)\n",
        "    x = tf.keras.layers.Activation('relu')(x)\n",
        "    x = tf.keras.layers.Conv2D(64, (3, 3), strides=(1, 1), padding='same', name='conv2_2')(x)\n",
        "    x = tf.keras.layers.BatchNormalization(axis=3, name='bn2_2')(x)\n",
        "    x = tf.keras.layers.Activation('relu')(x)\n",
        "    x = tf.keras.layers.Conv2D(256, (1, 1), strides=(1, 1), name='conv2_3')(x)\n",
        "    x = tf.keras.layers.BatchNormalization(axis=3, name='bn2_3')(x)\n",
        "\n",
        "    #shortcut\n",
        "    shortcut = tf.keras.layers.Conv2D(256, (1, 1), strides=(1, 1), name='conv2_4')(x)\n",
        "    shortcut = tf.keras.layers.BatchNormalization(axis=3, name='bn2_4')(shortcut)\n",
        "    x = tf.keras.layers.Add()([x, shortcut])\n",
        "    x = tf.keras.layers.Activation('relu')(x)\n",
        "\n",
        "    # Fully Connected Layer\n",
        "    x = tf.keras.layers.AveragePooling2D(pool_size=(7, 7), name='avg_pool')(x)\n",
        "    x = tf.keras.layers.Flatten()(x)\n",
        "    x = tf.keras.layers.Dense(num_classes, activation='softmax', name='fc1000')(x)\n",
        "\n",
        "    model = models.Model(inputs=input_tensor, outputs=x, name='resnet50')\n",
        "\n",
        "    return model\n",
        "\n",
        "#ResNet-50 model\n",
        "input_shape = (IMAGE_WIDTH, IMAGE_HEIGHT, IMAGE_CHANNELS)\n",
        "num_classes = 2\n",
        "resnet50_model = ResNet50(input_shape, num_classes)\n",
        "\n",
        "early_stopping = EarlyStopping(monitor='val_accuracy',  # You can choose 'val_loss' or other metrics\n",
        "                               patience=10,             # Number of epochs with no improvement before stopping\n",
        "                               restore_best_weights=True)\n",
        "optimizer = Adam(learning_rate=0.00001)\n",
        "resnet50_model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "resnet50_model.summary()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ptG9QNT0ZO_D",
        "outputId": "95ed5ec6-2208-48ed-948c-7c3ec482051e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"resnet50\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_3 (InputLayer)        [(None, 100, 100, 3)]        0         []                            \n",
            "                                                                                                  \n",
            " zero_padding2d (ZeroPaddin  (None, 106, 106, 3)          0         ['input_3[0][0]']             \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv1 (Conv2D)              (None, 50, 50, 64)           9472      ['zero_padding2d[0][0]']      \n",
            "                                                                                                  \n",
            " bn_conv1 (BatchNormalizati  (None, 50, 50, 64)           256       ['conv1[0][0]']               \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " activation (Activation)     (None, 50, 50, 64)           0         ['bn_conv1[0][0]']            \n",
            "                                                                                                  \n",
            " zero_padding2d_1 (ZeroPadd  (None, 52, 52, 64)           0         ['activation[0][0]']          \n",
            " ing2D)                                                                                           \n",
            "                                                                                                  \n",
            " max_pooling2d_2 (MaxPoolin  (None, 25, 25, 64)           0         ['zero_padding2d_1[0][0]']    \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv2_1 (Conv2D)            (None, 25, 25, 64)           4160      ['max_pooling2d_2[0][0]']     \n",
            "                                                                                                  \n",
            " bn2_1 (BatchNormalization)  (None, 25, 25, 64)           256       ['conv2_1[0][0]']             \n",
            "                                                                                                  \n",
            " activation_1 (Activation)   (None, 25, 25, 64)           0         ['bn2_1[0][0]']               \n",
            "                                                                                                  \n",
            " conv2_2 (Conv2D)            (None, 25, 25, 64)           36928     ['activation_1[0][0]']        \n",
            "                                                                                                  \n",
            " bn2_2 (BatchNormalization)  (None, 25, 25, 64)           256       ['conv2_2[0][0]']             \n",
            "                                                                                                  \n",
            " activation_2 (Activation)   (None, 25, 25, 64)           0         ['bn2_2[0][0]']               \n",
            "                                                                                                  \n",
            " conv2_3 (Conv2D)            (None, 25, 25, 256)          16640     ['activation_2[0][0]']        \n",
            "                                                                                                  \n",
            " bn2_3 (BatchNormalization)  (None, 25, 25, 256)          1024      ['conv2_3[0][0]']             \n",
            "                                                                                                  \n",
            " conv2_4 (Conv2D)            (None, 25, 25, 256)          65792     ['bn2_3[0][0]']               \n",
            "                                                                                                  \n",
            " bn2_4 (BatchNormalization)  (None, 25, 25, 256)          1024      ['conv2_4[0][0]']             \n",
            "                                                                                                  \n",
            " add_32 (Add)                (None, 25, 25, 256)          0         ['bn2_3[0][0]',               \n",
            "                                                                     'bn2_4[0][0]']               \n",
            "                                                                                                  \n",
            " activation_3 (Activation)   (None, 25, 25, 256)          0         ['add_32[0][0]']              \n",
            "                                                                                                  \n",
            " avg_pool (AveragePooling2D  (None, 3, 3, 256)            0         ['activation_3[0][0]']        \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " flatten_2 (Flatten)         (None, 2304)                 0         ['avg_pool[0][0]']            \n",
            "                                                                                                  \n",
            " fc1000 (Dense)              (None, 2)                    4610      ['flatten_2[0][0]']           \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 140418 (548.51 KB)\n",
            "Trainable params: 139010 (543.01 KB)\n",
            "Non-trainable params: 1408 (5.50 KB)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "steps_per_epoch = len(x_train_normalized) // batch_size\n",
        "validation_steps = len(x_val_normalized) // batch_size\n",
        "\n",
        "# Train\n",
        "training_history = resnet50_model.fit(\n",
        "    train_set_conv,\n",
        "    steps_per_epoch=steps_per_epoch,\n",
        "    epochs=25,\n",
        "    validation_data=valid_set_conv,\n",
        "    validation_steps=validation_steps,\n",
        "    callbacks=[early_stopping]\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CqPeL3Qx6959",
        "outputId": "e7ae2adc-0605-4629-bf62-f7799adc64e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "36/36 [==============================] - 11s 182ms/step - loss: 0.7443 - accuracy: 0.5708 - val_loss: 0.6953 - val_accuracy: 0.4812\n",
            "Epoch 2/25\n",
            "36/36 [==============================] - 8s 218ms/step - loss: 0.5532 - accuracy: 0.7115 - val_loss: 0.6899 - val_accuracy: 0.5281\n",
            "Epoch 3/25\n",
            "36/36 [==============================] - 6s 166ms/step - loss: 0.4954 - accuracy: 0.7377 - val_loss: 0.6874 - val_accuracy: 0.5312\n",
            "Epoch 4/25\n",
            "36/36 [==============================] - 8s 214ms/step - loss: 0.4721 - accuracy: 0.7674 - val_loss: 0.6961 - val_accuracy: 0.5094\n",
            "Epoch 5/25\n",
            "36/36 [==============================] - 6s 167ms/step - loss: 0.4470 - accuracy: 0.7732 - val_loss: 0.7012 - val_accuracy: 0.5094\n",
            "Epoch 6/25\n",
            "36/36 [==============================] - 8s 218ms/step - loss: 0.4335 - accuracy: 0.7847 - val_loss: 0.6948 - val_accuracy: 0.5125\n",
            "Epoch 7/25\n",
            "36/36 [==============================] - 6s 162ms/step - loss: 0.4205 - accuracy: 0.7901 - val_loss: 0.6863 - val_accuracy: 0.5156\n",
            "Epoch 8/25\n",
            "36/36 [==============================] - 8s 230ms/step - loss: 0.4132 - accuracy: 0.7856 - val_loss: 0.6513 - val_accuracy: 0.5375\n",
            "Epoch 9/25\n",
            "36/36 [==============================] - 7s 195ms/step - loss: 0.4072 - accuracy: 0.7963 - val_loss: 0.6271 - val_accuracy: 0.5656\n",
            "Epoch 10/25\n",
            "36/36 [==============================] - 7s 202ms/step - loss: 0.3989 - accuracy: 0.8069 - val_loss: 0.5773 - val_accuracy: 0.6187\n",
            "Epoch 11/25\n",
            "36/36 [==============================] - 7s 207ms/step - loss: 0.3940 - accuracy: 0.8100 - val_loss: 0.5587 - val_accuracy: 0.6656\n",
            "Epoch 12/25\n",
            "36/36 [==============================] - 6s 173ms/step - loss: 0.3906 - accuracy: 0.8078 - val_loss: 0.5304 - val_accuracy: 0.7031\n",
            "Epoch 13/25\n",
            "36/36 [==============================] - 8s 219ms/step - loss: 0.3817 - accuracy: 0.8198 - val_loss: 0.4719 - val_accuracy: 0.7375\n",
            "Epoch 14/25\n",
            "36/36 [==============================] - 6s 172ms/step - loss: 0.3817 - accuracy: 0.8038 - val_loss: 0.4409 - val_accuracy: 0.7500\n",
            "Epoch 15/25\n",
            "36/36 [==============================] - 8s 225ms/step - loss: 0.3770 - accuracy: 0.8078 - val_loss: 0.4347 - val_accuracy: 0.7594\n",
            "Epoch 16/25\n",
            "36/36 [==============================] - 7s 187ms/step - loss: 0.3771 - accuracy: 0.8189 - val_loss: 0.4006 - val_accuracy: 0.7875\n",
            "Epoch 17/25\n",
            "36/36 [==============================] - 6s 166ms/step - loss: 0.3644 - accuracy: 0.8158 - val_loss: 0.4042 - val_accuracy: 0.7844\n",
            "Epoch 18/25\n",
            "36/36 [==============================] - 8s 220ms/step - loss: 0.3695 - accuracy: 0.8171 - val_loss: 0.4176 - val_accuracy: 0.7781\n",
            "Epoch 19/25\n",
            "36/36 [==============================] - 6s 164ms/step - loss: 0.3679 - accuracy: 0.8180 - val_loss: 0.3455 - val_accuracy: 0.8188\n",
            "Epoch 20/25\n",
            "36/36 [==============================] - 8s 218ms/step - loss: 0.3660 - accuracy: 0.8233 - val_loss: 0.3120 - val_accuracy: 0.8656\n",
            "Epoch 21/25\n",
            "36/36 [==============================] - 6s 164ms/step - loss: 0.3574 - accuracy: 0.8265 - val_loss: 0.3090 - val_accuracy: 0.8656\n",
            "Epoch 22/25\n",
            "36/36 [==============================] - 6s 168ms/step - loss: 0.3548 - accuracy: 0.8331 - val_loss: 0.3191 - val_accuracy: 0.8469\n",
            "Epoch 23/25\n",
            "36/36 [==============================] - 6s 172ms/step - loss: 0.3593 - accuracy: 0.8211 - val_loss: 0.3111 - val_accuracy: 0.8656\n",
            "Epoch 24/25\n",
            "36/36 [==============================] - 7s 207ms/step - loss: 0.3529 - accuracy: 0.8313 - val_loss: 0.2955 - val_accuracy: 0.8719\n",
            "Epoch 25/25\n",
            "36/36 [==============================] - 6s 173ms/step - loss: 0.3520 - accuracy: 0.8287 - val_loss: 0.2997 - val_accuracy: 0.8687\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.xlabel('Epoch Number')\n",
        "plt.ylabel('Loss')\n",
        "plt.plot(training_history.history['loss'], label='training set')\n",
        "plt.plot(training_history.history['val_loss'], label='test set')\n",
        "plt.legend()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 466
        },
        "id": "Pvh1fbOj6_3F",
        "outputId": "2e6ec2b0-41e6-4b48-e237-e955527c3e79"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7ce391b48040>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.xlabel('Epoch Number')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.plot(training_history.history['accuracy'], label='training set')\n",
        "plt.plot(training_history.history['val_accuracy'], label='test set')\n",
        "plt.legend()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 466
        },
        "id": "L2Q4Qbvm7BKb",
        "outputId": "d9b407df-b03c-49c0-f94c-9e262e9e568c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7ce391a04a30>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the ResNet-50 model on the training set\n",
        "train_loss, train_accuracy = resnet50_model.evaluate(train_set_conv, steps=len(x_train_normalized) // batch_size)\n",
        "print(f\"Training Accuracy: {train_accuracy * 100:.2f}%\")\n",
        "\n",
        "# Evaluate the ResNet-50 model on the test set\n",
        "test_loss, test_accuracy = resnet50_model.evaluate(test_set_conv)\n",
        "print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_O9nWaDy7DGd",
        "outputId": "91b2d5e9-9de5-41f0-d4f7-1c94fa4f4259"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "36/36 [==============================] - 6s 165ms/step - loss: 0.3481 - accuracy: 0.8368\n",
            "Training Accuracy: 83.68%\n",
            "11/11 [==============================] - 0s 21ms/step - loss: 0.3678 - accuracy: 0.8567\n",
            "Test Accuracy: 85.67%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract features from ResNet-50\n",
        "x_train_features = resnet50_model.predict(x_train_normalized)\n",
        "x_val_features = resnet50_model.predict(x_val_normalized)\n",
        "x_test_features = resnet50_model.predict(x_test_normalized)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cOn0EnWsviSH",
        "outputId": "b347b930-10c5-4f9d-fa96-7d5433c2d7c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "73/73 [==============================] - 1s 8ms/step\n",
            "11/11 [==============================] - 0s 22ms/step\n",
            "21/21 [==============================] - 0s 6ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_features = x_train_features.reshape(x_train_features.shape[0], -1)\n",
        "x_val_features = x_val_features.reshape(x_val_features.shape[0], -1)\n",
        "x_test_features = x_test_features.reshape(x_test_features.shape[0], -1)"
      ],
      "metadata": {
        "id": "Sp3OAYa7vqFA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "param_grid = {\n",
        "    'C': [0.1, 1, 10],\n",
        "    'gamma': [0.01, 0.1, 1],\n",
        "    'kernel': ['rbf', 'linear', 'poly']\n",
        "}\n"
      ],
      "metadata": {
        "id": "MRnK2AU4yhpu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Define the SVM classifier\n",
        "svm_model = SVC()\n",
        "\n",
        "# Create GridSearchCV with the parameter grid and cross-validation\n",
        "grid_search = GridSearchCV(estimator=svm_model, param_grid=param_grid, cv=3, n_jobs=-1)\n",
        "\n",
        "# Perform the grid search on the training data\n",
        "grid_search.fit(x_train_features, y_train)\n",
        "\n",
        "# Print the best hyperparameters found by the grid search\n",
        "print(\"Best Hyperparameters:\", grid_search.best_params_)\n",
        "\n",
        "# Get the best SVM model from the grid search\n",
        "best_svm_model = grid_search.best_estimator_\n",
        "\n",
        "# Evaluate the best model on the test data\n",
        "y_pred_svm = best_svm_model.predict(x_test_features)\n",
        "\n",
        "svm_accuracy = accuracy_score(y_test, y_pred_svm)\n",
        "svm_precision = precision_score(y_test, y_pred_svm)\n",
        "svm_recall = recall_score(y_test, y_pred_svm)\n",
        "svm_f1 = f1_score(y_test, y_pred_svm)\n",
        "\n",
        "tn, fp, fn, tp = confusion_matrix(y_test, y_pred_svm).ravel()\n",
        "svm_specificity = tn / (tn + fp)\n",
        "\n",
        "print(\"SVM Accuracy:\", svm_accuracy)\n",
        "print(\"SVM Precision:\", svm_precision)\n",
        "print(\"SVM Sensitivity (Recall):\", svm_recall)\n",
        "print(\"SVM Specificity:\", svm_specificity)\n",
        "print(\"SVM F1 Score:\", svm_f1)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xRBdl8ywvyhc",
        "outputId": "f5444d15-39c1-4112-d646-b7cd56c8100e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Hyperparameters: {'C': 1, 'gamma': 0.01, 'kernel': 'linear'}\n",
            "SVM Accuracy: 0.8582202111613876\n",
            "SVM Precision: 0.8314285714285714\n",
            "SVM Sensitivity (Recall): 0.8926380368098159\n",
            "SVM Specificity: 0.8249258160237388\n",
            "SVM F1 Score: 0.8609467455621301\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "import numpy as np\n",
        "\n",
        "# Define the parameter distributions for RandomizedSearchCV\n",
        "param_dist = {\n",
        "    'n_estimators': [100, 200, 300, 400],\n",
        "    'max_depth': [None, 10, 20, 30],\n",
        "    'min_samples_split': [2, 5, 10, 15],\n",
        "    'min_samples_leaf': [1, 2, 4, 8],\n",
        "    'max_features': ['auto', 'sqrt']\n",
        "}\n",
        "\n",
        "# Instantiate the Random Forest classifier\n",
        "rf_model = RandomForestClassifier(random_state=42)\n",
        "\n",
        "# Instantiate RandomizedSearchCV with the model, parameter distributions, and evaluation metric\n",
        "random_search = RandomizedSearchCV(estimator=rf_model, param_distributions=param_dist, n_iter=50, cv=3, n_jobs=-1, random_state=42, scoring='accuracy')\n",
        "\n",
        "# Early stopping parameters\n",
        "max_epochs = 25  # Maximum number of epochs to train\n",
        "patience = 5  # Number of epochs to wait for improvement\n",
        "counter = 0  # Counter to keep track of epochs with no improvement\n",
        "best_accuracy = 0  # Best validation accuracy\n",
        "\n",
        "# Training loop with early stopping\n",
        "for epoch in range(max_epochs):\n",
        "    # Perform the randomized search on your training data (x_train_features, y_train)\n",
        "    random_search.fit(x_train_features, y_train)\n",
        "\n",
        "    # Get the best hyperparameters and best model\n",
        "    best_params = random_search.best_params_\n",
        "    best_rf_model = random_search.best_estimator_\n",
        "\n",
        "    # Evaluate the model on the validation data\n",
        "    y_pred_val = best_rf_model.predict(x_val_features)\n",
        "    val_accuracy = accuracy_score(y_val, y_pred_val)\n",
        "\n",
        "    print(\"Epoch {}: Validation Accuracy: {:.4f}\".format(epoch, val_accuracy))\n",
        "\n",
        "    # Check for improvement in validation accuracy\n",
        "    if val_accuracy > best_accuracy:\n",
        "        best_accuracy = val_accuracy\n",
        "        counter = 0\n",
        "    else:\n",
        "        counter += 1\n",
        "\n",
        "    # Early stopping condition\n",
        "    if counter >= patience:\n",
        "        print(\"Early stopping after {} epochs of no improvement.\".format(epoch))\n",
        "        break\n",
        "\n",
        "# Evaluate the best model on the test data (x_test_features, y_test)\n",
        "y_pred_rf = best_rf_model.predict(x_test_features)\n",
        "rf_accuracy = accuracy_score(y_test, y_pred_rf)\n",
        "rf_precision = precision_score(y_test, y_pred_rf)\n",
        "rf_recall = recall_score(y_test, y_pred_rf)\n",
        "rf_f1 = f1_score(y_test, y_pred_rf)\n",
        "\n",
        "tn, fp, fn, tp = confusion_matrix(y_test, y_pred_rf).ravel()\n",
        "rf_specificity = tn / (tn + fp)\n",
        "\n",
        "print(\"Best Hyperparameters:\", best_params)\n",
        "print(\"Random Forest Accuracy:\", rf_accuracy)\n",
        "print(\"Random Forest Precision:\", rf_precision)\n",
        "print(\"Random Forest Sensitivity (Recall):\", rf_recall)\n",
        "print(\"Random Forest Specificity:\", rf_specificity)\n",
        "print(\"Random Forest F1 Score:\", rf_f1)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ak9VZwQEzTYX",
        "outputId": "7f5f7681-149d-4766-d4af-ea765b24aeb0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0: Validation Accuracy: 0.8278\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Validation Accuracy: 0.8278\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2: Validation Accuracy: 0.8278\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3: Validation Accuracy: 0.8278\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4: Validation Accuracy: 0.8278\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5: Validation Accuracy: 0.8278\n",
            "Early stopping after 5 epochs of no improvement.\n",
            "Best Hyperparameters: {'n_estimators': 200, 'min_samples_split': 2, 'min_samples_leaf': 4, 'max_features': 'auto', 'max_depth': 20}\n",
            "Random Forest Accuracy: 0.799396681749623\n",
            "Random Forest Precision: 0.796923076923077\n",
            "Random Forest Sensitivity (Recall): 0.7944785276073619\n",
            "Random Forest Specificity: 0.8041543026706232\n",
            "Random Forest F1 Score: 0.7956989247311829\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "\n",
        "# Instantiate the KNN classifier\n",
        "knn_model = KNeighborsClassifier(n_neighbors=5)\n",
        "\n",
        "# Early stopping parameters\n",
        "max_epochs = 10  # Maximum number of epochs (iterations) to train\n",
        "patience = 5  # Number of epochs to wait for improvement\n",
        "best_accuracy = 0  # Best validation accuracy\n",
        "counter = 0  # Counter to keep track of epochs with no improvement\n",
        "\n",
        "# Training loop with early stopping\n",
        "for epoch in range(max_epochs):\n",
        "    # Train the KNN model\n",
        "    knn_model.fit(x_train_features, y_train)\n",
        "\n",
        "    # Validate the model on the validation data\n",
        "    y_pred_val = knn_model.predict(x_val_features)\n",
        "    val_accuracy = accuracy_score(y_val, y_pred_val)\n",
        "\n",
        "    print(\"Epoch {}: Validation Accuracy: {:.4f}\".format(epoch, val_accuracy))\n",
        "\n",
        "    # Check for improvement in validation accuracy\n",
        "    if val_accuracy > best_accuracy:\n",
        "        best_accuracy = val_accuracy\n",
        "        counter = 0\n",
        "    else:\n",
        "        counter += 1\n",
        "\n",
        "    # Early stopping condition\n",
        "    if counter >= patience:\n",
        "        print(\"Early stopping after {} epochs of no improvement.\".format(epoch))\n",
        "        break\n",
        "\n",
        "# Evaluate the best model on the test data\n",
        "y_pred_test = knn_model.predict(x_test_features)\n",
        "knn_accuracy = accuracy_score(y_test, y_pred_test)\n",
        "knn_precision = precision_score(y_test, y_pred_test)\n",
        "knn_recall = recall_score(y_test, y_pred_test)\n",
        "knn_f1 = f1_score(y_test, y_pred_test)\n",
        "\n",
        "tn, fp, fn, tp = confusion_matrix(y_test, y_pred_test).ravel()\n",
        "knn_specificity = tn / (tn + fp)\n",
        "\n",
        "print(\"KNN Accuracy:\", knn_accuracy)\n",
        "print(\"KNN Precision:\", knn_precision)\n",
        "print(\"KNN Sensitivity (Recall):\", knn_recall)\n",
        "print(\"KNN Specificity:\", knn_specificity)\n",
        "print(\"KNN F1 Score:\", knn_f1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3j6NJyU_4tec",
        "outputId": "f4829a82-389f-47d2-ca76-00f4da0863ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0: Validation Accuracy: 0.8308\n",
            "Epoch 1: Validation Accuracy: 0.8308\n",
            "Epoch 2: Validation Accuracy: 0.8308\n",
            "Epoch 3: Validation Accuracy: 0.8308\n",
            "Epoch 4: Validation Accuracy: 0.8308\n",
            "Epoch 5: Validation Accuracy: 0.8308\n",
            "Early stopping after 5 epochs of no improvement.\n",
            "KNN Accuracy: 0.7963800904977375\n",
            "KNN Precision: 0.790273556231003\n",
            "KNN Sensitivity (Recall): 0.7975460122699386\n",
            "KNN Specificity: 0.7952522255192879\n",
            "KNN F1 Score: 0.7938931297709925\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import os\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "\n",
        "def VGG16(input_shape, num_classes):\n",
        "    inputs = Input(shape=input_shape)\n",
        "\n",
        "    # Block 1\n",
        "    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv1')(inputs)\n",
        "    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv2')(x)\n",
        "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block1_pool')(x)\n",
        "\n",
        "    # Block 2\n",
        "    x = Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv1')(x)\n",
        "    x = Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv2')(x)\n",
        "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block2_pool')(x)\n",
        "\n",
        "    # Block 3\n",
        "    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv1')(x)\n",
        "    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv2')(x)\n",
        "    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv3')(x)\n",
        "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block3_pool')(x)\n",
        "\n",
        "    # Block 4\n",
        "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv1')(x)\n",
        "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv2')(x)\n",
        "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv3')(x)\n",
        "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block4_pool')(x)\n",
        "\n",
        "    # Block 5\n",
        "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv1')(x)\n",
        "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv2')(x)\n",
        "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv3')(x)\n",
        "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block5_pool')(x)\n",
        "\n",
        "    # Flatten and Fully Connected Layers\n",
        "    x = Flatten(name='flatten')(x)\n",
        "    x = Dense(4096, activation='relu', name='fc1')(x)\n",
        "    x = Dropout(0.5)(x)\n",
        "    x = Dense(4096, activation='relu', name='fc2')(x)\n",
        "    x = Dropout(0.5)(x)\n",
        "    predictions = Dense(num_classes, activation='softmax', name='predictions')(x)\n",
        "\n",
        "    # Create the model\n",
        "    model = Model(inputs=inputs, outputs=predictions)\n",
        "    return model\n",
        "\n",
        "# Modify the input shape and number of classes based on your needs\n",
        "input_shape = (100, 100, 3)\n",
        "num_classes = 2\n",
        "\n",
        "model = VGG16(input_shape, num_classes)\n",
        "\n",
        "# Print model summary\n",
        "model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MtB5iJOhPGes",
        "outputId": "fa7a6b32-4683-4719-8cbd-338396a04cdb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_4 (InputLayer)        [(None, 100, 100, 3)]     0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, 100, 100, 64)      1792      \n",
            "                                                                 \n",
            " block1_conv2 (Conv2D)       (None, 100, 100, 64)      36928     \n",
            "                                                                 \n",
            " block1_pool (MaxPooling2D)  (None, 50, 50, 64)        0         \n",
            "                                                                 \n",
            " block2_conv1 (Conv2D)       (None, 50, 50, 128)       73856     \n",
            "                                                                 \n",
            " block2_conv2 (Conv2D)       (None, 50, 50, 128)       147584    \n",
            "                                                                 \n",
            " block2_pool (MaxPooling2D)  (None, 25, 25, 128)       0         \n",
            "                                                                 \n",
            " block3_conv1 (Conv2D)       (None, 25, 25, 256)       295168    \n",
            "                                                                 \n",
            " block3_conv2 (Conv2D)       (None, 25, 25, 256)       590080    \n",
            "                                                                 \n",
            " block3_conv3 (Conv2D)       (None, 25, 25, 256)       590080    \n",
            "                                                                 \n",
            " block3_pool (MaxPooling2D)  (None, 12, 12, 256)       0         \n",
            "                                                                 \n",
            " block4_conv1 (Conv2D)       (None, 12, 12, 512)       1180160   \n",
            "                                                                 \n",
            " block4_conv2 (Conv2D)       (None, 12, 12, 512)       2359808   \n",
            "                                                                 \n",
            " block4_conv3 (Conv2D)       (None, 12, 12, 512)       2359808   \n",
            "                                                                 \n",
            " block4_pool (MaxPooling2D)  (None, 6, 6, 512)         0         \n",
            "                                                                 \n",
            " block5_conv1 (Conv2D)       (None, 6, 6, 512)         2359808   \n",
            "                                                                 \n",
            " block5_conv2 (Conv2D)       (None, 6, 6, 512)         2359808   \n",
            "                                                                 \n",
            " block5_conv3 (Conv2D)       (None, 6, 6, 512)         2359808   \n",
            "                                                                 \n",
            " block5_pool (MaxPooling2D)  (None, 3, 3, 512)         0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 4608)              0         \n",
            "                                                                 \n",
            " fc1 (Dense)                 (None, 4096)              18878464  \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 4096)              0         \n",
            "                                                                 \n",
            " fc2 (Dense)                 (None, 4096)              16781312  \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 4096)              0         \n",
            "                                                                 \n",
            " predictions (Dense)         (None, 2)                 8194      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 50382658 (192.19 MB)\n",
            "Trainable params: 50382658 (192.19 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Define learning rate\n",
        "learning_rate = 0.00001\n",
        "\n",
        "# Compile the model with the specified learning rate\n",
        "optimizer = Adam(learning_rate=learning_rate)\n",
        "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Define steps per epoch and validation steps\n",
        "steps_per_epoch = len(x_train_normalized) // batch_size\n",
        "validation_steps = len(x_val_normalized) // batch_size\n",
        "\n",
        "# Train the VGG16 model\n",
        "history = model.fit(\n",
        "    train_set_conv,\n",
        "    steps_per_epoch=steps_per_epoch,\n",
        "    epochs=25,  # You can adjust the number of epochs\n",
        "    validation_data=valid_set_conv,\n",
        "    validation_steps=validation_steps\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5qWDx_s3PwnT",
        "outputId": "6b94e664-ac98-432a-e67c-1121f5373a4a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "36/36 [==============================] - 24s 320ms/step - loss: 0.6881 - accuracy: 0.5539 - val_loss: 0.6891 - val_accuracy: 0.5094\n",
            "Epoch 2/25\n",
            "36/36 [==============================] - 9s 253ms/step - loss: 0.6482 - accuracy: 0.5584 - val_loss: 0.6053 - val_accuracy: 0.5188\n",
            "Epoch 3/25\n",
            "36/36 [==============================] - 9s 255ms/step - loss: 0.5661 - accuracy: 0.6582 - val_loss: 0.4870 - val_accuracy: 0.7719\n",
            "Epoch 4/25\n",
            "36/36 [==============================] - 10s 281ms/step - loss: 0.4905 - accuracy: 0.7554 - val_loss: 0.4936 - val_accuracy: 0.7688\n",
            "Epoch 5/25\n",
            "36/36 [==============================] - 10s 279ms/step - loss: 0.4902 - accuracy: 0.7585 - val_loss: 0.3866 - val_accuracy: 0.8406\n",
            "Epoch 6/25\n",
            "36/36 [==============================] - 9s 246ms/step - loss: 0.4499 - accuracy: 0.7807 - val_loss: 0.3832 - val_accuracy: 0.8375\n",
            "Epoch 7/25\n",
            "36/36 [==============================] - 13s 351ms/step - loss: 0.4429 - accuracy: 0.7816 - val_loss: 0.3893 - val_accuracy: 0.8313\n",
            "Epoch 8/25\n",
            "36/36 [==============================] - 11s 294ms/step - loss: 0.4261 - accuracy: 0.7807 - val_loss: 0.3692 - val_accuracy: 0.8313\n",
            "Epoch 9/25\n",
            "36/36 [==============================] - 9s 258ms/step - loss: 0.4349 - accuracy: 0.7759 - val_loss: 0.3500 - val_accuracy: 0.8281\n",
            "Epoch 10/25\n",
            "36/36 [==============================] - 9s 251ms/step - loss: 0.4045 - accuracy: 0.7901 - val_loss: 0.3488 - val_accuracy: 0.8438\n",
            "Epoch 11/25\n",
            "36/36 [==============================] - 10s 286ms/step - loss: 0.4099 - accuracy: 0.7985 - val_loss: 0.3471 - val_accuracy: 0.8500\n",
            "Epoch 12/25\n",
            "36/36 [==============================] - 9s 244ms/step - loss: 0.3995 - accuracy: 0.8025 - val_loss: 0.3272 - val_accuracy: 0.8594\n",
            "Epoch 13/25\n",
            "36/36 [==============================] - 10s 267ms/step - loss: 0.4122 - accuracy: 0.8065 - val_loss: 0.3694 - val_accuracy: 0.8719\n",
            "Epoch 14/25\n",
            "36/36 [==============================] - 10s 287ms/step - loss: 0.4013 - accuracy: 0.8105 - val_loss: 0.3339 - val_accuracy: 0.8656\n",
            "Epoch 15/25\n",
            "36/36 [==============================] - 9s 247ms/step - loss: 0.3875 - accuracy: 0.8105 - val_loss: 0.3270 - val_accuracy: 0.8594\n",
            "Epoch 16/25\n",
            "36/36 [==============================] - 10s 281ms/step - loss: 0.3808 - accuracy: 0.8140 - val_loss: 0.3213 - val_accuracy: 0.8594\n",
            "Epoch 17/25\n",
            "36/36 [==============================] - 10s 276ms/step - loss: 0.3879 - accuracy: 0.8136 - val_loss: 0.3116 - val_accuracy: 0.8750\n",
            "Epoch 18/25\n",
            "36/36 [==============================] - 9s 240ms/step - loss: 0.3776 - accuracy: 0.8162 - val_loss: 0.3300 - val_accuracy: 0.8625\n",
            "Epoch 19/25\n",
            "36/36 [==============================] - 11s 298ms/step - loss: 0.3797 - accuracy: 0.8194 - val_loss: 0.3091 - val_accuracy: 0.8625\n",
            "Epoch 20/25\n",
            "36/36 [==============================] - 10s 271ms/step - loss: 0.3735 - accuracy: 0.8185 - val_loss: 0.2990 - val_accuracy: 0.8750\n",
            "Epoch 21/25\n",
            "36/36 [==============================] - 10s 258ms/step - loss: 0.3801 - accuracy: 0.8109 - val_loss: 0.3147 - val_accuracy: 0.8625\n",
            "Epoch 22/25\n",
            "36/36 [==============================] - 11s 300ms/step - loss: 0.3710 - accuracy: 0.8185 - val_loss: 0.3090 - val_accuracy: 0.8562\n",
            "Epoch 23/25\n",
            "36/36 [==============================] - 10s 282ms/step - loss: 0.3784 - accuracy: 0.8131 - val_loss: 0.3412 - val_accuracy: 0.8219\n",
            "Epoch 24/25\n",
            "36/36 [==============================] - 11s 289ms/step - loss: 0.3731 - accuracy: 0.8181 - val_loss: 0.3609 - val_accuracy: 0.8562\n",
            "Epoch 25/25\n",
            "36/36 [==============================] - 10s 284ms/step - loss: 0.3729 - accuracy: 0.8331 - val_loss: 0.3242 - val_accuracy: 0.8594\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on the training set\n",
        "train_loss, train_accuracy = model.evaluate(train_set_conv, steps=steps_per_epoch)\n",
        "print(f'Training Loss: {train_loss:.4f}')\n",
        "print(f'Training Accuracy: {train_accuracy * 100:.2f}%')\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "test_loss, test_accuracy = model.evaluate(test_set_conv)\n",
        "print(f'Test Loss: {test_loss:.4f}')\n",
        "print(f'Test Accuracy: {test_accuracy * 100:.2f}%')\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ykhi1MqhSG7x",
        "outputId": "952ac595-6190-4626-e27d-f351edef2041"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "36/36 [==============================] - 8s 232ms/step - loss: 0.3734 - accuracy: 0.8181\n",
            "Training Loss: 0.3734\n",
            "Training Accuracy: 81.81%\n",
            "11/11 [==============================] - 2s 150ms/step - loss: 0.3870 - accuracy: 0.8431\n",
            "Test Loss: 0.3870\n",
            "Test Accuracy: 84.31%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_features = model.predict(x_train_normalized)\n",
        "x_val_features = model.predict(x_val_normalized)\n",
        "x_test_features = model.predict(x_test_normalized)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sSURlrrO7X7S",
        "outputId": "cb8563b3-9a23-4922-aea1-55ea85f307c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "73/73 [==============================] - 5s 34ms/step\n",
            "11/11 [==============================] - 1s 103ms/step\n",
            "21/21 [==============================] - 1s 31ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_features = x_train_features.reshape(x_train_features.shape[0], -1)\n",
        "x_val_features = x_val_features.reshape(x_val_features.shape[0], -1)\n",
        "x_test_features = x_test_features.reshape(x_test_features.shape[0], -1)"
      ],
      "metadata": {
        "id": "pMvq9dBD7sPj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "\n",
        "# SVM Classifier\n",
        "svm_model = SVC(kernel='rbf', C=1, gamma='scale')\n",
        "\n",
        "# Early stopping parameters\n",
        "max_epochs = 25  # Maximum number of epochs (iterations) to train\n",
        "patience = 5  # Number of epochs to wait for improvement\n",
        "best_accuracy = 0  # Best validation accuracy\n",
        "counter = 0  # Counter to keep track of epochs with no improvement\n",
        "\n",
        "# Training loop with early stopping\n",
        "for epoch in range(max_epochs):\n",
        "    # Train the SVM model\n",
        "    svm_model.fit(x_train_features, y_train)\n",
        "\n",
        "    # Validate the model on the validation data\n",
        "    y_pred_val = svm_model.predict(x_val_features)\n",
        "    val_accuracy = accuracy_score(y_val, y_pred_val)\n",
        "\n",
        "    print(\"Epoch {}: Validation Accuracy: {:.4f}\".format(epoch, val_accuracy))\n",
        "\n",
        "    # Check for improvement in validation accuracy\n",
        "    if val_accuracy > best_accuracy:\n",
        "        best_accuracy = val_accuracy\n",
        "        counter = 0\n",
        "    else:\n",
        "        counter += 1\n",
        "\n",
        "    # Early stopping condition\n",
        "    if counter >= patience:\n",
        "        print(\"Early stopping after {} epochs of no improvement.\".format(epoch))\n",
        "        break\n",
        "\n",
        "# Evaluate the best model on the test data\n",
        "y_pred_test = svm_model.predict(x_test_features)\n",
        "svm_accuracy = accuracy_score(y_test, y_pred_test)\n",
        "svm_precision = precision_score(y_test, y_pred_test)\n",
        "svm_recall = recall_score(y_test, y_pred_test)\n",
        "svm_f1 = f1_score(y_test, y_pred_test)\n",
        "\n",
        "tn, fp, fn, tp = confusion_matrix(y_test, y_pred_test).ravel()\n",
        "svm_specificity = tn / (tn + fp)\n",
        "\n",
        "print(\"SVM Accuracy:\", svm_accuracy)\n",
        "print(\"SVM Precision:\", svm_precision)\n",
        "print(\"SVM Sensitivity (Recall):\", svm_recall)\n",
        "print(\"SVM Specificity:\", svm_specificity)\n",
        "print(\"SVM F1 Score:\", svm_f1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HpVu3WlK-ISk",
        "outputId": "8dbffaed-4cba-4db5-8739-ebf4c7efa1b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0: Validation Accuracy: 0.8671\n",
            "Epoch 1: Validation Accuracy: 0.8671\n",
            "Epoch 2: Validation Accuracy: 0.8671\n",
            "Epoch 3: Validation Accuracy: 0.8671\n",
            "Epoch 4: Validation Accuracy: 0.8671\n",
            "Epoch 5: Validation Accuracy: 0.8671\n",
            "Early stopping after 5 epochs of no improvement.\n",
            "SVM Accuracy: 0.8416289592760181\n",
            "SVM Precision: 0.8060941828254847\n",
            "SVM Sensitivity (Recall): 0.8926380368098159\n",
            "SVM Specificity: 0.7922848664688428\n",
            "SVM F1 Score: 0.8471615720524017\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "import numpy as np\n",
        "\n",
        "# Define the parameter distributions for RandomizedSearchCV\n",
        "param_dist = {\n",
        "    'n_estimators': [100, 200, 300, 400],\n",
        "    'max_depth': [None, 10, 20, 30],\n",
        "    'min_samples_split': [2, 5, 10, 15],\n",
        "    'min_samples_leaf': [1, 2, 4, 8],\n",
        "    'max_features': ['auto', 'sqrt']\n",
        "}\n",
        "\n",
        "# Instantiate the Random Forest classifier\n",
        "rf_model = RandomForestClassifier(random_state=42)\n",
        "\n",
        "# Instantiate RandomizedSearchCV with the model, parameter distributions, and evaluation metric\n",
        "random_search = RandomizedSearchCV(estimator=rf_model, param_distributions=param_dist, n_iter=50, cv=3, n_jobs=-1, random_state=42, scoring='accuracy')\n",
        "\n",
        "# Perform the randomized search on your training data (x_train_features, y_train)\n",
        "random_search.fit(x_train_features, y_train)\n",
        "\n",
        "# Get the best hyperparameters and best model\n",
        "best_params = random_search.best_params_\n",
        "best_rf_model = random_search.best_estimator_\n",
        "\n",
        "# Evaluate the best model on the test data (x_test_features, y_test)\n",
        "y_pred_rf = best_rf_model.predict(x_test_features)\n",
        "rf_accuracy = accuracy_score(y_test, y_pred_rf)\n",
        "rf_precision = precision_score(y_test, y_pred_rf)\n",
        "rf_recall = recall_score(y_test, y_pred_rf)\n",
        "rf_f1 = f1_score(y_test, y_pred_rf)\n",
        "\n",
        "tn, fp, fn, tp = confusion_matrix(y_test, y_pred_rf).ravel()\n",
        "rf_specificity = tn / (tn + fp)\n",
        "\n",
        "print(\"Best Hyperparameters:\", best_params)\n",
        "print(\"Random Forest Accuracy:\", rf_accuracy)\n",
        "print(\"Random Forest Precision:\", rf_precision)\n",
        "print(\"Random Forest Sensitivity (Recall):\", rf_recall)\n",
        "print(\"Random Forest Specificity:\", rf_specificity)\n",
        "print(\"Random Forest F1 Score:\", rf_f1)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VpshrZHv-Xyg",
        "outputId": "d0b3845d-7a6a-4948-fe5e-5353296c4285"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Hyperparameters: {'n_estimators': 200, 'min_samples_split': 2, 'min_samples_leaf': 4, 'max_features': 'sqrt', 'max_depth': 10}\n",
            "Random Forest Accuracy: 0.8205128205128205\n",
            "Random Forest Precision: 0.7965616045845272\n",
            "Random Forest Sensitivity (Recall): 0.852760736196319\n",
            "Random Forest Specificity: 0.7893175074183977\n",
            "Random Forest F1 Score: 0.8237037037037037\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Define the parameter grid for GridSearchCV\n",
        "param_grid = {\n",
        "    'n_neighbors': [3, 5, 7, 9],  # Example values for the number of neighbors\n",
        "    'weights': ['uniform', 'distance'],  # Example values for the weight function\n",
        "    'p': [1, 2]  # Example values for the power parameter (1 for Manhattan distance, 2 for Euclidean distance)\n",
        "}\n",
        "\n",
        "# Instantiate the KNN classifier\n",
        "knn_model = KNeighborsClassifier()\n",
        "\n",
        "# Instantiate GridSearchCV with the model and parameter grid\n",
        "grid_search = GridSearchCV(estimator=knn_model, param_grid=param_grid, cv=3, n_jobs=-1, scoring='accuracy')\n",
        "\n",
        "# Perform grid search on your training data (x_train_features, y_train)\n",
        "grid_search.fit(x_train_features, y_train)\n",
        "\n",
        "# Get the best hyperparameters and best model\n",
        "best_params = grid_search.best_params_\n",
        "best_knn_model = grid_search.best_estimator_\n",
        "\n",
        "# Print the best hyperparameters\n",
        "print(\"Best Hyperparameters:\", best_params)\n",
        "\n",
        "# Evaluate the best model on the test data (x_test_features, y_test)\n",
        "y_pred_knn = best_knn_model.predict(x_test_features)\n",
        "knn_accuracy = accuracy_score(y_test, y_pred_knn)\n",
        "knn_precision = precision_score(y_test, y_pred_knn)\n",
        "knn_recall = recall_score(y_test, y_pred_knn)\n",
        "knn_f1 = f1_score(y_test, y_pred_knn)\n",
        "\n",
        "tn, fp, fn, tp = confusion_matrix(y_test, y_pred_knn).ravel()\n",
        "knn_specificity = tn / (tn + fp)\n",
        "\n",
        "print(\"KNN Accuracy:\", knn_accuracy)\n",
        "print(\"KNN Precision:\", knn_precision)\n",
        "print(\"KNN Sensitivity (Recall):\", knn_recall)\n",
        "print(\"KNN Specificity:\", knn_specificity)\n",
        "print(\"KNN F1 Score:\", knn_f1)\n",
        "\n",
        "# The best trained KNN model is stored in the variable 'best_knn_model'\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UbBXUe1f_mwM",
        "outputId": "36de7a83-ec69-428c-b032-4d8badc1989c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Hyperparameters: {'n_neighbors': 9, 'p': 1, 'weights': 'uniform'}\n",
            "KNN Accuracy: 0.8205128205128205\n",
            "KNN Precision: 0.8\n",
            "KNN Sensitivity (Recall): 0.8466257668711656\n",
            "KNN Specificity: 0.7952522255192879\n",
            "KNN F1 Score: 0.8226527570789867\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "def ShuffleNet(input_shape, num_classes):\n",
        "    def group(input, groups, in_channels, out_channels):\n",
        "        group_list = []\n",
        "        for i in range(groups):\n",
        "            x = layers.Conv2D(out_channels // groups, (1, 1), use_bias=False)(input)\n",
        "            x = layers.BatchNormalization()(x)\n",
        "            x = layers.Activation('relu')(x)\n",
        "            group_list.append(x)\n",
        "        if groups == 1:\n",
        "            return group_list[0]\n",
        "        else:\n",
        "            return layers.Concatenate()(group_list)\n",
        "\n",
        "    def channel_shuffle(x, groups):\n",
        "        _, width, height, channels = x.shape\n",
        "        group_channels = channels // groups\n",
        "        x = tf.reshape(x, [-1, width, height, group_channels, groups])\n",
        "        x = tf.transpose(x, [0, 1, 2, 4, 3])\n",
        "        x = tf.reshape(x, [-1, width, height, channels])\n",
        "        return x\n",
        "\n",
        "    input_tensor = tf.keras.layers.Input(shape=input_shape)\n",
        "    x = layers.Conv2D(24, (3, 3), strides=(2, 2), padding='same', use_bias=False)(input_tensor)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation('relu')(x)\n",
        "    x = layers.MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n",
        "\n",
        "    x = group(x, 4, 24, 384)\n",
        "    x = layers.Conv2D(196, (1, 1), use_bias=False)(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation('relu')(x)\n",
        "    x = channel_shuffle(x, 4)\n",
        "    x = layers.DepthwiseConv2D((3, 3), padding='same', use_bias=False)(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Conv2D(196, (1, 1), use_bias=False)(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation('relu')(x)\n",
        "\n",
        "    x = group(x, 4, 196, 384)\n",
        "    x = layers.Conv2D(392, (1, 1), use_bias=False)(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation('relu')(x)\n",
        "    x = channel_shuffle(x, 4)\n",
        "    x = layers.DepthwiseConv2D((3, 3), padding='same', use_bias=False)(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Conv2D(392, (1, 1), use_bias=False)(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation('relu')(x)\n",
        "\n",
        "    x = group(x, 4, 392, 784)\n",
        "    x = layers.Conv2D(196, (1, 1), use_bias=False)(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation('relu')(x)\n",
        "    x = channel_shuffle(x, 4)\n",
        "    x = layers.DepthwiseConv2D((3, 3), padding='same', use_bias=False)(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Conv2D(196, (1, 1), use_bias=False)(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation('relu')(x)\n",
        "\n",
        "    x = layers.GlobalAveragePooling2D()(x)\n",
        "    x = layers.Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "    model = models.Model(inputs=input_tensor, outputs=x, name='shufflenet')\n",
        "\n",
        "    return model\n",
        "\n",
        "input_shape = (100, 100, 3)\n",
        "num_classes = 2\n",
        "shufflenet_model = ShuffleNet(input_shape, num_classes)\n",
        "\n",
        "# Compile model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "optimizer = Adam(learning_rate=0.00001)\n",
        "shufflenet_model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "shufflenet_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2VOo_gpfCEiv",
        "outputId": "d81588b9-0a43-4f37-d4a2-08b03fd3aed9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"shufflenet\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_5 (InputLayer)        [(None, 100, 100, 3)]        0         []                            \n",
            "                                                                                                  \n",
            " conv2d_130 (Conv2D)         (None, 50, 50, 24)           648       ['input_5[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_130 (B  (None, 50, 50, 24)           96        ['conv2d_130[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_4 (Activation)   (None, 50, 50, 24)           0         ['batch_normalization_130[0][0\n",
            "                                                                    ]']                           \n",
            "                                                                                                  \n",
            " max_pooling2d_3 (MaxPoolin  (None, 25, 25, 24)           0         ['activation_4[0][0]']        \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv2d_131 (Conv2D)         (None, 25, 25, 96)           2304      ['max_pooling2d_3[0][0]']     \n",
            "                                                                                                  \n",
            " conv2d_132 (Conv2D)         (None, 25, 25, 96)           2304      ['max_pooling2d_3[0][0]']     \n",
            "                                                                                                  \n",
            " conv2d_133 (Conv2D)         (None, 25, 25, 96)           2304      ['max_pooling2d_3[0][0]']     \n",
            "                                                                                                  \n",
            " conv2d_134 (Conv2D)         (None, 25, 25, 96)           2304      ['max_pooling2d_3[0][0]']     \n",
            "                                                                                                  \n",
            " batch_normalization_131 (B  (None, 25, 25, 96)           384       ['conv2d_131[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_132 (B  (None, 25, 25, 96)           384       ['conv2d_132[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_133 (B  (None, 25, 25, 96)           384       ['conv2d_133[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_134 (B  (None, 25, 25, 96)           384       ['conv2d_134[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_5 (Activation)   (None, 25, 25, 96)           0         ['batch_normalization_131[0][0\n",
            "                                                                    ]']                           \n",
            "                                                                                                  \n",
            " activation_6 (Activation)   (None, 25, 25, 96)           0         ['batch_normalization_132[0][0\n",
            "                                                                    ]']                           \n",
            "                                                                                                  \n",
            " activation_7 (Activation)   (None, 25, 25, 96)           0         ['batch_normalization_133[0][0\n",
            "                                                                    ]']                           \n",
            "                                                                                                  \n",
            " activation_8 (Activation)   (None, 25, 25, 96)           0         ['batch_normalization_134[0][0\n",
            "                                                                    ]']                           \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)   (None, 25, 25, 384)          0         ['activation_5[0][0]',        \n",
            "                                                                     'activation_6[0][0]',        \n",
            "                                                                     'activation_7[0][0]',        \n",
            "                                                                     'activation_8[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_135 (Conv2D)         (None, 25, 25, 196)          75264     ['concatenate[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_135 (B  (None, 25, 25, 196)          784       ['conv2d_135[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_9 (Activation)   (None, 25, 25, 196)          0         ['batch_normalization_135[0][0\n",
            "                                                                    ]']                           \n",
            "                                                                                                  \n",
            " tf.reshape (TFOpLambda)     (None, 25, 25, 49, 4)        0         ['activation_9[0][0]']        \n",
            "                                                                                                  \n",
            " tf.compat.v1.transpose (TF  (None, 25, 25, 4, 49)        0         ['tf.reshape[0][0]']          \n",
            " OpLambda)                                                                                        \n",
            "                                                                                                  \n",
            " tf.reshape_1 (TFOpLambda)   (None, 25, 25, 196)          0         ['tf.compat.v1.transpose[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " depthwise_conv2d (Depthwis  (None, 25, 25, 196)          1764      ['tf.reshape_1[0][0]']        \n",
            " eConv2D)                                                                                         \n",
            "                                                                                                  \n",
            " batch_normalization_136 (B  (None, 25, 25, 196)          784       ['depthwise_conv2d[0][0]']    \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " conv2d_136 (Conv2D)         (None, 25, 25, 196)          38416     ['batch_normalization_136[0][0\n",
            "                                                                    ]']                           \n",
            "                                                                                                  \n",
            " batch_normalization_137 (B  (None, 25, 25, 196)          784       ['conv2d_136[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_10 (Activation)  (None, 25, 25, 196)          0         ['batch_normalization_137[0][0\n",
            "                                                                    ]']                           \n",
            "                                                                                                  \n",
            " conv2d_137 (Conv2D)         (None, 25, 25, 96)           18816     ['activation_10[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_138 (Conv2D)         (None, 25, 25, 96)           18816     ['activation_10[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_139 (Conv2D)         (None, 25, 25, 96)           18816     ['activation_10[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_140 (Conv2D)         (None, 25, 25, 96)           18816     ['activation_10[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_138 (B  (None, 25, 25, 96)           384       ['conv2d_137[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_139 (B  (None, 25, 25, 96)           384       ['conv2d_138[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_140 (B  (None, 25, 25, 96)           384       ['conv2d_139[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_141 (B  (None, 25, 25, 96)           384       ['conv2d_140[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_11 (Activation)  (None, 25, 25, 96)           0         ['batch_normalization_138[0][0\n",
            "                                                                    ]']                           \n",
            "                                                                                                  \n",
            " activation_12 (Activation)  (None, 25, 25, 96)           0         ['batch_normalization_139[0][0\n",
            "                                                                    ]']                           \n",
            "                                                                                                  \n",
            " activation_13 (Activation)  (None, 25, 25, 96)           0         ['batch_normalization_140[0][0\n",
            "                                                                    ]']                           \n",
            "                                                                                                  \n",
            " activation_14 (Activation)  (None, 25, 25, 96)           0         ['batch_normalization_141[0][0\n",
            "                                                                    ]']                           \n",
            "                                                                                                  \n",
            " concatenate_1 (Concatenate  (None, 25, 25, 384)          0         ['activation_11[0][0]',       \n",
            " )                                                                   'activation_12[0][0]',       \n",
            "                                                                     'activation_13[0][0]',       \n",
            "                                                                     'activation_14[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_141 (Conv2D)         (None, 25, 25, 392)          150528    ['concatenate_1[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_142 (B  (None, 25, 25, 392)          1568      ['conv2d_141[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_15 (Activation)  (None, 25, 25, 392)          0         ['batch_normalization_142[0][0\n",
            "                                                                    ]']                           \n",
            "                                                                                                  \n",
            " tf.reshape_2 (TFOpLambda)   (None, 25, 25, 98, 4)        0         ['activation_15[0][0]']       \n",
            "                                                                                                  \n",
            " tf.compat.v1.transpose_1 (  (None, 25, 25, 4, 98)        0         ['tf.reshape_2[0][0]']        \n",
            " TFOpLambda)                                                                                      \n",
            "                                                                                                  \n",
            " tf.reshape_3 (TFOpLambda)   (None, 25, 25, 392)          0         ['tf.compat.v1.transpose_1[0][\n",
            "                                                                    0]']                          \n",
            "                                                                                                  \n",
            " depthwise_conv2d_1 (Depthw  (None, 25, 25, 392)          3528      ['tf.reshape_3[0][0]']        \n",
            " iseConv2D)                                                                                       \n",
            "                                                                                                  \n",
            " batch_normalization_143 (B  (None, 25, 25, 392)          1568      ['depthwise_conv2d_1[0][0]']  \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " conv2d_142 (Conv2D)         (None, 25, 25, 392)          153664    ['batch_normalization_143[0][0\n",
            "                                                                    ]']                           \n",
            "                                                                                                  \n",
            " batch_normalization_144 (B  (None, 25, 25, 392)          1568      ['conv2d_142[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_16 (Activation)  (None, 25, 25, 392)          0         ['batch_normalization_144[0][0\n",
            "                                                                    ]']                           \n",
            "                                                                                                  \n",
            " conv2d_143 (Conv2D)         (None, 25, 25, 196)          76832     ['activation_16[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_144 (Conv2D)         (None, 25, 25, 196)          76832     ['activation_16[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_145 (Conv2D)         (None, 25, 25, 196)          76832     ['activation_16[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_146 (Conv2D)         (None, 25, 25, 196)          76832     ['activation_16[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_145 (B  (None, 25, 25, 196)          784       ['conv2d_143[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_146 (B  (None, 25, 25, 196)          784       ['conv2d_144[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_147 (B  (None, 25, 25, 196)          784       ['conv2d_145[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_148 (B  (None, 25, 25, 196)          784       ['conv2d_146[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_17 (Activation)  (None, 25, 25, 196)          0         ['batch_normalization_145[0][0\n",
            "                                                                    ]']                           \n",
            "                                                                                                  \n",
            " activation_18 (Activation)  (None, 25, 25, 196)          0         ['batch_normalization_146[0][0\n",
            "                                                                    ]']                           \n",
            "                                                                                                  \n",
            " activation_19 (Activation)  (None, 25, 25, 196)          0         ['batch_normalization_147[0][0\n",
            "                                                                    ]']                           \n",
            "                                                                                                  \n",
            " activation_20 (Activation)  (None, 25, 25, 196)          0         ['batch_normalization_148[0][0\n",
            "                                                                    ]']                           \n",
            "                                                                                                  \n",
            " concatenate_2 (Concatenate  (None, 25, 25, 784)          0         ['activation_17[0][0]',       \n",
            " )                                                                   'activation_18[0][0]',       \n",
            "                                                                     'activation_19[0][0]',       \n",
            "                                                                     'activation_20[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_147 (Conv2D)         (None, 25, 25, 196)          153664    ['concatenate_2[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_149 (B  (None, 25, 25, 196)          784       ['conv2d_147[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_21 (Activation)  (None, 25, 25, 196)          0         ['batch_normalization_149[0][0\n",
            "                                                                    ]']                           \n",
            "                                                                                                  \n",
            " tf.reshape_4 (TFOpLambda)   (None, 25, 25, 49, 4)        0         ['activation_21[0][0]']       \n",
            "                                                                                                  \n",
            " tf.compat.v1.transpose_2 (  (None, 25, 25, 4, 49)        0         ['tf.reshape_4[0][0]']        \n",
            " TFOpLambda)                                                                                      \n",
            "                                                                                                  \n",
            " tf.reshape_5 (TFOpLambda)   (None, 25, 25, 196)          0         ['tf.compat.v1.transpose_2[0][\n",
            "                                                                    0]']                          \n",
            "                                                                                                  \n",
            " depthwise_conv2d_2 (Depthw  (None, 25, 25, 196)          1764      ['tf.reshape_5[0][0]']        \n",
            " iseConv2D)                                                                                       \n",
            "                                                                                                  \n",
            " batch_normalization_150 (B  (None, 25, 25, 196)          784       ['depthwise_conv2d_2[0][0]']  \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " conv2d_148 (Conv2D)         (None, 25, 25, 196)          38416     ['batch_normalization_150[0][0\n",
            "                                                                    ]']                           \n",
            "                                                                                                  \n",
            " batch_normalization_151 (B  (None, 25, 25, 196)          784       ['conv2d_148[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_22 (Activation)  (None, 25, 25, 196)          0         ['batch_normalization_151[0][0\n",
            "                                                                    ]']                           \n",
            "                                                                                                  \n",
            " global_average_pooling2d (  (None, 196)                  0         ['activation_22[0][0]']       \n",
            " GlobalAveragePooling2D)                                                                          \n",
            "                                                                                                  \n",
            " dense_2 (Dense)             (None, 2)                    394       ['global_average_pooling2d[0][\n",
            "                                                                    0]']                          \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 1025570 (3.91 MB)\n",
            "Trainable params: 1017714 (3.88 MB)\n",
            "Non-trainable params: 7856 (30.69 KB)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "\n",
        "# Define steps per epoch and validation steps\n",
        "steps_per_epoch = len(x_train_normalized) // batch_size\n",
        "validation_steps = len(x_val_normalized) // batch_size\n",
        "\n",
        "# Train the model\n",
        "history = shufflenet_model.fit(\n",
        "    train_set_conv,\n",
        "    steps_per_epoch=steps_per_epoch,\n",
        "    epochs=25,  # You can adjust the number of epochs\n",
        "    validation_data=valid_set_conv,\n",
        "    validation_steps=validation_steps\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uy-XajMKply9",
        "outputId": "e400a4dc-37c3-45cd-92c7-fec28e14965b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "36/36 [==============================] - 22s 241ms/step - loss: 1.1040 - accuracy: 0.4376 - val_loss: 0.6937 - val_accuracy: 0.4750\n",
            "Epoch 2/25\n",
            "36/36 [==============================] - 10s 263ms/step - loss: 0.9024 - accuracy: 0.5411 - val_loss: 0.6936 - val_accuracy: 0.4875\n",
            "Epoch 3/25\n",
            "36/36 [==============================] - 10s 265ms/step - loss: 0.7912 - accuracy: 0.6622 - val_loss: 0.6938 - val_accuracy: 0.4781\n",
            "Epoch 4/25\n",
            "36/36 [==============================] - 8s 225ms/step - loss: 0.7294 - accuracy: 0.7124 - val_loss: 0.6932 - val_accuracy: 0.4844\n",
            "Epoch 5/25\n",
            "36/36 [==============================] - 10s 264ms/step - loss: 0.6587 - accuracy: 0.7408 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
            "Epoch 6/25\n",
            "36/36 [==============================] - 10s 271ms/step - loss: 0.6111 - accuracy: 0.7679 - val_loss: 0.6928 - val_accuracy: 0.5125\n",
            "Epoch 7/25\n",
            "36/36 [==============================] - 8s 223ms/step - loss: 0.5780 - accuracy: 0.7790 - val_loss: 0.6922 - val_accuracy: 0.5219\n",
            "Epoch 8/25\n",
            "36/36 [==============================] - 10s 258ms/step - loss: 0.5359 - accuracy: 0.7941 - val_loss: 0.6953 - val_accuracy: 0.5156\n",
            "Epoch 9/25\n",
            "36/36 [==============================] - 10s 272ms/step - loss: 0.5073 - accuracy: 0.8056 - val_loss: 0.7002 - val_accuracy: 0.5188\n",
            "Epoch 10/25\n",
            "36/36 [==============================] - 8s 218ms/step - loss: 0.4964 - accuracy: 0.7976 - val_loss: 0.7070 - val_accuracy: 0.5250\n",
            "Epoch 11/25\n",
            "36/36 [==============================] - 10s 270ms/step - loss: 0.4766 - accuracy: 0.8114 - val_loss: 0.7202 - val_accuracy: 0.5156\n",
            "Epoch 12/25\n",
            "36/36 [==============================] - 9s 249ms/step - loss: 0.4645 - accuracy: 0.8131 - val_loss: 0.7138 - val_accuracy: 0.5250\n",
            "Epoch 13/25\n",
            "36/36 [==============================] - 8s 222ms/step - loss: 0.4613 - accuracy: 0.8105 - val_loss: 0.6976 - val_accuracy: 0.5281\n",
            "Epoch 14/25\n",
            "36/36 [==============================] - 10s 269ms/step - loss: 0.4424 - accuracy: 0.8123 - val_loss: 0.6627 - val_accuracy: 0.5656\n",
            "Epoch 15/25\n",
            "36/36 [==============================] - 9s 246ms/step - loss: 0.4487 - accuracy: 0.8145 - val_loss: 0.6115 - val_accuracy: 0.5969\n",
            "Epoch 16/25\n",
            "36/36 [==============================] - 8s 218ms/step - loss: 0.4277 - accuracy: 0.8198 - val_loss: 0.5527 - val_accuracy: 0.6438\n",
            "Epoch 17/25\n",
            "36/36 [==============================] - 9s 255ms/step - loss: 0.4226 - accuracy: 0.8225 - val_loss: 0.4870 - val_accuracy: 0.6906\n",
            "Epoch 18/25\n",
            "36/36 [==============================] - 10s 270ms/step - loss: 0.4105 - accuracy: 0.8180 - val_loss: 0.4300 - val_accuracy: 0.7625\n",
            "Epoch 19/25\n",
            "36/36 [==============================] - 8s 218ms/step - loss: 0.4058 - accuracy: 0.8273 - val_loss: 0.3779 - val_accuracy: 0.7875\n",
            "Epoch 20/25\n",
            "36/36 [==============================] - 9s 240ms/step - loss: 0.3974 - accuracy: 0.8225 - val_loss: 0.3465 - val_accuracy: 0.8281\n",
            "Epoch 21/25\n",
            "36/36 [==============================] - 10s 269ms/step - loss: 0.3897 - accuracy: 0.8265 - val_loss: 0.3303 - val_accuracy: 0.8562\n",
            "Epoch 22/25\n",
            "36/36 [==============================] - 8s 226ms/step - loss: 0.3775 - accuracy: 0.8251 - val_loss: 0.3148 - val_accuracy: 0.8750\n",
            "Epoch 23/25\n",
            "36/36 [==============================] - 8s 220ms/step - loss: 0.3868 - accuracy: 0.8300 - val_loss: 0.3179 - val_accuracy: 0.8719\n",
            "Epoch 24/25\n",
            "36/36 [==============================] - 10s 272ms/step - loss: 0.3848 - accuracy: 0.8336 - val_loss: 0.3263 - val_accuracy: 0.8687\n",
            "Epoch 25/25\n",
            "36/36 [==============================] - 13s 360ms/step - loss: 0.3774 - accuracy: 0.8304 - val_loss: 0.3236 - val_accuracy: 0.8750\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on the training data\n",
        "train_loss, train_accuracy = shufflenet_model.evaluate(train_set_conv, steps=steps_per_epoch)\n",
        "print(f\"Training Loss: {train_loss:.4f}\")\n",
        "print(f\"Training Accuracy: {train_accuracy * 100:.2f}%\")\n",
        "\n",
        "# Evaluate the model on the test data\n",
        "test_loss, test_accuracy = shufflenet_model.evaluate(test_set_conv, steps=validation_steps)\n",
        "print(f\"Test Loss: {test_loss:.4f}\")\n",
        "print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RSnmXTC0rgkf",
        "outputId": "9e6ea7e7-e1f6-43e9-8145-872159d21219"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "36/36 [==============================] - 11s 317ms/step - loss: 0.3513 - accuracy: 0.8359\n",
            "Training Loss: 0.3513\n",
            "Training Accuracy: 83.59%\n",
            "5/5 [==============================] - 0s 60ms/step - loss: 0.3635 - accuracy: 0.8500\n",
            "Test Loss: 0.3635\n",
            "Test Accuracy: 85.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_features = shufflenet_model.predict(x_train_normalized)\n",
        "x_val_features = shufflenet_model.predict(x_val_normalized)\n",
        "x_test_features = shufflenet_model.predict(x_test_normalized)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GGpcNLq2DZ58",
        "outputId": "b861e432-eb92-4ea1-a86a-202a6dbd5bd5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "73/73 [==============================] - 2s 21ms/step\n",
            "11/11 [==============================] - 0s 44ms/step\n",
            "21/21 [==============================] - 1s 38ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "d_Wvxch7M6UF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_features = x_train_features.reshape(x_train_features.shape[0], -1)\n",
        "x_val_features = x_val_features.reshape(x_val_features.shape[0], -1)\n",
        "x_test_features = x_test_features.reshape(x_test_features.shape[0], -1)"
      ],
      "metadata": {
        "id": "XbPLQEM5DZ7l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix"
      ],
      "metadata": {
        "id": "A-Ct9-3yDtlf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Define the parameter grid for GridSearchCV\n",
        "param_grid = {\n",
        "    'C': [0.1, 1, 10, 100],  # Example values for the regularization parameter\n",
        "    'gamma': ['scale', 'auto', 0.1, 1]  # Example values for the kernel coefficient (gamma) parameter\n",
        "}\n",
        "\n",
        "# Instantiate the SVM classifier\n",
        "svm_model = SVC(kernel='rbf')\n",
        "\n",
        "# Early stopping parameters\n",
        "max_epochs = 25  # Maximum number of epochs (iterations) to train\n",
        "patience = 5  # Number of epochs to wait for improvement\n",
        "best_accuracy = 0  # Best validation accuracy\n",
        "counter = 0  # Counter to keep track of epochs with no improvement\n",
        "\n",
        "# Training loop with early stopping and hyperparameter tuning using GridSearchCV\n",
        "for epoch in range(max_epochs):\n",
        "    # Perform grid search on your training data (x_train_features, y_train)\n",
        "    grid_search = GridSearchCV(estimator=svm_model, param_grid=param_grid, cv=3, n_jobs=-1, scoring='accuracy')\n",
        "    grid_search.fit(x_train_features, y_train)\n",
        "\n",
        "    # Get the best hyperparameters and best model\n",
        "    best_params = grid_search.best_params_\n",
        "    best_svm_model = grid_search.best_estimator_\n",
        "\n",
        "    # Validate the best model on the validation data\n",
        "    y_pred_val = best_svm_model.predict(x_val_features)\n",
        "    val_accuracy = accuracy_score(y_val, y_pred_val)\n",
        "\n",
        "    print(\"Epoch {}: Validation Accuracy: {:.4f}\".format(epoch, val_accuracy))\n",
        "\n",
        "    # Check for improvement in validation accuracy\n",
        "    if val_accuracy > best_accuracy:\n",
        "        best_accuracy = val_accuracy\n",
        "        counter = 0\n",
        "    else:\n",
        "        counter += 1\n",
        "\n",
        "    # Early stopping condition\n",
        "    if counter >= patience:\n",
        "        print(\"Early stopping after {} epochs of no improvement.\".format(epoch))\n",
        "        break\n",
        "\n",
        "# Evaluate the best model on the test data\n",
        "y_pred_svm = best_svm_model.predict(x_test_features)\n",
        "svm_accuracy = accuracy_score(y_test, y_pred_svm)\n",
        "svm_precision = precision_score(y_test, y_pred_svm)\n",
        "svm_recall = recall_score(y_test, y_pred_svm)\n",
        "svm_f1 = f1_score(y_test, y_pred_svm)\n",
        "\n",
        "tn, fp, fn, tp = confusion_matrix(y_test, y_pred_svm).ravel()\n",
        "svm_specificity = tn / (tn + fp)\n",
        "\n",
        "print(\"Best Hyperparameters:\", best_params)\n",
        "print(\"SVM Accuracy:\", svm_accuracy)\n",
        "print(\"SVM Precision:\", svm_precision)\n",
        "print(\"SVM Sensitivity (Recall):\", svm_recall)\n",
        "print(\"SVM Specificity:\", svm_specificity)\n",
        "print(\"SVM F1 Score:\", svm_f1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MlZ4CiFvEX7e",
        "outputId": "9744e3ac-8246-4a27-adab-d8608a573e43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0: Validation Accuracy: 0.8731\n",
            "Epoch 1: Validation Accuracy: 0.8731\n",
            "Epoch 2: Validation Accuracy: 0.8731\n",
            "Epoch 3: Validation Accuracy: 0.8731\n",
            "Epoch 4: Validation Accuracy: 0.8731\n",
            "Epoch 5: Validation Accuracy: 0.8731\n",
            "Early stopping after 5 epochs of no improvement.\n",
            "Best Hyperparameters: {'C': 1, 'gamma': 1}\n",
            "SVM Accuracy: 0.8431372549019608\n",
            "SVM Precision: 0.8016304347826086\n",
            "SVM Sensitivity (Recall): 0.9049079754601227\n",
            "SVM Specificity: 0.7833827893175074\n",
            "SVM F1 Score: 0.8501440922190201\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
        "\n",
        "# Define a wider range of hyperparameters for the grid search\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'max_depth': [None, 10, 20],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4]\n",
        "}\n",
        "\n",
        "# Instantiate the Random Forest Classifier\n",
        "rf_model = RandomForestClassifier(random_state=42)\n",
        "\n",
        "# Perform Grid Search with cross-validation\n",
        "grid_search = GridSearchCV(estimator=rf_model, param_grid=param_grid, cv=3, n_jobs=-1, scoring='accuracy')\n",
        "\n",
        "# Fit the grid search to the data\n",
        "grid_search.fit(x_train_features, y_train)\n",
        "\n",
        "# Get the best hyperparameters and best model\n",
        "best_params = grid_search.best_params_\n",
        "best_rf_model = grid_search.best_estimator_\n",
        "\n",
        "# Evaluate the best model using cross-validation\n",
        "cv_scores = cross_val_score(best_rf_model, x_train_features, y_train, cv=5, scoring='accuracy')\n",
        "mean_cv_accuracy = cv_scores.mean()\n",
        "\n",
        "# Evaluate the best model on the test data\n",
        "y_pred_rf = best_rf_model.predict(x_test_features)\n",
        "rf_accuracy = accuracy_score(y_test, y_pred_rf)\n",
        "rf_precision = precision_score(y_test, y_pred_rf)\n",
        "rf_recall = recall_score(y_test, y_pred_rf)\n",
        "rf_f1 = f1_score(y_test, y_pred_rf)\n",
        "\n",
        "tn, fp, fn, tp = confusion_matrix(y_test, y_pred_rf).ravel()\n",
        "rf_specificity = tn / (tn + fp)\n",
        "\n",
        "print(\"Best Hyperparameters:\", best_params)\n",
        "print(\"Mean Cross-Validation Accuracy:\", mean_cv_accuracy)\n",
        "print(\"Random Forest Accuracy on Test Data:\", rf_accuracy)\n",
        "print(\"Random Forest Precision:\", rf_precision)\n",
        "print(\"Random Forest Sensitivity (Recall):\", rf_recall)\n",
        "print(\"Random Forest Specificity:\", rf_specificity)\n",
        "print(\"Random Forest F1 Score:\", rf_f1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nIiKeMbLGmaG",
        "outputId": "53a002a4-9378-4d29-86e8-7e09f827e56a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Hyperparameters: {'max_depth': 10, 'min_samples_leaf': 4, 'min_samples_split': 10, 'n_estimators': 100}\n",
            "Mean Cross-Validation Accuracy: 0.8114033291129813\n",
            "Random Forest Accuracy on Test Data: 0.8295625942684767\n",
            "Random Forest Precision: 0.8016997167138811\n",
            "Random Forest Sensitivity (Recall): 0.8680981595092024\n",
            "Random Forest Specificity: 0.7922848664688428\n",
            "Random Forest F1 Score: 0.8335787923416791\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "# Define a wider range of neighbors for RandomizedSearchCV\n",
        "param_dist = {\n",
        "    'n_neighbors': list(range(1, 101))  # Experiment with a wider range of neighbors (1 to 100)\n",
        "}\n",
        "\n",
        "# Instantiate the KNN Classifier\n",
        "knn_model = KNeighborsClassifier()\n",
        "\n",
        "# Perform RandomizedSearchCV\n",
        "random_search = RandomizedSearchCV(estimator=knn_model, param_distributions=param_dist, n_iter=30, cv=3, n_jobs=-1, scoring='accuracy')\n",
        "\n",
        "# Fit the randomized search to the data\n",
        "random_search.fit(x_train_features, y_train)\n",
        "\n",
        "# Get the best hyperparameters and best model\n",
        "best_params = random_search.best_params_\n",
        "best_knn_model = random_search.best_estimator_\n",
        "\n",
        "# Evaluate the best model using cross-validation\n",
        "cv_scores = cross_val_score(best_knn_model, x_train_features, y_train, cv=5, scoring='accuracy')\n",
        "mean_cv_accuracy = cv_scores.mean()\n",
        "\n",
        "# Evaluate the best model on the test data\n",
        "y_pred_knn = best_knn_model.predict(x_test_features)\n",
        "knn_accuracy = accuracy_score(y_test, y_pred_knn)\n",
        "knn_precision = precision_score(y_test, y_pred_knn)\n",
        "knn_recall = recall_score(y_test, y_pred_knn)\n",
        "knn_f1 = f1_score(y_test, y_pred_knn)\n",
        "\n",
        "tn, fp, fn, tp = confusion_matrix(y_test, y_pred_knn).ravel()\n",
        "knn_specificity = tn / (tn + fp)\n",
        "\n",
        "print(\"Best Hyperparameters:\", best_params)\n",
        "print(\"Mean Cross-Validation Accuracy:\", mean_cv_accuracy)\n",
        "print(\"KNN Accuracy on Test Data:\", knn_accuracy)\n",
        "print(\"KNN Precision:\", knn_precision)\n",
        "print(\"KNN Sensitivity (Recall):\", knn_recall)\n",
        "print(\"KNN Specificity:\", knn_specificity)\n",
        "print(\"KNN F1 Score:\", knn_f1)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PTNbp-xdH7wI",
        "outputId": "86ad98f9-ce49-4bba-a9d0-f258777ca5fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Hyperparameters: {'n_neighbors': 92}\n",
            "Mean Cross-Validation Accuracy: 0.8355673270276309\n",
            "KNN Accuracy on Test Data: 0.8401206636500754\n",
            "KNN Precision: 0.7941176470588235\n",
            "KNN Sensitivity (Recall): 0.911042944785276\n",
            "KNN Specificity: 0.771513353115727\n",
            "KNN F1 Score: 0.8485714285714285\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Conv2D, DepthwiseConv2D, BatchNormalization, ReLU, GlobalAveragePooling2D, Dense\n",
        "\n",
        "def MobileNetCustom(input_shape, num_classes):\n",
        "    input_tensor = Input(shape=input_shape)\n",
        "\n",
        "    # Initial Convolution Layer\n",
        "    x = Conv2D(32, (3, 3), strides=(2, 2), padding='same')(input_tensor)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = ReLU()(x)\n",
        "\n",
        "    # Depthwise Convolution Blocks\n",
        "    def depthwise_block(x, filters, strides):\n",
        "        x = DepthwiseConv2D((3, 3), strides=strides, padding='same')(x)\n",
        "        x = BatchNormalization()(x)\n",
        "        x = ReLU()(x)\n",
        "        x = Conv2D(filters, (1, 1), padding='same')(x)\n",
        "        x = BatchNormalization()(x)\n",
        "        x = ReLU()(x)\n",
        "        return x\n",
        "\n",
        "    x = depthwise_block(x, 64, (1, 1))\n",
        "    x = depthwise_block(x, 128, (2, 2))\n",
        "    x = depthwise_block(x, 128, (1, 1))\n",
        "    x = depthwise_block(x, 256, (2, 2))\n",
        "    x = depthwise_block(x, 256, (1, 1))\n",
        "    x = depthwise_block(x, 512, (2, 2))\n",
        "\n",
        "    # Global Average Pooling\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "\n",
        "    # Fully Connected Layer\n",
        "    x = Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "    model = tf.keras.Model(inputs=input_tensor, outputs=x)\n",
        "\n",
        "    return model\n",
        "\n",
        "input_shape = (100, 100, 3)\n",
        "num_classes = 2\n",
        "mobilenet_custom_model = MobileNetCustom(input_shape, num_classes)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.00001)\n",
        "mobilenet_custom_model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "early_stopping = EarlyStopping(monitor='val_accuracy',  # You can choose 'val_loss' or other metrics\n",
        "                               patience=10,             # Number of epochs with no improvement before stopping\n",
        "                               restore_best_weights=True)\n",
        "\n",
        "mobilenet_custom_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1GezI2g6tAaz",
        "outputId": "c90170a4-cedb-4847-93de-68a3290faf99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_7 (InputLayer)        [(None, 100, 100, 3)]     0         \n",
            "                                                                 \n",
            " conv2d_156 (Conv2D)         (None, 50, 50, 32)        896       \n",
            "                                                                 \n",
            " batch_normalization_165 (B  (None, 50, 50, 32)        128       \n",
            " atchNormalization)                                              \n",
            "                                                                 \n",
            " re_lu_111 (ReLU)            (None, 50, 50, 32)        0         \n",
            "                                                                 \n",
            " depthwise_conv2d_9 (Depthw  (None, 50, 50, 32)        320       \n",
            " iseConv2D)                                                      \n",
            "                                                                 \n",
            " batch_normalization_166 (B  (None, 50, 50, 32)        128       \n",
            " atchNormalization)                                              \n",
            "                                                                 \n",
            " re_lu_112 (ReLU)            (None, 50, 50, 32)        0         \n",
            "                                                                 \n",
            " conv2d_157 (Conv2D)         (None, 50, 50, 64)        2112      \n",
            "                                                                 \n",
            " batch_normalization_167 (B  (None, 50, 50, 64)        256       \n",
            " atchNormalization)                                              \n",
            "                                                                 \n",
            " re_lu_113 (ReLU)            (None, 50, 50, 64)        0         \n",
            "                                                                 \n",
            " depthwise_conv2d_10 (Depth  (None, 25, 25, 64)        640       \n",
            " wiseConv2D)                                                     \n",
            "                                                                 \n",
            " batch_normalization_168 (B  (None, 25, 25, 64)        256       \n",
            " atchNormalization)                                              \n",
            "                                                                 \n",
            " re_lu_114 (ReLU)            (None, 25, 25, 64)        0         \n",
            "                                                                 \n",
            " conv2d_158 (Conv2D)         (None, 25, 25, 128)       8320      \n",
            "                                                                 \n",
            " batch_normalization_169 (B  (None, 25, 25, 128)       512       \n",
            " atchNormalization)                                              \n",
            "                                                                 \n",
            " re_lu_115 (ReLU)            (None, 25, 25, 128)       0         \n",
            "                                                                 \n",
            " depthwise_conv2d_11 (Depth  (None, 25, 25, 128)       1280      \n",
            " wiseConv2D)                                                     \n",
            "                                                                 \n",
            " batch_normalization_170 (B  (None, 25, 25, 128)       512       \n",
            " atchNormalization)                                              \n",
            "                                                                 \n",
            " re_lu_116 (ReLU)            (None, 25, 25, 128)       0         \n",
            "                                                                 \n",
            " conv2d_159 (Conv2D)         (None, 25, 25, 128)       16512     \n",
            "                                                                 \n",
            " batch_normalization_171 (B  (None, 25, 25, 128)       512       \n",
            " atchNormalization)                                              \n",
            "                                                                 \n",
            " re_lu_117 (ReLU)            (None, 25, 25, 128)       0         \n",
            "                                                                 \n",
            " depthwise_conv2d_12 (Depth  (None, 13, 13, 128)       1280      \n",
            " wiseConv2D)                                                     \n",
            "                                                                 \n",
            " batch_normalization_172 (B  (None, 13, 13, 128)       512       \n",
            " atchNormalization)                                              \n",
            "                                                                 \n",
            " re_lu_118 (ReLU)            (None, 13, 13, 128)       0         \n",
            "                                                                 \n",
            " conv2d_160 (Conv2D)         (None, 13, 13, 256)       33024     \n",
            "                                                                 \n",
            " batch_normalization_173 (B  (None, 13, 13, 256)       1024      \n",
            " atchNormalization)                                              \n",
            "                                                                 \n",
            " re_lu_119 (ReLU)            (None, 13, 13, 256)       0         \n",
            "                                                                 \n",
            " depthwise_conv2d_13 (Depth  (None, 13, 13, 256)       2560      \n",
            " wiseConv2D)                                                     \n",
            "                                                                 \n",
            " batch_normalization_174 (B  (None, 13, 13, 256)       1024      \n",
            " atchNormalization)                                              \n",
            "                                                                 \n",
            " re_lu_120 (ReLU)            (None, 13, 13, 256)       0         \n",
            "                                                                 \n",
            " conv2d_161 (Conv2D)         (None, 13, 13, 256)       65792     \n",
            "                                                                 \n",
            " batch_normalization_175 (B  (None, 13, 13, 256)       1024      \n",
            " atchNormalization)                                              \n",
            "                                                                 \n",
            " re_lu_121 (ReLU)            (None, 13, 13, 256)       0         \n",
            "                                                                 \n",
            " depthwise_conv2d_14 (Depth  (None, 7, 7, 256)         2560      \n",
            " wiseConv2D)                                                     \n",
            "                                                                 \n",
            " batch_normalization_176 (B  (None, 7, 7, 256)         1024      \n",
            " atchNormalization)                                              \n",
            "                                                                 \n",
            " re_lu_122 (ReLU)            (None, 7, 7, 256)         0         \n",
            "                                                                 \n",
            " conv2d_162 (Conv2D)         (None, 7, 7, 512)         131584    \n",
            "                                                                 \n",
            " batch_normalization_177 (B  (None, 7, 7, 512)         2048      \n",
            " atchNormalization)                                              \n",
            "                                                                 \n",
            " re_lu_123 (ReLU)            (None, 7, 7, 512)         0         \n",
            "                                                                 \n",
            " global_average_pooling2d_2  (None, 512)               0         \n",
            "  (GlobalAveragePooling2D)                                       \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 2)                 1026      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 276866 (1.06 MB)\n",
            "Trainable params: 272386 (1.04 MB)\n",
            "Non-trainable params: 4480 (17.50 KB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# Define early stopping callback\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "\n",
        "# Perform hyperparameter tuning with early stopping\n",
        "best_accuracy = 0\n",
        "best_hyperparameters = None\n",
        "\n",
        "for epoch in range(25):\n",
        "    # Train the model with the current hyperparameters\n",
        "    training_history = mobilenet_custom_model.fit(\n",
        "        train_set_conv,\n",
        "        steps_per_epoch=steps_per_epoch,\n",
        "        epochs=1,  # Train for one epoch at a time\n",
        "        validation_data=valid_set_conv,\n",
        "        validation_steps=validation_steps,\n",
        "        callbacks=[early_stopping]\n",
        "    )\n",
        "\n",
        "    # Get the validation accuracy from the training history\n",
        "    val_accuracy = training_history.history['val_accuracy'][0]\n",
        "\n",
        "    # Check for improvement in validation accuracy\n",
        "    if val_accuracy > best_accuracy:\n",
        "        best_accuracy = val_accuracy\n",
        "        best_hyperparameters = mobilenet_custom_model.get_config()  # Save the best hyperparameters\n",
        "\n",
        "    print(\"Epoch {}: Validation Accuracy: {:.4f}\".format(epoch, val_accuracy))\n",
        "\n",
        "    # Early stopping condition\n",
        "    if early_stopping.stopped_epoch > 0:\n",
        "        print(\"Early stopping after {} epochs of no improvement.\".format(early_stopping.stopped_epoch))\n",
        "        break\n",
        "\n",
        "# Evaluate the model with the best hyperparameters on the test data\n",
        "test_accuracy = mobilenet_custom_model.evaluate(test_set_conv)[1]\n",
        "print(\"Best Validation Accuracy:\", best_accuracy)\n",
        "print(\"Test Accuracy with Best Hyperparameters:\", test_accuracy)\n",
        "print(\"Best Hyperparameters:\", best_hyperparameters)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ey745hVWtjTE",
        "outputId": "6d2f7035-ffb9-4fdf-926d-e7f6b28ddd47"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "36/36 [==============================] - 13s 377ms/step - loss: 0.4616 - accuracy: 0.7723 - val_loss: 0.9020 - val_accuracy: 0.5219\n",
            "Epoch 0: Validation Accuracy: 0.5219\n",
            "36/36 [==============================] - 6s 174ms/step - loss: 0.4395 - accuracy: 0.7932 - val_loss: 0.9890 - val_accuracy: 0.5156\n",
            "Epoch 1: Validation Accuracy: 0.5156\n",
            "36/36 [==============================] - 6s 173ms/step - loss: 0.4350 - accuracy: 0.7949 - val_loss: 1.0833 - val_accuracy: 0.5156\n",
            "Epoch 2: Validation Accuracy: 0.5156\n",
            "36/36 [==============================] - 8s 229ms/step - loss: 0.4248 - accuracy: 0.7958 - val_loss: 1.1667 - val_accuracy: 0.5219\n",
            "Epoch 3: Validation Accuracy: 0.5219\n",
            "36/36 [==============================] - 6s 172ms/step - loss: 0.4118 - accuracy: 0.7914 - val_loss: 1.2757 - val_accuracy: 0.5125\n",
            "Epoch 4: Validation Accuracy: 0.5125\n",
            "36/36 [==============================] - 8s 233ms/step - loss: 0.4136 - accuracy: 0.7887 - val_loss: 1.3103 - val_accuracy: 0.5250\n",
            "Epoch 5: Validation Accuracy: 0.5250\n",
            "36/36 [==============================] - 6s 174ms/step - loss: 0.4025 - accuracy: 0.8038 - val_loss: 1.3605 - val_accuracy: 0.5156\n",
            "Epoch 6: Validation Accuracy: 0.5156\n",
            "36/36 [==============================] - 7s 184ms/step - loss: 0.4036 - accuracy: 0.8074 - val_loss: 1.3233 - val_accuracy: 0.5188\n",
            "Epoch 7: Validation Accuracy: 0.5188\n",
            "36/36 [==============================] - 8s 209ms/step - loss: 0.4006 - accuracy: 0.8109 - val_loss: 1.2108 - val_accuracy: 0.5219\n",
            "Epoch 8: Validation Accuracy: 0.5219\n",
            "36/36 [==============================] - 7s 194ms/step - loss: 0.4023 - accuracy: 0.8016 - val_loss: 1.0789 - val_accuracy: 0.5125\n",
            "Epoch 9: Validation Accuracy: 0.5125\n",
            "36/36 [==============================] - 7s 199ms/step - loss: 0.3921 - accuracy: 0.8087 - val_loss: 0.8866 - val_accuracy: 0.5219\n",
            "Epoch 10: Validation Accuracy: 0.5219\n",
            "36/36 [==============================] - 8s 229ms/step - loss: 0.3925 - accuracy: 0.8007 - val_loss: 0.6893 - val_accuracy: 0.5562\n",
            "Epoch 11: Validation Accuracy: 0.5562\n",
            "36/36 [==============================] - 6s 175ms/step - loss: 0.3931 - accuracy: 0.8105 - val_loss: 0.5453 - val_accuracy: 0.6406\n",
            "Epoch 12: Validation Accuracy: 0.6406\n",
            "36/36 [==============================] - 6s 169ms/step - loss: 0.3860 - accuracy: 0.8074 - val_loss: 0.4511 - val_accuracy: 0.7469\n",
            "Epoch 13: Validation Accuracy: 0.7469\n",
            "36/36 [==============================] - 8s 234ms/step - loss: 0.3832 - accuracy: 0.8091 - val_loss: 0.3840 - val_accuracy: 0.7969\n",
            "Epoch 14: Validation Accuracy: 0.7969\n",
            "36/36 [==============================] - 6s 173ms/step - loss: 0.3936 - accuracy: 0.8109 - val_loss: 0.3687 - val_accuracy: 0.8281\n",
            "Epoch 15: Validation Accuracy: 0.8281\n",
            "36/36 [==============================] - 8s 230ms/step - loss: 0.3867 - accuracy: 0.8123 - val_loss: 0.3611 - val_accuracy: 0.8375\n",
            "Epoch 16: Validation Accuracy: 0.8375\n",
            "36/36 [==============================] - 6s 172ms/step - loss: 0.3876 - accuracy: 0.8051 - val_loss: 0.3508 - val_accuracy: 0.8469\n",
            "Epoch 17: Validation Accuracy: 0.8469\n",
            "36/36 [==============================] - 8s 224ms/step - loss: 0.3826 - accuracy: 0.8109 - val_loss: 0.3453 - val_accuracy: 0.8438\n",
            "Epoch 18: Validation Accuracy: 0.8438\n",
            "36/36 [==============================] - 6s 174ms/step - loss: 0.3841 - accuracy: 0.8176 - val_loss: 0.3413 - val_accuracy: 0.8469\n",
            "Epoch 19: Validation Accuracy: 0.8469\n",
            "36/36 [==============================] - 8s 233ms/step - loss: 0.3826 - accuracy: 0.8078 - val_loss: 0.3491 - val_accuracy: 0.8344\n",
            "Epoch 20: Validation Accuracy: 0.8344\n",
            "36/36 [==============================] - 6s 168ms/step - loss: 0.3878 - accuracy: 0.8034 - val_loss: 0.3481 - val_accuracy: 0.8375\n",
            "Epoch 21: Validation Accuracy: 0.8375\n",
            "36/36 [==============================] - 8s 233ms/step - loss: 0.3856 - accuracy: 0.8100 - val_loss: 0.3400 - val_accuracy: 0.8438\n",
            "Epoch 22: Validation Accuracy: 0.8438\n",
            "36/36 [==============================] - 8s 215ms/step - loss: 0.3782 - accuracy: 0.8189 - val_loss: 0.3498 - val_accuracy: 0.8281\n",
            "Epoch 23: Validation Accuracy: 0.8281\n",
            "36/36 [==============================] - 6s 171ms/step - loss: 0.3822 - accuracy: 0.8029 - val_loss: 0.3470 - val_accuracy: 0.8281\n",
            "Epoch 24: Validation Accuracy: 0.8281\n",
            "11/11 [==============================] - 0s 38ms/step - loss: 0.3955 - accuracy: 0.8446\n",
            "Best Validation Accuracy: 0.846875011920929\n",
            "Test Accuracy with Best Hyperparameters: 0.8446455597877502\n",
            "Best Hyperparameters: {'name': 'model_2', 'trainable': True, 'layers': [{'module': 'keras.layers', 'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 100, 100, 3), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'input_7'}, 'registered_name': None, 'name': 'input_7', 'inbound_nodes': []}, {'module': 'keras.layers', 'class_name': 'Conv2D', 'config': {'name': 'conv2d_156', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (3, 3), 'strides': (2, 2), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'module': 'keras.initializers', 'class_name': 'GlorotUniform', 'config': {'seed': None}, 'registered_name': None}, 'bias_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}, 'registered_name': None, 'build_config': {'input_shape': (None, 100, 100, 3)}, 'name': 'conv2d_156', 'inbound_nodes': [[['input_7', 0, 0, {}]]]}, {'module': 'keras.layers', 'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_165', 'trainable': True, 'dtype': 'float32', 'axis': [3], 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'gamma_initializer': {'module': 'keras.initializers', 'class_name': 'Ones', 'config': {}, 'registered_name': None}, 'moving_mean_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'moving_variance_initializer': {'module': 'keras.initializers', 'class_name': 'Ones', 'config': {}, 'registered_name': None}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}, 'registered_name': None, 'build_config': {'input_shape': (None, 50, 50, 32)}, 'name': 'batch_normalization_165', 'inbound_nodes': [[['conv2d_156', 0, 0, {}]]]}, {'module': 'keras.layers', 'class_name': 'ReLU', 'config': {'name': 're_lu_111', 'trainable': True, 'dtype': 'float32', 'max_value': None, 'negative_slope': 0.0, 'threshold': 0.0}, 'registered_name': None, 'build_config': {'input_shape': (None, 50, 50, 32)}, 'name': 're_lu_111', 'inbound_nodes': [[['batch_normalization_165', 0, 0, {}]]]}, {'module': 'keras.layers', 'class_name': 'DepthwiseConv2D', 'config': {'name': 'depthwise_conv2d_9', 'trainable': True, 'dtype': 'float32', 'kernel_size': (3, 3), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'linear', 'use_bias': True, 'bias_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'bias_regularizer': None, 'activity_regularizer': None, 'bias_constraint': None, 'depth_multiplier': 1, 'depthwise_initializer': {'module': 'keras.initializers', 'class_name': 'GlorotUniform', 'config': {'seed': None}, 'registered_name': None}, 'depthwise_regularizer': None, 'depthwise_constraint': None}, 'registered_name': None, 'build_config': {'input_shape': (None, 50, 50, 32)}, 'name': 'depthwise_conv2d_9', 'inbound_nodes': [[['re_lu_111', 0, 0, {}]]]}, {'module': 'keras.layers', 'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_166', 'trainable': True, 'dtype': 'float32', 'axis': [3], 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'gamma_initializer': {'module': 'keras.initializers', 'class_name': 'Ones', 'config': {}, 'registered_name': None}, 'moving_mean_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'moving_variance_initializer': {'module': 'keras.initializers', 'class_name': 'Ones', 'config': {}, 'registered_name': None}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}, 'registered_name': None, 'build_config': {'input_shape': (None, 50, 50, 32)}, 'name': 'batch_normalization_166', 'inbound_nodes': [[['depthwise_conv2d_9', 0, 0, {}]]]}, {'module': 'keras.layers', 'class_name': 'ReLU', 'config': {'name': 're_lu_112', 'trainable': True, 'dtype': 'float32', 'max_value': None, 'negative_slope': 0.0, 'threshold': 0.0}, 'registered_name': None, 'build_config': {'input_shape': (None, 50, 50, 32)}, 'name': 're_lu_112', 'inbound_nodes': [[['batch_normalization_166', 0, 0, {}]]]}, {'module': 'keras.layers', 'class_name': 'Conv2D', 'config': {'name': 'conv2d_157', 'trainable': True, 'dtype': 'float32', 'filters': 64, 'kernel_size': (1, 1), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'module': 'keras.initializers', 'class_name': 'GlorotUniform', 'config': {'seed': None}, 'registered_name': None}, 'bias_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}, 'registered_name': None, 'build_config': {'input_shape': (None, 50, 50, 32)}, 'name': 'conv2d_157', 'inbound_nodes': [[['re_lu_112', 0, 0, {}]]]}, {'module': 'keras.layers', 'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_167', 'trainable': True, 'dtype': 'float32', 'axis': [3], 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'gamma_initializer': {'module': 'keras.initializers', 'class_name': 'Ones', 'config': {}, 'registered_name': None}, 'moving_mean_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'moving_variance_initializer': {'module': 'keras.initializers', 'class_name': 'Ones', 'config': {}, 'registered_name': None}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}, 'registered_name': None, 'build_config': {'input_shape': (None, 50, 50, 64)}, 'name': 'batch_normalization_167', 'inbound_nodes': [[['conv2d_157', 0, 0, {}]]]}, {'module': 'keras.layers', 'class_name': 'ReLU', 'config': {'name': 're_lu_113', 'trainable': True, 'dtype': 'float32', 'max_value': None, 'negative_slope': 0.0, 'threshold': 0.0}, 'registered_name': None, 'build_config': {'input_shape': (None, 50, 50, 64)}, 'name': 're_lu_113', 'inbound_nodes': [[['batch_normalization_167', 0, 0, {}]]]}, {'module': 'keras.layers', 'class_name': 'DepthwiseConv2D', 'config': {'name': 'depthwise_conv2d_10', 'trainable': True, 'dtype': 'float32', 'kernel_size': (3, 3), 'strides': (2, 2), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'linear', 'use_bias': True, 'bias_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'bias_regularizer': None, 'activity_regularizer': None, 'bias_constraint': None, 'depth_multiplier': 1, 'depthwise_initializer': {'module': 'keras.initializers', 'class_name': 'GlorotUniform', 'config': {'seed': None}, 'registered_name': None}, 'depthwise_regularizer': None, 'depthwise_constraint': None}, 'registered_name': None, 'build_config': {'input_shape': (None, 50, 50, 64)}, 'name': 'depthwise_conv2d_10', 'inbound_nodes': [[['re_lu_113', 0, 0, {}]]]}, {'module': 'keras.layers', 'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_168', 'trainable': True, 'dtype': 'float32', 'axis': [3], 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'gamma_initializer': {'module': 'keras.initializers', 'class_name': 'Ones', 'config': {}, 'registered_name': None}, 'moving_mean_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'moving_variance_initializer': {'module': 'keras.initializers', 'class_name': 'Ones', 'config': {}, 'registered_name': None}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}, 'registered_name': None, 'build_config': {'input_shape': (None, 25, 25, 64)}, 'name': 'batch_normalization_168', 'inbound_nodes': [[['depthwise_conv2d_10', 0, 0, {}]]]}, {'module': 'keras.layers', 'class_name': 'ReLU', 'config': {'name': 're_lu_114', 'trainable': True, 'dtype': 'float32', 'max_value': None, 'negative_slope': 0.0, 'threshold': 0.0}, 'registered_name': None, 'build_config': {'input_shape': (None, 25, 25, 64)}, 'name': 're_lu_114', 'inbound_nodes': [[['batch_normalization_168', 0, 0, {}]]]}, {'module': 'keras.layers', 'class_name': 'Conv2D', 'config': {'name': 'conv2d_158', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (1, 1), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'module': 'keras.initializers', 'class_name': 'GlorotUniform', 'config': {'seed': None}, 'registered_name': None}, 'bias_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}, 'registered_name': None, 'build_config': {'input_shape': (None, 25, 25, 64)}, 'name': 'conv2d_158', 'inbound_nodes': [[['re_lu_114', 0, 0, {}]]]}, {'module': 'keras.layers', 'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_169', 'trainable': True, 'dtype': 'float32', 'axis': [3], 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'gamma_initializer': {'module': 'keras.initializers', 'class_name': 'Ones', 'config': {}, 'registered_name': None}, 'moving_mean_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'moving_variance_initializer': {'module': 'keras.initializers', 'class_name': 'Ones', 'config': {}, 'registered_name': None}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}, 'registered_name': None, 'build_config': {'input_shape': (None, 25, 25, 128)}, 'name': 'batch_normalization_169', 'inbound_nodes': [[['conv2d_158', 0, 0, {}]]]}, {'module': 'keras.layers', 'class_name': 'ReLU', 'config': {'name': 're_lu_115', 'trainable': True, 'dtype': 'float32', 'max_value': None, 'negative_slope': 0.0, 'threshold': 0.0}, 'registered_name': None, 'build_config': {'input_shape': (None, 25, 25, 128)}, 'name': 're_lu_115', 'inbound_nodes': [[['batch_normalization_169', 0, 0, {}]]]}, {'module': 'keras.layers', 'class_name': 'DepthwiseConv2D', 'config': {'name': 'depthwise_conv2d_11', 'trainable': True, 'dtype': 'float32', 'kernel_size': (3, 3), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'linear', 'use_bias': True, 'bias_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'bias_regularizer': None, 'activity_regularizer': None, 'bias_constraint': None, 'depth_multiplier': 1, 'depthwise_initializer': {'module': 'keras.initializers', 'class_name': 'GlorotUniform', 'config': {'seed': None}, 'registered_name': None}, 'depthwise_regularizer': None, 'depthwise_constraint': None}, 'registered_name': None, 'build_config': {'input_shape': (None, 25, 25, 128)}, 'name': 'depthwise_conv2d_11', 'inbound_nodes': [[['re_lu_115', 0, 0, {}]]]}, {'module': 'keras.layers', 'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_170', 'trainable': True, 'dtype': 'float32', 'axis': [3], 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'gamma_initializer': {'module': 'keras.initializers', 'class_name': 'Ones', 'config': {}, 'registered_name': None}, 'moving_mean_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'moving_variance_initializer': {'module': 'keras.initializers', 'class_name': 'Ones', 'config': {}, 'registered_name': None}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}, 'registered_name': None, 'build_config': {'input_shape': (None, 25, 25, 128)}, 'name': 'batch_normalization_170', 'inbound_nodes': [[['depthwise_conv2d_11', 0, 0, {}]]]}, {'module': 'keras.layers', 'class_name': 'ReLU', 'config': {'name': 're_lu_116', 'trainable': True, 'dtype': 'float32', 'max_value': None, 'negative_slope': 0.0, 'threshold': 0.0}, 'registered_name': None, 'build_config': {'input_shape': (None, 25, 25, 128)}, 'name': 're_lu_116', 'inbound_nodes': [[['batch_normalization_170', 0, 0, {}]]]}, {'module': 'keras.layers', 'class_name': 'Conv2D', 'config': {'name': 'conv2d_159', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (1, 1), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'module': 'keras.initializers', 'class_name': 'GlorotUniform', 'config': {'seed': None}, 'registered_name': None}, 'bias_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}, 'registered_name': None, 'build_config': {'input_shape': (None, 25, 25, 128)}, 'name': 'conv2d_159', 'inbound_nodes': [[['re_lu_116', 0, 0, {}]]]}, {'module': 'keras.layers', 'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_171', 'trainable': True, 'dtype': 'float32', 'axis': [3], 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'gamma_initializer': {'module': 'keras.initializers', 'class_name': 'Ones', 'config': {}, 'registered_name': None}, 'moving_mean_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'moving_variance_initializer': {'module': 'keras.initializers', 'class_name': 'Ones', 'config': {}, 'registered_name': None}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}, 'registered_name': None, 'build_config': {'input_shape': (None, 25, 25, 128)}, 'name': 'batch_normalization_171', 'inbound_nodes': [[['conv2d_159', 0, 0, {}]]]}, {'module': 'keras.layers', 'class_name': 'ReLU', 'config': {'name': 're_lu_117', 'trainable': True, 'dtype': 'float32', 'max_value': None, 'negative_slope': 0.0, 'threshold': 0.0}, 'registered_name': None, 'build_config': {'input_shape': (None, 25, 25, 128)}, 'name': 're_lu_117', 'inbound_nodes': [[['batch_normalization_171', 0, 0, {}]]]}, {'module': 'keras.layers', 'class_name': 'DepthwiseConv2D', 'config': {'name': 'depthwise_conv2d_12', 'trainable': True, 'dtype': 'float32', 'kernel_size': (3, 3), 'strides': (2, 2), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'linear', 'use_bias': True, 'bias_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'bias_regularizer': None, 'activity_regularizer': None, 'bias_constraint': None, 'depth_multiplier': 1, 'depthwise_initializer': {'module': 'keras.initializers', 'class_name': 'GlorotUniform', 'config': {'seed': None}, 'registered_name': None}, 'depthwise_regularizer': None, 'depthwise_constraint': None}, 'registered_name': None, 'build_config': {'input_shape': (None, 25, 25, 128)}, 'name': 'depthwise_conv2d_12', 'inbound_nodes': [[['re_lu_117', 0, 0, {}]]]}, {'module': 'keras.layers', 'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_172', 'trainable': True, 'dtype': 'float32', 'axis': [3], 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'gamma_initializer': {'module': 'keras.initializers', 'class_name': 'Ones', 'config': {}, 'registered_name': None}, 'moving_mean_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'moving_variance_initializer': {'module': 'keras.initializers', 'class_name': 'Ones', 'config': {}, 'registered_name': None}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}, 'registered_name': None, 'build_config': {'input_shape': (None, 13, 13, 128)}, 'name': 'batch_normalization_172', 'inbound_nodes': [[['depthwise_conv2d_12', 0, 0, {}]]]}, {'module': 'keras.layers', 'class_name': 'ReLU', 'config': {'name': 're_lu_118', 'trainable': True, 'dtype': 'float32', 'max_value': None, 'negative_slope': 0.0, 'threshold': 0.0}, 'registered_name': None, 'build_config': {'input_shape': (None, 13, 13, 128)}, 'name': 're_lu_118', 'inbound_nodes': [[['batch_normalization_172', 0, 0, {}]]]}, {'module': 'keras.layers', 'class_name': 'Conv2D', 'config': {'name': 'conv2d_160', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (1, 1), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'module': 'keras.initializers', 'class_name': 'GlorotUniform', 'config': {'seed': None}, 'registered_name': None}, 'bias_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}, 'registered_name': None, 'build_config': {'input_shape': (None, 13, 13, 128)}, 'name': 'conv2d_160', 'inbound_nodes': [[['re_lu_118', 0, 0, {}]]]}, {'module': 'keras.layers', 'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_173', 'trainable': True, 'dtype': 'float32', 'axis': [3], 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'gamma_initializer': {'module': 'keras.initializers', 'class_name': 'Ones', 'config': {}, 'registered_name': None}, 'moving_mean_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'moving_variance_initializer': {'module': 'keras.initializers', 'class_name': 'Ones', 'config': {}, 'registered_name': None}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}, 'registered_name': None, 'build_config': {'input_shape': (None, 13, 13, 256)}, 'name': 'batch_normalization_173', 'inbound_nodes': [[['conv2d_160', 0, 0, {}]]]}, {'module': 'keras.layers', 'class_name': 'ReLU', 'config': {'name': 're_lu_119', 'trainable': True, 'dtype': 'float32', 'max_value': None, 'negative_slope': 0.0, 'threshold': 0.0}, 'registered_name': None, 'build_config': {'input_shape': (None, 13, 13, 256)}, 'name': 're_lu_119', 'inbound_nodes': [[['batch_normalization_173', 0, 0, {}]]]}, {'module': 'keras.layers', 'class_name': 'DepthwiseConv2D', 'config': {'name': 'depthwise_conv2d_13', 'trainable': True, 'dtype': 'float32', 'kernel_size': (3, 3), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'linear', 'use_bias': True, 'bias_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'bias_regularizer': None, 'activity_regularizer': None, 'bias_constraint': None, 'depth_multiplier': 1, 'depthwise_initializer': {'module': 'keras.initializers', 'class_name': 'GlorotUniform', 'config': {'seed': None}, 'registered_name': None}, 'depthwise_regularizer': None, 'depthwise_constraint': None}, 'registered_name': None, 'build_config': {'input_shape': (None, 13, 13, 256)}, 'name': 'depthwise_conv2d_13', 'inbound_nodes': [[['re_lu_119', 0, 0, {}]]]}, {'module': 'keras.layers', 'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_174', 'trainable': True, 'dtype': 'float32', 'axis': [3], 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'gamma_initializer': {'module': 'keras.initializers', 'class_name': 'Ones', 'config': {}, 'registered_name': None}, 'moving_mean_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'moving_variance_initializer': {'module': 'keras.initializers', 'class_name': 'Ones', 'config': {}, 'registered_name': None}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}, 'registered_name': None, 'build_config': {'input_shape': (None, 13, 13, 256)}, 'name': 'batch_normalization_174', 'inbound_nodes': [[['depthwise_conv2d_13', 0, 0, {}]]]}, {'module': 'keras.layers', 'class_name': 'ReLU', 'config': {'name': 're_lu_120', 'trainable': True, 'dtype': 'float32', 'max_value': None, 'negative_slope': 0.0, 'threshold': 0.0}, 'registered_name': None, 'build_config': {'input_shape': (None, 13, 13, 256)}, 'name': 're_lu_120', 'inbound_nodes': [[['batch_normalization_174', 0, 0, {}]]]}, {'module': 'keras.layers', 'class_name': 'Conv2D', 'config': {'name': 'conv2d_161', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (1, 1), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'module': 'keras.initializers', 'class_name': 'GlorotUniform', 'config': {'seed': None}, 'registered_name': None}, 'bias_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}, 'registered_name': None, 'build_config': {'input_shape': (None, 13, 13, 256)}, 'name': 'conv2d_161', 'inbound_nodes': [[['re_lu_120', 0, 0, {}]]]}, {'module': 'keras.layers', 'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_175', 'trainable': True, 'dtype': 'float32', 'axis': [3], 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'gamma_initializer': {'module': 'keras.initializers', 'class_name': 'Ones', 'config': {}, 'registered_name': None}, 'moving_mean_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'moving_variance_initializer': {'module': 'keras.initializers', 'class_name': 'Ones', 'config': {}, 'registered_name': None}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}, 'registered_name': None, 'build_config': {'input_shape': (None, 13, 13, 256)}, 'name': 'batch_normalization_175', 'inbound_nodes': [[['conv2d_161', 0, 0, {}]]]}, {'module': 'keras.layers', 'class_name': 'ReLU', 'config': {'name': 're_lu_121', 'trainable': True, 'dtype': 'float32', 'max_value': None, 'negative_slope': 0.0, 'threshold': 0.0}, 'registered_name': None, 'build_config': {'input_shape': (None, 13, 13, 256)}, 'name': 're_lu_121', 'inbound_nodes': [[['batch_normalization_175', 0, 0, {}]]]}, {'module': 'keras.layers', 'class_name': 'DepthwiseConv2D', 'config': {'name': 'depthwise_conv2d_14', 'trainable': True, 'dtype': 'float32', 'kernel_size': (3, 3), 'strides': (2, 2), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'linear', 'use_bias': True, 'bias_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'bias_regularizer': None, 'activity_regularizer': None, 'bias_constraint': None, 'depth_multiplier': 1, 'depthwise_initializer': {'module': 'keras.initializers', 'class_name': 'GlorotUniform', 'config': {'seed': None}, 'registered_name': None}, 'depthwise_regularizer': None, 'depthwise_constraint': None}, 'registered_name': None, 'build_config': {'input_shape': (None, 13, 13, 256)}, 'name': 'depthwise_conv2d_14', 'inbound_nodes': [[['re_lu_121', 0, 0, {}]]]}, {'module': 'keras.layers', 'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_176', 'trainable': True, 'dtype': 'float32', 'axis': [3], 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'gamma_initializer': {'module': 'keras.initializers', 'class_name': 'Ones', 'config': {}, 'registered_name': None}, 'moving_mean_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'moving_variance_initializer': {'module': 'keras.initializers', 'class_name': 'Ones', 'config': {}, 'registered_name': None}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}, 'registered_name': None, 'build_config': {'input_shape': (None, 7, 7, 256)}, 'name': 'batch_normalization_176', 'inbound_nodes': [[['depthwise_conv2d_14', 0, 0, {}]]]}, {'module': 'keras.layers', 'class_name': 'ReLU', 'config': {'name': 're_lu_122', 'trainable': True, 'dtype': 'float32', 'max_value': None, 'negative_slope': 0.0, 'threshold': 0.0}, 'registered_name': None, 'build_config': {'input_shape': (None, 7, 7, 256)}, 'name': 're_lu_122', 'inbound_nodes': [[['batch_normalization_176', 0, 0, {}]]]}, {'module': 'keras.layers', 'class_name': 'Conv2D', 'config': {'name': 'conv2d_162', 'trainable': True, 'dtype': 'float32', 'filters': 512, 'kernel_size': (1, 1), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'module': 'keras.initializers', 'class_name': 'GlorotUniform', 'config': {'seed': None}, 'registered_name': None}, 'bias_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}, 'registered_name': None, 'build_config': {'input_shape': (None, 7, 7, 256)}, 'name': 'conv2d_162', 'inbound_nodes': [[['re_lu_122', 0, 0, {}]]]}, {'module': 'keras.layers', 'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_177', 'trainable': True, 'dtype': 'float32', 'axis': [3], 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'gamma_initializer': {'module': 'keras.initializers', 'class_name': 'Ones', 'config': {}, 'registered_name': None}, 'moving_mean_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'moving_variance_initializer': {'module': 'keras.initializers', 'class_name': 'Ones', 'config': {}, 'registered_name': None}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}, 'registered_name': None, 'build_config': {'input_shape': (None, 7, 7, 512)}, 'name': 'batch_normalization_177', 'inbound_nodes': [[['conv2d_162', 0, 0, {}]]]}, {'module': 'keras.layers', 'class_name': 'ReLU', 'config': {'name': 're_lu_123', 'trainable': True, 'dtype': 'float32', 'max_value': None, 'negative_slope': 0.0, 'threshold': 0.0}, 'registered_name': None, 'build_config': {'input_shape': (None, 7, 7, 512)}, 'name': 're_lu_123', 'inbound_nodes': [[['batch_normalization_177', 0, 0, {}]]]}, {'module': 'keras.layers', 'class_name': 'GlobalAveragePooling2D', 'config': {'name': 'global_average_pooling2d_2', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last', 'keepdims': False}, 'registered_name': None, 'build_config': {'input_shape': (None, 7, 7, 512)}, 'name': 'global_average_pooling2d_2', 'inbound_nodes': [[['re_lu_123', 0, 0, {}]]]}, {'module': 'keras.layers', 'class_name': 'Dense', 'config': {'name': 'dense_4', 'trainable': True, 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'module': 'keras.initializers', 'class_name': 'GlorotUniform', 'config': {'seed': None}, 'registered_name': None}, 'bias_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}, 'registered_name': None, 'build_config': {'input_shape': (None, 512)}, 'name': 'dense_4', 'inbound_nodes': [[['global_average_pooling2d_2', 0, 0, {}]]]}], 'input_layers': [['input_7', 0, 0]], 'output_layers': [['dense_4', 0, 0]]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on the training data\n",
        "train_loss, train_accuracy = mobilenet_custom_model.evaluate(train_set_conv, steps=steps_per_epoch)\n",
        "print(f\"Training Loss: {train_loss:.4f}\")\n",
        "print(f\"Training Accuracy: {train_accuracy * 100:.2f}%\")\n",
        "\n",
        "# Evaluate the model on the test data\n",
        "test_loss, test_accuracy = mobilenet_custom_model.evaluate(test_set_conv, steps=validation_steps)\n",
        "print(f\"Test Loss: {test_loss:.4f}\")\n",
        "print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Le26pi9MvEY7",
        "outputId": "3db411a1-625b-41e4-f329-c1637f2e1f58"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "36/36 [==============================] - 6s 176ms/step - loss: 0.3679 - accuracy: 0.8173\n",
            "Training Loss: 0.3679\n",
            "Training Accuracy: 81.73%\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3170 - accuracy: 0.8813\n",
            "Test Loss: 0.3170\n",
            "Test Accuracy: 88.13%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_features = mobilenet_custom_model.predict(x_train_normalized)\n",
        "x_val_features = mobilenet_custom_model.predict(x_val_normalized)\n",
        "x_test_features = mobilenet_custom_model.predict(x_test_normalized)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hGHgE5ZGM_OD",
        "outputId": "7f3316c1-eee5-4a19-89c9-7b78db6647e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "73/73 [==============================] - 1s 7ms/step\n",
            "11/11 [==============================] - 0s 21ms/step\n",
            "21/21 [==============================] - 0s 6ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_features = x_train_features.reshape(x_train_features.shape[0], -1)\n",
        "x_val_features = x_val_features.reshape(x_val_features.shape[0], -1)\n",
        "x_test_features = x_test_features.reshape(x_test_features.shape[0], -1)"
      ],
      "metadata": {
        "id": "GIWUvQF5OI7E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix"
      ],
      "metadata": {
        "id": "CAqytp7HOKgh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install scikit-optimize\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "of-QGjosQp2Q",
        "outputId": "cc4e1f93-152d-4e75-8546-722c15941ba8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting scikit-optimize\n",
            "  Downloading scikit_optimize-0.9.0-py2.py3-none-any.whl (100 kB)\n",
            "\u001b[?25l     \u001b[90m\u001b[0m \u001b[32m0.0/100.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m\u001b[0m\u001b[91m\u001b[0m\u001b[90m\u001b[0m \u001b[32m61.4/100.3 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m\u001b[0m \u001b[32m100.3/100.3 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.10/dist-packages (from scikit-optimize) (1.3.2)\n",
            "Collecting pyaml>=16.9 (from scikit-optimize)\n",
            "  Downloading pyaml-23.9.7-py3-none-any.whl (23 kB)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.10/dist-packages (from scikit-optimize) (1.23.5)\n",
            "Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.10/dist-packages (from scikit-optimize) (1.11.3)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from scikit-optimize) (1.2.2)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from pyaml>=16.9->scikit-optimize) (6.0.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->scikit-optimize) (3.2.0)\n",
            "Installing collected packages: pyaml, scikit-optimize\n",
            "Successfully installed pyaml-23.9.7 scikit-optimize-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Support Vector Machine (SVM) with L2 Regularization-like behavior\n",
        "svm_model = SVC(kernel='rbf', C=4.5, gamma=0.006184517020465486)  # Set a smaller C for L2 regularization\n",
        "svm_model.fit(x_train_features, y_train)\n",
        "y_pred_svm = svm_model.predict(x_test_features)\n",
        "\n",
        "svm_accuracy = accuracy_score(y_test, y_pred_svm)\n",
        "svm_precision = precision_score(y_test, y_pred_svm)\n",
        "svm_recall = recall_score(y_test, y_pred_svm)\n",
        "svm_f1 = f1_score(y_test, y_pred_svm)\n",
        "\n",
        "tn, fp, fn, tp = confusion_matrix(y_test, y_pred_svm).ravel()\n",
        "svm_specificity = tn / (tn + fp)\n",
        "\n",
        "print(\"SVM Accuracy:\", svm_accuracy)\n",
        "print(\"SVM Precision:\", svm_precision)\n",
        "print(\"SVM Sensitivity (Recall):\", svm_recall)\n",
        "print(\"SVM Specificity:\", svm_specificity)\n",
        "print(\"SVM F1 Score:\", svm_f1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OKtS48F_TPgx",
        "outputId": "bb8a1fa8-9fcc-4d91-f2af-9968c6540633"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVM Accuracy: 0.8461538461538461\n",
            "SVM Precision: 0.788659793814433\n",
            "SVM Sensitivity (Recall): 0.9386503067484663\n",
            "SVM Specificity: 0.7566765578635015\n",
            "SVM F1 Score: 0.8571428571428571\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "\n",
        "# Define the parameter grid for GridSearchCV\n",
        "param_grid = {\n",
        "    'n_estimators': [50, 100, 200],  # Number of trees in the forest\n",
        "    'max_depth': [None, 10, 20, 30],  # Maximum depth of the tree\n",
        "    'min_samples_split': [2, 5, 10],  # Minimum number of samples required to split an internal node\n",
        "    'min_samples_leaf': [1, 2, 4]  # Minimum number of samples required to be at a leaf node\n",
        "}\n",
        "\n",
        "# Instantiate the Random Forest Classifier\n",
        "rf_model = RandomForestClassifier(random_state=42)\n",
        "\n",
        "# Perform Grid Search with cross-validation\n",
        "grid_search = GridSearchCV(estimator=rf_model, param_grid=param_grid, cv=3, n_jobs=-1, scoring='accuracy')\n",
        "\n",
        "# Fit the grid search to the data\n",
        "grid_search.fit(x_train_features, y_train)\n",
        "\n",
        "# Get the best hyperparameters and best model\n",
        "best_params = grid_search.best_params_\n",
        "best_rf_model = grid_search.best_estimator_\n",
        "\n",
        "# Evaluate the best model on the test data\n",
        "y_pred_rf = best_rf_model.predict(x_test_features)\n",
        "rf_accuracy = accuracy_score(y_test, y_pred_rf)\n",
        "rf_precision = precision_score(y_test, y_pred_rf)\n",
        "rf_recall = recall_score(y_test, y_pred_rf)\n",
        "rf_f1 = f1_score(y_test, y_pred_rf)\n",
        "\n",
        "tn, fp, fn, tp = confusion_matrix(y_test, y_pred_rf).ravel()\n",
        "rf_specificity = tn / (tn + fp)\n",
        "\n",
        "print(\"Best Hyperparameters:\", best_params)\n",
        "print(\"Random Forest Accuracy:\", rf_accuracy)\n",
        "print(\"Random Forest Precision:\", rf_precision)\n",
        "print(\"Random Forest Sensitivity (Recall):\", rf_recall)\n",
        "print(\"Random Forest Specificity:\", rf_specificity)\n",
        "print(\"Random Forest F1 Score:\", rf_f1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-fRzc0F7TPiT",
        "outputId": "1460ef05-d387-4cf8-f259-17ce107d47db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Hyperparameters: {'max_depth': 10, 'min_samples_leaf': 4, 'min_samples_split': 10, 'n_estimators': 50}\n",
            "Random Forest Accuracy: 0.8099547511312217\n",
            "Random Forest Precision: 0.7941176470588235\n",
            "Random Forest Sensitivity (Recall): 0.8282208588957055\n",
            "Random Forest Specificity: 0.7922848664688428\n",
            "Random Forest F1 Score: 0.8108108108108107\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "\n",
        "# Define the parameter grid for GridSearchCV\n",
        "param_grid = {\n",
        "    'n_neighbors': [3, 5, 7, 9, 11]  # Example values for the number of neighbors (k)\n",
        "}\n",
        "\n",
        "# Instantiate the KNN Classifier\n",
        "knn_model = KNeighborsClassifier()\n",
        "\n",
        "# Early stopping parameters\n",
        "max_epochs = 25  # Maximum number of epochs (iterations) to train\n",
        "patience = 5  # Number of epochs to wait for improvement\n",
        "best_accuracy = 0  # Best validation accuracy\n",
        "counter = 0  # Counter to keep track of epochs with no improvement\n",
        "\n",
        "# Training loop with early stopping and hyperparameter tuning using GridSearchCV\n",
        "for epoch in range(max_epochs):\n",
        "    # Perform grid search on your training data (x_train_features, y_train)\n",
        "    grid_search = GridSearchCV(estimator=knn_model, param_grid=param_grid, cv=3, n_jobs=-1, scoring='accuracy')\n",
        "    grid_search.fit(x_train_features, y_train)\n",
        "\n",
        "    # Get the best hyperparameters and best model\n",
        "    best_params = grid_search.best_params_\n",
        "    best_knn_model = grid_search.best_estimator_\n",
        "\n",
        "    # Validate the best model on the validation data\n",
        "    y_pred_val = best_knn_model.predict(x_val_features)\n",
        "    val_accuracy = accuracy_score(y_val, y_pred_val)\n",
        "\n",
        "    print(\"Epoch {}: Validation Accuracy: {:.4f}\".format(epoch, val_accuracy))\n",
        "\n",
        "    # Check for improvement in validation accuracy\n",
        "    if val_accuracy > best_accuracy:\n",
        "        best_accuracy = val_accuracy\n",
        "        counter = 0\n",
        "    else:\n",
        "        counter += 1\n",
        "\n",
        "    # Early stopping condition\n",
        "    if counter >= patience:\n",
        "        print(\"Early stopping after {} epochs of no improvement.\".format(epoch))\n",
        "        break\n",
        "\n",
        "# Evaluate the best model on the test data\n",
        "y_pred_knn = best_knn_model.predict(x_test_features)\n",
        "knn_accuracy = accuracy_score(y_test, y_pred_knn)\n",
        "knn_precision = precision_score(y_test, y_pred_knn)\n",
        "knn_recall = recall_score(y_test, y_pred_knn)\n",
        "knn_f1 = f1_score(y_test, y_pred_knn)\n",
        "\n",
        "tn, fp, fn, tp = confusion_matrix(y_test, y_pred_knn).ravel()\n",
        "knn_specificity = tn / (tn + fp)\n",
        "\n",
        "print(\"Best Hyperparameters:\", best_params)\n",
        "print(\"KNN Accuracy on Test Data:\", knn_accuracy)\n",
        "print(\"KNN Precision:\", knn_precision)\n",
        "print(\"KNN Sensitivity (Recall):\", knn_recall)\n",
        "print(\"KNN Specificity:\", knn_specificity)\n",
        "print(\"KNN F1 Score:\", knn_f1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BhmBnlk9SLcu",
        "outputId": "9669238f-2250-41b1-d467-ec9a3aa1320c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0: Validation Accuracy: 0.8097\n",
            "Epoch 1: Validation Accuracy: 0.8097\n",
            "Epoch 2: Validation Accuracy: 0.8097\n",
            "Epoch 3: Validation Accuracy: 0.8097\n",
            "Epoch 4: Validation Accuracy: 0.8097\n",
            "Epoch 5: Validation Accuracy: 0.8097\n",
            "Early stopping after 5 epochs of no improvement.\n",
            "Best Hyperparameters: {'n_neighbors': 7}\n",
            "KNN Accuracy on Test Data: 0.8114630467571644\n",
            "KNN Precision: 0.793002915451895\n",
            "KNN Sensitivity (Recall): 0.8343558282208589\n",
            "KNN Specificity: 0.7893175074183977\n",
            "KNN F1 Score: 0.8131539611360239\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Conv2D, BatchNormalization, Activation, MaxPooling2D, GlobalAveragePooling2D, Dense, AveragePooling2D, Concatenate\n",
        "\n",
        "# Define your input shape and number of classes\n",
        "IMAGE_WIDTH, IMAGE_HEIGHT, IMAGE_CHANNELS = 100, 100, 3\n",
        "NUM_CLASSES = 2\n",
        "\n",
        "# Define the dense block\n",
        "def dense_block(x, growth_rate):\n",
        "    x1 = BatchNormalization()(x)\n",
        "    x1 = Activation('relu')(x1)\n",
        "    x1 = Conv2D(4 * growth_rate, (1, 1), padding='same')(x1)\n",
        "\n",
        "    x1 = BatchNormalization()(x1)\n",
        "    x1 = Activation('relu')(x1)\n",
        "    x1 = Conv2D(growth_rate, (3, 3), padding='same')(x1)\n",
        "\n",
        "    x = Concatenate()([x, x1])\n",
        "    return x\n",
        "\n",
        "# Define the transition layer\n",
        "def transition_block(x, reduction):\n",
        "    num_filters = int(x.shape[-1])\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Conv2D(int(num_filters * reduction), (1, 1), padding='same')(x)\n",
        "    x = AveragePooling2D((2, 2), strides=(2, 2))(x)\n",
        "    return x\n",
        "\n",
        "# Define the input shape\n",
        "input_shape = (IMAGE_WIDTH, IMAGE_HEIGHT, IMAGE_CHANNELS)\n",
        "input_tensor = Input(shape=input_shape)\n",
        "\n",
        "# Initial Convolution\n",
        "x = Conv2D(64, (7, 7), strides=(2, 2), padding='same')(input_tensor)\n",
        "x = BatchNormalization()(x)\n",
        "x = Activation('relu')(x)\n",
        "x = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n",
        "\n",
        "# Dense Blocks\n",
        "for _ in range(6):\n",
        "    x = dense_block(x, 32)\n",
        "\n",
        "x = transition_block(x, 0.5)\n",
        "\n",
        "for _ in range(12):\n",
        "    x = dense_block(x, 32)\n",
        "\n",
        "x = transition_block(x, 0.5)\n",
        "\n",
        "for _ in range(48):\n",
        "    x = dense_block(x, 32)\n",
        "\n",
        "# Global Average Pooling\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "\n",
        "# Fully Connected Layer\n",
        "output = Dense(NUM_CLASSES, activation='softmax')(x)\n",
        "\n",
        "# Create the model\n",
        "model = Model(inputs=input_tensor, outputs=output)\n",
        "\n",
        "# Compile the model with a learning rate of 0.00001\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.00001)\n",
        "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Print the model summary\n",
        "model.summary()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fqJ2WO3HvEaZ",
        "outputId": "379b7613-9228-4742-e899-7a53f3d2469a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)        [(None, 100, 100, 3)]        0         []                            \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)             (None, 50, 50, 64)           9472      ['input_1[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization (Batch  (None, 50, 50, 64)           256       ['conv2d[0][0]']              \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation (Activation)     (None, 50, 50, 64)           0         ['batch_normalization[0][0]'] \n",
            "                                                                                                  \n",
            " max_pooling2d (MaxPooling2  (None, 25, 25, 64)           0         ['activation[0][0]']          \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_1 (Bat  (None, 25, 25, 64)           256       ['max_pooling2d[0][0]']       \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " activation_1 (Activation)   (None, 25, 25, 64)           0         ['batch_normalization_1[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)           (None, 25, 25, 128)          8320      ['activation_1[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_2 (Bat  (None, 25, 25, 128)          512       ['conv2d_1[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " activation_2 (Activation)   (None, 25, 25, 128)          0         ['batch_normalization_2[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)           (None, 25, 25, 32)           36896     ['activation_2[0][0]']        \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)   (None, 25, 25, 96)           0         ['max_pooling2d[0][0]',       \n",
            "                                                                     'conv2d_2[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_3 (Bat  (None, 25, 25, 96)           384       ['concatenate[0][0]']         \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " activation_3 (Activation)   (None, 25, 25, 96)           0         ['batch_normalization_3[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " conv2d_3 (Conv2D)           (None, 25, 25, 128)          12416     ['activation_3[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_4 (Bat  (None, 25, 25, 128)          512       ['conv2d_3[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " activation_4 (Activation)   (None, 25, 25, 128)          0         ['batch_normalization_4[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " conv2d_4 (Conv2D)           (None, 25, 25, 32)           36896     ['activation_4[0][0]']        \n",
            "                                                                                                  \n",
            " concatenate_1 (Concatenate  (None, 25, 25, 128)          0         ['concatenate[0][0]',         \n",
            " )                                                                   'conv2d_4[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_5 (Bat  (None, 25, 25, 128)          512       ['concatenate_1[0][0]']       \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " activation_5 (Activation)   (None, 25, 25, 128)          0         ['batch_normalization_5[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " conv2d_5 (Conv2D)           (None, 25, 25, 128)          16512     ['activation_5[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_6 (Bat  (None, 25, 25, 128)          512       ['conv2d_5[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " activation_6 (Activation)   (None, 25, 25, 128)          0         ['batch_normalization_6[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " conv2d_6 (Conv2D)           (None, 25, 25, 32)           36896     ['activation_6[0][0]']        \n",
            "                                                                                                  \n",
            " concatenate_2 (Concatenate  (None, 25, 25, 160)          0         ['concatenate_1[0][0]',       \n",
            " )                                                                   'conv2d_6[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_7 (Bat  (None, 25, 25, 160)          640       ['concatenate_2[0][0]']       \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " activation_7 (Activation)   (None, 25, 25, 160)          0         ['batch_normalization_7[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " conv2d_7 (Conv2D)           (None, 25, 25, 128)          20608     ['activation_7[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_8 (Bat  (None, 25, 25, 128)          512       ['conv2d_7[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " activation_8 (Activation)   (None, 25, 25, 128)          0         ['batch_normalization_8[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " conv2d_8 (Conv2D)           (None, 25, 25, 32)           36896     ['activation_8[0][0]']        \n",
            "                                                                                                  \n",
            " concatenate_3 (Concatenate  (None, 25, 25, 192)          0         ['concatenate_2[0][0]',       \n",
            " )                                                                   'conv2d_8[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_9 (Bat  (None, 25, 25, 192)          768       ['concatenate_3[0][0]']       \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " activation_9 (Activation)   (None, 25, 25, 192)          0         ['batch_normalization_9[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " conv2d_9 (Conv2D)           (None, 25, 25, 128)          24704     ['activation_9[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_10 (Ba  (None, 25, 25, 128)          512       ['conv2d_9[0][0]']            \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_10 (Activation)  (None, 25, 25, 128)          0         ['batch_normalization_10[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_10 (Conv2D)          (None, 25, 25, 32)           36896     ['activation_10[0][0]']       \n",
            "                                                                                                  \n",
            " concatenate_4 (Concatenate  (None, 25, 25, 224)          0         ['concatenate_3[0][0]',       \n",
            " )                                                                   'conv2d_10[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_11 (Ba  (None, 25, 25, 224)          896       ['concatenate_4[0][0]']       \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_11 (Activation)  (None, 25, 25, 224)          0         ['batch_normalization_11[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_11 (Conv2D)          (None, 25, 25, 128)          28800     ['activation_11[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_12 (Ba  (None, 25, 25, 128)          512       ['conv2d_11[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_12 (Activation)  (None, 25, 25, 128)          0         ['batch_normalization_12[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_12 (Conv2D)          (None, 25, 25, 32)           36896     ['activation_12[0][0]']       \n",
            "                                                                                                  \n",
            " concatenate_5 (Concatenate  (None, 25, 25, 256)          0         ['concatenate_4[0][0]',       \n",
            " )                                                                   'conv2d_12[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_13 (Ba  (None, 25, 25, 256)          1024      ['concatenate_5[0][0]']       \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_13 (Activation)  (None, 25, 25, 256)          0         ['batch_normalization_13[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_13 (Conv2D)          (None, 25, 25, 128)          32896     ['activation_13[0][0]']       \n",
            "                                                                                                  \n",
            " average_pooling2d (Average  (None, 12, 12, 128)          0         ['conv2d_13[0][0]']           \n",
            " Pooling2D)                                                                                       \n",
            "                                                                                                  \n",
            " batch_normalization_14 (Ba  (None, 12, 12, 128)          512       ['average_pooling2d[0][0]']   \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_14 (Activation)  (None, 12, 12, 128)          0         ['batch_normalization_14[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_14 (Conv2D)          (None, 12, 12, 128)          16512     ['activation_14[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_15 (Ba  (None, 12, 12, 128)          512       ['conv2d_14[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_15 (Activation)  (None, 12, 12, 128)          0         ['batch_normalization_15[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_15 (Conv2D)          (None, 12, 12, 32)           36896     ['activation_15[0][0]']       \n",
            "                                                                                                  \n",
            " concatenate_6 (Concatenate  (None, 12, 12, 160)          0         ['average_pooling2d[0][0]',   \n",
            " )                                                                   'conv2d_15[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_16 (Ba  (None, 12, 12, 160)          640       ['concatenate_6[0][0]']       \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_16 (Activation)  (None, 12, 12, 160)          0         ['batch_normalization_16[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_16 (Conv2D)          (None, 12, 12, 128)          20608     ['activation_16[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_17 (Ba  (None, 12, 12, 128)          512       ['conv2d_16[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_17 (Activation)  (None, 12, 12, 128)          0         ['batch_normalization_17[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_17 (Conv2D)          (None, 12, 12, 32)           36896     ['activation_17[0][0]']       \n",
            "                                                                                                  \n",
            " concatenate_7 (Concatenate  (None, 12, 12, 192)          0         ['concatenate_6[0][0]',       \n",
            " )                                                                   'conv2d_17[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_18 (Ba  (None, 12, 12, 192)          768       ['concatenate_7[0][0]']       \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_18 (Activation)  (None, 12, 12, 192)          0         ['batch_normalization_18[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_18 (Conv2D)          (None, 12, 12, 128)          24704     ['activation_18[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_19 (Ba  (None, 12, 12, 128)          512       ['conv2d_18[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_19 (Activation)  (None, 12, 12, 128)          0         ['batch_normalization_19[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_19 (Conv2D)          (None, 12, 12, 32)           36896     ['activation_19[0][0]']       \n",
            "                                                                                                  \n",
            " concatenate_8 (Concatenate  (None, 12, 12, 224)          0         ['concatenate_7[0][0]',       \n",
            " )                                                                   'conv2d_19[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_20 (Ba  (None, 12, 12, 224)          896       ['concatenate_8[0][0]']       \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_20 (Activation)  (None, 12, 12, 224)          0         ['batch_normalization_20[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_20 (Conv2D)          (None, 12, 12, 128)          28800     ['activation_20[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_21 (Ba  (None, 12, 12, 128)          512       ['conv2d_20[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_21 (Activation)  (None, 12, 12, 128)          0         ['batch_normalization_21[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_21 (Conv2D)          (None, 12, 12, 32)           36896     ['activation_21[0][0]']       \n",
            "                                                                                                  \n",
            " concatenate_9 (Concatenate  (None, 12, 12, 256)          0         ['concatenate_8[0][0]',       \n",
            " )                                                                   'conv2d_21[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_22 (Ba  (None, 12, 12, 256)          1024      ['concatenate_9[0][0]']       \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_22 (Activation)  (None, 12, 12, 256)          0         ['batch_normalization_22[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_22 (Conv2D)          (None, 12, 12, 128)          32896     ['activation_22[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_23 (Ba  (None, 12, 12, 128)          512       ['conv2d_22[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_23 (Activation)  (None, 12, 12, 128)          0         ['batch_normalization_23[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_23 (Conv2D)          (None, 12, 12, 32)           36896     ['activation_23[0][0]']       \n",
            "                                                                                                  \n",
            " concatenate_10 (Concatenat  (None, 12, 12, 288)          0         ['concatenate_9[0][0]',       \n",
            " e)                                                                  'conv2d_23[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_24 (Ba  (None, 12, 12, 288)          1152      ['concatenate_10[0][0]']      \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_24 (Activation)  (None, 12, 12, 288)          0         ['batch_normalization_24[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_24 (Conv2D)          (None, 12, 12, 128)          36992     ['activation_24[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_25 (Ba  (None, 12, 12, 128)          512       ['conv2d_24[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_25 (Activation)  (None, 12, 12, 128)          0         ['batch_normalization_25[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_25 (Conv2D)          (None, 12, 12, 32)           36896     ['activation_25[0][0]']       \n",
            "                                                                                                  \n",
            " concatenate_11 (Concatenat  (None, 12, 12, 320)          0         ['concatenate_10[0][0]',      \n",
            " e)                                                                  'conv2d_25[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_26 (Ba  (None, 12, 12, 320)          1280      ['concatenate_11[0][0]']      \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_26 (Activation)  (None, 12, 12, 320)          0         ['batch_normalization_26[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_26 (Conv2D)          (None, 12, 12, 128)          41088     ['activation_26[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_27 (Ba  (None, 12, 12, 128)          512       ['conv2d_26[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_27 (Activation)  (None, 12, 12, 128)          0         ['batch_normalization_27[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_27 (Conv2D)          (None, 12, 12, 32)           36896     ['activation_27[0][0]']       \n",
            "                                                                                                  \n",
            " concatenate_12 (Concatenat  (None, 12, 12, 352)          0         ['concatenate_11[0][0]',      \n",
            " e)                                                                  'conv2d_27[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_28 (Ba  (None, 12, 12, 352)          1408      ['concatenate_12[0][0]']      \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_28 (Activation)  (None, 12, 12, 352)          0         ['batch_normalization_28[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_28 (Conv2D)          (None, 12, 12, 128)          45184     ['activation_28[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_29 (Ba  (None, 12, 12, 128)          512       ['conv2d_28[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_29 (Activation)  (None, 12, 12, 128)          0         ['batch_normalization_29[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_29 (Conv2D)          (None, 12, 12, 32)           36896     ['activation_29[0][0]']       \n",
            "                                                                                                  \n",
            " concatenate_13 (Concatenat  (None, 12, 12, 384)          0         ['concatenate_12[0][0]',      \n",
            " e)                                                                  'conv2d_29[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_30 (Ba  (None, 12, 12, 384)          1536      ['concatenate_13[0][0]']      \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_30 (Activation)  (None, 12, 12, 384)          0         ['batch_normalization_30[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_30 (Conv2D)          (None, 12, 12, 128)          49280     ['activation_30[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_31 (Ba  (None, 12, 12, 128)          512       ['conv2d_30[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_31 (Activation)  (None, 12, 12, 128)          0         ['batch_normalization_31[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_31 (Conv2D)          (None, 12, 12, 32)           36896     ['activation_31[0][0]']       \n",
            "                                                                                                  \n",
            " concatenate_14 (Concatenat  (None, 12, 12, 416)          0         ['concatenate_13[0][0]',      \n",
            " e)                                                                  'conv2d_31[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_32 (Ba  (None, 12, 12, 416)          1664      ['concatenate_14[0][0]']      \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_32 (Activation)  (None, 12, 12, 416)          0         ['batch_normalization_32[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_32 (Conv2D)          (None, 12, 12, 128)          53376     ['activation_32[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_33 (Ba  (None, 12, 12, 128)          512       ['conv2d_32[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_33 (Activation)  (None, 12, 12, 128)          0         ['batch_normalization_33[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_33 (Conv2D)          (None, 12, 12, 32)           36896     ['activation_33[0][0]']       \n",
            "                                                                                                  \n",
            " concatenate_15 (Concatenat  (None, 12, 12, 448)          0         ['concatenate_14[0][0]',      \n",
            " e)                                                                  'conv2d_33[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_34 (Ba  (None, 12, 12, 448)          1792      ['concatenate_15[0][0]']      \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_34 (Activation)  (None, 12, 12, 448)          0         ['batch_normalization_34[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_34 (Conv2D)          (None, 12, 12, 128)          57472     ['activation_34[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_35 (Ba  (None, 12, 12, 128)          512       ['conv2d_34[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_35 (Activation)  (None, 12, 12, 128)          0         ['batch_normalization_35[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_35 (Conv2D)          (None, 12, 12, 32)           36896     ['activation_35[0][0]']       \n",
            "                                                                                                  \n",
            " concatenate_16 (Concatenat  (None, 12, 12, 480)          0         ['concatenate_15[0][0]',      \n",
            " e)                                                                  'conv2d_35[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_36 (Ba  (None, 12, 12, 480)          1920      ['concatenate_16[0][0]']      \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_36 (Activation)  (None, 12, 12, 480)          0         ['batch_normalization_36[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_36 (Conv2D)          (None, 12, 12, 128)          61568     ['activation_36[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_37 (Ba  (None, 12, 12, 128)          512       ['conv2d_36[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_37 (Activation)  (None, 12, 12, 128)          0         ['batch_normalization_37[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_37 (Conv2D)          (None, 12, 12, 32)           36896     ['activation_37[0][0]']       \n",
            "                                                                                                  \n",
            " concatenate_17 (Concatenat  (None, 12, 12, 512)          0         ['concatenate_16[0][0]',      \n",
            " e)                                                                  'conv2d_37[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_38 (Ba  (None, 12, 12, 512)          2048      ['concatenate_17[0][0]']      \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_38 (Activation)  (None, 12, 12, 512)          0         ['batch_normalization_38[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_38 (Conv2D)          (None, 12, 12, 256)          131328    ['activation_38[0][0]']       \n",
            "                                                                                                  \n",
            " average_pooling2d_1 (Avera  (None, 6, 6, 256)            0         ['conv2d_38[0][0]']           \n",
            " gePooling2D)                                                                                     \n",
            "                                                                                                  \n",
            " batch_normalization_39 (Ba  (None, 6, 6, 256)            1024      ['average_pooling2d_1[0][0]'] \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_39 (Activation)  (None, 6, 6, 256)            0         ['batch_normalization_39[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_39 (Conv2D)          (None, 6, 6, 128)            32896     ['activation_39[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_40 (Ba  (None, 6, 6, 128)            512       ['conv2d_39[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_40 (Activation)  (None, 6, 6, 128)            0         ['batch_normalization_40[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_40 (Conv2D)          (None, 6, 6, 32)             36896     ['activation_40[0][0]']       \n",
            "                                                                                                  \n",
            " concatenate_18 (Concatenat  (None, 6, 6, 288)            0         ['average_pooling2d_1[0][0]', \n",
            " e)                                                                  'conv2d_40[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_41 (Ba  (None, 6, 6, 288)            1152      ['concatenate_18[0][0]']      \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_41 (Activation)  (None, 6, 6, 288)            0         ['batch_normalization_41[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_41 (Conv2D)          (None, 6, 6, 128)            36992     ['activation_41[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_42 (Ba  (None, 6, 6, 128)            512       ['conv2d_41[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_42 (Activation)  (None, 6, 6, 128)            0         ['batch_normalization_42[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_42 (Conv2D)          (None, 6, 6, 32)             36896     ['activation_42[0][0]']       \n",
            "                                                                                                  \n",
            " concatenate_19 (Concatenat  (None, 6, 6, 320)            0         ['concatenate_18[0][0]',      \n",
            " e)                                                                  'conv2d_42[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_43 (Ba  (None, 6, 6, 320)            1280      ['concatenate_19[0][0]']      \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_43 (Activation)  (None, 6, 6, 320)            0         ['batch_normalization_43[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_43 (Conv2D)          (None, 6, 6, 128)            41088     ['activation_43[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_44 (Ba  (None, 6, 6, 128)            512       ['conv2d_43[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_44 (Activation)  (None, 6, 6, 128)            0         ['batch_normalization_44[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_44 (Conv2D)          (None, 6, 6, 32)             36896     ['activation_44[0][0]']       \n",
            "                                                                                                  \n",
            " concatenate_20 (Concatenat  (None, 6, 6, 352)            0         ['concatenate_19[0][0]',      \n",
            " e)                                                                  'conv2d_44[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_45 (Ba  (None, 6, 6, 352)            1408      ['concatenate_20[0][0]']      \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_45 (Activation)  (None, 6, 6, 352)            0         ['batch_normalization_45[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_45 (Conv2D)          (None, 6, 6, 128)            45184     ['activation_45[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_46 (Ba  (None, 6, 6, 128)            512       ['conv2d_45[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_46 (Activation)  (None, 6, 6, 128)            0         ['batch_normalization_46[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_46 (Conv2D)          (None, 6, 6, 32)             36896     ['activation_46[0][0]']       \n",
            "                                                                                                  \n",
            " concatenate_21 (Concatenat  (None, 6, 6, 384)            0         ['concatenate_20[0][0]',      \n",
            " e)                                                                  'conv2d_46[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_47 (Ba  (None, 6, 6, 384)            1536      ['concatenate_21[0][0]']      \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_47 (Activation)  (None, 6, 6, 384)            0         ['batch_normalization_47[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_47 (Conv2D)          (None, 6, 6, 128)            49280     ['activation_47[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_48 (Ba  (None, 6, 6, 128)            512       ['conv2d_47[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_48 (Activation)  (None, 6, 6, 128)            0         ['batch_normalization_48[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_48 (Conv2D)          (None, 6, 6, 32)             36896     ['activation_48[0][0]']       \n",
            "                                                                                                  \n",
            " concatenate_22 (Concatenat  (None, 6, 6, 416)            0         ['concatenate_21[0][0]',      \n",
            " e)                                                                  'conv2d_48[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_49 (Ba  (None, 6, 6, 416)            1664      ['concatenate_22[0][0]']      \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_49 (Activation)  (None, 6, 6, 416)            0         ['batch_normalization_49[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_49 (Conv2D)          (None, 6, 6, 128)            53376     ['activation_49[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_50 (Ba  (None, 6, 6, 128)            512       ['conv2d_49[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_50 (Activation)  (None, 6, 6, 128)            0         ['batch_normalization_50[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_50 (Conv2D)          (None, 6, 6, 32)             36896     ['activation_50[0][0]']       \n",
            "                                                                                                  \n",
            " concatenate_23 (Concatenat  (None, 6, 6, 448)            0         ['concatenate_22[0][0]',      \n",
            " e)                                                                  'conv2d_50[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_51 (Ba  (None, 6, 6, 448)            1792      ['concatenate_23[0][0]']      \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_51 (Activation)  (None, 6, 6, 448)            0         ['batch_normalization_51[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_51 (Conv2D)          (None, 6, 6, 128)            57472     ['activation_51[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_52 (Ba  (None, 6, 6, 128)            512       ['conv2d_51[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_52 (Activation)  (None, 6, 6, 128)            0         ['batch_normalization_52[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_52 (Conv2D)          (None, 6, 6, 32)             36896     ['activation_52[0][0]']       \n",
            "                                                                                                  \n",
            " concatenate_24 (Concatenat  (None, 6, 6, 480)            0         ['concatenate_23[0][0]',      \n",
            " e)                                                                  'conv2d_52[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_53 (Ba  (None, 6, 6, 480)            1920      ['concatenate_24[0][0]']      \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_53 (Activation)  (None, 6, 6, 480)            0         ['batch_normalization_53[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_53 (Conv2D)          (None, 6, 6, 128)            61568     ['activation_53[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_54 (Ba  (None, 6, 6, 128)            512       ['conv2d_53[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_54 (Activation)  (None, 6, 6, 128)            0         ['batch_normalization_54[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_54 (Conv2D)          (None, 6, 6, 32)             36896     ['activation_54[0][0]']       \n",
            "                                                                                                  \n",
            " concatenate_25 (Concatenat  (None, 6, 6, 512)            0         ['concatenate_24[0][0]',      \n",
            " e)                                                                  'conv2d_54[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_55 (Ba  (None, 6, 6, 512)            2048      ['concatenate_25[0][0]']      \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_55 (Activation)  (None, 6, 6, 512)            0         ['batch_normalization_55[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_55 (Conv2D)          (None, 6, 6, 128)            65664     ['activation_55[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_56 (Ba  (None, 6, 6, 128)            512       ['conv2d_55[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_56 (Activation)  (None, 6, 6, 128)            0         ['batch_normalization_56[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_56 (Conv2D)          (None, 6, 6, 32)             36896     ['activation_56[0][0]']       \n",
            "                                                                                                  \n",
            " concatenate_26 (Concatenat  (None, 6, 6, 544)            0         ['concatenate_25[0][0]',      \n",
            " e)                                                                  'conv2d_56[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_57 (Ba  (None, 6, 6, 544)            2176      ['concatenate_26[0][0]']      \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_57 (Activation)  (None, 6, 6, 544)            0         ['batch_normalization_57[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_57 (Conv2D)          (None, 6, 6, 128)            69760     ['activation_57[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_58 (Ba  (None, 6, 6, 128)            512       ['conv2d_57[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_58 (Activation)  (None, 6, 6, 128)            0         ['batch_normalization_58[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_58 (Conv2D)          (None, 6, 6, 32)             36896     ['activation_58[0][0]']       \n",
            "                                                                                                  \n",
            " concatenate_27 (Concatenat  (None, 6, 6, 576)            0         ['concatenate_26[0][0]',      \n",
            " e)                                                                  'conv2d_58[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_59 (Ba  (None, 6, 6, 576)            2304      ['concatenate_27[0][0]']      \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_59 (Activation)  (None, 6, 6, 576)            0         ['batch_normalization_59[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_59 (Conv2D)          (None, 6, 6, 128)            73856     ['activation_59[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_60 (Ba  (None, 6, 6, 128)            512       ['conv2d_59[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_60 (Activation)  (None, 6, 6, 128)            0         ['batch_normalization_60[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_60 (Conv2D)          (None, 6, 6, 32)             36896     ['activation_60[0][0]']       \n",
            "                                                                                                  \n",
            " concatenate_28 (Concatenat  (None, 6, 6, 608)            0         ['concatenate_27[0][0]',      \n",
            " e)                                                                  'conv2d_60[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_61 (Ba  (None, 6, 6, 608)            2432      ['concatenate_28[0][0]']      \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_61 (Activation)  (None, 6, 6, 608)            0         ['batch_normalization_61[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_61 (Conv2D)          (None, 6, 6, 128)            77952     ['activation_61[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_62 (Ba  (None, 6, 6, 128)            512       ['conv2d_61[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_62 (Activation)  (None, 6, 6, 128)            0         ['batch_normalization_62[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_62 (Conv2D)          (None, 6, 6, 32)             36896     ['activation_62[0][0]']       \n",
            "                                                                                                  \n",
            " concatenate_29 (Concatenat  (None, 6, 6, 640)            0         ['concatenate_28[0][0]',      \n",
            " e)                                                                  'conv2d_62[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_63 (Ba  (None, 6, 6, 640)            2560      ['concatenate_29[0][0]']      \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_63 (Activation)  (None, 6, 6, 640)            0         ['batch_normalization_63[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_63 (Conv2D)          (None, 6, 6, 128)            82048     ['activation_63[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_64 (Ba  (None, 6, 6, 128)            512       ['conv2d_63[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_64 (Activation)  (None, 6, 6, 128)            0         ['batch_normalization_64[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_64 (Conv2D)          (None, 6, 6, 32)             36896     ['activation_64[0][0]']       \n",
            "                                                                                                  \n",
            " concatenate_30 (Concatenat  (None, 6, 6, 672)            0         ['concatenate_29[0][0]',      \n",
            " e)                                                                  'conv2d_64[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_65 (Ba  (None, 6, 6, 672)            2688      ['concatenate_30[0][0]']      \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_65 (Activation)  (None, 6, 6, 672)            0         ['batch_normalization_65[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_65 (Conv2D)          (None, 6, 6, 128)            86144     ['activation_65[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_66 (Ba  (None, 6, 6, 128)            512       ['conv2d_65[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_66 (Activation)  (None, 6, 6, 128)            0         ['batch_normalization_66[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_66 (Conv2D)          (None, 6, 6, 32)             36896     ['activation_66[0][0]']       \n",
            "                                                                                                  \n",
            " concatenate_31 (Concatenat  (None, 6, 6, 704)            0         ['concatenate_30[0][0]',      \n",
            " e)                                                                  'conv2d_66[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_67 (Ba  (None, 6, 6, 704)            2816      ['concatenate_31[0][0]']      \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_67 (Activation)  (None, 6, 6, 704)            0         ['batch_normalization_67[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_67 (Conv2D)          (None, 6, 6, 128)            90240     ['activation_67[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_68 (Ba  (None, 6, 6, 128)            512       ['conv2d_67[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_68 (Activation)  (None, 6, 6, 128)            0         ['batch_normalization_68[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_68 (Conv2D)          (None, 6, 6, 32)             36896     ['activation_68[0][0]']       \n",
            "                                                                                                  \n",
            " concatenate_32 (Concatenat  (None, 6, 6, 736)            0         ['concatenate_31[0][0]',      \n",
            " e)                                                                  'conv2d_68[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_69 (Ba  (None, 6, 6, 736)            2944      ['concatenate_32[0][0]']      \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_69 (Activation)  (None, 6, 6, 736)            0         ['batch_normalization_69[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_69 (Conv2D)          (None, 6, 6, 128)            94336     ['activation_69[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_70 (Ba  (None, 6, 6, 128)            512       ['conv2d_69[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_70 (Activation)  (None, 6, 6, 128)            0         ['batch_normalization_70[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_70 (Conv2D)          (None, 6, 6, 32)             36896     ['activation_70[0][0]']       \n",
            "                                                                                                  \n",
            " concatenate_33 (Concatenat  (None, 6, 6, 768)            0         ['concatenate_32[0][0]',      \n",
            " e)                                                                  'conv2d_70[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_71 (Ba  (None, 6, 6, 768)            3072      ['concatenate_33[0][0]']      \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_71 (Activation)  (None, 6, 6, 768)            0         ['batch_normalization_71[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_71 (Conv2D)          (None, 6, 6, 128)            98432     ['activation_71[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_72 (Ba  (None, 6, 6, 128)            512       ['conv2d_71[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_72 (Activation)  (None, 6, 6, 128)            0         ['batch_normalization_72[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_72 (Conv2D)          (None, 6, 6, 32)             36896     ['activation_72[0][0]']       \n",
            "                                                                                                  \n",
            " concatenate_34 (Concatenat  (None, 6, 6, 800)            0         ['concatenate_33[0][0]',      \n",
            " e)                                                                  'conv2d_72[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_73 (Ba  (None, 6, 6, 800)            3200      ['concatenate_34[0][0]']      \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_73 (Activation)  (None, 6, 6, 800)            0         ['batch_normalization_73[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_73 (Conv2D)          (None, 6, 6, 128)            102528    ['activation_73[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_74 (Ba  (None, 6, 6, 128)            512       ['conv2d_73[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_74 (Activation)  (None, 6, 6, 128)            0         ['batch_normalization_74[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_74 (Conv2D)          (None, 6, 6, 32)             36896     ['activation_74[0][0]']       \n",
            "                                                                                                  \n",
            " concatenate_35 (Concatenat  (None, 6, 6, 832)            0         ['concatenate_34[0][0]',      \n",
            " e)                                                                  'conv2d_74[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_75 (Ba  (None, 6, 6, 832)            3328      ['concatenate_35[0][0]']      \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_75 (Activation)  (None, 6, 6, 832)            0         ['batch_normalization_75[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_75 (Conv2D)          (None, 6, 6, 128)            106624    ['activation_75[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_76 (Ba  (None, 6, 6, 128)            512       ['conv2d_75[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_76 (Activation)  (None, 6, 6, 128)            0         ['batch_normalization_76[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_76 (Conv2D)          (None, 6, 6, 32)             36896     ['activation_76[0][0]']       \n",
            "                                                                                                  \n",
            " concatenate_36 (Concatenat  (None, 6, 6, 864)            0         ['concatenate_35[0][0]',      \n",
            " e)                                                                  'conv2d_76[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_77 (Ba  (None, 6, 6, 864)            3456      ['concatenate_36[0][0]']      \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_77 (Activation)  (None, 6, 6, 864)            0         ['batch_normalization_77[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_77 (Conv2D)          (None, 6, 6, 128)            110720    ['activation_77[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_78 (Ba  (None, 6, 6, 128)            512       ['conv2d_77[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_78 (Activation)  (None, 6, 6, 128)            0         ['batch_normalization_78[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_78 (Conv2D)          (None, 6, 6, 32)             36896     ['activation_78[0][0]']       \n",
            "                                                                                                  \n",
            " concatenate_37 (Concatenat  (None, 6, 6, 896)            0         ['concatenate_36[0][0]',      \n",
            " e)                                                                  'conv2d_78[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_79 (Ba  (None, 6, 6, 896)            3584      ['concatenate_37[0][0]']      \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_79 (Activation)  (None, 6, 6, 896)            0         ['batch_normalization_79[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_79 (Conv2D)          (None, 6, 6, 128)            114816    ['activation_79[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_80 (Ba  (None, 6, 6, 128)            512       ['conv2d_79[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_80 (Activation)  (None, 6, 6, 128)            0         ['batch_normalization_80[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_80 (Conv2D)          (None, 6, 6, 32)             36896     ['activation_80[0][0]']       \n",
            "                                                                                                  \n",
            " concatenate_38 (Concatenat  (None, 6, 6, 928)            0         ['concatenate_37[0][0]',      \n",
            " e)                                                                  'conv2d_80[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_81 (Ba  (None, 6, 6, 928)            3712      ['concatenate_38[0][0]']      \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_81 (Activation)  (None, 6, 6, 928)            0         ['batch_normalization_81[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_81 (Conv2D)          (None, 6, 6, 128)            118912    ['activation_81[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_82 (Ba  (None, 6, 6, 128)            512       ['conv2d_81[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_82 (Activation)  (None, 6, 6, 128)            0         ['batch_normalization_82[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_82 (Conv2D)          (None, 6, 6, 32)             36896     ['activation_82[0][0]']       \n",
            "                                                                                                  \n",
            " concatenate_39 (Concatenat  (None, 6, 6, 960)            0         ['concatenate_38[0][0]',      \n",
            " e)                                                                  'conv2d_82[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_83 (Ba  (None, 6, 6, 960)            3840      ['concatenate_39[0][0]']      \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_83 (Activation)  (None, 6, 6, 960)            0         ['batch_normalization_83[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_83 (Conv2D)          (None, 6, 6, 128)            123008    ['activation_83[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_84 (Ba  (None, 6, 6, 128)            512       ['conv2d_83[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_84 (Activation)  (None, 6, 6, 128)            0         ['batch_normalization_84[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_84 (Conv2D)          (None, 6, 6, 32)             36896     ['activation_84[0][0]']       \n",
            "                                                                                                  \n",
            " concatenate_40 (Concatenat  (None, 6, 6, 992)            0         ['concatenate_39[0][0]',      \n",
            " e)                                                                  'conv2d_84[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_85 (Ba  (None, 6, 6, 992)            3968      ['concatenate_40[0][0]']      \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_85 (Activation)  (None, 6, 6, 992)            0         ['batch_normalization_85[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_85 (Conv2D)          (None, 6, 6, 128)            127104    ['activation_85[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_86 (Ba  (None, 6, 6, 128)            512       ['conv2d_85[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_86 (Activation)  (None, 6, 6, 128)            0         ['batch_normalization_86[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_86 (Conv2D)          (None, 6, 6, 32)             36896     ['activation_86[0][0]']       \n",
            "                                                                                                  \n",
            " concatenate_41 (Concatenat  (None, 6, 6, 1024)           0         ['concatenate_40[0][0]',      \n",
            " e)                                                                  'conv2d_86[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_87 (Ba  (None, 6, 6, 1024)           4096      ['concatenate_41[0][0]']      \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_87 (Activation)  (None, 6, 6, 1024)           0         ['batch_normalization_87[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_87 (Conv2D)          (None, 6, 6, 128)            131200    ['activation_87[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_88 (Ba  (None, 6, 6, 128)            512       ['conv2d_87[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_88 (Activation)  (None, 6, 6, 128)            0         ['batch_normalization_88[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_88 (Conv2D)          (None, 6, 6, 32)             36896     ['activation_88[0][0]']       \n",
            "                                                                                                  \n",
            " concatenate_42 (Concatenat  (None, 6, 6, 1056)           0         ['concatenate_41[0][0]',      \n",
            " e)                                                                  'conv2d_88[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_89 (Ba  (None, 6, 6, 1056)           4224      ['concatenate_42[0][0]']      \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_89 (Activation)  (None, 6, 6, 1056)           0         ['batch_normalization_89[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_89 (Conv2D)          (None, 6, 6, 128)            135296    ['activation_89[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_90 (Ba  (None, 6, 6, 128)            512       ['conv2d_89[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_90 (Activation)  (None, 6, 6, 128)            0         ['batch_normalization_90[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_90 (Conv2D)          (None, 6, 6, 32)             36896     ['activation_90[0][0]']       \n",
            "                                                                                                  \n",
            " concatenate_43 (Concatenat  (None, 6, 6, 1088)           0         ['concatenate_42[0][0]',      \n",
            " e)                                                                  'conv2d_90[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_91 (Ba  (None, 6, 6, 1088)           4352      ['concatenate_43[0][0]']      \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_91 (Activation)  (None, 6, 6, 1088)           0         ['batch_normalization_91[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_91 (Conv2D)          (None, 6, 6, 128)            139392    ['activation_91[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_92 (Ba  (None, 6, 6, 128)            512       ['conv2d_91[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_92 (Activation)  (None, 6, 6, 128)            0         ['batch_normalization_92[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_92 (Conv2D)          (None, 6, 6, 32)             36896     ['activation_92[0][0]']       \n",
            "                                                                                                  \n",
            " concatenate_44 (Concatenat  (None, 6, 6, 1120)           0         ['concatenate_43[0][0]',      \n",
            " e)                                                                  'conv2d_92[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_93 (Ba  (None, 6, 6, 1120)           4480      ['concatenate_44[0][0]']      \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_93 (Activation)  (None, 6, 6, 1120)           0         ['batch_normalization_93[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_93 (Conv2D)          (None, 6, 6, 128)            143488    ['activation_93[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_94 (Ba  (None, 6, 6, 128)            512       ['conv2d_93[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_94 (Activation)  (None, 6, 6, 128)            0         ['batch_normalization_94[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_94 (Conv2D)          (None, 6, 6, 32)             36896     ['activation_94[0][0]']       \n",
            "                                                                                                  \n",
            " concatenate_45 (Concatenat  (None, 6, 6, 1152)           0         ['concatenate_44[0][0]',      \n",
            " e)                                                                  'conv2d_94[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_95 (Ba  (None, 6, 6, 1152)           4608      ['concatenate_45[0][0]']      \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_95 (Activation)  (None, 6, 6, 1152)           0         ['batch_normalization_95[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_95 (Conv2D)          (None, 6, 6, 128)            147584    ['activation_95[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_96 (Ba  (None, 6, 6, 128)            512       ['conv2d_95[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_96 (Activation)  (None, 6, 6, 128)            0         ['batch_normalization_96[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_96 (Conv2D)          (None, 6, 6, 32)             36896     ['activation_96[0][0]']       \n",
            "                                                                                                  \n",
            " concatenate_46 (Concatenat  (None, 6, 6, 1184)           0         ['concatenate_45[0][0]',      \n",
            " e)                                                                  'conv2d_96[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_97 (Ba  (None, 6, 6, 1184)           4736      ['concatenate_46[0][0]']      \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_97 (Activation)  (None, 6, 6, 1184)           0         ['batch_normalization_97[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_97 (Conv2D)          (None, 6, 6, 128)            151680    ['activation_97[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_98 (Ba  (None, 6, 6, 128)            512       ['conv2d_97[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_98 (Activation)  (None, 6, 6, 128)            0         ['batch_normalization_98[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_98 (Conv2D)          (None, 6, 6, 32)             36896     ['activation_98[0][0]']       \n",
            "                                                                                                  \n",
            " concatenate_47 (Concatenat  (None, 6, 6, 1216)           0         ['concatenate_46[0][0]',      \n",
            " e)                                                                  'conv2d_98[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_99 (Ba  (None, 6, 6, 1216)           4864      ['concatenate_47[0][0]']      \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_99 (Activation)  (None, 6, 6, 1216)           0         ['batch_normalization_99[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_99 (Conv2D)          (None, 6, 6, 128)            155776    ['activation_99[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_100 (B  (None, 6, 6, 128)            512       ['conv2d_99[0][0]']           \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_100 (Activation  (None, 6, 6, 128)            0         ['batch_normalization_100[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_100 (Conv2D)         (None, 6, 6, 32)             36896     ['activation_100[0][0]']      \n",
            "                                                                                                  \n",
            " concatenate_48 (Concatenat  (None, 6, 6, 1248)           0         ['concatenate_47[0][0]',      \n",
            " e)                                                                  'conv2d_100[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_101 (B  (None, 6, 6, 1248)           4992      ['concatenate_48[0][0]']      \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_101 (Activation  (None, 6, 6, 1248)           0         ['batch_normalization_101[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_101 (Conv2D)         (None, 6, 6, 128)            159872    ['activation_101[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_102 (B  (None, 6, 6, 128)            512       ['conv2d_101[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_102 (Activation  (None, 6, 6, 128)            0         ['batch_normalization_102[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_102 (Conv2D)         (None, 6, 6, 32)             36896     ['activation_102[0][0]']      \n",
            "                                                                                                  \n",
            " concatenate_49 (Concatenat  (None, 6, 6, 1280)           0         ['concatenate_48[0][0]',      \n",
            " e)                                                                  'conv2d_102[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_103 (B  (None, 6, 6, 1280)           5120      ['concatenate_49[0][0]']      \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_103 (Activation  (None, 6, 6, 1280)           0         ['batch_normalization_103[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_103 (Conv2D)         (None, 6, 6, 128)            163968    ['activation_103[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_104 (B  (None, 6, 6, 128)            512       ['conv2d_103[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_104 (Activation  (None, 6, 6, 128)            0         ['batch_normalization_104[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_104 (Conv2D)         (None, 6, 6, 32)             36896     ['activation_104[0][0]']      \n",
            "                                                                                                  \n",
            " concatenate_50 (Concatenat  (None, 6, 6, 1312)           0         ['concatenate_49[0][0]',      \n",
            " e)                                                                  'conv2d_104[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_105 (B  (None, 6, 6, 1312)           5248      ['concatenate_50[0][0]']      \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_105 (Activation  (None, 6, 6, 1312)           0         ['batch_normalization_105[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_105 (Conv2D)         (None, 6, 6, 128)            168064    ['activation_105[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_106 (B  (None, 6, 6, 128)            512       ['conv2d_105[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_106 (Activation  (None, 6, 6, 128)            0         ['batch_normalization_106[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_106 (Conv2D)         (None, 6, 6, 32)             36896     ['activation_106[0][0]']      \n",
            "                                                                                                  \n",
            " concatenate_51 (Concatenat  (None, 6, 6, 1344)           0         ['concatenate_50[0][0]',      \n",
            " e)                                                                  'conv2d_106[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_107 (B  (None, 6, 6, 1344)           5376      ['concatenate_51[0][0]']      \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_107 (Activation  (None, 6, 6, 1344)           0         ['batch_normalization_107[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_107 (Conv2D)         (None, 6, 6, 128)            172160    ['activation_107[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_108 (B  (None, 6, 6, 128)            512       ['conv2d_107[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_108 (Activation  (None, 6, 6, 128)            0         ['batch_normalization_108[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_108 (Conv2D)         (None, 6, 6, 32)             36896     ['activation_108[0][0]']      \n",
            "                                                                                                  \n",
            " concatenate_52 (Concatenat  (None, 6, 6, 1376)           0         ['concatenate_51[0][0]',      \n",
            " e)                                                                  'conv2d_108[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_109 (B  (None, 6, 6, 1376)           5504      ['concatenate_52[0][0]']      \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_109 (Activation  (None, 6, 6, 1376)           0         ['batch_normalization_109[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_109 (Conv2D)         (None, 6, 6, 128)            176256    ['activation_109[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_110 (B  (None, 6, 6, 128)            512       ['conv2d_109[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_110 (Activation  (None, 6, 6, 128)            0         ['batch_normalization_110[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_110 (Conv2D)         (None, 6, 6, 32)             36896     ['activation_110[0][0]']      \n",
            "                                                                                                  \n",
            " concatenate_53 (Concatenat  (None, 6, 6, 1408)           0         ['concatenate_52[0][0]',      \n",
            " e)                                                                  'conv2d_110[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_111 (B  (None, 6, 6, 1408)           5632      ['concatenate_53[0][0]']      \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_111 (Activation  (None, 6, 6, 1408)           0         ['batch_normalization_111[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_111 (Conv2D)         (None, 6, 6, 128)            180352    ['activation_111[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_112 (B  (None, 6, 6, 128)            512       ['conv2d_111[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_112 (Activation  (None, 6, 6, 128)            0         ['batch_normalization_112[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_112 (Conv2D)         (None, 6, 6, 32)             36896     ['activation_112[0][0]']      \n",
            "                                                                                                  \n",
            " concatenate_54 (Concatenat  (None, 6, 6, 1440)           0         ['concatenate_53[0][0]',      \n",
            " e)                                                                  'conv2d_112[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_113 (B  (None, 6, 6, 1440)           5760      ['concatenate_54[0][0]']      \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_113 (Activation  (None, 6, 6, 1440)           0         ['batch_normalization_113[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_113 (Conv2D)         (None, 6, 6, 128)            184448    ['activation_113[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_114 (B  (None, 6, 6, 128)            512       ['conv2d_113[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_114 (Activation  (None, 6, 6, 128)            0         ['batch_normalization_114[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_114 (Conv2D)         (None, 6, 6, 32)             36896     ['activation_114[0][0]']      \n",
            "                                                                                                  \n",
            " concatenate_55 (Concatenat  (None, 6, 6, 1472)           0         ['concatenate_54[0][0]',      \n",
            " e)                                                                  'conv2d_114[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_115 (B  (None, 6, 6, 1472)           5888      ['concatenate_55[0][0]']      \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_115 (Activation  (None, 6, 6, 1472)           0         ['batch_normalization_115[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_115 (Conv2D)         (None, 6, 6, 128)            188544    ['activation_115[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_116 (B  (None, 6, 6, 128)            512       ['conv2d_115[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_116 (Activation  (None, 6, 6, 128)            0         ['batch_normalization_116[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_116 (Conv2D)         (None, 6, 6, 32)             36896     ['activation_116[0][0]']      \n",
            "                                                                                                  \n",
            " concatenate_56 (Concatenat  (None, 6, 6, 1504)           0         ['concatenate_55[0][0]',      \n",
            " e)                                                                  'conv2d_116[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_117 (B  (None, 6, 6, 1504)           6016      ['concatenate_56[0][0]']      \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_117 (Activation  (None, 6, 6, 1504)           0         ['batch_normalization_117[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_117 (Conv2D)         (None, 6, 6, 128)            192640    ['activation_117[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_118 (B  (None, 6, 6, 128)            512       ['conv2d_117[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_118 (Activation  (None, 6, 6, 128)            0         ['batch_normalization_118[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_118 (Conv2D)         (None, 6, 6, 32)             36896     ['activation_118[0][0]']      \n",
            "                                                                                                  \n",
            " concatenate_57 (Concatenat  (None, 6, 6, 1536)           0         ['concatenate_56[0][0]',      \n",
            " e)                                                                  'conv2d_118[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_119 (B  (None, 6, 6, 1536)           6144      ['concatenate_57[0][0]']      \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_119 (Activation  (None, 6, 6, 1536)           0         ['batch_normalization_119[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_119 (Conv2D)         (None, 6, 6, 128)            196736    ['activation_119[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_120 (B  (None, 6, 6, 128)            512       ['conv2d_119[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_120 (Activation  (None, 6, 6, 128)            0         ['batch_normalization_120[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_120 (Conv2D)         (None, 6, 6, 32)             36896     ['activation_120[0][0]']      \n",
            "                                                                                                  \n",
            " concatenate_58 (Concatenat  (None, 6, 6, 1568)           0         ['concatenate_57[0][0]',      \n",
            " e)                                                                  'conv2d_120[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_121 (B  (None, 6, 6, 1568)           6272      ['concatenate_58[0][0]']      \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_121 (Activation  (None, 6, 6, 1568)           0         ['batch_normalization_121[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_121 (Conv2D)         (None, 6, 6, 128)            200832    ['activation_121[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_122 (B  (None, 6, 6, 128)            512       ['conv2d_121[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_122 (Activation  (None, 6, 6, 128)            0         ['batch_normalization_122[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_122 (Conv2D)         (None, 6, 6, 32)             36896     ['activation_122[0][0]']      \n",
            "                                                                                                  \n",
            " concatenate_59 (Concatenat  (None, 6, 6, 1600)           0         ['concatenate_58[0][0]',      \n",
            " e)                                                                  'conv2d_122[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_123 (B  (None, 6, 6, 1600)           6400      ['concatenate_59[0][0]']      \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_123 (Activation  (None, 6, 6, 1600)           0         ['batch_normalization_123[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_123 (Conv2D)         (None, 6, 6, 128)            204928    ['activation_123[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_124 (B  (None, 6, 6, 128)            512       ['conv2d_123[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_124 (Activation  (None, 6, 6, 128)            0         ['batch_normalization_124[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_124 (Conv2D)         (None, 6, 6, 32)             36896     ['activation_124[0][0]']      \n",
            "                                                                                                  \n",
            " concatenate_60 (Concatenat  (None, 6, 6, 1632)           0         ['concatenate_59[0][0]',      \n",
            " e)                                                                  'conv2d_124[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_125 (B  (None, 6, 6, 1632)           6528      ['concatenate_60[0][0]']      \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_125 (Activation  (None, 6, 6, 1632)           0         ['batch_normalization_125[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_125 (Conv2D)         (None, 6, 6, 128)            209024    ['activation_125[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_126 (B  (None, 6, 6, 128)            512       ['conv2d_125[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_126 (Activation  (None, 6, 6, 128)            0         ['batch_normalization_126[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_126 (Conv2D)         (None, 6, 6, 32)             36896     ['activation_126[0][0]']      \n",
            "                                                                                                  \n",
            " concatenate_61 (Concatenat  (None, 6, 6, 1664)           0         ['concatenate_60[0][0]',      \n",
            " e)                                                                  'conv2d_126[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_127 (B  (None, 6, 6, 1664)           6656      ['concatenate_61[0][0]']      \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_127 (Activation  (None, 6, 6, 1664)           0         ['batch_normalization_127[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_127 (Conv2D)         (None, 6, 6, 128)            213120    ['activation_127[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_128 (B  (None, 6, 6, 128)            512       ['conv2d_127[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_128 (Activation  (None, 6, 6, 128)            0         ['batch_normalization_128[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_128 (Conv2D)         (None, 6, 6, 32)             36896     ['activation_128[0][0]']      \n",
            "                                                                                                  \n",
            " concatenate_62 (Concatenat  (None, 6, 6, 1696)           0         ['concatenate_61[0][0]',      \n",
            " e)                                                                  'conv2d_128[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_129 (B  (None, 6, 6, 1696)           6784      ['concatenate_62[0][0]']      \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_129 (Activation  (None, 6, 6, 1696)           0         ['batch_normalization_129[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_129 (Conv2D)         (None, 6, 6, 128)            217216    ['activation_129[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_130 (B  (None, 6, 6, 128)            512       ['conv2d_129[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_130 (Activation  (None, 6, 6, 128)            0         ['batch_normalization_130[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_130 (Conv2D)         (None, 6, 6, 32)             36896     ['activation_130[0][0]']      \n",
            "                                                                                                  \n",
            " concatenate_63 (Concatenat  (None, 6, 6, 1728)           0         ['concatenate_62[0][0]',      \n",
            " e)                                                                  'conv2d_130[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_131 (B  (None, 6, 6, 1728)           6912      ['concatenate_63[0][0]']      \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_131 (Activation  (None, 6, 6, 1728)           0         ['batch_normalization_131[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_131 (Conv2D)         (None, 6, 6, 128)            221312    ['activation_131[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_132 (B  (None, 6, 6, 128)            512       ['conv2d_131[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_132 (Activation  (None, 6, 6, 128)            0         ['batch_normalization_132[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_132 (Conv2D)         (None, 6, 6, 32)             36896     ['activation_132[0][0]']      \n",
            "                                                                                                  \n",
            " concatenate_64 (Concatenat  (None, 6, 6, 1760)           0         ['concatenate_63[0][0]',      \n",
            " e)                                                                  'conv2d_132[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_133 (B  (None, 6, 6, 1760)           7040      ['concatenate_64[0][0]']      \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_133 (Activation  (None, 6, 6, 1760)           0         ['batch_normalization_133[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_133 (Conv2D)         (None, 6, 6, 128)            225408    ['activation_133[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_134 (B  (None, 6, 6, 128)            512       ['conv2d_133[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_134 (Activation  (None, 6, 6, 128)            0         ['batch_normalization_134[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_134 (Conv2D)         (None, 6, 6, 32)             36896     ['activation_134[0][0]']      \n",
            "                                                                                                  \n",
            " concatenate_65 (Concatenat  (None, 6, 6, 1792)           0         ['concatenate_64[0][0]',      \n",
            " e)                                                                  'conv2d_134[0][0]']          \n",
            "                                                                                                  \n",
            " global_average_pooling2d (  (None, 1792)                 0         ['concatenate_65[0][0]']      \n",
            " GlobalAveragePooling2D)                                                                          \n",
            "                                                                                                  \n",
            " dense (Dense)               (None, 2)                    3586      ['global_average_pooling2d[0][\n",
            "                                                                    0]']                          \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 9640258 (36.77 MB)\n",
            "Trainable params: 9515906 (36.30 MB)\n",
            "Non-trainable params: 124352 (485.75 KB)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "learning_rate = 0.00001\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "\n",
        "\n",
        "# Define steps per epoch and validation steps\n",
        "steps_per_epoch = len(x_train_normalized) // batch_size\n",
        "validation_steps = len(x_val_normalized) // batch_size\n",
        "\n",
        "# Train the model with early stopping\n",
        "history = model.fit(\n",
        "    train_set_conv,\n",
        "    steps_per_epoch=steps_per_epoch,\n",
        "    epochs=25,  # You can adjust the number of epochs\n",
        "    validation_data=valid_set_conv,\n",
        "    validation_steps=validation_steps,\n",
        "\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IrFrlLXj00sa",
        "outputId": "1e78214a-7527-48be-9a7d-bfa1395bca70"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "36/36 [==============================] - 97s 354ms/step - loss: 0.4499 - accuracy: 0.7763 - val_loss: 0.6934 - val_accuracy: 0.4812\n",
            "Epoch 2/25\n",
            "36/36 [==============================] - 9s 254ms/step - loss: 0.4092 - accuracy: 0.8065 - val_loss: 0.6915 - val_accuracy: 0.5188\n",
            "Epoch 3/25\n",
            "36/36 [==============================] - 10s 278ms/step - loss: 0.3849 - accuracy: 0.8047 - val_loss: 0.6947 - val_accuracy: 0.5156\n",
            "Epoch 4/25\n",
            "36/36 [==============================] - 10s 289ms/step - loss: 0.3706 - accuracy: 0.8162 - val_loss: 0.7161 - val_accuracy: 0.5125\n",
            "Epoch 5/25\n",
            "36/36 [==============================] - 9s 244ms/step - loss: 0.3539 - accuracy: 0.8362 - val_loss: 0.7095 - val_accuracy: 0.5250\n",
            "Epoch 6/25\n",
            "36/36 [==============================] - 10s 277ms/step - loss: 0.3551 - accuracy: 0.8265 - val_loss: 0.7073 - val_accuracy: 0.5250\n",
            "Epoch 7/25\n",
            "36/36 [==============================] - 11s 291ms/step - loss: 0.3498 - accuracy: 0.8327 - val_loss: 0.7053 - val_accuracy: 0.5844\n",
            "Epoch 8/25\n",
            "36/36 [==============================] - 10s 283ms/step - loss: 0.3449 - accuracy: 0.8273 - val_loss: 0.7101 - val_accuracy: 0.5094\n",
            "Epoch 9/25\n",
            "36/36 [==============================] - 11s 297ms/step - loss: 0.3342 - accuracy: 0.8407 - val_loss: 0.6952 - val_accuracy: 0.5562\n",
            "Epoch 10/25\n",
            "36/36 [==============================] - 11s 291ms/step - loss: 0.3222 - accuracy: 0.8455 - val_loss: 0.6471 - val_accuracy: 0.6125\n",
            "Epoch 11/25\n",
            "36/36 [==============================] - 10s 287ms/step - loss: 0.3281 - accuracy: 0.8478 - val_loss: 0.6203 - val_accuracy: 0.6250\n",
            "Epoch 12/25\n",
            "36/36 [==============================] - 9s 244ms/step - loss: 0.3431 - accuracy: 0.8336 - val_loss: 0.6107 - val_accuracy: 0.6594\n",
            "Epoch 13/25\n",
            "36/36 [==============================] - 11s 284ms/step - loss: 0.3117 - accuracy: 0.8433 - val_loss: 0.6001 - val_accuracy: 0.6656\n",
            "Epoch 14/25\n",
            "36/36 [==============================] - 11s 288ms/step - loss: 0.3069 - accuracy: 0.8602 - val_loss: 0.6066 - val_accuracy: 0.6625\n",
            "Epoch 15/25\n",
            "36/36 [==============================] - 9s 258ms/step - loss: 0.3053 - accuracy: 0.8562 - val_loss: 0.5315 - val_accuracy: 0.7031\n",
            "Epoch 16/25\n",
            "36/36 [==============================] - 10s 257ms/step - loss: 0.2993 - accuracy: 0.8549 - val_loss: 0.3905 - val_accuracy: 0.7812\n",
            "Epoch 17/25\n",
            "36/36 [==============================] - 11s 290ms/step - loss: 0.2973 - accuracy: 0.8584 - val_loss: 0.3933 - val_accuracy: 0.8062\n",
            "Epoch 18/25\n",
            "36/36 [==============================] - 11s 290ms/step - loss: 0.2929 - accuracy: 0.8611 - val_loss: 0.3228 - val_accuracy: 0.8406\n",
            "Epoch 19/25\n",
            "36/36 [==============================] - 9s 254ms/step - loss: 0.2971 - accuracy: 0.8593 - val_loss: 0.2738 - val_accuracy: 0.8813\n",
            "Epoch 20/25\n",
            "36/36 [==============================] - 10s 260ms/step - loss: 0.2932 - accuracy: 0.8557 - val_loss: 0.2509 - val_accuracy: 0.9000\n",
            "Epoch 21/25\n",
            "36/36 [==============================] - 11s 293ms/step - loss: 0.2795 - accuracy: 0.8676 - val_loss: 0.2730 - val_accuracy: 0.8781\n",
            "Epoch 22/25\n",
            "36/36 [==============================] - 11s 291ms/step - loss: 0.2867 - accuracy: 0.8704 - val_loss: 0.2712 - val_accuracy: 0.8938\n",
            "Epoch 23/25\n",
            "36/36 [==============================] - 9s 259ms/step - loss: 0.2757 - accuracy: 0.8700 - val_loss: 0.2429 - val_accuracy: 0.8969\n",
            "Epoch 24/25\n",
            "36/36 [==============================] - 10s 270ms/step - loss: 0.2679 - accuracy: 0.8748 - val_loss: 0.2409 - val_accuracy: 0.9000\n",
            "Epoch 25/25\n",
            "36/36 [==============================] - 10s 288ms/step - loss: 0.2635 - accuracy: 0.8766 - val_loss: 0.2753 - val_accuracy: 0.8750\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on the training data\n",
        "train_loss, train_accuracy = model.evaluate(train_set_conv, steps=steps_per_epoch)\n",
        "print(f\"Training Loss: {train_loss:.4f}\")\n",
        "print(f\"Training Accuracy: {train_accuracy * 100:.2f}%\")\n",
        "\n",
        "# Evaluate the model on the test data\n",
        "test_loss, test_accuracy = model.evaluate(test_set_conv, steps=validation_steps)\n",
        "print(f\"Test Loss: {test_loss:.4f}\")\n",
        "print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SWuZRBUS2PjM",
        "outputId": "c5dc1e6a-0475-4cb5-ac75-f8b0ac984c5c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "36/36 [==============================] - 7s 190ms/step - loss: 0.2846 - accuracy: 0.8668\n",
            "Training Loss: 0.2846\n",
            "Training Accuracy: 86.68%\n",
            "5/5 [==============================] - 0s 87ms/step - loss: 0.3132 - accuracy: 0.8625\n",
            "Test Loss: 0.3132\n",
            "Test Accuracy: 86.25%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_features = model.predict(x_train_normalized)\n",
        "x_val_features = model.predict(x_val_normalized)\n",
        "x_test_features = model.predict(x_test_normalized)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QM-Z5XlreDzt",
        "outputId": "5eb30b2c-cc69-47b0-bcc5-ddf31db1cf8a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "73/73 [==============================] - 10s 33ms/step\n",
            "11/11 [==============================] - 2s 169ms/step\n",
            "21/21 [==============================] - 2s 110ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_features = x_train_features.reshape(x_train_features.shape[0], -1)\n",
        "x_val_features = x_val_features.reshape(x_val_features.shape[0], -1)\n",
        "x_test_features = x_test_features.reshape(x_test_features.shape[0], -1)"
      ],
      "metadata": {
        "id": "27F309BPhjSY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix"
      ],
      "metadata": {
        "id": "FN70K9hzhtGD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Support Vector Machine (SVM)\n",
        "svm_model = SVC(kernel='rbf', C=4, gamma='scale')\n",
        "svm_model.fit(x_train_features, y_train)\n",
        "y_pred_svm = svm_model.predict(x_test_features)\n",
        "\n",
        "svm_accuracy = accuracy_score(y_test, y_pred_svm)\n",
        "svm_precision = precision_score(y_test, y_pred_svm)\n",
        "svm_recall = recall_score(y_test, y_pred_svm)\n",
        "svm_f1 = f1_score(y_test, y_pred_svm)\n",
        "\n",
        "tn, fp, fn, tp = confusion_matrix(y_test, y_pred_svm).ravel()\n",
        "svm_specificity = tn / (tn + fp)\n",
        "\n",
        "print(\"SVM Accuracy:\", svm_accuracy)\n",
        "print(\"SVM Precision:\", svm_precision)\n",
        "print(\"SVM Sensitivity (Recall):\", svm_recall)\n",
        "print(\"SVM Specificity:\", svm_specificity)\n",
        "print(\"SVM F1 Score:\", svm_f1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XtM1oVJdh5kE",
        "outputId": "dd60f35d-8150-4f2b-f420-41d84fb866de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVM Accuracy: 0.8733031674208145\n",
            "SVM Precision: 0.8558823529411764\n",
            "SVM Sensitivity (Recall): 0.8926380368098159\n",
            "SVM Specificity: 0.8545994065281899\n",
            "SVM F1 Score: 0.8738738738738737\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Random Forest Classifier\n",
        "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf_model.fit(x_train_features, y_train)\n",
        "y_pred_rf = rf_model.predict(x_test_features)\n",
        "\n",
        "rf_accuracy = accuracy_score(y_test, y_pred_rf)\n",
        "rf_precision = precision_score(y_test, y_pred_rf)\n",
        "rf_recall = recall_score(y_test, y_pred_rf)\n",
        "rf_f1 = f1_score(y_test, y_pred_rf)\n",
        "\n",
        "tn, fp, fn, tp = confusion_matrix(y_test, y_pred_rf).ravel()\n",
        "rf_specificity = tn / (tn + fp)\n",
        "\n",
        "print(\"Random Forest Accuracy:\", rf_accuracy)\n",
        "print(\"Random Forest Precision:\", rf_precision)\n",
        "print(\"Random Forest Sensitivity (Recall):\", rf_recall)\n",
        "print(\"Random Forest Specificity:\", rf_specificity)\n",
        "print(\"Random Forest F1 Score:\", rf_f1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x9i0kygfivs3",
        "outputId": "583ee415-c50e-4fbe-c5c5-b22451f2c6ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest Accuracy: 0.8310708898944194\n",
            "Random Forest Precision: 0.842948717948718\n",
            "Random Forest Sensitivity (Recall): 0.8067484662576687\n",
            "Random Forest Specificity: 0.8545994065281899\n",
            "Random Forest F1 Score: 0.8244514106583071\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# K-Nearest Neighbors Classifier\n",
        "knn_model = KNeighborsClassifier(n_neighbors=5)\n",
        "knn_model.fit(x_train_features, y_train)\n",
        "y_pred_knn = knn_model.predict(x_test_features)\n",
        "\n",
        "knn_accuracy = accuracy_score(y_test, y_pred_knn)\n",
        "knn_precision = precision_score(y_test, y_pred_knn)\n",
        "knn_recall = recall_score(y_test, y_pred_knn)\n",
        "knn_f1 = f1_score(y_test, y_pred_knn)\n",
        "\n",
        "tn, fp, fn, tp = confusion_matrix(y_test, y_pred_knn).ravel()\n",
        "knn_specificity = tn / (tn + fp)\n",
        "\n",
        "print(\"KNN Accuracy:\", knn_accuracy)\n",
        "print(\"KNN Precision:\", knn_precision)\n",
        "print(\"KNN Sensitivity (Recall):\", knn_recall)\n",
        "print(\"KNN Specificity:\", knn_specificity)\n",
        "print(\"KNN F1 Score:\", knn_f1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uczXAF8ri2g6",
        "outputId": "d6880b0d-f168-4f6a-9899-182852ebe5d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KNN Accuracy: 0.8567119155354449\n",
            "KNN Precision: 0.851063829787234\n",
            "KNN Sensitivity (Recall): 0.8588957055214724\n",
            "KNN Specificity: 0.8545994065281899\n",
            "KNN F1 Score: 0.8549618320610687\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Conv2D, BatchNormalization, ReLU, DepthwiseConv2D, GlobalAveragePooling2D, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.layers import Dropout\n",
        "\n",
        "# Define input shape\n",
        "input_shape = (100, 100, 3)  # Assuming input images have shape (224, 224, 3)\n",
        "num_classes = 2  # Number of output classes\n",
        "\n",
        "# Build ResNet50-like architecture\n",
        "def build_resnet50(input_shape):\n",
        "    input_tensor = Input(shape=input_shape)\n",
        "\n",
        "    # Initial convolutional layer\n",
        "    x = Conv2D(64, (7, 7), strides=(2, 2), padding='same')(input_tensor)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = ReLU()(x)\n",
        "\n",
        "    # Residual blocks\n",
        "    x = resnet_block(x, filters=[64, 64, 256], strides=1, block_name='block1')\n",
        "    x = resnet_block(x, filters=[128, 128, 512], strides=2, block_name='block2')\n",
        "    x = resnet_block(x, filters=[256, 256, 1024], strides=2, block_name='block3')\n",
        "    x = resnet_block(x, filters=[512, 512, 2048], strides=2, block_name='block4')\n",
        "\n",
        "    # Global Average Pooling\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "\n",
        "    return Model(inputs=input_tensor, outputs=x)\n",
        "\n",
        "# Define MobileNet-like architecture\n",
        "def build_mobilenet(input_shape):\n",
        "    input_tensor = Input(shape=input_shape)\n",
        "\n",
        "    # Initial depthwise separable convolution\n",
        "    x = DepthwiseConv2D((3, 3), strides=(2, 2), padding='same')(input_tensor)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = ReLU()(x)\n",
        "\n",
        "    # Depthwise separable convolutions\n",
        "    x = mobilenet_block(x, filters=128, strides=1, block_name='block1')\n",
        "    x = mobilenet_block(x, filters=256, strides=2, block_name='block2')\n",
        "    x = mobilenet_block(x, filters=512, strides=2, block_name='block3')\n",
        "    x = mobilenet_block(x, filters=1024, strides=2, block_name='block4')\n",
        "\n",
        "    # Global Average Pooling\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "\n",
        "    return Model(inputs=input_tensor, outputs=x)\n",
        "\n",
        "# ResNet block\n",
        "def resnet_block(input_tensor, filters, strides, block_name):\n",
        "    x = Conv2D(filters[0], (1, 1), strides=strides, padding='same', name=block_name+'_conv1')(input_tensor)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = ReLU()(x)\n",
        "\n",
        "    x = Conv2D(filters[1], (3, 3), padding='same', name=block_name+'_conv2')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = ReLU()(x)\n",
        "\n",
        "    x = Conv2D(filters[2], (1, 1), padding='same', name=block_name+'_conv3')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "\n",
        "    # Shortcut connection\n",
        "    shortcut = Conv2D(filters[2], (1, 1), strides=strides, padding='same', name=block_name+'_shortcut')(input_tensor)\n",
        "    shortcut = BatchNormalization()(shortcut)\n",
        "\n",
        "    # Add shortcut to the output\n",
        "    x = tf.keras.layers.add([x, shortcut])\n",
        "    x = ReLU()(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "# MobileNet block\n",
        "def mobilenet_block(input_tensor, filters, strides, block_name):\n",
        "    x = DepthwiseConv2D((3, 3), strides=strides, padding='same', name=block_name+'_depthwise')(input_tensor)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = ReLU()(x)\n",
        "\n",
        "    x = Conv2D(filters, (1, 1), padding='same', name=block_name+'_pointwise')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = ReLU()(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "# Build ResNet50 model\n",
        "resnet_model = build_resnet50(input_shape)\n",
        "\n",
        "# Build MobileNet model\n",
        "mobilenet_model = build_mobilenet(input_shape)\n",
        "\n",
        "# Concatenate the output tensors from ResNet50 and MobileNet\n",
        "concatenated_output = tf.keras.layers.Concatenate()([resnet_model.output, mobilenet_model.output])\n",
        "\n",
        "# Add custom dense layers for classification with regularization\n",
        "dense_layer = Dense(128, activation='relu', kernel_regularizer=l2(0.001))(concatenated_output)\n",
        "dense_layer = Dropout(0.5)(dense_layer)  # Adding dropout with a rate of 0.5\n",
        "\n",
        "output_layer = Dense(num_classes, activation='softmax', kernel_regularizer=l2(0.001))(dense_layer)\n",
        "\n",
        "# Create the hybrid model with regularization\n",
        "hybrid_model_regularized = Model(inputs=[resnet_model.input, mobilenet_model.input], outputs=output_layer)\n",
        "\n",
        "# Compile the model\n",
        "hybrid_model_regularized.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Print summary of the model architecture\n",
        "hybrid_model_regularized.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tcFcTMo-j2-J",
        "outputId": "282fa962-2cc9-4ea5-cae9-341eb921aea1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)        [(None, 100, 100, 3)]        0         []                            \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)             (None, 50, 50, 64)           9472      ['input_1[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization (Batch  (None, 50, 50, 64)           256       ['conv2d[0][0]']              \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " re_lu (ReLU)                (None, 50, 50, 64)           0         ['batch_normalization[0][0]'] \n",
            "                                                                                                  \n",
            " block1_conv1 (Conv2D)       (None, 50, 50, 64)           4160      ['re_lu[0][0]']               \n",
            "                                                                                                  \n",
            " batch_normalization_1 (Bat  (None, 50, 50, 64)           256       ['block1_conv1[0][0]']        \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " re_lu_1 (ReLU)              (None, 50, 50, 64)           0         ['batch_normalization_1[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " block1_conv2 (Conv2D)       (None, 50, 50, 64)           36928     ['re_lu_1[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_2 (Bat  (None, 50, 50, 64)           256       ['block1_conv2[0][0]']        \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " re_lu_2 (ReLU)              (None, 50, 50, 64)           0         ['batch_normalization_2[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " block1_conv3 (Conv2D)       (None, 50, 50, 256)          16640     ['re_lu_2[0][0]']             \n",
            "                                                                                                  \n",
            " block1_shortcut (Conv2D)    (None, 50, 50, 256)          16640     ['re_lu[0][0]']               \n",
            "                                                                                                  \n",
            " batch_normalization_3 (Bat  (None, 50, 50, 256)          1024      ['block1_conv3[0][0]']        \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_4 (Bat  (None, 50, 50, 256)          1024      ['block1_shortcut[0][0]']     \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " add (Add)                   (None, 50, 50, 256)          0         ['batch_normalization_3[0][0]'\n",
            "                                                                    , 'batch_normalization_4[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " re_lu_3 (ReLU)              (None, 50, 50, 256)          0         ['add[0][0]']                 \n",
            "                                                                                                  \n",
            " block2_conv1 (Conv2D)       (None, 25, 25, 128)          32896     ['re_lu_3[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_5 (Bat  (None, 25, 25, 128)          512       ['block2_conv1[0][0]']        \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " re_lu_4 (ReLU)              (None, 25, 25, 128)          0         ['batch_normalization_5[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)        [(None, 100, 100, 3)]        0         []                            \n",
            "                                                                                                  \n",
            " block2_conv2 (Conv2D)       (None, 25, 25, 128)          147584    ['re_lu_4[0][0]']             \n",
            "                                                                                                  \n",
            " depthwise_conv2d (Depthwis  (None, 50, 50, 3)            30        ['input_2[0][0]']             \n",
            " eConv2D)                                                                                         \n",
            "                                                                                                  \n",
            " batch_normalization_6 (Bat  (None, 25, 25, 128)          512       ['block2_conv2[0][0]']        \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_17 (Ba  (None, 50, 50, 3)            12        ['depthwise_conv2d[0][0]']    \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " re_lu_5 (ReLU)              (None, 25, 25, 128)          0         ['batch_normalization_6[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " re_lu_13 (ReLU)             (None, 50, 50, 3)            0         ['batch_normalization_17[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " block2_conv3 (Conv2D)       (None, 25, 25, 512)          66048     ['re_lu_5[0][0]']             \n",
            "                                                                                                  \n",
            " block2_shortcut (Conv2D)    (None, 25, 25, 512)          131584    ['re_lu_3[0][0]']             \n",
            "                                                                                                  \n",
            " block1_depthwise (Depthwis  (None, 50, 50, 3)            30        ['re_lu_13[0][0]']            \n",
            " eConv2D)                                                                                         \n",
            "                                                                                                  \n",
            " batch_normalization_7 (Bat  (None, 25, 25, 512)          2048      ['block2_conv3[0][0]']        \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_8 (Bat  (None, 25, 25, 512)          2048      ['block2_shortcut[0][0]']     \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_18 (Ba  (None, 50, 50, 3)            12        ['block1_depthwise[0][0]']    \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " add_1 (Add)                 (None, 25, 25, 512)          0         ['batch_normalization_7[0][0]'\n",
            "                                                                    , 'batch_normalization_8[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " re_lu_14 (ReLU)             (None, 50, 50, 3)            0         ['batch_normalization_18[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " re_lu_6 (ReLU)              (None, 25, 25, 512)          0         ['add_1[0][0]']               \n",
            "                                                                                                  \n",
            " block1_pointwise (Conv2D)   (None, 50, 50, 128)          512       ['re_lu_14[0][0]']            \n",
            "                                                                                                  \n",
            " block3_conv1 (Conv2D)       (None, 13, 13, 256)          131328    ['re_lu_6[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_19 (Ba  (None, 50, 50, 128)          512       ['block1_pointwise[0][0]']    \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_9 (Bat  (None, 13, 13, 256)          1024      ['block3_conv1[0][0]']        \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " re_lu_15 (ReLU)             (None, 50, 50, 128)          0         ['batch_normalization_19[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " re_lu_7 (ReLU)              (None, 13, 13, 256)          0         ['batch_normalization_9[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " block2_depthwise (Depthwis  (None, 25, 25, 128)          1280      ['re_lu_15[0][0]']            \n",
            " eConv2D)                                                                                         \n",
            "                                                                                                  \n",
            " block3_conv2 (Conv2D)       (None, 13, 13, 256)          590080    ['re_lu_7[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_20 (Ba  (None, 25, 25, 128)          512       ['block2_depthwise[0][0]']    \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_10 (Ba  (None, 13, 13, 256)          1024      ['block3_conv2[0][0]']        \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " re_lu_16 (ReLU)             (None, 25, 25, 128)          0         ['batch_normalization_20[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " re_lu_8 (ReLU)              (None, 13, 13, 256)          0         ['batch_normalization_10[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " block2_pointwise (Conv2D)   (None, 25, 25, 256)          33024     ['re_lu_16[0][0]']            \n",
            "                                                                                                  \n",
            " block3_conv3 (Conv2D)       (None, 13, 13, 1024)         263168    ['re_lu_8[0][0]']             \n",
            "                                                                                                  \n",
            " block3_shortcut (Conv2D)    (None, 13, 13, 1024)         525312    ['re_lu_6[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_21 (Ba  (None, 25, 25, 256)          1024      ['block2_pointwise[0][0]']    \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_11 (Ba  (None, 13, 13, 1024)         4096      ['block3_conv3[0][0]']        \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_12 (Ba  (None, 13, 13, 1024)         4096      ['block3_shortcut[0][0]']     \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " re_lu_17 (ReLU)             (None, 25, 25, 256)          0         ['batch_normalization_21[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " add_2 (Add)                 (None, 13, 13, 1024)         0         ['batch_normalization_11[0][0]\n",
            "                                                                    ',                            \n",
            "                                                                     'batch_normalization_12[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " block3_depthwise (Depthwis  (None, 13, 13, 256)          2560      ['re_lu_17[0][0]']            \n",
            " eConv2D)                                                                                         \n",
            "                                                                                                  \n",
            " re_lu_9 (ReLU)              (None, 13, 13, 1024)         0         ['add_2[0][0]']               \n",
            "                                                                                                  \n",
            " batch_normalization_22 (Ba  (None, 13, 13, 256)          1024      ['block3_depthwise[0][0]']    \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " block4_conv1 (Conv2D)       (None, 7, 7, 512)            524800    ['re_lu_9[0][0]']             \n",
            "                                                                                                  \n",
            " re_lu_18 (ReLU)             (None, 13, 13, 256)          0         ['batch_normalization_22[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " batch_normalization_13 (Ba  (None, 7, 7, 512)            2048      ['block4_conv1[0][0]']        \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " block3_pointwise (Conv2D)   (None, 13, 13, 512)          131584    ['re_lu_18[0][0]']            \n",
            "                                                                                                  \n",
            " re_lu_10 (ReLU)             (None, 7, 7, 512)            0         ['batch_normalization_13[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " batch_normalization_23 (Ba  (None, 13, 13, 512)          2048      ['block3_pointwise[0][0]']    \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " block4_conv2 (Conv2D)       (None, 7, 7, 512)            2359808   ['re_lu_10[0][0]']            \n",
            "                                                                                                  \n",
            " re_lu_19 (ReLU)             (None, 13, 13, 512)          0         ['batch_normalization_23[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " batch_normalization_14 (Ba  (None, 7, 7, 512)            2048      ['block4_conv2[0][0]']        \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " block4_depthwise (Depthwis  (None, 7, 7, 512)            5120      ['re_lu_19[0][0]']            \n",
            " eConv2D)                                                                                         \n",
            "                                                                                                  \n",
            " re_lu_11 (ReLU)             (None, 7, 7, 512)            0         ['batch_normalization_14[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " batch_normalization_24 (Ba  (None, 7, 7, 512)            2048      ['block4_depthwise[0][0]']    \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " block4_conv3 (Conv2D)       (None, 7, 7, 2048)           1050624   ['re_lu_11[0][0]']            \n",
            "                                                                                                  \n",
            " block4_shortcut (Conv2D)    (None, 7, 7, 2048)           2099200   ['re_lu_9[0][0]']             \n",
            "                                                                                                  \n",
            " re_lu_20 (ReLU)             (None, 7, 7, 512)            0         ['batch_normalization_24[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " batch_normalization_15 (Ba  (None, 7, 7, 2048)           8192      ['block4_conv3[0][0]']        \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_16 (Ba  (None, 7, 7, 2048)           8192      ['block4_shortcut[0][0]']     \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " block4_pointwise (Conv2D)   (None, 7, 7, 1024)           525312    ['re_lu_20[0][0]']            \n",
            "                                                                                                  \n",
            " add_3 (Add)                 (None, 7, 7, 2048)           0         ['batch_normalization_15[0][0]\n",
            "                                                                    ',                            \n",
            "                                                                     'batch_normalization_16[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " batch_normalization_25 (Ba  (None, 7, 7, 1024)           4096      ['block4_pointwise[0][0]']    \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " re_lu_12 (ReLU)             (None, 7, 7, 2048)           0         ['add_3[0][0]']               \n",
            "                                                                                                  \n",
            " re_lu_21 (ReLU)             (None, 7, 7, 1024)           0         ['batch_normalization_25[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " global_average_pooling2d (  (None, 2048)                 0         ['re_lu_12[0][0]']            \n",
            " GlobalAveragePooling2D)                                                                          \n",
            "                                                                                                  \n",
            " global_average_pooling2d_1  (None, 1024)                 0         ['re_lu_21[0][0]']            \n",
            "  (GlobalAveragePooling2D)                                                                        \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)   (None, 3072)                 0         ['global_average_pooling2d[0][\n",
            "                                                                    0]',                          \n",
            "                                                                     'global_average_pooling2d_1[0\n",
            "                                                                    ][0]']                        \n",
            "                                                                                                  \n",
            " dense (Dense)               (None, 128)                  393344    ['concatenate[0][0]']         \n",
            "                                                                                                  \n",
            " dropout (Dropout)           (None, 128)                  0         ['dense[0][0]']               \n",
            "                                                                                                  \n",
            " dense_1 (Dense)             (None, 2)                    258       ['dropout[0][0]']             \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 9149270 (34.90 MB)\n",
            "Trainable params: 9124298 (34.81 MB)\n",
            "Non-trainable params: 24972 (97.55 KB)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.layers import Dropout\n",
        "\n",
        "# Assuming you have your optimizer, data, and other parameters defined\n",
        "\n",
        "learning_rate = 0.00001\n",
        "optimizer = Adam(learning_rate=learning_rate)\n",
        "\n",
        "# ... (Define x_train_normalized, x_val_normalized, y_train, y_val, batch_size, etc.)\n",
        "\n",
        "# Build the hybrid model with regularization (using previously modified code)\n",
        "# ... (Code for building the model as previously shown)\n",
        "\n",
        "# Compile the model\n",
        "hybrid_model_regularized.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "epochs = 25\n",
        "\n",
        "# Train the regularized model\n",
        "history_regularized = hybrid_model_regularized.fit(\n",
        "    [x_train_normalized, x_train_normalized],\n",
        "    y_train,\n",
        "    epochs=epochs,\n",
        "    batch_size=batch_size,\n",
        "    validation_data=([x_val_normalized, x_val_normalized], y_val)\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_cUxpb9Tj5mH",
        "outputId": "d819fcb1-b4ad-4ebc-aa56-6225aaf384fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "37/37 [==============================] - 45s 317ms/step - loss: 0.7934 - accuracy: 0.7173 - val_loss: 0.9422 - val_accuracy: 0.5166\n",
            "Epoch 2/25\n",
            "37/37 [==============================] - 8s 222ms/step - loss: 0.6879 - accuracy: 0.7730 - val_loss: 0.9536 - val_accuracy: 0.5166\n",
            "Epoch 3/25\n",
            "37/37 [==============================] - 8s 227ms/step - loss: 0.6469 - accuracy: 0.8140 - val_loss: 0.9788 - val_accuracy: 0.5166\n",
            "Epoch 4/25\n",
            "37/37 [==============================] - 8s 226ms/step - loss: 0.6221 - accuracy: 0.8218 - val_loss: 0.9897 - val_accuracy: 0.5166\n",
            "Epoch 5/25\n",
            "37/37 [==============================] - 9s 230ms/step - loss: 0.6059 - accuracy: 0.8274 - val_loss: 0.9630 - val_accuracy: 0.5166\n",
            "Epoch 6/25\n",
            "37/37 [==============================] - 8s 228ms/step - loss: 0.5823 - accuracy: 0.8386 - val_loss: 0.9333 - val_accuracy: 0.5166\n",
            "Epoch 7/25\n",
            "37/37 [==============================] - 9s 232ms/step - loss: 0.5798 - accuracy: 0.8416 - val_loss: 0.8968 - val_accuracy: 0.5378\n",
            "Epoch 8/25\n",
            "37/37 [==============================] - 9s 240ms/step - loss: 0.5763 - accuracy: 0.8386 - val_loss: 0.8423 - val_accuracy: 0.6677\n",
            "Epoch 9/25\n",
            "37/37 [==============================] - 9s 241ms/step - loss: 0.5654 - accuracy: 0.8425 - val_loss: 0.8176 - val_accuracy: 0.7462\n",
            "Epoch 10/25\n",
            "37/37 [==============================] - 9s 244ms/step - loss: 0.5430 - accuracy: 0.8649 - val_loss: 0.7878 - val_accuracy: 0.7976\n",
            "Epoch 11/25\n",
            "37/37 [==============================] - 9s 241ms/step - loss: 0.5276 - accuracy: 0.8701 - val_loss: 0.7551 - val_accuracy: 0.8006\n",
            "Epoch 12/25\n",
            "37/37 [==============================] - 9s 244ms/step - loss: 0.5246 - accuracy: 0.8727 - val_loss: 0.7204 - val_accuracy: 0.7885\n",
            "Epoch 13/25\n",
            "37/37 [==============================] - 9s 255ms/step - loss: 0.5103 - accuracy: 0.8787 - val_loss: 0.6723 - val_accuracy: 0.7885\n",
            "Epoch 14/25\n",
            "37/37 [==============================] - 9s 249ms/step - loss: 0.5040 - accuracy: 0.8848 - val_loss: 0.6468 - val_accuracy: 0.7976\n",
            "Epoch 15/25\n",
            "37/37 [==============================] - 9s 242ms/step - loss: 0.4932 - accuracy: 0.8813 - val_loss: 0.6268 - val_accuracy: 0.8187\n",
            "Epoch 16/25\n",
            "37/37 [==============================] - 9s 252ms/step - loss: 0.4868 - accuracy: 0.8891 - val_loss: 0.5968 - val_accuracy: 0.8248\n",
            "Epoch 17/25\n",
            "37/37 [==============================] - 9s 239ms/step - loss: 0.4637 - accuracy: 0.9016 - val_loss: 0.6058 - val_accuracy: 0.8218\n",
            "Epoch 18/25\n",
            "37/37 [==============================] - 9s 249ms/step - loss: 0.4710 - accuracy: 0.9012 - val_loss: 0.5511 - val_accuracy: 0.8520\n",
            "Epoch 19/25\n",
            "37/37 [==============================] - 9s 247ms/step - loss: 0.4665 - accuracy: 0.9016 - val_loss: 0.5294 - val_accuracy: 0.8701\n",
            "Epoch 20/25\n",
            "37/37 [==============================] - 9s 242ms/step - loss: 0.4470 - accuracy: 0.9111 - val_loss: 0.5376 - val_accuracy: 0.8731\n",
            "Epoch 21/25\n",
            "37/37 [==============================] - 9s 254ms/step - loss: 0.4326 - accuracy: 0.9189 - val_loss: 0.4925 - val_accuracy: 0.8792\n",
            "Epoch 22/25\n",
            "37/37 [==============================] - 9s 243ms/step - loss: 0.4205 - accuracy: 0.9249 - val_loss: 0.4925 - val_accuracy: 0.8973\n",
            "Epoch 23/25\n",
            "37/37 [==============================] - 9s 253ms/step - loss: 0.4215 - accuracy: 0.9232 - val_loss: 0.4819 - val_accuracy: 0.8852\n",
            "Epoch 24/25\n",
            "37/37 [==============================] - 9s 249ms/step - loss: 0.4024 - accuracy: 0.9370 - val_loss: 0.4854 - val_accuracy: 0.9003\n",
            "Epoch 25/25\n",
            "37/37 [==============================] - 9s 252ms/step - loss: 0.3922 - accuracy: 0.9417 - val_loss: 0.4812 - val_accuracy: 0.8852\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate on the training set\n",
        "train_evaluation = hybrid_model_regularized.evaluate([x_train_normalized, x_train_normalized], y_train)\n",
        "train_loss = train_evaluation[0]\n",
        "train_accuracy = train_evaluation[1]\n",
        "\n",
        "print(f\"Training Loss: {train_loss:.4f}\")\n",
        "print(f\"Training Accuracy: {train_accuracy:.4f}\")\n",
        "\n",
        "# Evaluate on the test set\n",
        "test_evaluation = hybrid_model_regularized.evaluate([x_test_normalized, x_test_normalized], y_test)\n",
        "test_loss = test_evaluation[0]\n",
        "test_accuracy = test_evaluation[1]\n",
        "\n",
        "print(f\"Test Loss: {test_loss:.4f}\")\n",
        "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9orXmIz9ma_W",
        "outputId": "d594cd76-1fae-489b-d1ac-fa6f0a4d73db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "73/73 [==============================] - 4s 37ms/step - loss: 0.3469 - accuracy: 0.9763\n",
            "Training Loss: 0.3469\n",
            "Training Accuracy: 0.9763\n",
            "21/21 [==============================] - 1s 69ms/step - loss: 0.5338 - accuracy: 0.8733\n",
            "Test Loss: 0.5338\n",
            "Test Accuracy: 0.8733\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Create an instance of ImageDataGenerator for augmentation\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=20,  # Random rotation within the range of (-20, 20) degrees\n",
        "    width_shift_range=0.1,  # Randomly shift images horizontally (10% of total width)\n",
        "    height_shift_range=0.1,  # Randomly shift images vertically (10% of total height)\n",
        "    shear_range=0.2,  # Shear intensity (20%)\n",
        "    zoom_range=0.2,  # Zoom randomly within 20% range\n",
        "    horizontal_flip=True,  # Randomly flip images horizontally\n",
        "    fill_mode='nearest'  # Strategy for filling in newly created pixels\n",
        ")\n",
        "\n",
        "# Fit the ImageDataGenerator on your original training data\n",
        "datagen.fit(x_train_normalized)\n",
        "\n",
        "# Define the number of augmented images you want to generate\n",
        "num_augmented_images = 1000  # Modify this based on your requirement\n",
        "\n",
        "# Generate augmented images using the ImageDataGenerator\n",
        "augmented_data = datagen.flow(x_train_normalized, y_train, batch_size=num_augmented_images)\n",
        "\n",
        "# Retrieve augmented images and labels\n",
        "x_augmented, y_augmented = augmented_data.next()\n",
        "\n",
        "# Concatenate augmented data with original data\n",
        "x_combined = np.concatenate((x_train_normalized, x_augmented))\n",
        "y_combined = np.concatenate((y_train, y_augmented))\n",
        "\n",
        "# Train the model using the augmented dataset\n",
        "# ... (continue with model creation, compilation, and training using x_combined, y_combined)\n"
      ],
      "metadata": {
        "id": "CGQSuMJBnp2W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Assuming you have your hybrid model already trained and stored in hybrid_model_regularized\n",
        "\n",
        "# Extract features from the hybrid model for training, validation, and test sets\n",
        "x_train_features = hybrid_model_regularized.predict([x_train_normalized, x_train_normalized])\n",
        "x_val_features = hybrid_model_regularized.predict([x_val_normalized, x_val_normalized])\n",
        "x_test_features = hybrid_model_regularized.predict([x_test_normalized, x_test_normalized])\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NBMxycobzUKN",
        "outputId": "91fae0c6-393f-4d49-89cf-b218efaad29c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "73/73 [==============================] - 3s 35ms/step\n",
            "11/11 [==============================] - 0s 37ms/step\n",
            "21/21 [==============================] - 1s 34ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_features = x_train_features.reshape(x_train_features.shape[0], -1)\n",
        "x_val_features = x_val_features.reshape(x_val_features.shape[0], -1)\n",
        "x_test_features = x_test_features.reshape(x_test_features.shape[0], -1)"
      ],
      "metadata": {
        "id": "bsPOAXS_0Xic"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "\n",
        "\n",
        "\n",
        "# Define the best hyperparameters obtained from GridSearchCV\n",
        "best_params = {'C': 6, 'gamma': 'scale'}  # Replace these values with the best parameters found\n",
        "\n",
        "# Train SVM model with the best hyperparameters\n",
        "svm_model = SVC(kernel='rbf', C=best_params['C'], gamma=best_params['gamma'])\n",
        "svm_model.fit(x_train_features, y_train)\n",
        "\n",
        "# Predict on the test set using the trained SVM model\n",
        "y_pred_svm = svm_model.predict(x_test_features)\n",
        "\n",
        "# Calculate evaluation metrics\n",
        "svm_accuracy = accuracy_score(y_test, y_pred_svm)\n",
        "svm_precision = precision_score(y_test, y_pred_svm)\n",
        "svm_recall = recall_score(y_test, y_pred_svm)\n",
        "svm_f1 = f1_score(y_test, y_pred_svm)\n",
        "\n",
        "# Calculate specificity\n",
        "tn, fp, fn, tp = confusion_matrix(y_test, y_pred_svm).ravel()\n",
        "svm_specificity = tn / (tn + fp)\n",
        "\n",
        "# Print evaluation metrics\n",
        "print(\"SVM Accuracy:\", svm_accuracy)\n",
        "print(\"SVM Precision:\", svm_precision)\n",
        "print(\"SVM Sensitivity (Recall):\", svm_recall)\n",
        "print(\"SVM Specificity:\", svm_specificity)\n",
        "print(\"SVM F1 Score:\", svm_f1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6E_riZegoOR3",
        "outputId": "731433d0-7358-4cc7-fdaa-1573d063d141"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVM Accuracy: 0.8778280542986425\n",
            "SVM Precision: 0.8635014836795252\n",
            "SVM Sensitivity (Recall): 0.8926380368098159\n",
            "SVM Specificity: 0.8635014836795252\n",
            "SVM F1 Score: 0.8778280542986425\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Create an instance of ImageDataGenerator for augmentation\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=20,  # Random rotation within the range of (-20, 20) degrees\n",
        "    width_shift_range=0.1,  # Randomly shift images horizontally (10% of total width)\n",
        "    height_shift_range=0.1,  # Randomly shift images vertically (10% of total height)\n",
        "    shear_range=0.2,  # Shear intensity (20%)\n",
        "    zoom_range=0.2,  # Zoom randomly within 20% range\n",
        "    horizontal_flip=True,  # Randomly flip images horizontally\n",
        "    fill_mode='nearest'  # Strategy for filling in newly created pixels\n",
        ")\n",
        "\n",
        "# Fit the ImageDataGenerator on your original training data\n",
        "datagen.fit(x_train_normalized)\n",
        "\n",
        "# Define the number of augmented images you want to generate\n",
        "num_augmented_images = 2000  # Modify this based on your requirement\n",
        "\n",
        "# Generate augmented images using the ImageDataGenerator\n",
        "augmented_data = datagen.flow(x_train_normalized, y_train, batch_size=num_augmented_images)\n",
        "\n",
        "# Retrieve augmented images and labels\n",
        "x_augmented, y_augmented = augmented_data.next()\n",
        "\n",
        "# Concatenate augmented data with original data\n",
        "x_combined = np.concatenate((x_train_normalized, x_augmented))\n",
        "y_combined = np.concatenate((y_train, y_augmented))\n",
        "\n",
        "# Train the model using the augmented dataset\n",
        "# ... (continue with model creation, compilation, and training using x_combined, y_combined)"
      ],
      "metadata": {
        "id": "u18qRHOLpa25"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Conv2D, BatchNormalization, ReLU, GlobalAveragePooling2D, Dense, Concatenate\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "# Define MobileNet-inspired architecture\n",
        "def MobileNetCustom(input_shape):\n",
        "    input_tensor = Input(shape=input_shape)\n",
        "\n",
        "    # Initial Convolution Layer\n",
        "    x = Conv2D(32, (3, 3), strides=(2, 2), padding='same')(input_tensor)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = ReLU()(x)\n",
        "    # Add more layers as per your MobileNet design\n",
        "\n",
        "    # Global Average Pooling\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "\n",
        "    return Model(inputs=input_tensor, outputs=x)\n",
        "\n",
        "# Define DenseNet-inspired architecture\n",
        "def DenseNetCustom(input_shape):\n",
        "    input_tensor = Input(shape=input_shape)\n",
        "\n",
        "    # Define your DenseNet-like architecture\n",
        "    # ... Add layers as per your DenseNet design\n",
        "\n",
        "    # Global Average Pooling\n",
        "    x = GlobalAveragePooling2D()(input_tensor)\n",
        "\n",
        "    return Model(inputs=input_tensor, outputs=x)\n",
        "\n",
        "# Input shape and number of classes\n",
        "input_shape = (100, 100, 3)\n",
        "num_classes = 2\n",
        "\n",
        "# Build MobileNet and DenseNet branches\n",
        "mobilenet_model = MobileNetCustom(input_shape)\n",
        "densenet_model = DenseNetCustom(input_shape)\n",
        "\n",
        "# Get the outputs of the two models\n",
        "mobilenet_output = mobilenet_model.output\n",
        "densenet_output = densenet_model.output\n",
        "\n",
        "# Concatenate the outputs\n",
        "merged_output = Concatenate()([mobilenet_output, densenet_output])\n",
        "\n",
        "# Add more layers for classification\n",
        "x = Dense(256, activation='relu')(merged_output)\n",
        "x = Dense(128, activation='relu')(x)\n",
        "predictions = Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "# Create the hybrid model\n",
        "hybrid_model = Model(inputs=[mobilenet_model.input, densenet_model.input], outputs=predictions)\n",
        "\n",
        "# Compile the model\n",
        "hybrid_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Display the summary of the hybrid model\n",
        "hybrid_model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TNChm1qAiEmw",
        "outputId": "98c444e8-2c09-48a7-a6e9-ad371a0c296b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_5\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_3 (InputLayer)        [(None, 100, 100, 3)]        0         []                            \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)           (None, 50, 50, 32)           896       ['input_3[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_1 (Bat  (None, 50, 50, 32)           128       ['conv2d_1[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " re_lu_1 (ReLU)              (None, 50, 50, 32)           0         ['batch_normalization_1[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " input_4 (InputLayer)        [(None, 100, 100, 3)]        0         []                            \n",
            "                                                                                                  \n",
            " global_average_pooling2d_2  (None, 32)                   0         ['re_lu_1[0][0]']             \n",
            "  (GlobalAveragePooling2D)                                                                        \n",
            "                                                                                                  \n",
            " global_average_pooling2d_3  (None, 3)                    0         ['input_4[0][0]']             \n",
            "  (GlobalAveragePooling2D)                                                                        \n",
            "                                                                                                  \n",
            " concatenate_1 (Concatenate  (None, 35)                   0         ['global_average_pooling2d_2[0\n",
            " )                                                                  ][0]',                        \n",
            "                                                                     'global_average_pooling2d_3[0\n",
            "                                                                    ][0]']                        \n",
            "                                                                                                  \n",
            " dense_3 (Dense)             (None, 256)                  9216      ['concatenate_1[0][0]']       \n",
            "                                                                                                  \n",
            " dense_4 (Dense)             (None, 128)                  32896     ['dense_3[0][0]']             \n",
            "                                                                                                  \n",
            " dense_5 (Dense)             (None, 2)                    258       ['dense_4[0][0]']             \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 43394 (169.51 KB)\n",
            "Trainable params: 43330 (169.26 KB)\n",
            "Non-trainable params: 64 (256.00 Byte)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Set the learning rate\n",
        "learning_rate = 0.00001\n",
        "\n",
        "# Compile the model with the specified learning rate\n",
        "hybrid_model.compile(optimizer=Adam(learning_rate=learning_rate),\n",
        "                     loss='categorical_crossentropy',\n",
        "                     metrics=['accuracy'])\n",
        "\n",
        "# Train the hybrid model for 25 epochs with the specified learning rate\n",
        "history = hybrid_model.fit(\n",
        "    [x_train_normalized, x_train_normalized],  # Replace with your training data\n",
        "    y_train_encoded,  # Replace with your training labels\n",
        "    epochs=25,\n",
        "    batch_size=batch_size,\n",
        "    validation_data=([x_val_normalized, x_val_normalized], y_val_encoded),  # Replace with your validation data\n",
        "    shuffle=True,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5pP9jGtGiN_e",
        "outputId": "9fb09a43-4a55-4905-e303-657174a0840b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "37/37 [==============================] - 4s 32ms/step - loss: 0.3214 - accuracy: 0.8403 - val_loss: 0.2848 - val_accuracy: 0.8882\n",
            "Epoch 2/25\n",
            "37/37 [==============================] - 1s 16ms/step - loss: 0.3168 - accuracy: 0.8455 - val_loss: 0.2836 - val_accuracy: 0.8943\n",
            "Epoch 3/25\n",
            "37/37 [==============================] - 1s 16ms/step - loss: 0.3194 - accuracy: 0.8442 - val_loss: 0.2834 - val_accuracy: 0.8852\n",
            "Epoch 4/25\n",
            "37/37 [==============================] - 1s 16ms/step - loss: 0.3194 - accuracy: 0.8399 - val_loss: 0.2853 - val_accuracy: 0.8852\n",
            "Epoch 5/25\n",
            "37/37 [==============================] - 1s 15ms/step - loss: 0.3135 - accuracy: 0.8464 - val_loss: 0.2857 - val_accuracy: 0.8882\n",
            "Epoch 6/25\n",
            "37/37 [==============================] - 1s 16ms/step - loss: 0.3205 - accuracy: 0.8442 - val_loss: 0.2843 - val_accuracy: 0.8822\n",
            "Epoch 7/25\n",
            "37/37 [==============================] - 1s 15ms/step - loss: 0.3147 - accuracy: 0.8464 - val_loss: 0.2852 - val_accuracy: 0.8852\n",
            "Epoch 8/25\n",
            "37/37 [==============================] - 1s 16ms/step - loss: 0.3186 - accuracy: 0.8433 - val_loss: 0.2846 - val_accuracy: 0.8792\n",
            "Epoch 9/25\n",
            "37/37 [==============================] - 1s 16ms/step - loss: 0.3179 - accuracy: 0.8399 - val_loss: 0.2844 - val_accuracy: 0.8822\n",
            "Epoch 10/25\n",
            "37/37 [==============================] - 1s 16ms/step - loss: 0.3150 - accuracy: 0.8438 - val_loss: 0.2848 - val_accuracy: 0.8792\n",
            "Epoch 11/25\n",
            "37/37 [==============================] - 1s 15ms/step - loss: 0.3170 - accuracy: 0.8377 - val_loss: 0.2851 - val_accuracy: 0.8822\n",
            "Epoch 12/25\n",
            "37/37 [==============================] - 1s 15ms/step - loss: 0.3202 - accuracy: 0.8446 - val_loss: 0.2835 - val_accuracy: 0.8792\n",
            "Epoch 13/25\n",
            "37/37 [==============================] - 1s 15ms/step - loss: 0.3224 - accuracy: 0.8407 - val_loss: 0.2840 - val_accuracy: 0.8792\n",
            "Epoch 14/25\n",
            "37/37 [==============================] - 1s 15ms/step - loss: 0.3143 - accuracy: 0.8468 - val_loss: 0.2855 - val_accuracy: 0.8792\n",
            "Epoch 15/25\n",
            "37/37 [==============================] - 1s 19ms/step - loss: 0.3134 - accuracy: 0.8438 - val_loss: 0.2870 - val_accuracy: 0.8882\n",
            "Epoch 16/25\n",
            "37/37 [==============================] - 1s 19ms/step - loss: 0.3165 - accuracy: 0.8481 - val_loss: 0.2864 - val_accuracy: 0.8822\n",
            "Epoch 17/25\n",
            "37/37 [==============================] - 1s 22ms/step - loss: 0.3142 - accuracy: 0.8446 - val_loss: 0.2875 - val_accuracy: 0.8852\n",
            "Epoch 18/25\n",
            "37/37 [==============================] - 1s 22ms/step - loss: 0.3123 - accuracy: 0.8438 - val_loss: 0.2864 - val_accuracy: 0.8852\n",
            "Epoch 19/25\n",
            "37/37 [==============================] - 1s 19ms/step - loss: 0.3179 - accuracy: 0.8412 - val_loss: 0.2866 - val_accuracy: 0.8882\n",
            "Epoch 20/25\n",
            "37/37 [==============================] - 1s 20ms/step - loss: 0.3191 - accuracy: 0.8446 - val_loss: 0.2865 - val_accuracy: 0.8852\n",
            "Epoch 21/25\n",
            "37/37 [==============================] - 1s 19ms/step - loss: 0.3141 - accuracy: 0.8407 - val_loss: 0.2853 - val_accuracy: 0.8822\n",
            "Epoch 22/25\n",
            "37/37 [==============================] - 1s 16ms/step - loss: 0.3162 - accuracy: 0.8459 - val_loss: 0.2880 - val_accuracy: 0.8882\n",
            "Epoch 23/25\n",
            "37/37 [==============================] - 1s 16ms/step - loss: 0.3190 - accuracy: 0.8446 - val_loss: 0.2851 - val_accuracy: 0.8852\n",
            "Epoch 24/25\n",
            "37/37 [==============================] - 1s 15ms/step - loss: 0.3164 - accuracy: 0.8407 - val_loss: 0.2862 - val_accuracy: 0.8852\n",
            "Epoch 25/25\n",
            "37/37 [==============================] - 1s 15ms/step - loss: 0.3205 - accuracy: 0.8416 - val_loss: 0.2873 - val_accuracy: 0.8882\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on the test data\n",
        "test_loss, test_accuracy = hybrid_model.evaluate([x_test_normalized, x_test_normalized], y_test_encoded)\n",
        "\n",
        "print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")\n",
        "print(f\"Test Loss: {test_loss}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9hNvk5Zgl8UX",
        "outputId": "14211cd1-f39a-41a8-e487-2d5ed9383f32"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "21/21 [==============================] - 0s 6ms/step - loss: 0.3563 - accuracy: 0.8507\n",
            "Test Accuracy: 85.07%\n",
            "Test Loss: 0.3562506139278412\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Conv2D, BatchNormalization, ReLU, GlobalAveragePooling2D, Dense, Concatenate\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "# Define MobileNet-inspired architecture\n",
        "def MobileNetCustom(input_shape):\n",
        "    input_tensor = Input(shape=input_shape)\n",
        "\n",
        "    # Initial Convolution Layer\n",
        "    x = Conv2D(32, (3, 3), strides=(2, 2), padding='same')(input_tensor)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = ReLU()(x)\n",
        "    # Add more layers as per your MobileNet design\n",
        "\n",
        "    # Global Average Pooling\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "\n",
        "    return Model(inputs=input_tensor, outputs=x)\n",
        "\n",
        "# Define DenseNet-inspired architecture\n",
        "def DenseNetCustom(input_shape):\n",
        "    input_tensor = Input(shape=input_shape)\n",
        "\n",
        "    # Define your DenseNet-like architecture\n",
        "    # ... Add layers as per your DenseNet design\n",
        "\n",
        "    # Global Average Pooling\n",
        "    x = GlobalAveragePooling2D()(input_tensor)\n",
        "\n",
        "    return Model(inputs=input_tensor, outputs=x)\n",
        "\n",
        "# Input shape and number of classes\n",
        "input_shape = (100, 100, 3)\n",
        "num_classes = 2\n",
        "\n",
        "# Build MobileNet and DenseNet branches\n",
        "mobilenet_model = MobileNetCustom(input_shape)\n",
        "densenet_model = DenseNetCustom(input_shape)\n",
        "\n",
        "# Get the outputs of the two models\n",
        "mobilenet_output = mobilenet_model.output\n",
        "densenet_output = densenet_model.output\n",
        "\n",
        "# Concatenate the outputs\n",
        "merged_output = Concatenate()([mobilenet_output, densenet_output])\n",
        "\n",
        "# Add more layers for classification\n",
        "x = Dense(256, activation='relu')(merged_output)\n",
        "x = Dense(128, activation='relu')(x)\n",
        "predictions = Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "# Create the hybrid model\n",
        "hybrid_model = Model(inputs=[mobilenet_model.input, densenet_model.input], outputs=predictions)\n",
        "\n",
        "# Compile the model\n",
        "hybrid_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Display the summary of the hybrid model\n",
        "hybrid_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BSWc_eY-JKc5",
        "outputId": "767e5568-9693-408e-f96c-de9bf6ad0a7f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)        [(None, 100, 100, 3)]        0         []                            \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)             (None, 50, 50, 32)           896       ['input_1[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization (Batch  (None, 50, 50, 32)           128       ['conv2d[0][0]']              \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " re_lu (ReLU)                (None, 50, 50, 32)           0         ['batch_normalization[0][0]'] \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)        [(None, 100, 100, 3)]        0         []                            \n",
            "                                                                                                  \n",
            " global_average_pooling2d (  (None, 32)                   0         ['re_lu[0][0]']               \n",
            " GlobalAveragePooling2D)                                                                          \n",
            "                                                                                                  \n",
            " global_average_pooling2d_1  (None, 3)                    0         ['input_2[0][0]']             \n",
            "  (GlobalAveragePooling2D)                                                                        \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)   (None, 35)                   0         ['global_average_pooling2d[0][\n",
            "                                                                    0]',                          \n",
            "                                                                     'global_average_pooling2d_1[0\n",
            "                                                                    ][0]']                        \n",
            "                                                                                                  \n",
            " dense (Dense)               (None, 256)                  9216      ['concatenate[0][0]']         \n",
            "                                                                                                  \n",
            " dense_1 (Dense)             (None, 128)                  32896     ['dense[0][0]']               \n",
            "                                                                                                  \n",
            " dense_2 (Dense)             (None, 2)                    258       ['dense_1[0][0]']             \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 43394 (169.51 KB)\n",
            "Trainable params: 43330 (169.26 KB)\n",
            "Non-trainable params: 64 (256.00 Byte)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Set the learning rate\n",
        "learning_rate = 0.0001\n",
        "\n",
        "# Compile the model with the specified learning rate\n",
        "hybrid_model.compile(optimizer=Adam(learning_rate=learning_rate),\n",
        "                     loss='categorical_crossentropy',\n",
        "                     metrics=['accuracy'])\n",
        "\n",
        "# Train the hybrid model for 25 epochs with the specified learning rate\n",
        "history = hybrid_model.fit(\n",
        "    [x_train_normalized, x_train_normalized],  # Replace with your training data\n",
        "    y_train_encoded,  # Replace with your training labels\n",
        "    epochs=50,\n",
        "    batch_size=batch_size,\n",
        "    validation_data=([x_val_normalized, x_val_normalized], y_val_encoded),  # Replace with your validation data\n",
        "    shuffle=True,\n",
        "    verbose=1\n",
        ")\n"
      ],
      "metadata": {
        "id": "3GFcunUin-St",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e27a45f-75ba-43e5-c3df-0423dce8383d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "37/37 [==============================] - 6s 45ms/step - loss: 0.3689 - accuracy: 0.8230 - val_loss: 0.3574 - val_accuracy: 0.8399\n",
            "Epoch 2/50\n",
            "37/37 [==============================] - 1s 25ms/step - loss: 0.3661 - accuracy: 0.8287 - val_loss: 0.3262 - val_accuracy: 0.8489\n",
            "Epoch 3/50\n",
            "37/37 [==============================] - 1s 24ms/step - loss: 0.3669 - accuracy: 0.8239 - val_loss: 0.3174 - val_accuracy: 0.8520\n",
            "Epoch 4/50\n",
            "37/37 [==============================] - 1s 24ms/step - loss: 0.3643 - accuracy: 0.8213 - val_loss: 0.3254 - val_accuracy: 0.8610\n",
            "Epoch 5/50\n",
            "37/37 [==============================] - 1s 18ms/step - loss: 0.3605 - accuracy: 0.8291 - val_loss: 0.3365 - val_accuracy: 0.8278\n",
            "Epoch 6/50\n",
            "37/37 [==============================] - 1s 17ms/step - loss: 0.3636 - accuracy: 0.8239 - val_loss: 0.3246 - val_accuracy: 0.8459\n",
            "Epoch 7/50\n",
            "37/37 [==============================] - 1s 17ms/step - loss: 0.3631 - accuracy: 0.8200 - val_loss: 0.3289 - val_accuracy: 0.8671\n",
            "Epoch 8/50\n",
            "37/37 [==============================] - 1s 17ms/step - loss: 0.3636 - accuracy: 0.8239 - val_loss: 0.3122 - val_accuracy: 0.8701\n",
            "Epoch 9/50\n",
            "37/37 [==============================] - 1s 18ms/step - loss: 0.3622 - accuracy: 0.8261 - val_loss: 0.3057 - val_accuracy: 0.8731\n",
            "Epoch 10/50\n",
            "37/37 [==============================] - 1s 17ms/step - loss: 0.3606 - accuracy: 0.8239 - val_loss: 0.3080 - val_accuracy: 0.8731\n",
            "Epoch 11/50\n",
            "37/37 [==============================] - 1s 17ms/step - loss: 0.3599 - accuracy: 0.8274 - val_loss: 0.3100 - val_accuracy: 0.8671\n",
            "Epoch 12/50\n",
            "37/37 [==============================] - 1s 17ms/step - loss: 0.3570 - accuracy: 0.8230 - val_loss: 0.3293 - val_accuracy: 0.8640\n",
            "Epoch 13/50\n",
            "37/37 [==============================] - 1s 17ms/step - loss: 0.3618 - accuracy: 0.8174 - val_loss: 0.3089 - val_accuracy: 0.8671\n",
            "Epoch 14/50\n",
            "37/37 [==============================] - 1s 18ms/step - loss: 0.3580 - accuracy: 0.8287 - val_loss: 0.3042 - val_accuracy: 0.8761\n",
            "Epoch 15/50\n",
            "37/37 [==============================] - 1s 18ms/step - loss: 0.3555 - accuracy: 0.8325 - val_loss: 0.3092 - val_accuracy: 0.8671\n",
            "Epoch 16/50\n",
            "37/37 [==============================] - 1s 17ms/step - loss: 0.3559 - accuracy: 0.8235 - val_loss: 0.3117 - val_accuracy: 0.8489\n",
            "Epoch 17/50\n",
            "37/37 [==============================] - 1s 17ms/step - loss: 0.3566 - accuracy: 0.8230 - val_loss: 0.3052 - val_accuracy: 0.8701\n",
            "Epoch 18/50\n",
            "37/37 [==============================] - 1s 17ms/step - loss: 0.3515 - accuracy: 0.8295 - val_loss: 0.3284 - val_accuracy: 0.8429\n",
            "Epoch 19/50\n",
            "37/37 [==============================] - 1s 18ms/step - loss: 0.3522 - accuracy: 0.8338 - val_loss: 0.3287 - val_accuracy: 0.8278\n",
            "Epoch 20/50\n",
            "37/37 [==============================] - 1s 21ms/step - loss: 0.3529 - accuracy: 0.8265 - val_loss: 0.3060 - val_accuracy: 0.8701\n",
            "Epoch 21/50\n",
            "37/37 [==============================] - 1s 23ms/step - loss: 0.3563 - accuracy: 0.8243 - val_loss: 0.3025 - val_accuracy: 0.8671\n",
            "Epoch 22/50\n",
            "37/37 [==============================] - 1s 23ms/step - loss: 0.3542 - accuracy: 0.8312 - val_loss: 0.3288 - val_accuracy: 0.8640\n",
            "Epoch 23/50\n",
            "37/37 [==============================] - 1s 23ms/step - loss: 0.3524 - accuracy: 0.8325 - val_loss: 0.4104 - val_accuracy: 0.8127\n",
            "Epoch 24/50\n",
            "37/37 [==============================] - 1s 23ms/step - loss: 0.3542 - accuracy: 0.8287 - val_loss: 0.3175 - val_accuracy: 0.8701\n",
            "Epoch 25/50\n",
            "37/37 [==============================] - 1s 25ms/step - loss: 0.3506 - accuracy: 0.8243 - val_loss: 0.3107 - val_accuracy: 0.8550\n",
            "Epoch 26/50\n",
            "37/37 [==============================] - 1s 22ms/step - loss: 0.3474 - accuracy: 0.8265 - val_loss: 0.3182 - val_accuracy: 0.8459\n",
            "Epoch 27/50\n",
            "37/37 [==============================] - 1s 23ms/step - loss: 0.3475 - accuracy: 0.8252 - val_loss: 0.3257 - val_accuracy: 0.8550\n",
            "Epoch 28/50\n",
            "37/37 [==============================] - 1s 22ms/step - loss: 0.3462 - accuracy: 0.8278 - val_loss: 0.3037 - val_accuracy: 0.8701\n",
            "Epoch 29/50\n",
            "37/37 [==============================] - 1s 17ms/step - loss: 0.3441 - accuracy: 0.8347 - val_loss: 0.2991 - val_accuracy: 0.8731\n",
            "Epoch 30/50\n",
            "37/37 [==============================] - 1s 17ms/step - loss: 0.3466 - accuracy: 0.8282 - val_loss: 0.3615 - val_accuracy: 0.8248\n",
            "Epoch 31/50\n",
            "37/37 [==============================] - 1s 17ms/step - loss: 0.3450 - accuracy: 0.8325 - val_loss: 0.3484 - val_accuracy: 0.8218\n",
            "Epoch 32/50\n",
            "37/37 [==============================] - 1s 17ms/step - loss: 0.3426 - accuracy: 0.8304 - val_loss: 0.3091 - val_accuracy: 0.8429\n",
            "Epoch 33/50\n",
            "37/37 [==============================] - 1s 17ms/step - loss: 0.3438 - accuracy: 0.8304 - val_loss: 0.3051 - val_accuracy: 0.8610\n",
            "Epoch 34/50\n",
            "37/37 [==============================] - 1s 17ms/step - loss: 0.3433 - accuracy: 0.8325 - val_loss: 0.3046 - val_accuracy: 0.8671\n",
            "Epoch 35/50\n",
            "37/37 [==============================] - 1s 18ms/step - loss: 0.3412 - accuracy: 0.8360 - val_loss: 0.3040 - val_accuracy: 0.8640\n",
            "Epoch 36/50\n",
            "37/37 [==============================] - 1s 17ms/step - loss: 0.3396 - accuracy: 0.8399 - val_loss: 0.3019 - val_accuracy: 0.8640\n",
            "Epoch 37/50\n",
            "37/37 [==============================] - 1s 17ms/step - loss: 0.3419 - accuracy: 0.8308 - val_loss: 0.3038 - val_accuracy: 0.8610\n",
            "Epoch 38/50\n",
            "37/37 [==============================] - 1s 17ms/step - loss: 0.3368 - accuracy: 0.8334 - val_loss: 0.3149 - val_accuracy: 0.8580\n",
            "Epoch 39/50\n",
            "37/37 [==============================] - 1s 16ms/step - loss: 0.3407 - accuracy: 0.8343 - val_loss: 0.3033 - val_accuracy: 0.8671\n",
            "Epoch 40/50\n",
            "37/37 [==============================] - 1s 18ms/step - loss: 0.3406 - accuracy: 0.8274 - val_loss: 0.3149 - val_accuracy: 0.8520\n",
            "Epoch 41/50\n",
            "37/37 [==============================] - 1s 17ms/step - loss: 0.3400 - accuracy: 0.8334 - val_loss: 0.3188 - val_accuracy: 0.8610\n",
            "Epoch 42/50\n",
            "37/37 [==============================] - 1s 18ms/step - loss: 0.3368 - accuracy: 0.8312 - val_loss: 0.3546 - val_accuracy: 0.8399\n",
            "Epoch 43/50\n",
            "37/37 [==============================] - 1s 17ms/step - loss: 0.3432 - accuracy: 0.8364 - val_loss: 0.3430 - val_accuracy: 0.8308\n",
            "Epoch 44/50\n",
            "37/37 [==============================] - 1s 24ms/step - loss: 0.3409 - accuracy: 0.8300 - val_loss: 0.3255 - val_accuracy: 0.8308\n",
            "Epoch 45/50\n",
            "37/37 [==============================] - 1s 24ms/step - loss: 0.3388 - accuracy: 0.8261 - val_loss: 0.3229 - val_accuracy: 0.8399\n",
            "Epoch 46/50\n",
            "37/37 [==============================] - 1s 22ms/step - loss: 0.3347 - accuracy: 0.8330 - val_loss: 0.3669 - val_accuracy: 0.8127\n",
            "Epoch 47/50\n",
            "37/37 [==============================] - 1s 25ms/step - loss: 0.3346 - accuracy: 0.8338 - val_loss: 0.3248 - val_accuracy: 0.8550\n",
            "Epoch 48/50\n",
            "37/37 [==============================] - 1s 25ms/step - loss: 0.3366 - accuracy: 0.8377 - val_loss: 0.2913 - val_accuracy: 0.8822\n",
            "Epoch 49/50\n",
            "37/37 [==============================] - 1s 22ms/step - loss: 0.3331 - accuracy: 0.8334 - val_loss: 0.3109 - val_accuracy: 0.8610\n",
            "Epoch 50/50\n",
            "37/37 [==============================] - 1s 21ms/step - loss: 0.3336 - accuracy: 0.8364 - val_loss: 0.3074 - val_accuracy: 0.8580\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on the test data\n",
        "test_loss, test_accuracy = hybrid_model.evaluate([x_test_normalized, x_test_normalized], y_test_encoded)\n",
        "\n",
        "print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")\n",
        "print(f\"Test Loss: {test_loss}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u5oo2AK-JmC9",
        "outputId": "a09eb905-09ba-4f89-f134-9002eed5b4fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "21/21 [==============================] - 0s 7ms/step - loss: 0.3763 - accuracy: 0.8431\n",
            "Test Accuracy: 84.31%\n",
            "Test Loss: 0.3763152062892914\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Assuming you have your hybrid model already trained and stored in hybrid_model_regularized\n",
        "\n",
        "# Extract features from the hybrid model for training, validation, and test sets\n",
        "x_train_features = hybrid_model.predict([x_train_normalized, x_train_normalized])\n",
        "x_val_features = hybrid_model.predict([x_val_normalized, x_val_normalized])\n",
        "x_test_features = hybrid_model.predict([x_test_normalized, x_test_normalized])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fpehwDOMJ7uC",
        "outputId": "fd5c4cb9-08f3-4c3e-f2ad-8c7c92e46064"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "73/73 [==============================] - 0s 5ms/step\n",
            "11/11 [==============================] - 0s 6ms/step\n",
            "21/21 [==============================] - 0s 6ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_features = x_train_features.reshape(x_train_features.shape[0], -1)\n",
        "x_val_features = x_val_features.reshape(x_val_features.shape[0], -1)\n",
        "x_test_features = x_test_features.reshape(x_test_features.shape[0], -1)"
      ],
      "metadata": {
        "id": "Gpp9Rm__KVDD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "\n",
        "\n",
        "\n",
        "# Define the best hyperparameters obtained from GridSearchCV\n",
        "best_params = {'C': 4, 'gamma': 'scale'}  # Replace these values with the best parameters found\n",
        "\n",
        "# Train SVM model with the best hyperparameters\n",
        "svm_model = SVC(kernel='rbf', C=best_params['C'], gamma=best_params['gamma'])\n",
        "svm_model.fit(x_train_features, y_train)\n",
        "\n",
        "# Predict on the test set using the trained SVM model\n",
        "y_pred_svm = svm_model.predict(x_test_features)\n",
        "\n",
        "# Calculate evaluation metrics\n",
        "svm_accuracy = accuracy_score(y_test, y_pred_svm)\n",
        "svm_precision = precision_score(y_test, y_pred_svm)\n",
        "svm_recall = recall_score(y_test, y_pred_svm)\n",
        "svm_f1 = f1_score(y_test, y_pred_svm)\n",
        "\n",
        "# Calculate specificity\n",
        "tn, fp, fn, tp = confusion_matrix(y_test, y_pred_svm).ravel()\n",
        "svm_specificity = tn / (tn + fp)\n",
        "\n",
        "# Print evaluation metrics\n",
        "print(\"SVM Accuracy:\", svm_accuracy)\n",
        "print(\"SVM Precision:\", svm_precision)\n",
        "print(\"SVM Sensitivity (Recall):\", svm_recall)\n",
        "print(\"SVM Specificity:\", svm_specificity)\n",
        "print(\"SVM F1 Score:\", svm_f1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8DLwKW3zKdmQ",
        "outputId": "6371ce91-8d15-4d16-b487-8ddd7a5f895e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVM Accuracy: 0.8567119155354449\n",
            "SVM Precision: 0.830945558739255\n",
            "SVM Sensitivity (Recall): 0.8895705521472392\n",
            "SVM Specificity: 0.8249258160237388\n",
            "SVM F1 Score: 0.8592592592592593\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Conv2D, BatchNormalization, ReLU, Add, Concatenate, GlobalAveragePooling2D, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "# ResNet50-inspired architecture (more detailed)\n",
        "def ResNet50Custom(input_shape):\n",
        "    input_tensor = Input(shape=input_shape)\n",
        "\n",
        "    # Stage 1\n",
        "    x = Conv2D(64, (7, 7), strides=(2, 2), padding='same')(input_tensor)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = ReLU()(x)\n",
        "\n",
        "    # Stage 2\n",
        "    x = Conv2D(64, (3, 3), padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = ReLU()(x)\n",
        "    x = Conv2D(64, (3, 3), padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    shortcut = Conv2D(64, (1, 1), strides=(2, 2), padding='same')(input_tensor)\n",
        "    shortcut = BatchNormalization()(shortcut)\n",
        "    x = Add()([x, shortcut])\n",
        "    x = ReLU()(x)\n",
        "\n",
        "    # Stage 3 (you can extend these stages similar to a real ResNet50)\n",
        "\n",
        "    # Global Average Pooling\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "\n",
        "    return Model(inputs=input_tensor, outputs=x)\n",
        "\n",
        "# DenseNet201-inspired architecture (more detailed)\n",
        "def DenseNet201Custom(input_shape):\n",
        "    input_tensor = Input(shape=input_shape)\n",
        "\n",
        "    # Dense Block 1\n",
        "    x = Conv2D(64, (3, 3), padding='same')(input_tensor)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = ReLU()(x)\n",
        "    concat_layers = [x]\n",
        "\n",
        "    # Transition Layer\n",
        "    x = Conv2D(128, (1, 1), padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = ReLU()(x)\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "\n",
        "    return Model(inputs=input_tensor, outputs=x)\n",
        "\n",
        "# Input shape and number of classes\n",
        "input_shape = (100, 100, 3)\n",
        "num_classes = 2\n",
        "\n",
        "# Build ResNet50 and DenseNet201 branches\n",
        "resnet_model = ResNet50Custom(input_shape)\n",
        "densenet_model = DenseNet201Custom(input_shape)\n",
        "\n",
        "# Get the outputs of the two models\n",
        "resnet_output = resnet_model.output\n",
        "densenet_output = densenet_model.output\n",
        "\n",
        "# Concatenate the outputs\n",
        "merged_output = Concatenate()([resnet_output, densenet_output])\n",
        "\n",
        "# Add more layers for classification\n",
        "x = Dense(256, activation='relu')(merged_output)\n",
        "x = Dense(128, activation='relu')(x)\n",
        "predictions = Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "# Create the hybrid model\n",
        "hybrid_model = Model(inputs=[resnet_model.input, densenet_model.input], outputs=predictions)\n",
        "\n",
        "# Compile the model\n",
        "hybrid_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Display the summary of the hybrid model\n",
        "hybrid_model.summary()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9G2pZppSOmNh",
        "outputId": "8f7cacc6-80ab-4ca9-b2ca-b9810403bc40"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_8\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_5 (InputLayer)        [(None, 100, 100, 3)]        0         []                            \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)           (None, 50, 50, 64)           9472      ['input_5[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_1 (Bat  (None, 50, 50, 64)           256       ['conv2d_1[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " re_lu_1 (ReLU)              (None, 50, 50, 64)           0         ['batch_normalization_1[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)           (None, 50, 50, 64)           36928     ['re_lu_1[0][0]']             \n",
            "                                                                                                  \n",
            " input_6 (InputLayer)        [(None, 100, 100, 3)]        0         []                            \n",
            "                                                                                                  \n",
            " batch_normalization_2 (Bat  (None, 50, 50, 64)           256       ['conv2d_2[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " conv2d_5 (Conv2D)           (None, 100, 100, 64)         1792      ['input_6[0][0]']             \n",
            "                                                                                                  \n",
            " re_lu_2 (ReLU)              (None, 50, 50, 64)           0         ['batch_normalization_2[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " batch_normalization_5 (Bat  (None, 100, 100, 64)         256       ['conv2d_5[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " conv2d_3 (Conv2D)           (None, 50, 50, 64)           36928     ['re_lu_2[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_4 (Conv2D)           (None, 50, 50, 64)           256       ['input_5[0][0]']             \n",
            "                                                                                                  \n",
            " re_lu_4 (ReLU)              (None, 100, 100, 64)         0         ['batch_normalization_5[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " batch_normalization_3 (Bat  (None, 50, 50, 64)           256       ['conv2d_3[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_4 (Bat  (None, 50, 50, 64)           256       ['conv2d_4[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " conv2d_6 (Conv2D)           (None, 100, 100, 128)        8320      ['re_lu_4[0][0]']             \n",
            "                                                                                                  \n",
            " add (Add)                   (None, 50, 50, 64)           0         ['batch_normalization_3[0][0]'\n",
            "                                                                    , 'batch_normalization_4[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " batch_normalization_6 (Bat  (None, 100, 100, 128)        512       ['conv2d_6[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " re_lu_3 (ReLU)              (None, 50, 50, 64)           0         ['add[0][0]']                 \n",
            "                                                                                                  \n",
            " re_lu_5 (ReLU)              (None, 100, 100, 128)        0         ['batch_normalization_6[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " global_average_pooling2d_4  (None, 64)                   0         ['re_lu_3[0][0]']             \n",
            "  (GlobalAveragePooling2D)                                                                        \n",
            "                                                                                                  \n",
            " global_average_pooling2d_5  (None, 128)                  0         ['re_lu_5[0][0]']             \n",
            "  (GlobalAveragePooling2D)                                                                        \n",
            "                                                                                                  \n",
            " concatenate_2 (Concatenate  (None, 192)                  0         ['global_average_pooling2d_4[0\n",
            " )                                                                  ][0]',                        \n",
            "                                                                     'global_average_pooling2d_5[0\n",
            "                                                                    ][0]']                        \n",
            "                                                                                                  \n",
            " dense_6 (Dense)             (None, 256)                  49408     ['concatenate_2[0][0]']       \n",
            "                                                                                                  \n",
            " dense_7 (Dense)             (None, 128)                  32896     ['dense_6[0][0]']             \n",
            "                                                                                                  \n",
            " dense_8 (Dense)             (None, 2)                    258       ['dense_7[0][0]']             \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 178050 (695.51 KB)\n",
            "Trainable params: 177154 (692.01 KB)\n",
            "Non-trainable params: 896 (3.50 KB)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# Set the learning rate\n",
        "learning_rate = 0.00001\n",
        "\n",
        "# Compile the model with the specified learning rate\n",
        "hybrid_model.compile(optimizer=Adam(learning_rate=learning_rate),\n",
        "                     loss='categorical_crossentropy',\n",
        "                     metrics=['accuracy'])\n",
        "\n",
        "# Define early stopping criteria\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "\n",
        "# Train the hybrid model with early stopping\n",
        "history = hybrid_model.fit(\n",
        "    [x_train_normalized, x_train_normalized],  # Replace with your training data\n",
        "    y_train_encoded,  # Replace with your training labels\n",
        "    epochs=60,\n",
        "    batch_size=batch_size,\n",
        "    validation_data=([x_val_normalized, x_val_normalized], y_val_encoded),  # Replace with your validation data\n",
        "    shuffle=True,\n",
        "    verbose=1,\n",
        "    callbacks=[early_stopping]  # Include the early stopping callback\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DVdcNByQP2CK",
        "outputId": "6ce62c7e-4f23-4886-f277-7905fe804e6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/60\n",
            "37/37 [==============================] - 10s 141ms/step - loss: 0.3191 - accuracy: 0.8433 - val_loss: 0.3064 - val_accuracy: 0.8580\n",
            "Epoch 2/60\n",
            "37/37 [==============================] - 4s 121ms/step - loss: 0.3073 - accuracy: 0.8511 - val_loss: 0.2861 - val_accuracy: 0.8761\n",
            "Epoch 3/60\n",
            "37/37 [==============================] - 4s 117ms/step - loss: 0.3007 - accuracy: 0.8541 - val_loss: 0.2759 - val_accuracy: 0.8822\n",
            "Epoch 4/60\n",
            "37/37 [==============================] - 4s 121ms/step - loss: 0.2949 - accuracy: 0.8558 - val_loss: 0.2681 - val_accuracy: 0.8761\n",
            "Epoch 5/60\n",
            "37/37 [==============================] - 5s 125ms/step - loss: 0.2908 - accuracy: 0.8576 - val_loss: 0.2639 - val_accuracy: 0.8761\n",
            "Epoch 6/60\n",
            "37/37 [==============================] - 4s 122ms/step - loss: 0.2932 - accuracy: 0.8619 - val_loss: 0.2584 - val_accuracy: 0.8822\n",
            "Epoch 7/60\n",
            "37/37 [==============================] - 4s 119ms/step - loss: 0.2904 - accuracy: 0.8558 - val_loss: 0.2570 - val_accuracy: 0.8822\n",
            "Epoch 8/60\n",
            "37/37 [==============================] - 5s 122ms/step - loss: 0.2935 - accuracy: 0.8576 - val_loss: 0.2557 - val_accuracy: 0.8822\n",
            "Epoch 9/60\n",
            "37/37 [==============================] - 5s 126ms/step - loss: 0.2867 - accuracy: 0.8619 - val_loss: 0.2553 - val_accuracy: 0.8792\n",
            "Epoch 10/60\n",
            "37/37 [==============================] - 4s 120ms/step - loss: 0.2850 - accuracy: 0.8619 - val_loss: 0.2548 - val_accuracy: 0.8792\n",
            "Epoch 11/60\n",
            "37/37 [==============================] - 4s 122ms/step - loss: 0.2839 - accuracy: 0.8623 - val_loss: 0.2543 - val_accuracy: 0.8822\n",
            "Epoch 12/60\n",
            "37/37 [==============================] - 5s 123ms/step - loss: 0.2855 - accuracy: 0.8606 - val_loss: 0.2539 - val_accuracy: 0.8822\n",
            "Epoch 13/60\n",
            "37/37 [==============================] - 5s 123ms/step - loss: 0.2810 - accuracy: 0.8692 - val_loss: 0.2525 - val_accuracy: 0.8761\n",
            "Epoch 14/60\n",
            "37/37 [==============================] - 5s 122ms/step - loss: 0.2808 - accuracy: 0.8615 - val_loss: 0.2542 - val_accuracy: 0.8731\n",
            "Epoch 15/60\n",
            "37/37 [==============================] - 4s 120ms/step - loss: 0.2781 - accuracy: 0.8610 - val_loss: 0.2534 - val_accuracy: 0.8761\n",
            "Epoch 16/60\n",
            "37/37 [==============================] - 4s 120ms/step - loss: 0.2788 - accuracy: 0.8636 - val_loss: 0.2535 - val_accuracy: 0.8731\n",
            "Epoch 17/60\n",
            "37/37 [==============================] - 5s 124ms/step - loss: 0.2756 - accuracy: 0.8679 - val_loss: 0.2556 - val_accuracy: 0.8792\n",
            "Epoch 18/60\n",
            "37/37 [==============================] - 4s 118ms/step - loss: 0.2762 - accuracy: 0.8640 - val_loss: 0.2566 - val_accuracy: 0.8792\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on the test data\n",
        "test_loss, test_accuracy = hybrid_model.evaluate([x_test_normalized, x_test_normalized], y_test_encoded)\n",
        "\n",
        "print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")\n",
        "print(f\"Test Loss: {test_loss}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YKcy4NEbRGNC",
        "outputId": "ee7b123a-92f2-417c-a68e-8afa802a6dd7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "21/21 [==============================] - 0s 22ms/step - loss: 0.3206 - accuracy: 0.8567\n",
            "Test Accuracy: 85.67%\n",
            "Test Loss: 0.32062655687332153\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Assuming you have your hybrid model already trained and stored in hybrid_model_regularized\n",
        "\n",
        "# Extract features from the hybrid model for training, validation, and test sets\n",
        "x_train_features = hybrid_model.predict([x_train_normalized, x_train_normalized])\n",
        "x_val_features = hybrid_model.predict([x_val_normalized, x_val_normalized])\n",
        "x_test_features = hybrid_model.predict([x_test_normalized, x_test_normalized])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LTrhr2lYTeLk",
        "outputId": "92e17524-3e51-4664-c5e4-1d0a55213d75"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "73/73 [==============================] - 2s 19ms/step\n",
            "11/11 [==============================] - 0s 19ms/step\n",
            "21/21 [==============================] - 0s 19ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_features = x_train_features.reshape(x_train_features.shape[0], -1)\n",
        "x_val_features = x_val_features.reshape(x_val_features.shape[0], -1)\n",
        "x_test_features = x_test_features.reshape(x_test_features.shape[0], -1)"
      ],
      "metadata": {
        "id": "7b8zviITTokP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "\n",
        "\n",
        "\n",
        "# Define the best hyperparameters obtained from GridSearchCV\n",
        "best_params = {'C': 1, 'gamma': 'scale'}  # Replace these values with the best parameters found\n",
        "\n",
        "# Train SVM model with the best hyperparameters\n",
        "svm_model = SVC(kernel='rbf', C=best_params['C'], gamma=best_params['gamma'])\n",
        "svm_model.fit(x_train_features, y_train)\n",
        "\n",
        "# Predict on the test set using the trained SVM model\n",
        "y_pred_svm = svm_model.predict(x_test_features)\n",
        "\n",
        "# Calculate evaluation metrics\n",
        "svm_accuracy = accuracy_score(y_test, y_pred_svm)\n",
        "svm_precision = precision_score(y_test, y_pred_svm)\n",
        "svm_recall = recall_score(y_test, y_pred_svm)\n",
        "svm_f1 = f1_score(y_test, y_pred_svm)\n",
        "\n",
        "# Calculate specificity\n",
        "tn, fp, fn, tp = confusion_matrix(y_test, y_pred_svm).ravel()\n",
        "svm_specificity = tn / (tn + fp)\n",
        "\n",
        "# Print evaluation metrics\n",
        "print(\"SVM Accuracy:\", svm_accuracy)\n",
        "print(\"SVM Precision:\", svm_precision)\n",
        "print(\"SVM Sensitivity (Recall):\", svm_recall)\n",
        "print(\"SVM Specificity:\", svm_specificity)\n",
        "print(\"SVM F1 Score:\", svm_f1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MYfWgTTFTuD0",
        "outputId": "d0640da1-ae50-49ff-a572-187a5f9c863b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVM Accuracy: 0.8687782805429864\n",
            "SVM Precision: 0.8525073746312685\n",
            "SVM Sensitivity (Recall): 0.8865030674846626\n",
            "SVM Specificity: 0.8516320474777448\n",
            "SVM F1 Score: 0.8691729323308272\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Input, Conv2D, BatchNormalization, ReLU, GlobalAveragePooling2D, Dense, Concatenate\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "# Depthwise Separable Convolution Block\n",
        "def depthwise_separable_block(input_tensor, filters, kernel_size, strides):\n",
        "    x = Conv2D(filters, kernel_size, strides=strides, padding='same')(input_tensor)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = ReLU()(x)\n",
        "    return x\n",
        "\n",
        "# ShuffleNet-like architecture\n",
        "def ShuffleNetCustom(input_shape):\n",
        "    input_tensor = Input(shape=input_shape)\n",
        "\n",
        "    x = Conv2D(64, (3, 3), strides=(2, 2), padding='same')(input_tensor)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = ReLU()(x)\n",
        "\n",
        "    # Depthwise separable blocks (simplified for demonstration)\n",
        "    x = depthwise_separable_block(x, 128, (3, 3), strides=(1, 1))\n",
        "    x = depthwise_separable_block(x, 128, (3, 3), strides=(1, 1))\n",
        "    x = depthwise_separable_block(x, 128, (3, 3), strides=(1, 1))\n",
        "\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    return Model(inputs=input_tensor, outputs=x)\n",
        "\n",
        "# MobileNet-like architecture\n",
        "def MobileNetCustom(input_shape):\n",
        "    input_tensor = Input(shape=input_shape)\n",
        "\n",
        "    x = Conv2D(32, (3, 3), strides=(2, 2), padding='same')(input_tensor)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = ReLU()(x)\n",
        "\n",
        "    # Depthwise separable blocks (simplified for demonstration)\n",
        "    x = depthwise_separable_block(x, 64, (3, 3), strides=(1, 1))\n",
        "    x = depthwise_separable_block(x, 64, (3, 3), strides=(1, 1))\n",
        "    x = depthwise_separable_block(x, 64, (3, 3), strides=(1, 1))\n",
        "\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    return Model(inputs=input_tensor, outputs=x)\n",
        "\n",
        "# Input shape and number of classes\n",
        "input_shape = (100, 100, 3)\n",
        "num_classes = 2\n",
        "\n",
        "# Build ShuffleNet-like and MobileNet-like models\n",
        "shufflenet_model = ShuffleNetCustom(input_shape)\n",
        "mobilenet_model = MobileNetCustom(input_shape)\n",
        "\n",
        "# Get the output tensors from both models\n",
        "shufflenet_output = shufflenet_model.output\n",
        "mobilenet_output = mobilenet_model.output\n",
        "\n",
        "# Concatenate the outputs\n",
        "merged_output = Concatenate()([shufflenet_output, mobilenet_output])\n",
        "\n",
        "# Add more layers for classification\n",
        "x = Dense(256, activation='relu')(merged_output)\n",
        "x = Dense(128, activation='relu')(x)\n",
        "predictions = Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "# Create the hybrid model\n",
        "hybrid_model = Model(inputs=[shufflenet_model.input, mobilenet_model.input], outputs=predictions)\n",
        "\n",
        "# Compile the hybrid model\n",
        "hybrid_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Display the summary of the hybrid model\n",
        "hybrid_model.summary()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WVQj9VkWT8po",
        "outputId": "8ee2adef-4e16-4f4e-f938-4e2f7aaecf39"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_13\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_9 (InputLayer)        [(None, 100, 100, 3)]        0         []                            \n",
            "                                                                                                  \n",
            " input_10 (InputLayer)       [(None, 100, 100, 3)]        0         []                            \n",
            "                                                                                                  \n",
            " conv2d_15 (Conv2D)          (None, 50, 50, 64)           1792      ['input_9[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_19 (Conv2D)          (None, 50, 50, 32)           896       ['input_10[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_15 (Ba  (None, 50, 50, 64)           256       ['conv2d_15[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_19 (Ba  (None, 50, 50, 32)           128       ['conv2d_19[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " re_lu_14 (ReLU)             (None, 50, 50, 64)           0         ['batch_normalization_15[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " re_lu_18 (ReLU)             (None, 50, 50, 32)           0         ['batch_normalization_19[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_16 (Conv2D)          (None, 50, 50, 128)          73856     ['re_lu_14[0][0]']            \n",
            "                                                                                                  \n",
            " conv2d_20 (Conv2D)          (None, 50, 50, 64)           18496     ['re_lu_18[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_16 (Ba  (None, 50, 50, 128)          512       ['conv2d_16[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_20 (Ba  (None, 50, 50, 64)           256       ['conv2d_20[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " re_lu_15 (ReLU)             (None, 50, 50, 128)          0         ['batch_normalization_16[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " re_lu_19 (ReLU)             (None, 50, 50, 64)           0         ['batch_normalization_20[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_17 (Conv2D)          (None, 50, 50, 128)          147584    ['re_lu_15[0][0]']            \n",
            "                                                                                                  \n",
            " conv2d_21 (Conv2D)          (None, 50, 50, 64)           36928     ['re_lu_19[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_17 (Ba  (None, 50, 50, 128)          512       ['conv2d_17[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_21 (Ba  (None, 50, 50, 64)           256       ['conv2d_21[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " re_lu_16 (ReLU)             (None, 50, 50, 128)          0         ['batch_normalization_17[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " re_lu_20 (ReLU)             (None, 50, 50, 64)           0         ['batch_normalization_21[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_18 (Conv2D)          (None, 50, 50, 128)          147584    ['re_lu_16[0][0]']            \n",
            "                                                                                                  \n",
            " conv2d_22 (Conv2D)          (None, 50, 50, 64)           36928     ['re_lu_20[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_18 (Ba  (None, 50, 50, 128)          512       ['conv2d_18[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_22 (Ba  (None, 50, 50, 64)           256       ['conv2d_22[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " re_lu_17 (ReLU)             (None, 50, 50, 128)          0         ['batch_normalization_18[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " re_lu_21 (ReLU)             (None, 50, 50, 64)           0         ['batch_normalization_22[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " global_average_pooling2d_8  (None, 128)                  0         ['re_lu_17[0][0]']            \n",
            "  (GlobalAveragePooling2D)                                                                        \n",
            "                                                                                                  \n",
            " global_average_pooling2d_9  (None, 64)                   0         ['re_lu_21[0][0]']            \n",
            "  (GlobalAveragePooling2D)                                                                        \n",
            "                                                                                                  \n",
            " concatenate_3 (Concatenate  (None, 192)                  0         ['global_average_pooling2d_8[0\n",
            " )                                                                  ][0]',                        \n",
            "                                                                     'global_average_pooling2d_9[0\n",
            "                                                                    ][0]']                        \n",
            "                                                                                                  \n",
            " dense_9 (Dense)             (None, 256)                  49408     ['concatenate_3[0][0]']       \n",
            "                                                                                                  \n",
            " dense_10 (Dense)            (None, 128)                  32896     ['dense_9[0][0]']             \n",
            "                                                                                                  \n",
            " dense_11 (Dense)            (None, 2)                    258       ['dense_10[0][0]']            \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 549314 (2.10 MB)\n",
            "Trainable params: 547970 (2.09 MB)\n",
            "Non-trainable params: 1344 (5.25 KB)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# Set the learning rate\n",
        "learning_rate = 0.00001\n",
        "\n",
        "# Compile the model with the specified learning rate\n",
        "hybrid_model.compile(optimizer=Adam(learning_rate=learning_rate),\n",
        "                     loss='categorical_crossentropy',\n",
        "                     metrics=['accuracy'])\n",
        "\n",
        "# Define early stopping criteria\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "\n",
        "# Train the hybrid model with early stopping\n",
        "history = hybrid_model.fit(\n",
        "    [x_train_normalized, x_train_normalized],  # Replace with your training data\n",
        "    y_train_encoded,  # Replace with your training labels\n",
        "    epochs=60,\n",
        "    batch_size=batch_size,\n",
        "    validation_data=([x_val_normalized, x_val_normalized], y_val_encoded),  # Replace with your validation data\n",
        "    shuffle=True,\n",
        "    verbose=1,\n",
        "    callbacks=[early_stopping]  # Include the early stopping callback\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GRHY1ONZU8n1",
        "outputId": "78c625a6-5d29-4b23-b241-b03d507e9f0a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/60\n",
            "37/37 [==============================] - 17s 181ms/step - loss: 0.6483 - accuracy: 0.6301 - val_loss: 0.6921 - val_accuracy: 0.4834\n",
            "Epoch 2/60\n",
            "37/37 [==============================] - 5s 146ms/step - loss: 0.5408 - accuracy: 0.7678 - val_loss: 0.6899 - val_accuracy: 0.4834\n",
            "Epoch 3/60\n",
            "37/37 [==============================] - 5s 142ms/step - loss: 0.4877 - accuracy: 0.7782 - val_loss: 0.6818 - val_accuracy: 0.6586\n",
            "Epoch 4/60\n",
            "37/37 [==============================] - 5s 140ms/step - loss: 0.4543 - accuracy: 0.7885 - val_loss: 0.6696 - val_accuracy: 0.6163\n",
            "Epoch 5/60\n",
            "37/37 [==============================] - 5s 148ms/step - loss: 0.4347 - accuracy: 0.7976 - val_loss: 0.6506 - val_accuracy: 0.6677\n",
            "Epoch 6/60\n",
            "37/37 [==============================] - 5s 146ms/step - loss: 0.4238 - accuracy: 0.8002 - val_loss: 0.6256 - val_accuracy: 0.6858\n",
            "Epoch 7/60\n",
            "37/37 [==============================] - 5s 144ms/step - loss: 0.4122 - accuracy: 0.8002 - val_loss: 0.5973 - val_accuracy: 0.6979\n",
            "Epoch 8/60\n",
            "37/37 [==============================] - 5s 147ms/step - loss: 0.4085 - accuracy: 0.7963 - val_loss: 0.5691 - val_accuracy: 0.7251\n",
            "Epoch 9/60\n",
            "37/37 [==============================] - 5s 142ms/step - loss: 0.3978 - accuracy: 0.8105 - val_loss: 0.5411 - val_accuracy: 0.7311\n",
            "Epoch 10/60\n",
            "37/37 [==============================] - 5s 141ms/step - loss: 0.3915 - accuracy: 0.8066 - val_loss: 0.5065 - val_accuracy: 0.7583\n",
            "Epoch 11/60\n",
            "37/37 [==============================] - 5s 143ms/step - loss: 0.3902 - accuracy: 0.8105 - val_loss: 0.4757 - val_accuracy: 0.7764\n",
            "Epoch 12/60\n",
            "37/37 [==============================] - 5s 148ms/step - loss: 0.3835 - accuracy: 0.8092 - val_loss: 0.4488 - val_accuracy: 0.7915\n",
            "Epoch 13/60\n",
            "37/37 [==============================] - 5s 138ms/step - loss: 0.3817 - accuracy: 0.8097 - val_loss: 0.4257 - val_accuracy: 0.8036\n",
            "Epoch 14/60\n",
            "37/37 [==============================] - 5s 142ms/step - loss: 0.3768 - accuracy: 0.8118 - val_loss: 0.4042 - val_accuracy: 0.8127\n",
            "Epoch 15/60\n",
            "37/37 [==============================] - 5s 145ms/step - loss: 0.3783 - accuracy: 0.8088 - val_loss: 0.3893 - val_accuracy: 0.8338\n",
            "Epoch 16/60\n",
            "37/37 [==============================] - 5s 140ms/step - loss: 0.3726 - accuracy: 0.8136 - val_loss: 0.3684 - val_accuracy: 0.8127\n",
            "Epoch 17/60\n",
            "37/37 [==============================] - 5s 141ms/step - loss: 0.3690 - accuracy: 0.8144 - val_loss: 0.3588 - val_accuracy: 0.8187\n",
            "Epoch 18/60\n",
            "37/37 [==============================] - 5s 146ms/step - loss: 0.3707 - accuracy: 0.8230 - val_loss: 0.3432 - val_accuracy: 0.8338\n",
            "Epoch 19/60\n",
            "37/37 [==============================] - 5s 141ms/step - loss: 0.3672 - accuracy: 0.8187 - val_loss: 0.3365 - val_accuracy: 0.8278\n",
            "Epoch 20/60\n",
            "37/37 [==============================] - 5s 140ms/step - loss: 0.3637 - accuracy: 0.8148 - val_loss: 0.3271 - val_accuracy: 0.8369\n",
            "Epoch 21/60\n",
            "37/37 [==============================] - 5s 146ms/step - loss: 0.3627 - accuracy: 0.8187 - val_loss: 0.3231 - val_accuracy: 0.8520\n",
            "Epoch 22/60\n",
            "37/37 [==============================] - 5s 143ms/step - loss: 0.3666 - accuracy: 0.8148 - val_loss: 0.3226 - val_accuracy: 0.8429\n",
            "Epoch 23/60\n",
            "37/37 [==============================] - 5s 142ms/step - loss: 0.3589 - accuracy: 0.8213 - val_loss: 0.3140 - val_accuracy: 0.8580\n",
            "Epoch 24/60\n",
            "37/37 [==============================] - 5s 145ms/step - loss: 0.3553 - accuracy: 0.8252 - val_loss: 0.3077 - val_accuracy: 0.8640\n",
            "Epoch 25/60\n",
            "37/37 [==============================] - 5s 141ms/step - loss: 0.3561 - accuracy: 0.8261 - val_loss: 0.3075 - val_accuracy: 0.8610\n",
            "Epoch 26/60\n",
            "37/37 [==============================] - 5s 141ms/step - loss: 0.3506 - accuracy: 0.8213 - val_loss: 0.3058 - val_accuracy: 0.8580\n",
            "Epoch 27/60\n",
            "37/37 [==============================] - 5s 143ms/step - loss: 0.3561 - accuracy: 0.8183 - val_loss: 0.3060 - val_accuracy: 0.8610\n",
            "Epoch 28/60\n",
            "37/37 [==============================] - 5s 142ms/step - loss: 0.3528 - accuracy: 0.8248 - val_loss: 0.2995 - val_accuracy: 0.8610\n",
            "Epoch 29/60\n",
            "37/37 [==============================] - 5s 138ms/step - loss: 0.3479 - accuracy: 0.8269 - val_loss: 0.3003 - val_accuracy: 0.8610\n",
            "Epoch 30/60\n",
            "37/37 [==============================] - 5s 142ms/step - loss: 0.3474 - accuracy: 0.8226 - val_loss: 0.2988 - val_accuracy: 0.8640\n",
            "Epoch 31/60\n",
            "37/37 [==============================] - 5s 145ms/step - loss: 0.3444 - accuracy: 0.8291 - val_loss: 0.2991 - val_accuracy: 0.8610\n",
            "Epoch 32/60\n",
            "37/37 [==============================] - 5s 142ms/step - loss: 0.3435 - accuracy: 0.8265 - val_loss: 0.2975 - val_accuracy: 0.8610\n",
            "Epoch 33/60\n",
            "37/37 [==============================] - 5s 141ms/step - loss: 0.3474 - accuracy: 0.8278 - val_loss: 0.2968 - val_accuracy: 0.8671\n",
            "Epoch 34/60\n",
            "37/37 [==============================] - 5s 144ms/step - loss: 0.3427 - accuracy: 0.8287 - val_loss: 0.2995 - val_accuracy: 0.8610\n",
            "Epoch 35/60\n",
            "37/37 [==============================] - 5s 141ms/step - loss: 0.3436 - accuracy: 0.8317 - val_loss: 0.2939 - val_accuracy: 0.8580\n",
            "Epoch 36/60\n",
            "37/37 [==============================] - 5s 139ms/step - loss: 0.3350 - accuracy: 0.8330 - val_loss: 0.2911 - val_accuracy: 0.8580\n",
            "Epoch 37/60\n",
            "37/37 [==============================] - 5s 144ms/step - loss: 0.3409 - accuracy: 0.8282 - val_loss: 0.2960 - val_accuracy: 0.8640\n",
            "Epoch 38/60\n",
            "37/37 [==============================] - 5s 144ms/step - loss: 0.3355 - accuracy: 0.8343 - val_loss: 0.2919 - val_accuracy: 0.8701\n",
            "Epoch 39/60\n",
            "37/37 [==============================] - 5s 142ms/step - loss: 0.3405 - accuracy: 0.8278 - val_loss: 0.2911 - val_accuracy: 0.8610\n",
            "Epoch 40/60\n",
            "37/37 [==============================] - 5s 144ms/step - loss: 0.3334 - accuracy: 0.8325 - val_loss: 0.2904 - val_accuracy: 0.8761\n",
            "Epoch 41/60\n",
            "37/37 [==============================] - 5s 145ms/step - loss: 0.3290 - accuracy: 0.8343 - val_loss: 0.2889 - val_accuracy: 0.8671\n",
            "Epoch 42/60\n",
            "37/37 [==============================] - 5s 141ms/step - loss: 0.3325 - accuracy: 0.8308 - val_loss: 0.2972 - val_accuracy: 0.8640\n",
            "Epoch 43/60\n",
            "37/37 [==============================] - 5s 142ms/step - loss: 0.3294 - accuracy: 0.8394 - val_loss: 0.2896 - val_accuracy: 0.8610\n",
            "Epoch 44/60\n",
            "37/37 [==============================] - 5s 145ms/step - loss: 0.3264 - accuracy: 0.8377 - val_loss: 0.2911 - val_accuracy: 0.8731\n",
            "Epoch 45/60\n",
            "37/37 [==============================] - 5s 139ms/step - loss: 0.3281 - accuracy: 0.8351 - val_loss: 0.2897 - val_accuracy: 0.8640\n",
            "Epoch 46/60\n",
            "37/37 [==============================] - 5s 142ms/step - loss: 0.3301 - accuracy: 0.8338 - val_loss: 0.2855 - val_accuracy: 0.8580\n",
            "Epoch 47/60\n",
            "37/37 [==============================] - 5s 145ms/step - loss: 0.3310 - accuracy: 0.8459 - val_loss: 0.2887 - val_accuracy: 0.8580\n",
            "Epoch 48/60\n",
            "37/37 [==============================] - 5s 139ms/step - loss: 0.3298 - accuracy: 0.8399 - val_loss: 0.2870 - val_accuracy: 0.8671\n",
            "Epoch 49/60\n",
            "37/37 [==============================] - 5s 141ms/step - loss: 0.3270 - accuracy: 0.8377 - val_loss: 0.2863 - val_accuracy: 0.8550\n",
            "Epoch 50/60\n",
            "37/37 [==============================] - 5s 145ms/step - loss: 0.3267 - accuracy: 0.8369 - val_loss: 0.2901 - val_accuracy: 0.8610\n",
            "Epoch 51/60\n",
            "37/37 [==============================] - 5s 143ms/step - loss: 0.3249 - accuracy: 0.8390 - val_loss: 0.2839 - val_accuracy: 0.8701\n",
            "Epoch 52/60\n",
            "37/37 [==============================] - 5s 139ms/step - loss: 0.3259 - accuracy: 0.8377 - val_loss: 0.2853 - val_accuracy: 0.8761\n",
            "Epoch 53/60\n",
            "37/37 [==============================] - 5s 145ms/step - loss: 0.3200 - accuracy: 0.8412 - val_loss: 0.2819 - val_accuracy: 0.8580\n",
            "Epoch 54/60\n",
            "37/37 [==============================] - 5s 144ms/step - loss: 0.3181 - accuracy: 0.8455 - val_loss: 0.2843 - val_accuracy: 0.8731\n",
            "Epoch 55/60\n",
            "37/37 [==============================] - 5s 138ms/step - loss: 0.3197 - accuracy: 0.8420 - val_loss: 0.2848 - val_accuracy: 0.8640\n",
            "Epoch 56/60\n",
            "37/37 [==============================] - 5s 142ms/step - loss: 0.3233 - accuracy: 0.8364 - val_loss: 0.2819 - val_accuracy: 0.8640\n",
            "Epoch 57/60\n",
            "37/37 [==============================] - 5s 143ms/step - loss: 0.3194 - accuracy: 0.8420 - val_loss: 0.2822 - val_accuracy: 0.8671\n",
            "Epoch 58/60\n",
            "37/37 [==============================] - 5s 141ms/step - loss: 0.3163 - accuracy: 0.8485 - val_loss: 0.2795 - val_accuracy: 0.8671\n",
            "Epoch 59/60\n",
            "37/37 [==============================] - 5s 143ms/step - loss: 0.3166 - accuracy: 0.8459 - val_loss: 0.2765 - val_accuracy: 0.8701\n",
            "Epoch 60/60\n",
            "37/37 [==============================] - 5s 145ms/step - loss: 0.3160 - accuracy: 0.8429 - val_loss: 0.2807 - val_accuracy: 0.8701\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on the test data\n",
        "test_loss, test_accuracy = hybrid_model.evaluate([x_test_normalized, x_test_normalized], y_test_encoded)\n",
        "\n",
        "print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")\n",
        "print(f\"Test Loss: {test_loss}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rM3iQi_UUYPH",
        "outputId": "7b11d635-e57c-4098-b2f8-351863198397"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "21/21 [==============================] - 1s 44ms/step - loss: 0.3336 - accuracy: 0.8567\n",
            "Test Accuracy: 85.67%\n",
            "Test Loss: 0.3336206376552582\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Assuming you have your hybrid model already trained and stored in hybrid_model_regularized\n",
        "\n",
        "# Extract features from the hybrid model for training, validation, and test sets\n",
        "x_train_features = hybrid_model.predict([x_train_normalized, x_train_normalized])\n",
        "x_val_features = hybrid_model.predict([x_val_normalized, x_val_normalized])\n",
        "x_test_features = hybrid_model.predict([x_test_normalized, x_test_normalized])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7VX2J4xlWzF1",
        "outputId": "e620bb52-c766-447f-92a6-89b8eb372a2e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "73/73 [==============================] - 2s 24ms/step\n",
            "11/11 [==============================] - 0s 21ms/step\n",
            "21/21 [==============================] - 1s 23ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_features = x_train_features.reshape(x_train_features.shape[0], -1)\n",
        "x_val_features = x_val_features.reshape(x_val_features.shape[0], -1)\n",
        "x_test_features = x_test_features.reshape(x_test_features.shape[0], -1)"
      ],
      "metadata": {
        "id": "V9UUDTRFXDdC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "\n",
        "\n",
        "\n",
        "# Define the best hyperparameters obtained from GridSearchCV\n",
        "best_params = {'C': 0.1, 'gamma': 'scale'}  # Replace these values with the best parameters found\n",
        "\n",
        "# Train SVM model with the best hyperparameters\n",
        "svm_model = SVC(kernel='rbf', C=best_params['C'], gamma=best_params['gamma'])\n",
        "svm_model.fit(x_train_features, y_train)\n",
        "\n",
        "# Predict on the test set using the trained SVM model\n",
        "y_pred_svm = svm_model.predict(x_test_features)\n",
        "\n",
        "# Calculate evaluation metrics\n",
        "svm_accuracy = accuracy_score(y_test, y_pred_svm)\n",
        "svm_precision = precision_score(y_test, y_pred_svm)\n",
        "svm_recall = recall_score(y_test, y_pred_svm)\n",
        "svm_f1 = f1_score(y_test, y_pred_svm)\n",
        "\n",
        "# Calculate specificity\n",
        "tn, fp, fn, tp = confusion_matrix(y_test, y_pred_svm).ravel()\n",
        "svm_specificity = tn / (tn + fp)\n",
        "\n",
        "# Print evaluation metrics\n",
        "print(\"SVM Accuracy:\", svm_accuracy)\n",
        "print(\"SVM Precision:\", svm_precision)\n",
        "print(\"SVM Sensitivity (Recall):\", svm_recall)\n",
        "print(\"SVM Specificity:\", svm_specificity)\n",
        "print(\"SVM F1 Score:\", svm_f1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fHbZrxmqXJwF",
        "outputId": "8a650085-cc23-4455-c3a0-03386be61a7b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVM Accuracy: 0.8567119155354449\n",
            "SVM Precision: 0.8271954674220963\n",
            "SVM Sensitivity (Recall): 0.8957055214723927\n",
            "SVM Specificity: 0.8189910979228486\n",
            "SVM F1 Score: 0.8600883652430044\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Input, Conv2D, BatchNormalization, ReLU, GlobalAveragePooling2D, Dense, Concatenate, Add, MaxPooling2D\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "# Basic Convolution Block with BatchNormalization and ReLU\n",
        "def conv_block(input_tensor, filters, kernel_size, strides=(1, 1)):\n",
        "    x = Conv2D(filters, kernel_size, strides=strides, padding='same')(input_tensor)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = ReLU()(x)\n",
        "    return x\n",
        "\n",
        "# Residual Block\n",
        "def residual_block(input_tensor, filters, kernel_size=(3, 3), strides=(1, 1)):\n",
        "    shortcut = input_tensor\n",
        "    x = conv_block(input_tensor, filters, kernel_size, strides)\n",
        "    x = conv_block(x, filters, kernel_size)\n",
        "    shortcut = Conv2D(filters, (1, 1), strides=strides, padding='same')(shortcut)\n",
        "    x = Add()([x, shortcut])\n",
        "    x = ReLU()(x)\n",
        "    return x\n",
        "\n",
        "# ShuffleNet-like architecture (simplified)\n",
        "def ShuffleNetCustom(input_shape):\n",
        "    input_tensor = Input(shape=input_shape)\n",
        "\n",
        "    # Convolution Block\n",
        "    x = conv_block(input_tensor, 64, (3, 3), strides=(2, 2))\n",
        "\n",
        "    # Stage 1 - ShuffleNet-like\n",
        "    x = residual_block(x, 128)\n",
        "    x = residual_block(x, 128)\n",
        "    x = residual_block(x, 128)\n",
        "\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    return Model(inputs=input_tensor, outputs=x)\n",
        "\n",
        "# ResNet50-like architecture (simplified)\n",
        "def ResNet50Custom(input_shape):\n",
        "    input_tensor = Input(shape=input_shape)\n",
        "\n",
        "    # Convolution Block\n",
        "    x = conv_block(input_tensor, 64, (7, 7), strides=(2, 2))\n",
        "\n",
        "    # Stage 1 - ResNet50-like\n",
        "    x = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n",
        "\n",
        "    x = residual_block(x, 256)\n",
        "    x = residual_block(x, 256)\n",
        "    x = residual_block(x, 256)\n",
        "\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    return Model(inputs=input_tensor, outputs=x)\n",
        "\n",
        "# Input shape and number of classes\n",
        "input_shape = (100, 100, 3)\n",
        "num_classes = 2\n",
        "\n",
        "# Build ShuffleNet-like and ResNet50-like models\n",
        "shufflenet_model = ShuffleNetCustom(input_shape)\n",
        "resnet50_model = ResNet50Custom(input_shape)\n",
        "\n",
        "# Get the output tensors from both models\n",
        "shufflenet_output = shufflenet_model.output\n",
        "resnet50_output = resnet50_model.output\n",
        "\n",
        "# Concatenate the outputs\n",
        "merged_output = Concatenate()([shufflenet_output, resnet50_output])\n",
        "\n",
        "# Add more layers for classification\n",
        "x = Dense(256, activation='relu')(merged_output)\n",
        "x = Dense(128, activation='relu')(x)\n",
        "predictions = Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "# Create the hybrid model\n",
        "hybrid_model = Model(inputs=[shufflenet_model.input, resnet50_model.input], outputs=predictions)\n",
        "\n",
        "# Compile the hybrid model\n",
        "hybrid_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Display the summary of the hybrid model\n",
        "hybrid_model.summary()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rv9uhjSoYABm",
        "outputId": "2d66b47c-7a6e-449a-b43a-2950d15e1a2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_16\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_15 (InputLayer)       [(None, 100, 100, 3)]        0         []                            \n",
            "                                                                                                  \n",
            " input_14 (InputLayer)       [(None, 100, 100, 3)]        0         []                            \n",
            "                                                                                                  \n",
            " conv2d_42 (Conv2D)          (None, 50, 50, 64)           9472      ['input_15[0][0]']            \n",
            "                                                                                                  \n",
            " conv2d_32 (Conv2D)          (None, 50, 50, 64)           1792      ['input_14[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_39 (Ba  (None, 50, 50, 64)           256       ['conv2d_42[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_32 (Ba  (None, 50, 50, 64)           256       ['conv2d_32[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " re_lu_41 (ReLU)             (None, 50, 50, 64)           0         ['batch_normalization_39[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " re_lu_31 (ReLU)             (None, 50, 50, 64)           0         ['batch_normalization_32[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " max_pooling2d (MaxPooling2  (None, 25, 25, 64)           0         ['re_lu_41[0][0]']            \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv2d_33 (Conv2D)          (None, 50, 50, 128)          73856     ['re_lu_31[0][0]']            \n",
            "                                                                                                  \n",
            " conv2d_43 (Conv2D)          (None, 25, 25, 256)          147712    ['max_pooling2d[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_33 (Ba  (None, 50, 50, 128)          512       ['conv2d_33[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_40 (Ba  (None, 25, 25, 256)          1024      ['conv2d_43[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " re_lu_32 (ReLU)             (None, 50, 50, 128)          0         ['batch_normalization_33[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " re_lu_42 (ReLU)             (None, 25, 25, 256)          0         ['batch_normalization_40[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_34 (Conv2D)          (None, 50, 50, 128)          147584    ['re_lu_32[0][0]']            \n",
            "                                                                                                  \n",
            " conv2d_44 (Conv2D)          (None, 25, 25, 256)          590080    ['re_lu_42[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_34 (Ba  (None, 50, 50, 128)          512       ['conv2d_34[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_41 (Ba  (None, 25, 25, 256)          1024      ['conv2d_44[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " re_lu_33 (ReLU)             (None, 50, 50, 128)          0         ['batch_normalization_34[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_35 (Conv2D)          (None, 50, 50, 128)          8320      ['re_lu_31[0][0]']            \n",
            "                                                                                                  \n",
            " re_lu_43 (ReLU)             (None, 25, 25, 256)          0         ['batch_normalization_41[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_45 (Conv2D)          (None, 25, 25, 256)          16640     ['max_pooling2d[0][0]']       \n",
            "                                                                                                  \n",
            " add_4 (Add)                 (None, 50, 50, 128)          0         ['re_lu_33[0][0]',            \n",
            "                                                                     'conv2d_35[0][0]']           \n",
            "                                                                                                  \n",
            " add_7 (Add)                 (None, 25, 25, 256)          0         ['re_lu_43[0][0]',            \n",
            "                                                                     'conv2d_45[0][0]']           \n",
            "                                                                                                  \n",
            " re_lu_34 (ReLU)             (None, 50, 50, 128)          0         ['add_4[0][0]']               \n",
            "                                                                                                  \n",
            " re_lu_44 (ReLU)             (None, 25, 25, 256)          0         ['add_7[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_36 (Conv2D)          (None, 50, 50, 128)          147584    ['re_lu_34[0][0]']            \n",
            "                                                                                                  \n",
            " conv2d_46 (Conv2D)          (None, 25, 25, 256)          590080    ['re_lu_44[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_35 (Ba  (None, 50, 50, 128)          512       ['conv2d_36[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_42 (Ba  (None, 25, 25, 256)          1024      ['conv2d_46[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " re_lu_35 (ReLU)             (None, 50, 50, 128)          0         ['batch_normalization_35[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " re_lu_45 (ReLU)             (None, 25, 25, 256)          0         ['batch_normalization_42[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_37 (Conv2D)          (None, 50, 50, 128)          147584    ['re_lu_35[0][0]']            \n",
            "                                                                                                  \n",
            " conv2d_47 (Conv2D)          (None, 25, 25, 256)          590080    ['re_lu_45[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_36 (Ba  (None, 50, 50, 128)          512       ['conv2d_37[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_43 (Ba  (None, 25, 25, 256)          1024      ['conv2d_47[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " re_lu_36 (ReLU)             (None, 50, 50, 128)          0         ['batch_normalization_36[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_38 (Conv2D)          (None, 50, 50, 128)          16512     ['re_lu_34[0][0]']            \n",
            "                                                                                                  \n",
            " re_lu_46 (ReLU)             (None, 25, 25, 256)          0         ['batch_normalization_43[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_48 (Conv2D)          (None, 25, 25, 256)          65792     ['re_lu_44[0][0]']            \n",
            "                                                                                                  \n",
            " add_5 (Add)                 (None, 50, 50, 128)          0         ['re_lu_36[0][0]',            \n",
            "                                                                     'conv2d_38[0][0]']           \n",
            "                                                                                                  \n",
            " add_8 (Add)                 (None, 25, 25, 256)          0         ['re_lu_46[0][0]',            \n",
            "                                                                     'conv2d_48[0][0]']           \n",
            "                                                                                                  \n",
            " re_lu_37 (ReLU)             (None, 50, 50, 128)          0         ['add_5[0][0]']               \n",
            "                                                                                                  \n",
            " re_lu_47 (ReLU)             (None, 25, 25, 256)          0         ['add_8[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_39 (Conv2D)          (None, 50, 50, 128)          147584    ['re_lu_37[0][0]']            \n",
            "                                                                                                  \n",
            " conv2d_49 (Conv2D)          (None, 25, 25, 256)          590080    ['re_lu_47[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_37 (Ba  (None, 50, 50, 128)          512       ['conv2d_39[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_44 (Ba  (None, 25, 25, 256)          1024      ['conv2d_49[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " re_lu_38 (ReLU)             (None, 50, 50, 128)          0         ['batch_normalization_37[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " re_lu_48 (ReLU)             (None, 25, 25, 256)          0         ['batch_normalization_44[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_40 (Conv2D)          (None, 50, 50, 128)          147584    ['re_lu_38[0][0]']            \n",
            "                                                                                                  \n",
            " conv2d_50 (Conv2D)          (None, 25, 25, 256)          590080    ['re_lu_48[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_38 (Ba  (None, 50, 50, 128)          512       ['conv2d_40[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_45 (Ba  (None, 25, 25, 256)          1024      ['conv2d_50[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " re_lu_39 (ReLU)             (None, 50, 50, 128)          0         ['batch_normalization_38[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_41 (Conv2D)          (None, 50, 50, 128)          16512     ['re_lu_37[0][0]']            \n",
            "                                                                                                  \n",
            " re_lu_49 (ReLU)             (None, 25, 25, 256)          0         ['batch_normalization_45[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_51 (Conv2D)          (None, 25, 25, 256)          65792     ['re_lu_47[0][0]']            \n",
            "                                                                                                  \n",
            " add_6 (Add)                 (None, 50, 50, 128)          0         ['re_lu_39[0][0]',            \n",
            "                                                                     'conv2d_41[0][0]']           \n",
            "                                                                                                  \n",
            " add_9 (Add)                 (None, 25, 25, 256)          0         ['re_lu_49[0][0]',            \n",
            "                                                                     'conv2d_51[0][0]']           \n",
            "                                                                                                  \n",
            " re_lu_40 (ReLU)             (None, 50, 50, 128)          0         ['add_6[0][0]']               \n",
            "                                                                                                  \n",
            " re_lu_50 (ReLU)             (None, 25, 25, 256)          0         ['add_9[0][0]']               \n",
            "                                                                                                  \n",
            " global_average_pooling2d_1  (None, 128)                  0         ['re_lu_40[0][0]']            \n",
            " 0 (GlobalAveragePooling2D)                                                                       \n",
            "                                                                                                  \n",
            " global_average_pooling2d_1  (None, 256)                  0         ['re_lu_50[0][0]']            \n",
            " 1 (GlobalAveragePooling2D)                                                                       \n",
            "                                                                                                  \n",
            " concatenate_4 (Concatenate  (None, 384)                  0         ['global_average_pooling2d_10[\n",
            " )                                                                  0][0]',                       \n",
            "                                                                     'global_average_pooling2d_11[\n",
            "                                                                    0][0]']                       \n",
            "                                                                                                  \n",
            " dense_12 (Dense)            (None, 256)                  98560     ['concatenate_4[0][0]']       \n",
            "                                                                                                  \n",
            " dense_13 (Dense)            (None, 128)                  32896     ['dense_12[0][0]']            \n",
            "                                                                                                  \n",
            " dense_14 (Dense)            (None, 2)                    258       ['dense_13[0][0]']            \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 4252162 (16.22 MB)\n",
            "Trainable params: 4247298 (16.20 MB)\n",
            "Non-trainable params: 4864 (19.00 KB)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "\\\n",
        "\n",
        "# Set the learning rate\n",
        "learning_rate = 0.0001\n",
        "\n",
        "# Compile the model with the specified learning rate\n",
        "hybrid_model.compile(optimizer=Adam(learning_rate=learning_rate),\n",
        "                     loss='categorical_crossentropy',\n",
        "                     metrics=['accuracy'])\n",
        "\n",
        "# Train the hybrid model\n",
        "history = hybrid_model.fit(\n",
        "    [x_train_normalized, x_train_normalized],  # Replace with your training data\n",
        "    y_train_encoded,  # Replace with your training labels\n",
        "    epochs=55,\n",
        "    batch_size=batch_size,\n",
        "    validation_data=([x_val_normalized, x_val_normalized], y_val_encoded),  # Replace with your validation data\n",
        "    shuffle=True,\n",
        "    verbose=1,\n",
        "\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wdYync6zZObS",
        "outputId": "b401a050-ca9d-4e53-b17a-b25d69c5f2fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/55\n",
            "37/37 [==============================] - 27s 382ms/step - loss: 0.0729 - accuracy: 0.9715 - val_loss: 0.2911 - val_accuracy: 0.9184\n",
            "Epoch 2/55\n",
            "37/37 [==============================] - 14s 375ms/step - loss: 0.0615 - accuracy: 0.9784 - val_loss: 0.5749 - val_accuracy: 0.8489\n",
            "Epoch 3/55\n",
            "37/37 [==============================] - 14s 380ms/step - loss: 0.0522 - accuracy: 0.9836 - val_loss: 1.8061 - val_accuracy: 0.7674\n",
            "Epoch 4/55\n",
            "37/37 [==============================] - 14s 370ms/step - loss: 0.0391 - accuracy: 0.9875 - val_loss: 0.5191 - val_accuracy: 0.8640\n",
            "Epoch 5/55\n",
            "37/37 [==============================] - 13s 361ms/step - loss: 0.0290 - accuracy: 0.9914 - val_loss: 0.5405 - val_accuracy: 0.8399\n",
            "Epoch 6/55\n",
            "37/37 [==============================] - 13s 360ms/step - loss: 0.0444 - accuracy: 0.9836 - val_loss: 0.4668 - val_accuracy: 0.8369\n",
            "Epoch 7/55\n",
            "37/37 [==============================] - 13s 364ms/step - loss: 0.0609 - accuracy: 0.9767 - val_loss: 1.2318 - val_accuracy: 0.7462\n",
            "Epoch 8/55\n",
            "37/37 [==============================] - 14s 370ms/step - loss: 0.0369 - accuracy: 0.9866 - val_loss: 0.3848 - val_accuracy: 0.8640\n",
            "Epoch 9/55\n",
            "37/37 [==============================] - 14s 371ms/step - loss: 0.0336 - accuracy: 0.9888 - val_loss: 1.1459 - val_accuracy: 0.7221\n",
            "Epoch 10/55\n",
            "37/37 [==============================] - 14s 369ms/step - loss: 0.0903 - accuracy: 0.9642 - val_loss: 0.5598 - val_accuracy: 0.8127\n",
            "Epoch 11/55\n",
            "37/37 [==============================] - 14s 366ms/step - loss: 0.0454 - accuracy: 0.9819 - val_loss: 1.3684 - val_accuracy: 0.7795\n",
            "Epoch 12/55\n",
            "37/37 [==============================] - 14s 366ms/step - loss: 0.0207 - accuracy: 0.9940 - val_loss: 0.5756 - val_accuracy: 0.8580\n",
            "Epoch 13/55\n",
            "37/37 [==============================] - 14s 366ms/step - loss: 0.0430 - accuracy: 0.9858 - val_loss: 0.7185 - val_accuracy: 0.7976\n",
            "Epoch 14/55\n",
            "37/37 [==============================] - 14s 367ms/step - loss: 0.0167 - accuracy: 0.9961 - val_loss: 1.0760 - val_accuracy: 0.7764\n",
            "Epoch 15/55\n",
            "37/37 [==============================] - 14s 368ms/step - loss: 0.0703 - accuracy: 0.9732 - val_loss: 0.7796 - val_accuracy: 0.8580\n",
            "Epoch 16/55\n",
            "37/37 [==============================] - 14s 368ms/step - loss: 0.0859 - accuracy: 0.9698 - val_loss: 0.6787 - val_accuracy: 0.8006\n",
            "Epoch 17/55\n",
            "37/37 [==============================] - 14s 368ms/step - loss: 0.0292 - accuracy: 0.9896 - val_loss: 0.6592 - val_accuracy: 0.8157\n",
            "Epoch 18/55\n",
            "37/37 [==============================] - 14s 368ms/step - loss: 0.0156 - accuracy: 0.9957 - val_loss: 0.4327 - val_accuracy: 0.8882\n",
            "Epoch 19/55\n",
            "37/37 [==============================] - 14s 365ms/step - loss: 0.0305 - accuracy: 0.9905 - val_loss: 0.6093 - val_accuracy: 0.8308\n",
            "Epoch 20/55\n",
            "37/37 [==============================] - 14s 366ms/step - loss: 0.0235 - accuracy: 0.9901 - val_loss: 0.5318 - val_accuracy: 0.8761\n",
            "Epoch 21/55\n",
            "37/37 [==============================] - 14s 365ms/step - loss: 0.0359 - accuracy: 0.9875 - val_loss: 2.6563 - val_accuracy: 0.8187\n",
            "Epoch 22/55\n",
            "37/37 [==============================] - 13s 364ms/step - loss: 0.0190 - accuracy: 0.9931 - val_loss: 1.0302 - val_accuracy: 0.7855\n",
            "Epoch 23/55\n",
            "37/37 [==============================] - 14s 365ms/step - loss: 0.0124 - accuracy: 0.9974 - val_loss: 3.1480 - val_accuracy: 0.7251\n",
            "Epoch 24/55\n",
            "37/37 [==============================] - 14s 366ms/step - loss: 0.0064 - accuracy: 0.9983 - val_loss: 0.6858 - val_accuracy: 0.8308\n",
            "Epoch 25/55\n",
            "37/37 [==============================] - 14s 365ms/step - loss: 0.0278 - accuracy: 0.9896 - val_loss: 0.6052 - val_accuracy: 0.8218\n",
            "Epoch 26/55\n",
            "37/37 [==============================] - 14s 366ms/step - loss: 0.0131 - accuracy: 0.9957 - val_loss: 0.6527 - val_accuracy: 0.8701\n",
            "Epoch 27/55\n",
            "37/37 [==============================] - 14s 367ms/step - loss: 0.0130 - accuracy: 0.9961 - val_loss: 1.0616 - val_accuracy: 0.7795\n",
            "Epoch 28/55\n",
            "37/37 [==============================] - 14s 368ms/step - loss: 0.0192 - accuracy: 0.9935 - val_loss: 0.6133 - val_accuracy: 0.8580\n",
            "Epoch 29/55\n",
            "37/37 [==============================] - 14s 368ms/step - loss: 0.0271 - accuracy: 0.9914 - val_loss: 1.7305 - val_accuracy: 0.6858\n",
            "Epoch 30/55\n",
            "37/37 [==============================] - 14s 369ms/step - loss: 0.1010 - accuracy: 0.9629 - val_loss: 0.6959 - val_accuracy: 0.7915\n",
            "Epoch 31/55\n",
            "37/37 [==============================] - 14s 367ms/step - loss: 0.0318 - accuracy: 0.9914 - val_loss: 0.5950 - val_accuracy: 0.8610\n",
            "Epoch 32/55\n",
            "37/37 [==============================] - 14s 366ms/step - loss: 0.0405 - accuracy: 0.9858 - val_loss: 0.5646 - val_accuracy: 0.8459\n",
            "Epoch 33/55\n",
            "37/37 [==============================] - 14s 369ms/step - loss: 0.0148 - accuracy: 0.9961 - val_loss: 0.7616 - val_accuracy: 0.8671\n",
            "Epoch 34/55\n",
            "37/37 [==============================] - 14s 366ms/step - loss: 0.0101 - accuracy: 0.9983 - val_loss: 3.8524 - val_accuracy: 0.6495\n",
            "Epoch 35/55\n",
            "37/37 [==============================] - 14s 368ms/step - loss: 0.0709 - accuracy: 0.9707 - val_loss: 0.7406 - val_accuracy: 0.8097\n",
            "Epoch 36/55\n",
            "37/37 [==============================] - 14s 367ms/step - loss: 0.0405 - accuracy: 0.9849 - val_loss: 0.6639 - val_accuracy: 0.8369\n",
            "Epoch 37/55\n",
            "37/37 [==============================] - 14s 367ms/step - loss: 0.0674 - accuracy: 0.9767 - val_loss: 0.4733 - val_accuracy: 0.8761\n",
            "Epoch 38/55\n",
            "37/37 [==============================] - 14s 366ms/step - loss: 0.0145 - accuracy: 0.9965 - val_loss: 0.3897 - val_accuracy: 0.8852\n",
            "Epoch 39/55\n",
            "37/37 [==============================] - 14s 367ms/step - loss: 0.0080 - accuracy: 0.9983 - val_loss: 0.4814 - val_accuracy: 0.8701\n",
            "Epoch 40/55\n",
            "37/37 [==============================] - 14s 368ms/step - loss: 0.0107 - accuracy: 0.9978 - val_loss: 1.9639 - val_accuracy: 0.7704\n",
            "Epoch 41/55\n",
            "37/37 [==============================] - 14s 368ms/step - loss: 0.0529 - accuracy: 0.9832 - val_loss: 0.9638 - val_accuracy: 0.7855\n",
            "Epoch 42/55\n",
            "37/37 [==============================] - 14s 367ms/step - loss: 0.0196 - accuracy: 0.9957 - val_loss: 0.4209 - val_accuracy: 0.8429\n",
            "Epoch 43/55\n",
            "37/37 [==============================] - 14s 368ms/step - loss: 0.0249 - accuracy: 0.9918 - val_loss: 8.0660 - val_accuracy: 0.5076\n",
            "Epoch 44/55\n",
            "37/37 [==============================] - 14s 369ms/step - loss: 0.0192 - accuracy: 0.9927 - val_loss: 0.9146 - val_accuracy: 0.7704\n",
            "Epoch 45/55\n",
            "37/37 [==============================] - 14s 367ms/step - loss: 0.0366 - accuracy: 0.9879 - val_loss: 0.5322 - val_accuracy: 0.8731\n",
            "Epoch 46/55\n",
            "37/37 [==============================] - 14s 366ms/step - loss: 0.0108 - accuracy: 0.9974 - val_loss: 0.6481 - val_accuracy: 0.8369\n",
            "Epoch 47/55\n",
            "37/37 [==============================] - 14s 367ms/step - loss: 0.0035 - accuracy: 0.9996 - val_loss: 0.6267 - val_accuracy: 0.9063\n",
            "Epoch 48/55\n",
            "37/37 [==============================] - 14s 367ms/step - loss: 0.0544 - accuracy: 0.9797 - val_loss: 13.7063 - val_accuracy: 0.4894\n",
            "Epoch 49/55\n",
            "37/37 [==============================] - 14s 365ms/step - loss: 0.0549 - accuracy: 0.9814 - val_loss: 0.3806 - val_accuracy: 0.9003\n",
            "Epoch 50/55\n",
            "37/37 [==============================] - 14s 366ms/step - loss: 0.0486 - accuracy: 0.9814 - val_loss: 0.4053 - val_accuracy: 0.8701\n",
            "Epoch 51/55\n",
            "37/37 [==============================] - 14s 366ms/step - loss: 0.0182 - accuracy: 0.9948 - val_loss: 0.3727 - val_accuracy: 0.8912\n",
            "Epoch 52/55\n",
            "37/37 [==============================] - 14s 366ms/step - loss: 0.0084 - accuracy: 0.9978 - val_loss: 0.6188 - val_accuracy: 0.8520\n",
            "Epoch 53/55\n",
            "37/37 [==============================] - 14s 367ms/step - loss: 0.0097 - accuracy: 0.9970 - val_loss: 0.3763 - val_accuracy: 0.9094\n",
            "Epoch 54/55\n",
            "37/37 [==============================] - 14s 367ms/step - loss: 0.0064 - accuracy: 0.9987 - val_loss: 0.2798 - val_accuracy: 0.9184\n",
            "Epoch 55/55\n",
            "37/37 [==============================] - 14s 369ms/step - loss: 0.0097 - accuracy: 0.9970 - val_loss: 0.5719 - val_accuracy: 0.8399\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on the test data\n",
        "test_loss, test_accuracy = hybrid_model.evaluate([x_test_normalized, x_test_normalized], y_test_encoded)\n",
        "\n",
        "print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")\n",
        "print(f\"Test Loss: {test_loss}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y6VZe44jZ86G",
        "outputId": "d0f2a7dd-d981-4e64-80e9-a837bdccdbb7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "21/21 [==============================] - 1s 66ms/step - loss: 0.5710 - accuracy: 0.8537\n",
            "Test Accuracy: 85.37%\n",
            "Test Loss: 0.5710199475288391\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Assuming you have your hybrid model already trained and stored in hybrid_model_regularized\n",
        "\n",
        "# Extract features from the hybrid model for training, validation, and test sets\n",
        "x_train_features = hybrid_model.predict([x_train_normalized, x_train_normalized])\n",
        "x_val_features = hybrid_model.predict([x_val_normalized, x_val_normalized])\n",
        "x_test_features = hybrid_model.predict([x_test_normalized, x_test_normalized])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wi5T6VgmhJcf",
        "outputId": "68aaa57a-852a-4e03-956c-07899587bb05"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "73/73 [==============================] - 5s 58ms/step\n",
            "11/11 [==============================] - 1s 62ms/step\n",
            "21/21 [==============================] - 1s 58ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_features = x_train_features.reshape(x_train_features.shape[0], -1)\n",
        "x_val_features = x_val_features.reshape(x_val_features.shape[0], -1)\n",
        "x_test_features = x_test_features.reshape(x_test_features.shape[0], -1)"
      ],
      "metadata": {
        "id": "9bP1tTnvhQFY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "\n",
        "\n",
        "\n",
        "# Define the best hyperparameters obtained from GridSearchCV\n",
        "best_params = {'C': 3, 'gamma': 'scale'}  # Replace these values with the best parameters found\n",
        "\n",
        "# Train SVM model with the best hyperparameters\n",
        "svm_model = SVC(kernel='rbf', C=best_params['C'], gamma=best_params['gamma'])\n",
        "svm_model.fit(x_train_features, y_train)\n",
        "\n",
        "# Predict on the test set using the trained SVM model\n",
        "y_pred_svm = svm_model.predict(x_test_features)\n",
        "\n",
        "# Calculate evaluation metrics\n",
        "svm_accuracy = accuracy_score(y_test, y_pred_svm)\n",
        "svm_precision = precision_score(y_test, y_pred_svm)\n",
        "svm_recall = recall_score(y_test, y_pred_svm)\n",
        "svm_f1 = f1_score(y_test, y_pred_svm)\n",
        "\n",
        "# Calculate specificity\n",
        "tn, fp, fn, tp = confusion_matrix(y_test, y_pred_svm).ravel()\n",
        "svm_specificity = tn / (tn + fp)\n",
        "\n",
        "# Print evaluation metrics\n",
        "print(\"SVM Accuracy:\", svm_accuracy)\n",
        "print(\"SVM Precision:\", svm_precision)\n",
        "print(\"SVM Sensitivity (Recall):\", svm_recall)\n",
        "print(\"SVM Specificity:\", svm_specificity)\n",
        "print(\"SVM F1 Score:\", svm_f1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IowHNKiQhY6O",
        "outputId": "558af5af-b1f6-4fb4-ff05-15b48b7a2d8e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVM Accuracy: 0.8808446455505279\n",
            "SVM Precision: 0.8945686900958466\n",
            "SVM Sensitivity (Recall): 0.8588957055214724\n",
            "SVM Specificity: 0.9020771513353115\n",
            "SVM F1 Score: 0.8763693270735524\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Sm2FDZLazQ7m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Assuming x_train_features, x_test_features, y_train, and y_test are available\n",
        "\n",
        "# Train SVM model with the best hyperparameters (as previously defined)\n",
        "best_params = {'C': 4.5, 'gamma': 'scale'}\n",
        "svm_model = SVC(kernel='rbf', C=best_params['C'], gamma=best_params['gamma'])\n",
        "svm_model.fit(x_train_features, y_train)\n",
        "\n",
        "# Predict on the test set using the trained SVM model\n",
        "y_pred_svm = svm_model.predict(x_test_features)\n",
        "\n",
        "# Use Logistic Regression with L1 penalty for feature selection\n",
        "clf = LogisticRegression(penalty='l1', solver='liblinear')\n",
        "clf.fit(x_train_features, y_train)\n",
        "\n",
        "# Get selected features (non-zero coefficients)\n",
        "selected_indices = np.where(clf.coef_ != 0)[1]\n",
        "x_train_selected = x_train_features[:, selected_indices]\n",
        "x_test_selected = x_test_features[:, selected_indices]\n",
        "\n",
        "# Train SVM model on selected features\n",
        "svm_model_selected = SVC(kernel='rbf', C=best_params['C'], gamma=best_params['gamma'])\n",
        "svm_model_selected.fit(x_train_selected, y_train)\n",
        "\n",
        "# Predict on the test set using SVM with selected features\n",
        "y_pred_svm_selected = svm_model_selected.predict(x_test_selected)\n",
        "\n",
        "# Evaluate the performance of SVM with selected features\n",
        "# Calculate evaluation metrics for SVM with selected features\n",
        "svm_accuracy_selected = accuracy_score(y_test, y_pred_svm_selected)\n",
        "svm_precision_selected = precision_score(y_test, y_pred_svm_selected)\n",
        "svm_recall_selected = recall_score(y_test, y_pred_svm_selected)\n",
        "svm_f1_selected = f1_score(y_test, y_pred_svm_selected)\n",
        "# Calculate specificity for SVM with selected features\n",
        "tn_selected, fp_selected, fn_selected, tp_selected = confusion_matrix(y_test, y_pred_svm_selected).ravel()\n",
        "svm_specificity_selected = tn_selected / (tn_selected + fp_selected)\n",
        "\n",
        "# Print evaluation metrics for SVM with selected features\n",
        "print(\"SVM with Selected Features - Accuracy:\", svm_accuracy_selected)\n",
        "print(\"SVM with Selected Features - Precision:\", svm_precision_selected)\n",
        "print(\"SVM with Selected Features - Sensitivity (Recall):\", svm_recall_selected)\n",
        "print(\"SVM with Selected Features - Specificity:\", svm_specificity_selected)\n",
        "print(\"SVM with Selected Features - F1 Score:\", svm_f1_selected)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GEd6ssKzjejM",
        "outputId": "53488d45-d776-4cb5-d914-c11b93e527f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVM with Selected Features - Accuracy: 0.8808446455505279\n",
            "SVM with Selected Features - Precision: 0.8945686900958466\n",
            "SVM with Selected Features - Sensitivity (Recall): 0.8588957055214724\n",
            "SVM with Selected Features - Specificity: 0.9020771513353115\n",
            "SVM with Selected Features - F1 Score: 0.8763693270735524\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Input, Conv2D, BatchNormalization, ReLU, GlobalAveragePooling2D, Dense, Concatenate, MaxPooling2D\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "# Basic Convolution Block with BatchNormalization and ReLU\n",
        "def conv_block(input_tensor, filters, kernel_size, strides=(1, 1)):\n",
        "    x = Conv2D(filters, kernel_size, strides=strides, padding='same')(input_tensor)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = ReLU()(x)\n",
        "    return x\n",
        "\n",
        "# VGG16-like architecture (simplified)\n",
        "def VGG16Custom(input_shape):\n",
        "    input_tensor = Input(shape=input_shape)\n",
        "\n",
        "    # Convolution Block\n",
        "    x = conv_block(input_tensor, 64, (3, 3))\n",
        "    x = conv_block(x, 64, (3, 3))\n",
        "    x = MaxPooling2D((2, 2))(x)\n",
        "\n",
        "    x = conv_block(x, 128, (3, 3))\n",
        "    x = conv_block(x, 128, (3, 3))\n",
        "    x = MaxPooling2D((2, 2))(x)\n",
        "\n",
        "    x = conv_block(x, 256, (3, 3))\n",
        "    x = conv_block(x, 256, (3, 3))\n",
        "    x = conv_block(x, 256, (3, 3))\n",
        "    x = MaxPooling2D((2, 2))(x)\n",
        "\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    return Model(inputs=input_tensor, outputs=x)\n",
        "\n",
        "# ResNet50-like architecture (simplified)\n",
        "def ResNet50Custom(input_shape):\n",
        "    input_tensor = Input(shape=input_shape)\n",
        "\n",
        "    # Convolution Block\n",
        "    x = conv_block(input_tensor, 64, (7, 7), strides=(2, 2))\n",
        "    x = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n",
        "\n",
        "    x = residual_block(x, 256)\n",
        "    x = residual_block(x, 256)\n",
        "    x = residual_block(x, 256)\n",
        "\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    return Model(inputs=input_tensor, outputs=x)\n",
        "\n",
        "# Define the residual block used in ResNet50\n",
        "def residual_block(input_tensor, filters, kernel_size=(3, 3), strides=(1, 1)):\n",
        "    shortcut = input_tensor\n",
        "    x = conv_block(input_tensor, filters, kernel_size, strides)\n",
        "    x = conv_block(x, filters, kernel_size)\n",
        "    shortcut = Conv2D(filters, (1, 1), strides=strides, padding='same')(shortcut)\n",
        "    x = Add()([x, shortcut])\n",
        "    x = ReLU()(x)\n",
        "    return x\n",
        "\n",
        "# Input shape and number of classes\n",
        "input_shape = (100, 100, 3)\n",
        "num_classes = 2\n",
        "\n",
        "# Build VGG16-like and ResNet50-like models\n",
        "vgg16_model = VGG16Custom(input_shape)\n",
        "resnet50_model = ResNet50Custom(input_shape)\n",
        "\n",
        "# Get the output tensors from both models\n",
        "vgg16_output = vgg16_model.output\n",
        "resnet50_output = resnet50_model.output\n",
        "\n",
        "# Concatenate the outputs\n",
        "merged_output = Concatenate()([vgg16_output, resnet50_output])\n",
        "\n",
        "# Add more layers for classification\n",
        "x = Dense(256, activation='relu')(merged_output)\n",
        "x = Dense(128, activation='relu')(x)\n",
        "predictions = Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "# Create the hybrid model\n",
        "hybrid_model = Model(inputs=[vgg16_model.input, resnet50_model.input], outputs=predictions)\n",
        "\n",
        "# Compile the hybrid model\n",
        "hybrid_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Display the summary of the hybrid model\n",
        "hybrid_model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2BbXpU3nmYcu",
        "outputId": "3d7aabcc-650c-4fee-b794-dddea289552f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_28\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_27 (InputLayer)       [(None, 100, 100, 3)]        0         []                            \n",
            "                                                                                                  \n",
            " conv2d_96 (Conv2D)          (None, 50, 50, 64)           9472      ['input_27[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_76 (Ba  (None, 50, 50, 64)           256       ['conv2d_96[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " re_lu_87 (ReLU)             (None, 50, 50, 64)           0         ['batch_normalization_76[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " input_26 (InputLayer)       [(None, 100, 100, 3)]        0         []                            \n",
            "                                                                                                  \n",
            " max_pooling2d_14 (MaxPooli  (None, 25, 25, 64)           0         ['re_lu_87[0][0]']            \n",
            " ng2D)                                                                                            \n",
            "                                                                                                  \n",
            " conv2d_89 (Conv2D)          (None, 100, 100, 64)         1792      ['input_26[0][0]']            \n",
            "                                                                                                  \n",
            " conv2d_97 (Conv2D)          (None, 25, 25, 256)          147712    ['max_pooling2d_14[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_69 (Ba  (None, 100, 100, 64)         256       ['conv2d_89[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_77 (Ba  (None, 25, 25, 256)          1024      ['conv2d_97[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " re_lu_80 (ReLU)             (None, 100, 100, 64)         0         ['batch_normalization_69[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " re_lu_88 (ReLU)             (None, 25, 25, 256)          0         ['batch_normalization_77[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_90 (Conv2D)          (None, 100, 100, 64)         36928     ['re_lu_80[0][0]']            \n",
            "                                                                                                  \n",
            " conv2d_98 (Conv2D)          (None, 25, 25, 256)          590080    ['re_lu_88[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_70 (Ba  (None, 100, 100, 64)         256       ['conv2d_90[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_78 (Ba  (None, 25, 25, 256)          1024      ['conv2d_98[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " re_lu_81 (ReLU)             (None, 100, 100, 64)         0         ['batch_normalization_70[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " re_lu_89 (ReLU)             (None, 25, 25, 256)          0         ['batch_normalization_78[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_99 (Conv2D)          (None, 25, 25, 256)          16640     ['max_pooling2d_14[0][0]']    \n",
            "                                                                                                  \n",
            " max_pooling2d_11 (MaxPooli  (None, 50, 50, 64)           0         ['re_lu_81[0][0]']            \n",
            " ng2D)                                                                                            \n",
            "                                                                                                  \n",
            " add_16 (Add)                (None, 25, 25, 256)          0         ['re_lu_89[0][0]',            \n",
            "                                                                     'conv2d_99[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_91 (Conv2D)          (None, 50, 50, 128)          73856     ['max_pooling2d_11[0][0]']    \n",
            "                                                                                                  \n",
            " re_lu_90 (ReLU)             (None, 25, 25, 256)          0         ['add_16[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_71 (Ba  (None, 50, 50, 128)          512       ['conv2d_91[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " conv2d_100 (Conv2D)         (None, 25, 25, 256)          590080    ['re_lu_90[0][0]']            \n",
            "                                                                                                  \n",
            " re_lu_82 (ReLU)             (None, 50, 50, 128)          0         ['batch_normalization_71[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " batch_normalization_79 (Ba  (None, 25, 25, 256)          1024      ['conv2d_100[0][0]']          \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " conv2d_92 (Conv2D)          (None, 50, 50, 128)          147584    ['re_lu_82[0][0]']            \n",
            "                                                                                                  \n",
            " re_lu_91 (ReLU)             (None, 25, 25, 256)          0         ['batch_normalization_79[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " batch_normalization_72 (Ba  (None, 50, 50, 128)          512       ['conv2d_92[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " conv2d_101 (Conv2D)         (None, 25, 25, 256)          590080    ['re_lu_91[0][0]']            \n",
            "                                                                                                  \n",
            " re_lu_83 (ReLU)             (None, 50, 50, 128)          0         ['batch_normalization_72[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " batch_normalization_80 (Ba  (None, 25, 25, 256)          1024      ['conv2d_101[0][0]']          \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " max_pooling2d_12 (MaxPooli  (None, 25, 25, 128)          0         ['re_lu_83[0][0]']            \n",
            " ng2D)                                                                                            \n",
            "                                                                                                  \n",
            " re_lu_92 (ReLU)             (None, 25, 25, 256)          0         ['batch_normalization_80[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_102 (Conv2D)         (None, 25, 25, 256)          65792     ['re_lu_90[0][0]']            \n",
            "                                                                                                  \n",
            " conv2d_93 (Conv2D)          (None, 25, 25, 256)          295168    ['max_pooling2d_12[0][0]']    \n",
            "                                                                                                  \n",
            " add_17 (Add)                (None, 25, 25, 256)          0         ['re_lu_92[0][0]',            \n",
            "                                                                     'conv2d_102[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_73 (Ba  (None, 25, 25, 256)          1024      ['conv2d_93[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " re_lu_93 (ReLU)             (None, 25, 25, 256)          0         ['add_17[0][0]']              \n",
            "                                                                                                  \n",
            " re_lu_84 (ReLU)             (None, 25, 25, 256)          0         ['batch_normalization_73[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_103 (Conv2D)         (None, 25, 25, 256)          590080    ['re_lu_93[0][0]']            \n",
            "                                                                                                  \n",
            " conv2d_94 (Conv2D)          (None, 25, 25, 256)          590080    ['re_lu_84[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_81 (Ba  (None, 25, 25, 256)          1024      ['conv2d_103[0][0]']          \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_74 (Ba  (None, 25, 25, 256)          1024      ['conv2d_94[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " re_lu_94 (ReLU)             (None, 25, 25, 256)          0         ['batch_normalization_81[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " re_lu_85 (ReLU)             (None, 25, 25, 256)          0         ['batch_normalization_74[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_104 (Conv2D)         (None, 25, 25, 256)          590080    ['re_lu_94[0][0]']            \n",
            "                                                                                                  \n",
            " conv2d_95 (Conv2D)          (None, 25, 25, 256)          590080    ['re_lu_85[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_82 (Ba  (None, 25, 25, 256)          1024      ['conv2d_104[0][0]']          \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_75 (Ba  (None, 25, 25, 256)          1024      ['conv2d_95[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " re_lu_95 (ReLU)             (None, 25, 25, 256)          0         ['batch_normalization_82[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_105 (Conv2D)         (None, 25, 25, 256)          65792     ['re_lu_93[0][0]']            \n",
            "                                                                                                  \n",
            " re_lu_86 (ReLU)             (None, 25, 25, 256)          0         ['batch_normalization_75[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " add_18 (Add)                (None, 25, 25, 256)          0         ['re_lu_95[0][0]',            \n",
            "                                                                     'conv2d_105[0][0]']          \n",
            "                                                                                                  \n",
            " max_pooling2d_13 (MaxPooli  (None, 12, 12, 256)          0         ['re_lu_86[0][0]']            \n",
            " ng2D)                                                                                            \n",
            "                                                                                                  \n",
            " re_lu_96 (ReLU)             (None, 25, 25, 256)          0         ['add_18[0][0]']              \n",
            "                                                                                                  \n",
            " global_average_pooling2d_2  (None, 256)                  0         ['max_pooling2d_13[0][0]']    \n",
            " 1 (GlobalAveragePooling2D)                                                                       \n",
            "                                                                                                  \n",
            " global_average_pooling2d_2  (None, 256)                  0         ['re_lu_96[0][0]']            \n",
            " 2 (GlobalAveragePooling2D)                                                                       \n",
            "                                                                                                  \n",
            " concatenate_7 (Concatenate  (None, 512)                  0         ['global_average_pooling2d_21[\n",
            " )                                                                  0][0]',                       \n",
            "                                                                     'global_average_pooling2d_22[\n",
            "                                                                    0][0]']                       \n",
            "                                                                                                  \n",
            " dense_24 (Dense)            (None, 256)                  131328    ['concatenate_7[0][0]']       \n",
            "                                                                                                  \n",
            " dense_25 (Dense)            (None, 128)                  32896     ['dense_24[0][0]']            \n",
            "                                                                                                  \n",
            " dense_26 (Dense)            (None, 2)                    258       ['dense_25[0][0]']            \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 5166786 (19.71 MB)\n",
            "Trainable params: 5161282 (19.69 MB)\n",
            "Non-trainable params: 5504 (21.50 KB)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "\n",
        "# Set the learning rate\n",
        "learning_rate = 0.00001\n",
        "\n",
        "# Compile the model with the specified learning rate\n",
        "hybrid_model.compile(optimizer=Adam(learning_rate=learning_rate),\n",
        "                     loss='categorical_crossentropy',\n",
        "                     metrics=['accuracy'])\n",
        "\n",
        "# Train the hybrid model\n",
        "history = hybrid_model.fit(\n",
        "    [x_train_normalized, x_train_normalized],  # Replace with your training data\n",
        "    y_train_encoded,  # Replace with your training labels\n",
        "    epochs=55,\n",
        "    batch_size=batch_size,\n",
        "    validation_data=([x_val_normalized, x_val_normalized], y_val_encoded),  # Replace with your validation data\n",
        "    shuffle=True,\n",
        "    verbose=1,\n",
        "\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K9Lo3wUroRd7",
        "outputId": "cfc422e2-3d4e-443c-c121-ec537649c4b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/55\n",
            "37/37 [==============================] - 24s 355ms/step - loss: 0.4583 - accuracy: 0.7661 - val_loss: 0.6919 - val_accuracy: 0.5166\n",
            "Epoch 2/55\n",
            "37/37 [==============================] - 13s 345ms/step - loss: 0.3818 - accuracy: 0.8123 - val_loss: 0.6962 - val_accuracy: 0.5166\n",
            "Epoch 3/55\n",
            "37/37 [==============================] - 13s 355ms/step - loss: 0.3555 - accuracy: 0.8239 - val_loss: 0.7070 - val_accuracy: 0.5166\n",
            "Epoch 4/55\n",
            "37/37 [==============================] - 13s 349ms/step - loss: 0.3395 - accuracy: 0.8382 - val_loss: 0.7097 - val_accuracy: 0.5166\n",
            "Epoch 5/55\n",
            "37/37 [==============================] - 12s 336ms/step - loss: 0.3307 - accuracy: 0.8394 - val_loss: 0.7531 - val_accuracy: 0.5166\n",
            "Epoch 6/55\n",
            "37/37 [==============================] - 12s 337ms/step - loss: 0.3204 - accuracy: 0.8494 - val_loss: 0.7969 - val_accuracy: 0.5166\n",
            "Epoch 7/55\n",
            "37/37 [==============================] - 12s 334ms/step - loss: 0.3112 - accuracy: 0.8507 - val_loss: 0.8019 - val_accuracy: 0.5166\n",
            "Epoch 8/55\n",
            "37/37 [==============================] - 13s 341ms/step - loss: 0.3013 - accuracy: 0.8558 - val_loss: 0.7166 - val_accuracy: 0.5166\n",
            "Epoch 9/55\n",
            "37/37 [==============================] - 13s 343ms/step - loss: 0.2923 - accuracy: 0.8653 - val_loss: 0.7933 - val_accuracy: 0.5196\n",
            "Epoch 10/55\n",
            "37/37 [==============================] - 13s 344ms/step - loss: 0.2816 - accuracy: 0.8710 - val_loss: 0.7133 - val_accuracy: 0.5378\n",
            "Epoch 11/55\n",
            "37/37 [==============================] - 13s 341ms/step - loss: 0.2811 - accuracy: 0.8675 - val_loss: 0.6358 - val_accuracy: 0.6042\n",
            "Epoch 12/55\n",
            "37/37 [==============================] - 13s 342ms/step - loss: 0.2720 - accuracy: 0.8748 - val_loss: 0.6379 - val_accuracy: 0.6133\n",
            "Epoch 13/55\n",
            "37/37 [==============================] - 13s 341ms/step - loss: 0.2658 - accuracy: 0.8770 - val_loss: 0.6858 - val_accuracy: 0.5861\n",
            "Epoch 14/55\n",
            "37/37 [==============================] - 13s 340ms/step - loss: 0.2574 - accuracy: 0.8878 - val_loss: 0.5943 - val_accuracy: 0.6586\n",
            "Epoch 15/55\n",
            "37/37 [==============================] - 13s 340ms/step - loss: 0.2609 - accuracy: 0.8792 - val_loss: 0.5488 - val_accuracy: 0.6888\n",
            "Epoch 16/55\n",
            "37/37 [==============================] - 13s 343ms/step - loss: 0.2500 - accuracy: 0.8921 - val_loss: 0.3970 - val_accuracy: 0.8097\n",
            "Epoch 17/55\n",
            "37/37 [==============================] - 13s 344ms/step - loss: 0.2413 - accuracy: 0.8977 - val_loss: 0.3983 - val_accuracy: 0.8036\n",
            "Epoch 18/55\n",
            "37/37 [==============================] - 13s 340ms/step - loss: 0.2392 - accuracy: 0.8947 - val_loss: 0.3079 - val_accuracy: 0.8701\n",
            "Epoch 19/55\n",
            "37/37 [==============================] - 13s 342ms/step - loss: 0.2372 - accuracy: 0.8968 - val_loss: 0.2929 - val_accuracy: 0.8731\n",
            "Epoch 20/55\n",
            "37/37 [==============================] - 13s 342ms/step - loss: 0.2400 - accuracy: 0.9012 - val_loss: 0.2645 - val_accuracy: 0.8852\n",
            "Epoch 21/55\n",
            "37/37 [==============================] - 12s 338ms/step - loss: 0.2296 - accuracy: 0.8973 - val_loss: 0.2420 - val_accuracy: 0.9154\n",
            "Epoch 22/55\n",
            "37/37 [==============================] - 13s 340ms/step - loss: 0.2229 - accuracy: 0.9059 - val_loss: 0.2294 - val_accuracy: 0.8973\n",
            "Epoch 23/55\n",
            "37/37 [==============================] - 13s 343ms/step - loss: 0.2198 - accuracy: 0.9055 - val_loss: 0.2393 - val_accuracy: 0.9033\n",
            "Epoch 24/55\n",
            "37/37 [==============================] - 13s 341ms/step - loss: 0.2127 - accuracy: 0.9120 - val_loss: 0.2429 - val_accuracy: 0.8912\n",
            "Epoch 25/55\n",
            "37/37 [==============================] - 13s 339ms/step - loss: 0.2064 - accuracy: 0.9111 - val_loss: 0.2288 - val_accuracy: 0.9215\n",
            "Epoch 26/55\n",
            "37/37 [==============================] - 13s 342ms/step - loss: 0.2003 - accuracy: 0.9197 - val_loss: 0.2304 - val_accuracy: 0.9215\n",
            "Epoch 27/55\n",
            "37/37 [==============================] - 13s 341ms/step - loss: 0.2012 - accuracy: 0.9158 - val_loss: 0.2988 - val_accuracy: 0.8399\n",
            "Epoch 28/55\n",
            "37/37 [==============================] - 13s 340ms/step - loss: 0.2107 - accuracy: 0.9076 - val_loss: 0.2371 - val_accuracy: 0.8973\n",
            "Epoch 29/55\n",
            "37/37 [==============================] - 13s 342ms/step - loss: 0.1879 - accuracy: 0.9253 - val_loss: 0.2305 - val_accuracy: 0.9033\n",
            "Epoch 30/55\n",
            "37/37 [==============================] - 13s 343ms/step - loss: 0.1883 - accuracy: 0.9219 - val_loss: 0.2695 - val_accuracy: 0.8610\n",
            "Epoch 31/55\n",
            "37/37 [==============================] - 13s 341ms/step - loss: 0.2004 - accuracy: 0.9128 - val_loss: 0.2389 - val_accuracy: 0.9124\n",
            "Epoch 32/55\n",
            "37/37 [==============================] - 13s 342ms/step - loss: 0.1853 - accuracy: 0.9167 - val_loss: 0.2229 - val_accuracy: 0.9184\n",
            "Epoch 33/55\n",
            "37/37 [==============================] - 13s 341ms/step - loss: 0.1858 - accuracy: 0.9180 - val_loss: 0.3842 - val_accuracy: 0.8278\n",
            "Epoch 34/55\n",
            "37/37 [==============================] - 13s 343ms/step - loss: 0.1937 - accuracy: 0.9176 - val_loss: 0.2334 - val_accuracy: 0.8882\n",
            "Epoch 35/55\n",
            "37/37 [==============================] - 13s 341ms/step - loss: 0.1712 - accuracy: 0.9297 - val_loss: 0.2278 - val_accuracy: 0.9184\n",
            "Epoch 36/55\n",
            "37/37 [==============================] - 13s 340ms/step - loss: 0.1655 - accuracy: 0.9361 - val_loss: 0.2376 - val_accuracy: 0.9184\n",
            "Epoch 37/55\n",
            "37/37 [==============================] - 13s 341ms/step - loss: 0.1698 - accuracy: 0.9275 - val_loss: 0.2366 - val_accuracy: 0.9003\n",
            "Epoch 38/55\n",
            "37/37 [==============================] - 13s 340ms/step - loss: 0.1568 - accuracy: 0.9374 - val_loss: 0.2198 - val_accuracy: 0.9184\n",
            "Epoch 39/55\n",
            "37/37 [==============================] - 13s 342ms/step - loss: 0.1657 - accuracy: 0.9353 - val_loss: 0.2653 - val_accuracy: 0.9033\n",
            "Epoch 40/55\n",
            "37/37 [==============================] - 13s 344ms/step - loss: 0.1612 - accuracy: 0.9340 - val_loss: 0.2607 - val_accuracy: 0.8671\n",
            "Epoch 41/55\n",
            "37/37 [==============================] - 13s 343ms/step - loss: 0.1549 - accuracy: 0.9383 - val_loss: 0.2178 - val_accuracy: 0.9094\n",
            "Epoch 42/55\n",
            "37/37 [==============================] - 13s 343ms/step - loss: 0.1506 - accuracy: 0.9383 - val_loss: 0.2281 - val_accuracy: 0.8973\n",
            "Epoch 43/55\n",
            "37/37 [==============================] - 13s 341ms/step - loss: 0.1396 - accuracy: 0.9469 - val_loss: 0.2257 - val_accuracy: 0.9094\n",
            "Epoch 44/55\n",
            "37/37 [==============================] - 13s 342ms/step - loss: 0.1526 - accuracy: 0.9379 - val_loss: 0.3309 - val_accuracy: 0.8580\n",
            "Epoch 45/55\n",
            "37/37 [==============================] - 13s 343ms/step - loss: 0.1636 - accuracy: 0.9249 - val_loss: 0.2578 - val_accuracy: 0.8792\n",
            "Epoch 46/55\n",
            "37/37 [==============================] - 13s 342ms/step - loss: 0.1328 - accuracy: 0.9525 - val_loss: 0.2042 - val_accuracy: 0.9275\n",
            "Epoch 47/55\n",
            "37/37 [==============================] - 13s 342ms/step - loss: 0.1272 - accuracy: 0.9521 - val_loss: 0.2532 - val_accuracy: 0.8943\n",
            "Epoch 48/55\n",
            "37/37 [==============================] - 13s 343ms/step - loss: 0.1405 - accuracy: 0.9486 - val_loss: 0.2403 - val_accuracy: 0.9094\n",
            "Epoch 49/55\n",
            "37/37 [==============================] - 13s 341ms/step - loss: 0.1391 - accuracy: 0.9400 - val_loss: 0.2083 - val_accuracy: 0.9275\n",
            "Epoch 50/55\n",
            "37/37 [==============================] - 13s 342ms/step - loss: 0.1287 - accuracy: 0.9508 - val_loss: 0.2724 - val_accuracy: 0.8671\n",
            "Epoch 51/55\n",
            "37/37 [==============================] - 13s 342ms/step - loss: 0.1208 - accuracy: 0.9538 - val_loss: 0.3721 - val_accuracy: 0.8550\n",
            "Epoch 52/55\n",
            "37/37 [==============================] - 12s 337ms/step - loss: 0.1262 - accuracy: 0.9568 - val_loss: 0.2044 - val_accuracy: 0.9184\n",
            "Epoch 53/55\n",
            "37/37 [==============================] - 13s 341ms/step - loss: 0.1279 - accuracy: 0.9512 - val_loss: 0.2614 - val_accuracy: 0.9003\n",
            "Epoch 54/55\n",
            "37/37 [==============================] - 13s 338ms/step - loss: 0.1267 - accuracy: 0.9525 - val_loss: 0.3554 - val_accuracy: 0.8671\n",
            "Epoch 55/55\n",
            "37/37 [==============================] - 13s 340ms/step - loss: 0.1180 - accuracy: 0.9568 - val_loss: 0.2390 - val_accuracy: 0.9003\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on the test data\n",
        "test_loss, test_accuracy = hybrid_model.evaluate([x_test_normalized, x_test_normalized], y_test_encoded)\n",
        "\n",
        "print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")\n",
        "print(f\"Test Loss: {test_loss}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dqWdJmDoq424",
        "outputId": "8680b7aa-1f49-4f11-8063-ce81d92deacf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "21/21 [==============================] - 1s 58ms/step - loss: 0.2705 - accuracy: 0.8944\n",
            "Test Accuracy: 89.44%\n",
            "Test Loss: 0.2705395221710205\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Assuming you have your hybrid model already trained and stored in hybrid_model_regularized\n",
        "\n",
        "# Extract features from the hybrid model for training, validation, and test sets\n",
        "x_train_features = hybrid_model.predict([x_train_normalized, x_train_normalized])\n",
        "x_val_features = hybrid_model.predict([x_val_normalized, x_val_normalized])\n",
        "x_test_features = hybrid_model.predict([x_test_normalized, x_test_normalized])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_jzT1lNtrEPW",
        "outputId": "e7ddf05c-0dcb-4847-c6d2-2e5c594c8073"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "73/73 [==============================] - 4s 53ms/step\n",
            "11/11 [==============================] - 1s 50ms/step\n",
            "21/21 [==============================] - 1s 52ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_features = x_train_features.reshape(x_train_features.shape[0], -1)\n",
        "x_val_features = x_val_features.reshape(x_val_features.shape[0], -1)\n",
        "x_test_features = x_test_features.reshape(x_test_features.shape[0], -1)"
      ],
      "metadata": {
        "id": "VeMNUQTfrKUN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Assuming x_train_features, x_test_features, y_train, and y_test are available\n",
        "\n",
        "# Train SVM model with the best hyperparameters (as previously defined)\n",
        "best_params = {'C': 4.5, 'gamma': 'scale'}\n",
        "svm_model = SVC(kernel='rbf', C=best_params['C'], gamma=best_params['gamma'])\n",
        "svm_model.fit(x_train_features, y_train)\n",
        "\n",
        "# Predict on the test set using the trained SVM model\n",
        "y_pred_svm = svm_model.predict(x_test_features)\n",
        "\n",
        "# Use Logistic Regression with L1 penalty for feature selection\n",
        "clf = LogisticRegression(penalty='l1', solver='liblinear')\n",
        "clf.fit(x_train_features, y_train)\n",
        "\n",
        "# Get selected features (non-zero coefficients)\n",
        "selected_indices = np.where(clf.coef_ != 0)[1]\n",
        "x_train_selected = x_train_features[:, selected_indices]\n",
        "x_test_selected = x_test_features[:, selected_indices]\n",
        "\n",
        "# Train SVM model on selected features\n",
        "svm_model_selected = SVC(kernel='rbf', C=best_params['C'], gamma=best_params['gamma'])\n",
        "svm_model_selected.fit(x_train_selected, y_train)\n",
        "\n",
        "# Predict on the test set using SVM with selected features\n",
        "y_pred_svm_selected = svm_model_selected.predict(x_test_selected)\n",
        "\n",
        "# Evaluate the performance of SVM with selected features\n",
        "# Calculate evaluation metrics for SVM with selected features\n",
        "svm_accuracy_selected = accuracy_score(y_test, y_pred_svm_selected)\n",
        "svm_precision_selected = precision_score(y_test, y_pred_svm_selected)\n",
        "svm_recall_selected = recall_score(y_test, y_pred_svm_selected)\n",
        "svm_f1_selected = f1_score(y_test, y_pred_svm_selected)\n",
        "# Calculate specificity for SVM with selected features\n",
        "tn_selected, fp_selected, fn_selected, tp_selected = confusion_matrix(y_test, y_pred_svm_selected).ravel()\n",
        "svm_specificity_selected = tn_selected / (tn_selected + fp_selected)\n",
        "\n",
        "# Print evaluation metrics for SVM with selected features\n",
        "print(\"SVM with Selected Features - Accuracy:\", svm_accuracy_selected)\n",
        "print(\"SVM with Selected Features - Precision:\", svm_precision_selected)\n",
        "print(\"SVM with Selected Features - Sensitivity (Recall):\", svm_recall_selected)\n",
        "print(\"SVM with Selected Features - Specificity:\", svm_specificity_selected)\n",
        "print(\"SVM with Selected Features - F1 Score:\", svm_f1_selected)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 944
        },
        "id": "whH5db7erPN-",
        "outputId": "2be27863-a813-4e30-fcb8-83cd518ca536"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-110-51b63c41e7c6>\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mbest_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'C'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m4.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'gamma'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'scale'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0msvm_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSVC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'rbf'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbest_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'C'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbest_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'gamma'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0msvm_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# Predict on the test set using the trained SVM model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    190\u001b[0m             \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 192\u001b[0;31m             X, y = self._validate_data(\n\u001b[0m\u001b[1;32m    193\u001b[0m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m                 \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    582\u001b[0m                 \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"y\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 584\u001b[0;31m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    585\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    586\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m   1120\u001b[0m     )\n\u001b[1;32m   1121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1122\u001b[0;31m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmulti_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_numeric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_numeric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1124\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_check_y\u001b[0;34m(y, multi_output, y_numeric, estimator)\u001b[0m\n\u001b[1;32m   1141\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1142\u001b[0m         \u001b[0mestimator_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_estimator_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1143\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwarn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1144\u001b[0m         \u001b[0m_assert_all_finite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"y\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mestimator_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mestimator_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1145\u001b[0m         \u001b[0m_ensure_no_complex_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcolumn_or_1d\u001b[0;34m(y, dtype, warn)\u001b[0m\n\u001b[1;32m   1200\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_asarray_with_order\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"C\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1202\u001b[0;31m     raise ValueError(\n\u001b[0m\u001b[1;32m   1203\u001b[0m         \u001b[0;34m\"y should be a 1d array, got an array of shape {} instead.\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1204\u001b[0m     )\n",
            "\u001b[0;31mValueError\u001b[0m: y should be a 1d array, got an array of shape (1853, 2) instead."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "import numpy as np\n",
        "\n",
        "# Assuming x_train_features, x_test_features, y_train, and y_test are available\n",
        "\n",
        "# Extract features from the hybrid model for training and test sets\n",
        "x_train_features = hybrid_model.predict([x_train_normalized, x_train_normalized])\n",
        "x_test_features = hybrid_model.predict([x_test_normalized, x_test_normalized])\n",
        "\n",
        "# Reshape features\n",
        "x_train_features = x_train_features.reshape(x_train_features.shape[0], -1)\n",
        "x_test_features = x_test_features.reshape(x_test_features.shape[0], -1)\n",
        "\n",
        "# Convert one-hot encoded labels to categorical\n",
        "y_train_single = np.argmax(y_train, axis=1)\n",
        "y_test_single = np.argmax(y_test, axis=1)\n",
        "\n",
        "# Define the best hyperparameters obtained from GridSearchCV\n",
        "best_params = {'C': 3, 'gamma': 'scale'}  # Replace these values with the best parameters found\n",
        "\n",
        "# Train SVM model with the best hyperparameters\n",
        "svm_model = SVC(kernel='rbf', C=best_params['C'], gamma=best_params['gamma'])\n",
        "svm_model.fit(x_train_features, y_train_single)\n",
        "\n",
        "# Predict on the test set using the trained SVM model\n",
        "y_pred_svm = svm_model.predict(x_test_features)\n",
        "\n",
        "# Calculate evaluation metrics\n",
        "svm_accuracy = accuracy_score(y_test_single, y_pred_svm)\n",
        "svm_precision = precision_score(y_test_single, y_pred_svm)\n",
        "svm_recall = recall_score(y_test_single, y_pred_svm)\n",
        "svm_f1 = f1_score(y_test_single, y_pred_svm)\n",
        "\n",
        "# Calculate specificity\n",
        "tn, fp, fn, tp = confusion_matrix(y_test_single, y_pred_svm).ravel()\n",
        "svm_specificity = tn / (tn + fp)\n",
        "\n",
        "# Print evaluation metrics\n",
        "print(\"SVM Accuracy:\", svm_accuracy)\n",
        "print(\"SVM Precision:\", svm_precision)\n",
        "print(\"SVM Sensitivity (Recall):\", svm_recall)\n",
        "print(\"SVM Specificity:\", svm_specificity)\n",
        "print(\"SVM F1 Score:\", svm_f1)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        },
        "id": "xVCnIXSOzqV2",
        "outputId": "5453c96e-eb57-4f6f-e28b-8621f16721ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-dc42b51ce879>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Extract features from the hybrid model for training and test sets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mx_train_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhybrid_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx_train_normalized\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_train_normalized\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mx_test_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhybrid_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx_test_normalized\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test_normalized\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'hybrid_model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "\n",
        "# Assuming you have your hybrid model already trained and stored in hybrid_model\n",
        "\n",
        "# Extract features from the hybrid model for training, validation, and test sets\n",
        "x_train_features = hybrid_model.predict([x_train_normalized, x_train_normalized])\n",
        "x_val_features = hybrid_model.predict([x_val_normalized, x_val_normalized])\n",
        "x_test_features = hybrid_model.predict([x_test_normalized, x_test_normalized])\n",
        "\n",
        "# Assuming y_train, y_val, and y_test contain the corresponding labels for training, validation, and test sets\n",
        "\n",
        "# Reshape the features if necessary\n",
        "x_train_features = x_train_features.reshape(x_train_features.shape[0], -1)\n",
        "x_val_features = x_val_features.reshape(x_val_features.shape[0], -1)\n",
        "x_test_features = x_test_features.reshape(x_test_features.shape[0], -1)\n",
        "\n",
        "# Train SVM model with the best hyperparameters obtained from GridSearchCV\n",
        "best_params = {'C': 3, 'gamma': 'scale'}  # Replace these values with the best parameters found\n",
        "\n",
        "svm_model = SVC(kernel='rbf', C=best_params['C'], gamma=best_params['gamma'])\n",
        "svm_model.fit(x_train_features, y_train)\n",
        "\n",
        "# Predict on the test set using the trained SVM model\n",
        "y_pred_svm = svm_model.predict(x_test_features)\n",
        "\n",
        "# Calculate evaluation metrics\n",
        "svm_accuracy = accuracy_score(y_test, y_pred_svm)\n",
        "svm_precision = precision_score(y_test, y_pred_svm)\n",
        "svm_recall = recall_score(y_test, y_pred_svm)\n",
        "svm_f1 = f1_score(y_test, y_pred_svm)\n",
        "\n",
        "# Calculate specificity\n",
        "tn, fp, fn, tp = confusion_matrix(y_test, y_pred_svm).ravel()\n",
        "svm_specificity = tn / (tn + fp)\n",
        "\n",
        "# Print evaluation metrics\n",
        "print(\"SVM Accuracy:\", svm_accuracy)\n",
        "print(\"SVM Precision:\", svm_precision)\n",
        "print(\"SVM Sensitivity (Recall):\", svm_recall)\n",
        "print(\"SVM Specificity:\", svm_specificity)\n",
        "print(\"SVM F1 Score:\", svm_f1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 464
        },
        "id": "JmLWGWEpzUgg",
        "outputId": "b9e0189b-a974-4d44-bf25-66904b898b52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "73/73 [==============================] - 4s 51ms/step\n",
            "11/11 [==============================] - 1s 49ms/step\n",
            "21/21 [==============================] - 1s 50ms/step\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-114-bbf240b8a409>\u001b[0m in \u001b[0;36m<cell line: 22>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0msvm_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSVC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'rbf'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbest_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'C'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbest_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'gamma'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0msvm_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;31m# Predict on the test set using the trained SVM model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    190\u001b[0m             \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 192\u001b[0;31m             X, y = self._validate_data(\n\u001b[0m\u001b[1;32m    193\u001b[0m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m                 \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    582\u001b[0m                 \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"y\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 584\u001b[0;31m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    585\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    586\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m   1120\u001b[0m     )\n\u001b[1;32m   1121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1122\u001b[0;31m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmulti_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_numeric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_numeric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1124\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_check_y\u001b[0;34m(y, multi_output, y_numeric, estimator)\u001b[0m\n\u001b[1;32m   1141\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1142\u001b[0m         \u001b[0mestimator_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_estimator_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1143\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwarn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1144\u001b[0m         \u001b[0m_assert_all_finite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"y\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mestimator_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mestimator_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1145\u001b[0m         \u001b[0m_ensure_no_complex_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcolumn_or_1d\u001b[0;34m(y, dtype, warn)\u001b[0m\n\u001b[1;32m   1200\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_asarray_with_order\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"C\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1202\u001b[0;31m     raise ValueError(\n\u001b[0m\u001b[1;32m   1203\u001b[0m         \u001b[0;34m\"y should be a 1d array, got an array of shape {} instead.\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1204\u001b[0m     )\n",
            "\u001b[0;31mValueError\u001b[0m: y should be a 1d array, got an array of shape (1853, 2) instead."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Input, Conv2D, BatchNormalization, ReLU, GlobalAveragePooling2D, Dense, Concatenate, MaxPooling2D\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "# Basic Convolution Block with BatchNormalization and ReLU\n",
        "def conv_block(input_tensor, filters, kernel_size, strides=(1, 1)):\n",
        "    x = Conv2D(filters, kernel_size, strides=strides, padding='same')(input_tensor)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = ReLU()(x)\n",
        "    return x\n",
        "\n",
        "# VGG16-like architecture (simplified)\n",
        "def VGG16Custom(input_shape):\n",
        "    input_tensor = Input(shape=input_shape)\n",
        "\n",
        "    # Convolution Block\n",
        "    x = conv_block(input_tensor, 64, (3, 3))\n",
        "    x = conv_block(x, 64, (3, 3))\n",
        "    x = MaxPooling2D((2, 2))(x)\n",
        "\n",
        "    x = conv_block(x, 128, (3, 3))\n",
        "    x = conv_block(x, 128, (3, 3))\n",
        "    x = MaxPooling2D((2, 2))(x)\n",
        "\n",
        "    x = conv_block(x, 256, (3, 3))\n",
        "    x = conv_block(x, 256, (3, 3))\n",
        "    x = conv_block(x, 256, (3, 3))\n",
        "    x = MaxPooling2D((2, 2))(x)\n",
        "\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    return Model(inputs=input_tensor, outputs=x)\n",
        "\n",
        "# ResNet50-like architecture (simplified)\n",
        "def ResNet50Custom(input_shape):\n",
        "    input_tensor = Input(shape=input_shape)\n",
        "\n",
        "    # Convolution Block\n",
        "    x = conv_block(input_tensor, 64, (7, 7), strides=(2, 2))\n",
        "    x = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n",
        "\n",
        "    x = residual_block(x, 256)\n",
        "    x = residual_block(x, 256)\n",
        "    x = residual_block(x, 256)\n",
        "\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    return Model(inputs=input_tensor, outputs=x)\n",
        "\n",
        "# Define the residual block used in ResNet50\n",
        "def residual_block(input_tensor, filters, kernel_size=(3, 3), strides=(1, 1)):\n",
        "    shortcut = input_tensor\n",
        "    x = conv_block(input_tensor, filters, kernel_size, strides)\n",
        "    x = conv_block(x, filters, kernel_size)\n",
        "    shortcut = Conv2D(filters, (1, 1), strides=strides, padding='same')(shortcut)\n",
        "    x = Add()([x, shortcut])\n",
        "    x = ReLU()(x)\n",
        "    return x\n",
        "\n",
        "# Input shape and number of classes\n",
        "input_shape = (100, 100, 3)\n",
        "num_classes = 2\n",
        "\n",
        "# Build VGG16-like and ResNet50-like models\n",
        "vgg16_model = VGG16Custom(input_shape)\n",
        "resnet50_model = ResNet50Custom(input_shape)\n",
        "\n",
        "# Get the output tensors from both models\n",
        "vgg16_output = vgg16_model.output\n",
        "resnet50_output = resnet50_model.output\n",
        "\n",
        "# Concatenate the outputs\n",
        "merged_output = Concatenate()([vgg16_output, resnet50_output])\n",
        "\n",
        "# Add more layers for classification\n",
        "x = Dense(256, activation='relu')(merged_output)\n",
        "x = Dense(128, activation='relu')(x)\n",
        "predictions = Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "# Create the hybrid model\n",
        "hybrid_model = Model(inputs=[vgg16_model.input, resnet50_model.input], outputs=predictions)\n",
        "\n",
        "# Compile the hybrid model\n",
        "hybrid_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Display the summary of the hybrid model\n",
        "hybrid_model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z69SxBLy081Q",
        "outputId": "47b37751-c657-48ea-a663-938ae7c79339"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_5\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_4 (InputLayer)        [(None, 100, 100, 3)]        0         []                            \n",
            "                                                                                                  \n",
            " conv2d_24 (Conv2D)          (None, 50, 50, 64)           9472      ['input_4[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_21 (Ba  (None, 50, 50, 64)           256       ['conv2d_24[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " re_lu_24 (ReLU)             (None, 50, 50, 64)           0         ['batch_normalization_21[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " input_3 (InputLayer)        [(None, 100, 100, 3)]        0         []                            \n",
            "                                                                                                  \n",
            " max_pooling2d_7 (MaxPoolin  (None, 25, 25, 64)           0         ['re_lu_24[0][0]']            \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv2d_17 (Conv2D)          (None, 100, 100, 64)         1792      ['input_3[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_25 (Conv2D)          (None, 25, 25, 256)          147712    ['max_pooling2d_7[0][0]']     \n",
            "                                                                                                  \n",
            " batch_normalization_14 (Ba  (None, 100, 100, 64)         256       ['conv2d_17[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_22 (Ba  (None, 25, 25, 256)          1024      ['conv2d_25[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " re_lu_17 (ReLU)             (None, 100, 100, 64)         0         ['batch_normalization_14[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " re_lu_25 (ReLU)             (None, 25, 25, 256)          0         ['batch_normalization_22[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_18 (Conv2D)          (None, 100, 100, 64)         36928     ['re_lu_17[0][0]']            \n",
            "                                                                                                  \n",
            " conv2d_26 (Conv2D)          (None, 25, 25, 256)          590080    ['re_lu_25[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_15 (Ba  (None, 100, 100, 64)         256       ['conv2d_18[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_23 (Ba  (None, 25, 25, 256)          1024      ['conv2d_26[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " re_lu_18 (ReLU)             (None, 100, 100, 64)         0         ['batch_normalization_15[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " re_lu_26 (ReLU)             (None, 25, 25, 256)          0         ['batch_normalization_23[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_27 (Conv2D)          (None, 25, 25, 256)          16640     ['max_pooling2d_7[0][0]']     \n",
            "                                                                                                  \n",
            " max_pooling2d_4 (MaxPoolin  (None, 50, 50, 64)           0         ['re_lu_18[0][0]']            \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " add_3 (Add)                 (None, 25, 25, 256)          0         ['re_lu_26[0][0]',            \n",
            "                                                                     'conv2d_27[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_19 (Conv2D)          (None, 50, 50, 128)          73856     ['max_pooling2d_4[0][0]']     \n",
            "                                                                                                  \n",
            " re_lu_27 (ReLU)             (None, 25, 25, 256)          0         ['add_3[0][0]']               \n",
            "                                                                                                  \n",
            " batch_normalization_16 (Ba  (None, 50, 50, 128)          512       ['conv2d_19[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " conv2d_28 (Conv2D)          (None, 25, 25, 256)          590080    ['re_lu_27[0][0]']            \n",
            "                                                                                                  \n",
            " re_lu_19 (ReLU)             (None, 50, 50, 128)          0         ['batch_normalization_16[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " batch_normalization_24 (Ba  (None, 25, 25, 256)          1024      ['conv2d_28[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " conv2d_20 (Conv2D)          (None, 50, 50, 128)          147584    ['re_lu_19[0][0]']            \n",
            "                                                                                                  \n",
            " re_lu_28 (ReLU)             (None, 25, 25, 256)          0         ['batch_normalization_24[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " batch_normalization_17 (Ba  (None, 50, 50, 128)          512       ['conv2d_20[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " conv2d_29 (Conv2D)          (None, 25, 25, 256)          590080    ['re_lu_28[0][0]']            \n",
            "                                                                                                  \n",
            " re_lu_20 (ReLU)             (None, 50, 50, 128)          0         ['batch_normalization_17[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " batch_normalization_25 (Ba  (None, 25, 25, 256)          1024      ['conv2d_29[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " max_pooling2d_5 (MaxPoolin  (None, 25, 25, 128)          0         ['re_lu_20[0][0]']            \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " re_lu_29 (ReLU)             (None, 25, 25, 256)          0         ['batch_normalization_25[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_30 (Conv2D)          (None, 25, 25, 256)          65792     ['re_lu_27[0][0]']            \n",
            "                                                                                                  \n",
            " conv2d_21 (Conv2D)          (None, 25, 25, 256)          295168    ['max_pooling2d_5[0][0]']     \n",
            "                                                                                                  \n",
            " add_4 (Add)                 (None, 25, 25, 256)          0         ['re_lu_29[0][0]',            \n",
            "                                                                     'conv2d_30[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_18 (Ba  (None, 25, 25, 256)          1024      ['conv2d_21[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " re_lu_30 (ReLU)             (None, 25, 25, 256)          0         ['add_4[0][0]']               \n",
            "                                                                                                  \n",
            " re_lu_21 (ReLU)             (None, 25, 25, 256)          0         ['batch_normalization_18[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_31 (Conv2D)          (None, 25, 25, 256)          590080    ['re_lu_30[0][0]']            \n",
            "                                                                                                  \n",
            " conv2d_22 (Conv2D)          (None, 25, 25, 256)          590080    ['re_lu_21[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_26 (Ba  (None, 25, 25, 256)          1024      ['conv2d_31[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_19 (Ba  (None, 25, 25, 256)          1024      ['conv2d_22[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " re_lu_31 (ReLU)             (None, 25, 25, 256)          0         ['batch_normalization_26[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " re_lu_22 (ReLU)             (None, 25, 25, 256)          0         ['batch_normalization_19[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_32 (Conv2D)          (None, 25, 25, 256)          590080    ['re_lu_31[0][0]']            \n",
            "                                                                                                  \n",
            " conv2d_23 (Conv2D)          (None, 25, 25, 256)          590080    ['re_lu_22[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_27 (Ba  (None, 25, 25, 256)          1024      ['conv2d_32[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_20 (Ba  (None, 25, 25, 256)          1024      ['conv2d_23[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " re_lu_32 (ReLU)             (None, 25, 25, 256)          0         ['batch_normalization_27[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_33 (Conv2D)          (None, 25, 25, 256)          65792     ['re_lu_30[0][0]']            \n",
            "                                                                                                  \n",
            " re_lu_23 (ReLU)             (None, 25, 25, 256)          0         ['batch_normalization_20[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " add_5 (Add)                 (None, 25, 25, 256)          0         ['re_lu_32[0][0]',            \n",
            "                                                                     'conv2d_33[0][0]']           \n",
            "                                                                                                  \n",
            " max_pooling2d_6 (MaxPoolin  (None, 12, 12, 256)          0         ['re_lu_23[0][0]']            \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " re_lu_33 (ReLU)             (None, 25, 25, 256)          0         ['add_5[0][0]']               \n",
            "                                                                                                  \n",
            " global_average_pooling2d_2  (None, 256)                  0         ['max_pooling2d_6[0][0]']     \n",
            "  (GlobalAveragePooling2D)                                                                        \n",
            "                                                                                                  \n",
            " global_average_pooling2d_3  (None, 256)                  0         ['re_lu_33[0][0]']            \n",
            "  (GlobalAveragePooling2D)                                                                        \n",
            "                                                                                                  \n",
            " concatenate_1 (Concatenate  (None, 512)                  0         ['global_average_pooling2d_2[0\n",
            " )                                                                  ][0]',                        \n",
            "                                                                     'global_average_pooling2d_3[0\n",
            "                                                                    ][0]']                        \n",
            "                                                                                                  \n",
            " dense_3 (Dense)             (None, 256)                  131328    ['concatenate_1[0][0]']       \n",
            "                                                                                                  \n",
            " dense_4 (Dense)             (None, 128)                  32896     ['dense_3[0][0]']             \n",
            "                                                                                                  \n",
            " dense_5 (Dense)             (None, 2)                    258       ['dense_4[0][0]']             \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 5166786 (19.71 MB)\n",
            "Trainable params: 5161282 (19.69 MB)\n",
            "Non-trainable params: 5504 (21.50 KB)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "\n",
        "# Set the learning rate\n",
        "learning_rate = 0.00001\n",
        "\n",
        "# Compile the model with the specified learning rate\n",
        "hybrid_model.compile(optimizer=Adam(learning_rate=learning_rate),\n",
        "                     loss='categorical_crossentropy',\n",
        "                     metrics=['accuracy'])\n",
        "\n",
        "# Train the hybrid model\n",
        "history = hybrid_model.fit(\n",
        "    [x_train_normalized, x_train_normalized],  # Replace with your training data\n",
        "    y_train_encoded,  # Replace with your training labels\n",
        "    epochs=55,\n",
        "    batch_size=batch_size,\n",
        "    validation_data=([x_val_normalized, x_val_normalized], y_val_encoded),  # Replace with your validation data\n",
        "    shuffle=True,\n",
        "    verbose=1,\n",
        "\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HIeDWT5d1J-b",
        "outputId": "c9591f02-a2ac-4219-ddd2-e6937d00e601"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/55\n",
            "37/37 [==============================] - 53s 377ms/step - loss: 0.4626 - accuracy: 0.7730 - val_loss: 0.6914 - val_accuracy: 0.5166\n",
            "Epoch 2/55\n",
            "37/37 [==============================] - 11s 307ms/step - loss: 0.3730 - accuracy: 0.8174 - val_loss: 0.7053 - val_accuracy: 0.5166\n",
            "Epoch 3/55\n",
            "37/37 [==============================] - 11s 308ms/step - loss: 0.3519 - accuracy: 0.8308 - val_loss: 0.7450 - val_accuracy: 0.5166\n",
            "Epoch 4/55\n",
            "37/37 [==============================] - 12s 312ms/step - loss: 0.3445 - accuracy: 0.8347 - val_loss: 0.8169 - val_accuracy: 0.5166\n",
            "Epoch 5/55\n",
            "37/37 [==============================] - 12s 318ms/step - loss: 0.3360 - accuracy: 0.8347 - val_loss: 0.8560 - val_accuracy: 0.5166\n",
            "Epoch 6/55\n",
            "37/37 [==============================] - 12s 318ms/step - loss: 0.3273 - accuracy: 0.8377 - val_loss: 0.9565 - val_accuracy: 0.5166\n",
            "Epoch 7/55\n",
            "37/37 [==============================] - 12s 326ms/step - loss: 0.3181 - accuracy: 0.8464 - val_loss: 1.0227 - val_accuracy: 0.5166\n",
            "Epoch 8/55\n",
            "37/37 [==============================] - 12s 326ms/step - loss: 0.3085 - accuracy: 0.8541 - val_loss: 1.1294 - val_accuracy: 0.5166\n",
            "Epoch 9/55\n",
            "37/37 [==============================] - 12s 324ms/step - loss: 0.3000 - accuracy: 0.8615 - val_loss: 1.1675 - val_accuracy: 0.5166\n",
            "Epoch 10/55\n",
            "37/37 [==============================] - 12s 326ms/step - loss: 0.2964 - accuracy: 0.8602 - val_loss: 1.2008 - val_accuracy: 0.5166\n",
            "Epoch 11/55\n",
            "37/37 [==============================] - 12s 329ms/step - loss: 0.2918 - accuracy: 0.8602 - val_loss: 0.9975 - val_accuracy: 0.5196\n",
            "Epoch 12/55\n",
            "37/37 [==============================] - 12s 330ms/step - loss: 0.2891 - accuracy: 0.8649 - val_loss: 0.9955 - val_accuracy: 0.5347\n",
            "Epoch 13/55\n",
            "37/37 [==============================] - 12s 325ms/step - loss: 0.2856 - accuracy: 0.8658 - val_loss: 0.8774 - val_accuracy: 0.5559\n",
            "Epoch 14/55\n",
            "37/37 [==============================] - 12s 330ms/step - loss: 0.2829 - accuracy: 0.8653 - val_loss: 0.7038 - val_accuracy: 0.6073\n",
            "Epoch 15/55\n",
            "37/37 [==============================] - 12s 329ms/step - loss: 0.2693 - accuracy: 0.8744 - val_loss: 0.5366 - val_accuracy: 0.7190\n",
            "Epoch 16/55\n",
            "37/37 [==============================] - 12s 330ms/step - loss: 0.2642 - accuracy: 0.8735 - val_loss: 0.3912 - val_accuracy: 0.8006\n",
            "Epoch 17/55\n",
            "37/37 [==============================] - 12s 333ms/step - loss: 0.2548 - accuracy: 0.8869 - val_loss: 0.4646 - val_accuracy: 0.7523\n",
            "Epoch 18/55\n",
            "37/37 [==============================] - 12s 336ms/step - loss: 0.2577 - accuracy: 0.8830 - val_loss: 0.3093 - val_accuracy: 0.8610\n",
            "Epoch 19/55\n",
            "37/37 [==============================] - 12s 337ms/step - loss: 0.2575 - accuracy: 0.8766 - val_loss: 0.2604 - val_accuracy: 0.8882\n",
            "Epoch 20/55\n",
            "37/37 [==============================] - 12s 333ms/step - loss: 0.2446 - accuracy: 0.8908 - val_loss: 0.2952 - val_accuracy: 0.8580\n",
            "Epoch 21/55\n",
            "37/37 [==============================] - 12s 337ms/step - loss: 0.2369 - accuracy: 0.8930 - val_loss: 0.2988 - val_accuracy: 0.8731\n",
            "Epoch 22/55\n",
            "37/37 [==============================] - 12s 336ms/step - loss: 0.2365 - accuracy: 0.8947 - val_loss: 0.2941 - val_accuracy: 0.8610\n",
            "Epoch 23/55\n",
            "37/37 [==============================] - 12s 338ms/step - loss: 0.2321 - accuracy: 0.8977 - val_loss: 0.2440 - val_accuracy: 0.9063\n",
            "Epoch 24/55\n",
            "37/37 [==============================] - 13s 341ms/step - loss: 0.2384 - accuracy: 0.8899 - val_loss: 0.2524 - val_accuracy: 0.8943\n",
            "Epoch 25/55\n",
            "37/37 [==============================] - 13s 342ms/step - loss: 0.2257 - accuracy: 0.9050 - val_loss: 0.2688 - val_accuracy: 0.8912\n",
            "Epoch 26/55\n",
            "37/37 [==============================] - 13s 348ms/step - loss: 0.2161 - accuracy: 0.9068 - val_loss: 0.2301 - val_accuracy: 0.9033\n",
            "Epoch 27/55\n",
            "37/37 [==============================] - 13s 346ms/step - loss: 0.2155 - accuracy: 0.9012 - val_loss: 0.2830 - val_accuracy: 0.8761\n",
            "Epoch 28/55\n",
            "37/37 [==============================] - 13s 345ms/step - loss: 0.2224 - accuracy: 0.9016 - val_loss: 0.2386 - val_accuracy: 0.9094\n",
            "Epoch 29/55\n",
            "37/37 [==============================] - 13s 345ms/step - loss: 0.2064 - accuracy: 0.9072 - val_loss: 0.2259 - val_accuracy: 0.9094\n",
            "Epoch 30/55\n",
            "37/37 [==============================] - 13s 346ms/step - loss: 0.2109 - accuracy: 0.9059 - val_loss: 0.2561 - val_accuracy: 0.9033\n",
            "Epoch 31/55\n",
            "37/37 [==============================] - 13s 347ms/step - loss: 0.2031 - accuracy: 0.9115 - val_loss: 0.2372 - val_accuracy: 0.9154\n",
            "Epoch 32/55\n",
            "37/37 [==============================] - 13s 345ms/step - loss: 0.1906 - accuracy: 0.9163 - val_loss: 0.2384 - val_accuracy: 0.9124\n",
            "Epoch 33/55\n",
            "37/37 [==============================] - 13s 345ms/step - loss: 0.1870 - accuracy: 0.9184 - val_loss: 0.2257 - val_accuracy: 0.9094\n",
            "Epoch 34/55\n",
            "37/37 [==============================] - 13s 348ms/step - loss: 0.1881 - accuracy: 0.9219 - val_loss: 0.2431 - val_accuracy: 0.8731\n",
            "Epoch 35/55\n",
            "37/37 [==============================] - 13s 349ms/step - loss: 0.1855 - accuracy: 0.9227 - val_loss: 0.2317 - val_accuracy: 0.9124\n",
            "Epoch 36/55\n",
            "37/37 [==============================] - 13s 351ms/step - loss: 0.1695 - accuracy: 0.9305 - val_loss: 0.2525 - val_accuracy: 0.8973\n",
            "Epoch 37/55\n",
            "37/37 [==============================] - 13s 346ms/step - loss: 0.1784 - accuracy: 0.9215 - val_loss: 0.2472 - val_accuracy: 0.8822\n",
            "Epoch 38/55\n",
            "37/37 [==============================] - 13s 346ms/step - loss: 0.1746 - accuracy: 0.9227 - val_loss: 0.2533 - val_accuracy: 0.8761\n",
            "Epoch 39/55\n",
            "37/37 [==============================] - 13s 349ms/step - loss: 0.1781 - accuracy: 0.9202 - val_loss: 0.3000 - val_accuracy: 0.8671\n",
            "Epoch 40/55\n",
            "37/37 [==============================] - 13s 349ms/step - loss: 0.1729 - accuracy: 0.9327 - val_loss: 0.2307 - val_accuracy: 0.9063\n",
            "Epoch 41/55\n",
            "37/37 [==============================] - 13s 347ms/step - loss: 0.1729 - accuracy: 0.9318 - val_loss: 0.2288 - val_accuracy: 0.9063\n",
            "Epoch 42/55\n",
            "37/37 [==============================] - 13s 350ms/step - loss: 0.1554 - accuracy: 0.9340 - val_loss: 0.2335 - val_accuracy: 0.8973\n",
            "Epoch 43/55\n",
            "37/37 [==============================] - 13s 347ms/step - loss: 0.1553 - accuracy: 0.9422 - val_loss: 0.2547 - val_accuracy: 0.9094\n",
            "Epoch 44/55\n",
            "37/37 [==============================] - 13s 349ms/step - loss: 0.1554 - accuracy: 0.9340 - val_loss: 0.2685 - val_accuracy: 0.9033\n",
            "Epoch 45/55\n",
            "37/37 [==============================] - 13s 350ms/step - loss: 0.1425 - accuracy: 0.9422 - val_loss: 0.2422 - val_accuracy: 0.9063\n",
            "Epoch 46/55\n",
            "37/37 [==============================] - 13s 347ms/step - loss: 0.1404 - accuracy: 0.9443 - val_loss: 0.2945 - val_accuracy: 0.8882\n",
            "Epoch 47/55\n",
            "37/37 [==============================] - 13s 347ms/step - loss: 0.1467 - accuracy: 0.9366 - val_loss: 0.2681 - val_accuracy: 0.8822\n",
            "Epoch 48/55\n",
            "37/37 [==============================] - 13s 350ms/step - loss: 0.1389 - accuracy: 0.9499 - val_loss: 0.3239 - val_accuracy: 0.8640\n",
            "Epoch 49/55\n",
            "37/37 [==============================] - 13s 351ms/step - loss: 0.1287 - accuracy: 0.9486 - val_loss: 0.2567 - val_accuracy: 0.8912\n",
            "Epoch 50/55\n",
            "37/37 [==============================] - 13s 350ms/step - loss: 0.1418 - accuracy: 0.9443 - val_loss: 0.2895 - val_accuracy: 0.8761\n",
            "Epoch 51/55\n",
            "37/37 [==============================] - 13s 350ms/step - loss: 0.1263 - accuracy: 0.9525 - val_loss: 0.2315 - val_accuracy: 0.9003\n",
            "Epoch 52/55\n",
            "37/37 [==============================] - 13s 351ms/step - loss: 0.1353 - accuracy: 0.9478 - val_loss: 0.3130 - val_accuracy: 0.8671\n",
            "Epoch 53/55\n",
            "37/37 [==============================] - 13s 351ms/step - loss: 0.1323 - accuracy: 0.9491 - val_loss: 0.2424 - val_accuracy: 0.9033\n",
            "Epoch 54/55\n",
            "37/37 [==============================] - 13s 350ms/step - loss: 0.1257 - accuracy: 0.9461 - val_loss: 0.2410 - val_accuracy: 0.8852\n",
            "Epoch 55/55\n",
            "37/37 [==============================] - 13s 346ms/step - loss: 0.1188 - accuracy: 0.9564 - val_loss: 0.2788 - val_accuracy: 0.8943\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on the test data\n",
        "test_loss, test_accuracy = hybrid_model.evaluate([x_test_normalized, x_test_normalized], y_test_encoded)\n",
        "\n",
        "print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")\n",
        "print(f\"Test Loss: {test_loss}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a_KiL1Sv4JqU",
        "outputId": "8a1d9079-e0d3-4910-e71d-7b40383304cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "21/21 [==============================] - 4s 94ms/step - loss: 0.2960 - accuracy: 0.8733\n",
            "Test Accuracy: 87.33%\n",
            "Test Loss: 0.2960246503353119\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Assuming you have your hybrid model already trained and stored in hybrid_model_regularized\n",
        "\n",
        "# Extract features from the hybrid model for training, validation, and test sets\n",
        "x_train_features = hybrid_model.predict([x_train_normalized, x_train_normalized])\n",
        "x_val_features = hybrid_model.predict([x_val_normalized, x_val_normalized])\n",
        "x_test_features = hybrid_model.predict([x_test_normalized, x_test_normalized])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZVrKxgpH4N7R",
        "outputId": "7e4d1601-0b21-4a78-9943-d54673ea8815"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "73/73 [==============================] - 4s 52ms/step\n",
            "11/11 [==============================] - 1s 53ms/step\n",
            "21/21 [==============================] - 1s 55ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_features = x_train_features.reshape(x_train_features.shape[0], -1)\n",
        "x_val_features = x_val_features.reshape(x_val_features.shape[0], -1)\n",
        "x_test_features = x_test_features.reshape(x_test_features.shape[0], -1)"
      ],
      "metadata": {
        "id": "ZiPs70e-4mAC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "from keras import utils as np_utils\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import keras\n",
        "\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "import numpy as np\n",
        "\n",
        "# Assuming x_train_features, x_test_features, y_train, and y_test are available\n",
        "\n",
        "# Extract features from the hybrid model for training and test sets\n",
        "x_train_features = hybrid_model.predict([x_train_normalized, x_train_normalized])\n",
        "x_test_features = hybrid_model.predict([x_test_normalized, x_test_normalized])\n",
        "\n",
        "# Reshape features\n",
        "x_train_features = x_train_features.reshape(x_train_features.shape[0], -1)\n",
        "x_test_features = x_test_features.reshape(x_test_features.shape[0], -1)\n",
        "\n",
        "# Assuming y_train is a 1D array of labels\n",
        "# Convert it to a one-hot encoded matrix\n",
        "num_classes = 2  # Replace this with the actual number of classes\n",
        "y_train_one_hot = keras.utils.to_categorical(y_train, num_classes=num_classes)\n",
        "\n",
        "# Now y_train_one_hot should be a 2D array\n",
        "y_train_single = np.argmax(y_train_one_hot, axis=1)\n",
        "\n",
        "# Convert one-hot encoded labels to categorical\n",
        "y_train_single = np.argmax(y_train, axis=1)\n",
        "y_test_single = np.argmax(y_test, axis=1)\n",
        "\n",
        "# Define the best hyperparameters obtained from GridSearchCV\n",
        "best_params = {'C': 3, 'gamma': 'scale'}  # Replace these values with the best parameters found\n",
        "\n",
        "# Train SVM model with the best hyperparameters\n",
        "svm_model = SVC(kernel='rbf', C=best_params['C'], gamma=best_params['gamma'])\n",
        "svm_model.fit(x_train_features, y_train_single)\n",
        "\n",
        "# Predict on the test set using the trained SVM model\n",
        "y_pred_svm = svm_model.predict(x_test_features)\n",
        "\n",
        "# Calculate evaluation metrics\n",
        "svm_accuracy = accuracy_score(y_test_single, y_pred_svm)\n",
        "svm_precision = precision_score(y_test_single, y_pred_svm)\n",
        "svm_recall = recall_score(y_test_single, y_pred_svm)\n",
        "svm_f1 = f1_score(y_test_single, y_pred_svm)\n",
        "\n",
        "# Calculate specificity\n",
        "tn, fp, fn, tp = confusion_matrix(y_test_single, y_pred_svm).ravel()\n",
        "svm_specificity = tn / (tn + fp)\n",
        "\n",
        "# Print evaluation metrics\n",
        "print(\"SVM Accuracy:\", svm_accuracy)\n",
        "print(\"SVM Precision:\", svm_precision)\n",
        "print(\"SVM Sensitivity (Recall):\", svm_recall)\n",
        "print(\"SVM Specificity:\", svm_specificity)\n",
        "print(\"SVM F1 Score:\", svm_f1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 446
        },
        "id": "xmAsijYc4wZe",
        "outputId": "bb51a828-931a-4f50-fd43-f5c3b48679d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "73/73 [==============================] - 4s 50ms/step\n",
            "21/21 [==============================] - 1s 54ms/step\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AxisError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAxisError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-aa031599fe13>\u001b[0m in \u001b[0;36m<cell line: 28>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;31m# Convert one-hot encoded labels to categorical\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0my_train_single\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0my_test_single\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/core/overrides.py\u001b[0m in \u001b[0;36margmax\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36margmax\u001b[0;34m(a, axis, out, keepdims)\u001b[0m\n\u001b[1;32m   1214\u001b[0m     \"\"\"\n\u001b[1;32m   1215\u001b[0m     \u001b[0mkwds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'keepdims'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m}\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mkeepdims\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NoValue\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1216\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'argmax'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapfunc\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mbound\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;31m# A TypeError occurs if the object does have such a method in its\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAxisError\u001b[0m: axis 1 is out of bounds for array of dimension 1"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "\n",
        "# Set the learning rate\n",
        "learning_rate = 0.00001\n",
        "\n",
        "# Compile the model with the specified learning rate\n",
        "hybrid_model.compile(optimizer=Adam(learning_rate=learning_rate),\n",
        "                     loss='categorical_crossentropy',\n",
        "                     metrics=['accuracy'])\n",
        "\n",
        "# Train the hybrid model\n",
        "history = hybrid_model.fit(\n",
        "    [x_train_normalized, x_train_normalized],  # Replace with your training data\n",
        "    y_train_encoded,  # Replace with your training labels\n",
        "    epochs=55,\n",
        "    batch_size=batch_size,\n",
        "    validation_data=([x_val_normalized, x_val_normalized], y_val_encoded),  # Replace with your validation data\n",
        "    shuffle=True,\n",
        "    verbose=1,\n",
        "\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4hCFq_qZ7swS",
        "outputId": "1c3f2781-4e0f-45ed-c5b5-6f1b37ba2ac0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/55\n",
            "37/37 [==============================] - 27s 335ms/step - loss: 0.5069 - accuracy: 0.7303 - val_loss: 0.6942 - val_accuracy: 0.5166\n",
            "Epoch 2/55\n",
            "37/37 [==============================] - 12s 312ms/step - loss: 0.3826 - accuracy: 0.8105 - val_loss: 0.7105 - val_accuracy: 0.5166\n",
            "Epoch 3/55\n",
            "37/37 [==============================] - 12s 318ms/step - loss: 0.3642 - accuracy: 0.8209 - val_loss: 0.7512 - val_accuracy: 0.5166\n",
            "Epoch 4/55\n",
            "37/37 [==============================] - 12s 325ms/step - loss: 0.3483 - accuracy: 0.8239 - val_loss: 0.8175 - val_accuracy: 0.5166\n",
            "Epoch 5/55\n",
            "37/37 [==============================] - 12s 329ms/step - loss: 0.3378 - accuracy: 0.8317 - val_loss: 0.8912 - val_accuracy: 0.5166\n",
            "Epoch 6/55\n",
            "37/37 [==============================] - 12s 332ms/step - loss: 0.3344 - accuracy: 0.8369 - val_loss: 0.9958 - val_accuracy: 0.5166\n",
            "Epoch 7/55\n",
            "37/37 [==============================] - 13s 343ms/step - loss: 0.3204 - accuracy: 0.8442 - val_loss: 1.0671 - val_accuracy: 0.5166\n",
            "Epoch 8/55\n",
            "37/37 [==============================] - 13s 357ms/step - loss: 0.3166 - accuracy: 0.8502 - val_loss: 1.1499 - val_accuracy: 0.5166\n",
            "Epoch 9/55\n",
            "37/37 [==============================] - 13s 351ms/step - loss: 0.3156 - accuracy: 0.8485 - val_loss: 1.1160 - val_accuracy: 0.5166\n",
            "Epoch 10/55\n",
            "37/37 [==============================] - 13s 341ms/step - loss: 0.3075 - accuracy: 0.8558 - val_loss: 1.0821 - val_accuracy: 0.5166\n",
            "Epoch 11/55\n",
            "37/37 [==============================] - 12s 335ms/step - loss: 0.2948 - accuracy: 0.8567 - val_loss: 0.9612 - val_accuracy: 0.5257\n",
            "Epoch 12/55\n",
            "37/37 [==============================] - 12s 336ms/step - loss: 0.2922 - accuracy: 0.8619 - val_loss: 0.8905 - val_accuracy: 0.5498\n",
            "Epoch 13/55\n",
            "37/37 [==============================] - 13s 340ms/step - loss: 0.2818 - accuracy: 0.8692 - val_loss: 0.8267 - val_accuracy: 0.5740\n",
            "Epoch 14/55\n",
            "37/37 [==============================] - 13s 342ms/step - loss: 0.2747 - accuracy: 0.8705 - val_loss: 0.6734 - val_accuracy: 0.6405\n",
            "Epoch 15/55\n",
            "37/37 [==============================] - 13s 344ms/step - loss: 0.2673 - accuracy: 0.8792 - val_loss: 0.5738 - val_accuracy: 0.6677\n",
            "Epoch 16/55\n",
            "37/37 [==============================] - 13s 345ms/step - loss: 0.2652 - accuracy: 0.8757 - val_loss: 0.4958 - val_accuracy: 0.7311\n",
            "Epoch 17/55\n",
            "37/37 [==============================] - 13s 345ms/step - loss: 0.2535 - accuracy: 0.8861 - val_loss: 0.4703 - val_accuracy: 0.7553\n",
            "Epoch 18/55\n",
            "37/37 [==============================] - 13s 342ms/step - loss: 0.2582 - accuracy: 0.8830 - val_loss: 0.3019 - val_accuracy: 0.8610\n",
            "Epoch 19/55\n",
            "37/37 [==============================] - 13s 343ms/step - loss: 0.2501 - accuracy: 0.8930 - val_loss: 0.2843 - val_accuracy: 0.8671\n",
            "Epoch 20/55\n",
            "37/37 [==============================] - 13s 342ms/step - loss: 0.2443 - accuracy: 0.8874 - val_loss: 0.3252 - val_accuracy: 0.8550\n",
            "Epoch 21/55\n",
            "37/37 [==============================] - 13s 348ms/step - loss: 0.2427 - accuracy: 0.8908 - val_loss: 0.3033 - val_accuracy: 0.8550\n",
            "Epoch 22/55\n",
            "37/37 [==============================] - 13s 347ms/step - loss: 0.2351 - accuracy: 0.8947 - val_loss: 0.2614 - val_accuracy: 0.8912\n",
            "Epoch 23/55\n",
            "37/37 [==============================] - 13s 348ms/step - loss: 0.2335 - accuracy: 0.8934 - val_loss: 0.2571 - val_accuracy: 0.9033\n",
            "Epoch 24/55\n",
            "37/37 [==============================] - 13s 345ms/step - loss: 0.2320 - accuracy: 0.8999 - val_loss: 0.2399 - val_accuracy: 0.9124\n",
            "Epoch 25/55\n",
            "37/37 [==============================] - 13s 350ms/step - loss: 0.2209 - accuracy: 0.9046 - val_loss: 0.2544 - val_accuracy: 0.9124\n",
            "Epoch 26/55\n",
            "37/37 [==============================] - 13s 348ms/step - loss: 0.2193 - accuracy: 0.9063 - val_loss: 0.2536 - val_accuracy: 0.9003\n",
            "Epoch 27/55\n",
            "37/37 [==============================] - 13s 348ms/step - loss: 0.2139 - accuracy: 0.9003 - val_loss: 0.2643 - val_accuracy: 0.9003\n",
            "Epoch 28/55\n",
            "37/37 [==============================] - 13s 348ms/step - loss: 0.2042 - accuracy: 0.9167 - val_loss: 0.2462 - val_accuracy: 0.9033\n",
            "Epoch 29/55\n",
            "37/37 [==============================] - 13s 348ms/step - loss: 0.2058 - accuracy: 0.9107 - val_loss: 0.2708 - val_accuracy: 0.8822\n",
            "Epoch 30/55\n",
            "37/37 [==============================] - 13s 350ms/step - loss: 0.2009 - accuracy: 0.9227 - val_loss: 0.2431 - val_accuracy: 0.9184\n",
            "Epoch 31/55\n",
            "37/37 [==============================] - 13s 350ms/step - loss: 0.1941 - accuracy: 0.9189 - val_loss: 0.2425 - val_accuracy: 0.9215\n",
            "Epoch 32/55\n",
            "37/37 [==============================] - 13s 349ms/step - loss: 0.1987 - accuracy: 0.9145 - val_loss: 0.3116 - val_accuracy: 0.8731\n",
            "Epoch 33/55\n",
            "37/37 [==============================] - 13s 349ms/step - loss: 0.1950 - accuracy: 0.9154 - val_loss: 0.2652 - val_accuracy: 0.9033\n",
            "Epoch 34/55\n",
            "37/37 [==============================] - 13s 346ms/step - loss: 0.1831 - accuracy: 0.9249 - val_loss: 0.2475 - val_accuracy: 0.9003\n",
            "Epoch 35/55\n",
            "37/37 [==============================] - 13s 347ms/step - loss: 0.1735 - accuracy: 0.9301 - val_loss: 0.2631 - val_accuracy: 0.9063\n",
            "Epoch 36/55\n",
            "37/37 [==============================] - 13s 348ms/step - loss: 0.1824 - accuracy: 0.9227 - val_loss: 0.2458 - val_accuracy: 0.9154\n",
            "Epoch 37/55\n",
            "37/37 [==============================] - 13s 345ms/step - loss: 0.1768 - accuracy: 0.9223 - val_loss: 0.2374 - val_accuracy: 0.9124\n",
            "Epoch 38/55\n",
            "37/37 [==============================] - 13s 347ms/step - loss: 0.1661 - accuracy: 0.9297 - val_loss: 0.2400 - val_accuracy: 0.9063\n",
            "Epoch 39/55\n",
            "37/37 [==============================] - 13s 348ms/step - loss: 0.1718 - accuracy: 0.9288 - val_loss: 0.2524 - val_accuracy: 0.8973\n",
            "Epoch 40/55\n",
            "37/37 [==============================] - 13s 345ms/step - loss: 0.1618 - accuracy: 0.9396 - val_loss: 0.2707 - val_accuracy: 0.9003\n",
            "Epoch 41/55\n",
            "37/37 [==============================] - 13s 349ms/step - loss: 0.1613 - accuracy: 0.9353 - val_loss: 0.2442 - val_accuracy: 0.8973\n",
            "Epoch 42/55\n",
            "37/37 [==============================] - 13s 349ms/step - loss: 0.1725 - accuracy: 0.9240 - val_loss: 0.2575 - val_accuracy: 0.8912\n",
            "Epoch 43/55\n",
            "37/37 [==============================] - 13s 350ms/step - loss: 0.1509 - accuracy: 0.9448 - val_loss: 0.2619 - val_accuracy: 0.9063\n",
            "Epoch 44/55\n",
            "37/37 [==============================] - 13s 351ms/step - loss: 0.1430 - accuracy: 0.9443 - val_loss: 0.2493 - val_accuracy: 0.9003\n",
            "Epoch 45/55\n",
            "37/37 [==============================] - 13s 348ms/step - loss: 0.1506 - accuracy: 0.9409 - val_loss: 0.2521 - val_accuracy: 0.9063\n",
            "Epoch 46/55\n",
            "37/37 [==============================] - 13s 349ms/step - loss: 0.1488 - accuracy: 0.9430 - val_loss: 0.2434 - val_accuracy: 0.9154\n",
            "Epoch 47/55\n",
            "37/37 [==============================] - 13s 350ms/step - loss: 0.1346 - accuracy: 0.9521 - val_loss: 0.3182 - val_accuracy: 0.8640\n",
            "Epoch 48/55\n",
            "37/37 [==============================] - 13s 350ms/step - loss: 0.1327 - accuracy: 0.9486 - val_loss: 0.2940 - val_accuracy: 0.9033\n",
            "Epoch 49/55\n",
            "37/37 [==============================] - 13s 347ms/step - loss: 0.1362 - accuracy: 0.9461 - val_loss: 0.2331 - val_accuracy: 0.9094\n",
            "Epoch 50/55\n",
            "37/37 [==============================] - 13s 348ms/step - loss: 0.1337 - accuracy: 0.9439 - val_loss: 0.2308 - val_accuracy: 0.8973\n",
            "Epoch 51/55\n",
            "37/37 [==============================] - 13s 348ms/step - loss: 0.1283 - accuracy: 0.9517 - val_loss: 0.2767 - val_accuracy: 0.8822\n",
            "Epoch 52/55\n",
            "37/37 [==============================] - 13s 348ms/step - loss: 0.1283 - accuracy: 0.9512 - val_loss: 0.2426 - val_accuracy: 0.9003\n",
            "Epoch 53/55\n",
            "37/37 [==============================] - 13s 347ms/step - loss: 0.1260 - accuracy: 0.9538 - val_loss: 0.2216 - val_accuracy: 0.9124\n",
            "Epoch 54/55\n",
            "37/37 [==============================] - 13s 348ms/step - loss: 0.1344 - accuracy: 0.9387 - val_loss: 0.2392 - val_accuracy: 0.9063\n",
            "Epoch 55/55\n",
            "37/37 [==============================] - 13s 349ms/step - loss: 0.1111 - accuracy: 0.9560 - val_loss: 0.2469 - val_accuracy: 0.9094\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on the test data\n",
        "test_loss, test_accuracy = hybrid_model.evaluate([x_test_normalized, x_test_normalized], y_test_encoded)\n",
        "\n",
        "print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")\n",
        "print(f\"Test Loss: {test_loss}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T5fDgqP6-0LH",
        "outputId": "41b6962e-7581-43e9-f525-db3bb1322d25"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "21/21 [==============================] - 1s 62ms/step - loss: 0.2355 - accuracy: 0.9050\n",
            "Test Accuracy: 90.50%\n",
            "Test Loss: 0.2355358898639679\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract features from the hybrid model\n",
        "x_train_features = hybrid_model.predict([x_train_normalized, x_train_normalized])\n",
        "x_val_features = hybrid_model.predict([x_val_normalized, x_val_normalized])\n",
        "x_test_features = hybrid_model.predict([x_test_normalized, x_test_normalized])\n",
        "\n",
        "# Reshape the feature vectors if needed\n",
        "x_train_features = x_train_features.reshape(x_train_features.shape[0], -1)\n",
        "x_val_features = x_val_features.reshape(x_val_features.shape[0], -1)\n",
        "x_test_features = x_test_features.reshape(x_test_features.shape[0], -1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LXee7r-X7T57",
        "outputId": "7cd1b231-2646-4763-d176-f1b07d7791f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "73/73 [==============================] - 4s 57ms/step\n",
            "11/11 [==============================] - 1s 49ms/step\n",
            "21/21 [==============================] - 1s 51ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "\n",
        "# Define the best hyperparameters obtained from GridSearchCV\n",
        "best_params = {'C': 30, 'gamma': 'scale'}  # Replace these values with the best parameters found\n",
        "\n",
        "# Train SVM model with the best hyperparameters\n",
        "svm_model = SVC(kernel='rbf', C=best_params['C'], gamma=best_params['gamma'])\n",
        "svm_model.fit(x_train_features, y_train)\n",
        "\n",
        "# Predict on the test set using the trained SVM model\n",
        "y_pred_svm = svm_model.predict(x_test_features)\n",
        "\n",
        "# Calculate evaluation metrics\n",
        "svm_accuracy = accuracy_score(y_test, y_pred_svm)\n",
        "svm_precision = precision_score(y_test, y_pred_svm)\n",
        "svm_recall = recall_score(y_test, y_pred_svm)\n",
        "svm_f1 = f1_score(y_test, y_pred_svm)\n",
        "\n",
        "# Calculate specificity if needed\n",
        "tn, fp, fn, tp = confusion_matrix(y_test, y_pred_svm).ravel()\n",
        "svm_specificity = tn / (tn + fp)\n",
        "\n",
        "# Print evaluation metrics\n",
        "print(\"SVM Accuracy:\", svm_accuracy)\n",
        "print(\"SVM Precision:\", svm_precision)\n",
        "print(\"SVM Sensitivity (Recall):\", svm_recall)\n",
        "print(\"SVM Specificity:\", svm_specificity)\n",
        "print(\"SVM F1 Score:\", svm_f1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7UY6ekJC7WZ1",
        "outputId": "c66694fc-a5bc-4a2b-ea0f-414df1763bf3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVM Accuracy: 0.9004524886877828\n",
            "SVM Precision: 0.8869047619047619\n",
            "SVM Sensitivity (Recall): 0.9141104294478528\n",
            "SVM Specificity: 0.887240356083086\n",
            "SVM F1 Score: 0.9003021148036254\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "\n",
        "\n",
        "# Define the regularization parameter\n",
        "regularization_param = 0.1  # Adjust this value as needed\n",
        "\n",
        "# Train SVM model with regularization\n",
        "svm_model_reg = SVC(kernel='sigmoid', C=regularization_param, gamma='scale')\n",
        "svm_model_reg.fit(x_train_features, y_train)\n",
        "\n",
        "# Predict on the test set using the trained SVM model with regularization\n",
        "y_pred_svm_reg = svm_model_reg.predict(x_test_features)\n",
        "\n",
        "# Calculate evaluation metrics for the regularized SVM model\n",
        "svm_accuracy_reg = accuracy_score(y_test, y_pred_svm_reg)\n",
        "svm_precision_reg = precision_score(y_test, y_pred_svm_reg)\n",
        "svm_recall_reg = recall_score(y_test, y_pred_svm_reg)\n",
        "svm_f1_reg = f1_score(y_test, y_pred_svm_reg)\n",
        "\n",
        "# Calculate specificity for the regularized SVM model\n",
        "tn_reg, fp_reg, fn_reg, tp_reg = confusion_matrix(y_test, y_pred_svm_reg).ravel()\n",
        "svm_specificity_reg = tn_reg / (tn_reg + fp_reg)\n",
        "\n",
        "# Print evaluation metrics for the regularized SVM model\n",
        "print(\"Regularized SVM Accuracy:\", svm_accuracy_reg)\n",
        "print(\"Regularized SVM Precision:\", svm_precision_reg)\n",
        "print(\"Regularized SVM Sensitivity (Recall):\", svm_recall_reg)\n",
        "print(\"Regularized SVM Specificity:\", svm_specificity_reg)\n",
        "print(\"Regularized SVM F1 Score:\", svm_f1_reg)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dnXImNjZASRn",
        "outputId": "6d821e04-be7e-44c6-8f9f-c7d07feb5d8c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Regularized SVM Accuracy: 0.9064856711915535\n",
            "Regularized SVM Precision: 0.8975903614457831\n",
            "Regularized SVM Sensitivity (Recall): 0.9141104294478528\n",
            "Regularized SVM Specificity: 0.8991097922848664\n",
            "Regularized SVM F1 Score: 0.9057750759878419\n"
          ]
        }
      ]
    }
  ]
}